{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning Model Comparison.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "c3821KWLNey6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy.io.wavfile as wf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nxSASpgF7unA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "2fc65ebe-1946-485e-beb0-8c69c99a9d31"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "os.listdir('gdrive/My Drive/Colab')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "StFo8tBm8-4s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataPath = 'gdrive/My Drive/Colab/Data'\n",
        "\n",
        "\"\"\"\n",
        "folders = os.listdir(dataPath)\n",
        "\n",
        "for folder in folders:\n",
        "  files = os.listdir(dataPath + '/' + folder)\n",
        "  print(len(files))\n",
        "  print(files[-1])\n",
        "\"\"\"\n",
        "\n",
        "folderF1 = dataPath + '/' + 'A3F1P3'  \n",
        "folderF5 = dataPath + '/' + 'A3F5P3'\n",
        "filesF1 = os.listdir(folderF1)\n",
        "filesF5 = os.listdir(folderF5)\n",
        "\n",
        "folderA5 = dataPath + '/' + 'A5F3P3'\n",
        "filesA5 = os.listdir(folderA5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WqSDKWm5WE2f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "31147ea5-1b07-45ae-ac25-e968aca5872c"
      },
      "cell_type": "code",
      "source": [
        "filesF1[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A3.490879_F0.139398_P2.076554_H360.426598.wav'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "hVwdMUwTWnbp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fs, dataInt16 = wf.read(folderF1 + '/' + filesF1[0])\n",
        "dataFloat = dataInt16 / (2 ** 15)\n",
        "\n",
        "fs, dataInt16 = wf.read(folderF5 + '/' + filesF5[0])\n",
        "dataFloat = dataInt16 / (2 ** 15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xgGP7PZO-rTA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nsc = 1470\n",
        "nov = nsc/2\n",
        "nff = nsc "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AZQiR1afrToE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Pxx, freqs, bins, _ = plt.specgram(dataFloat, NFFT=nff, Fs=fs, noverlap=nov, \\\n",
        "                                   window=np.hamming(nsc), cmap='viridis')\n",
        "plt.close()\n",
        "img = Pxx[0:224, :]\n",
        "\n",
        "plt.imshow(10*np.log10(img), cmap='viridis')\n",
        "plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LwVFaqAjV_a9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tKdtQNWYAYpa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm, trange"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5AskF2qFT2xr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "67b809a4-827f-45c4-9dd2-2a980e3a21da"
      },
      "cell_type": "code",
      "source": [
        "imgSize = 224\n",
        "imgsF1 = np.zeros([len(filesF1), imgSize, imgSize])\n",
        "\n",
        "for i in trange(len(filesF1)):\n",
        "    fs, dataInt16 = wf.read(folderF1 + '/' + filesF1[i])\n",
        "    dataFloat = dataInt16 / (2 ** 15)\n",
        "    Pxx, _, _, _ = plt.specgram(dataFloat, NFFT=nff, Fs=fs, noverlap=nov, \\\n",
        "                                       window=np.hamming(nsc), cmap='viridis')\n",
        "    plt.close()\n",
        "    imgsF1[i, :, :] = 10 * np.log10(Pxx[0:224, :])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [06:09<00:00,  3.00it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "P_MZtpk3Br_i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "350f1d2f-9470-41f4-ced8-da74c80520b4"
      },
      "cell_type": "code",
      "source": [
        "imgsF5 = np.zeros([len(filesF5), imgSize, imgSize])\n",
        "\n",
        "for i in trange(len(filesF5)):\n",
        "    fs, dataInt16 = wf.read(folderF5 + '/' + filesF5[i])\n",
        "    dataFloat = dataInt16 / (2 ** 15)\n",
        "    Pxx, _, _, _ = plt.specgram(dataFloat, NFFT=nff, Fs=fs, noverlap=nov, \\\n",
        "                                       window=np.hamming(nsc), cmap='viridis')\n",
        "    plt.close()\n",
        "    imgsF5[i, :, :] = 10 * np.log10(Pxx[0:224, :])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [06:18<00:00,  2.91it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "e91QsAurSkIP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainIdxF1 = np.random.choice(len(imgsF1) - 1, int(len(imgsF1) * 0.8), replace=False)\n",
        "testIdxF1 = list(set(range(0, len(imgsF1))) - set(trainIdxF1))\n",
        "\n",
        "trainImgsF1 = imgsF1[trainIdxF1, :, :]\n",
        "testImgsF1 = imgsF1[testIdxF1, :, :]\n",
        "\n",
        "trainIdxF5 = np.random.choice(len(imgsF5) - 1, int(len(imgsF5) * 0.8), replace=False)\n",
        "testIdxF5 = list(set(range(0, len(imgsF5))) - set(trainIdxF5))\n",
        "\n",
        "trainImgsF5 = imgsF5[trainIdxF5, :, :]\n",
        "testImgsF5 = imgsF5[testIdxF5, :, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KtaG5p9lUcyq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainImgs = np.vstack([trainImgsF1, trainImgsF5])\n",
        "testImgs = np.vstack([testImgsF1, testImgsF5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "feQ_AHAcUgHD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainMean = np.mean(trainImgs)\n",
        "trainStd = np.std(trainImgs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wUi9IuXNUpir",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainImgsNorm = (trainImgs - trainMean) / trainStd\n",
        "testImgsNorm = (testImgs - trainMean) / trainStd\n",
        "\n",
        "trainImgsNorm = trainImgsNorm.reshape(list(trainImgsNorm.shape) + [1])\n",
        "testImgsNorm = testImgsNorm.reshape(list(testImgsNorm.shape) + [1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aklxiPz1Ve4n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = np.stack([trainImgsNorm[:, :, :, 0], trainImgsNorm[:, :, :, 0], trainImgsNorm[:, :, :, 0]], axis = -1)\n",
        "X_test = np.stack([testImgsNorm[:, :, :, 0], testImgsNorm[:, :, :, 0], testImgsNorm[:, :, :, 0]], axis = -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sRgIPzT7K_YP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainLabelF1 = np.stack((np.ones( int(len(imgsF1) * 0.8)), np.zeros( int(len(imgsF1) * 0.8))), axis = -1)\n",
        "testLabelF1 = np.stack((np.ones( int(len(imgsF1) * 0.2)), np.zeros( int(len(imgsF1) * 0.2))), axis = -1)\n",
        "\n",
        "trainLabelF5 = np.stack((np.zeros( int(len(imgsF5) * 0.8)), np.ones( int(len(imgsF5) * 0.8))), axis = -1)\n",
        "testLabelF5 = np.stack((np.zeros( int(len(imgsF5) * 0.2)), np.ones( int(len(imgsF5) * 0.2))), axis = -1)\n",
        "\n",
        "Y_train = np.vstack((trainLabelF1, trainLabelF5))\n",
        "Y_test = np.vstack((testLabelF1, testLabelF5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-m4Kq1y7YW0D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6ef15ab7-71fa-4e33-f6e3-364ac49df519"
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "from keras.layers import Input, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
        "from keras.models import Sequential"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "wwsOP0NKGnkh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 14077
        },
        "outputId": "c7eea90d-3721-43e6-faaa-c0a737cee90d"
      },
      "cell_type": "code",
      "source": [
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras import backend as K\n",
        "\n",
        "for i in range(100):\n",
        "\n",
        "    input_tensor = Input(shape=(224, 224, 3))\n",
        "    \n",
        "    modelInceptionV3WoTop = None\n",
        "    modelInceptionV3 = None\n",
        "\n",
        "    modelInceptionV3WoTop = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    # modelInceptionV3WoTop.summary()\n",
        "    # modelInceptionV3 = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=True)\n",
        "    # modelInceptionV3.summary()\n",
        "\n",
        "    modelInceptionV3 = Sequential()\n",
        "\n",
        "    modelInceptionV3.add(modelInceptionV3WoTop)\n",
        "    modelInceptionV3.add(GlobalAveragePooling2D())\n",
        "    modelInceptionV3.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    # modelInceptionV3.summary()\n",
        "\n",
        "    modelInceptionV3.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    modelInceptionV3.fit(X_train, Y_train,\n",
        "              batch_size=4, epochs=6, verbose=1,\n",
        "              validation_data=(X_test, Y_test))\n",
        "    \n",
        "    K.clear_session()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 4s 0us/step\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 80ms/step - loss: 0.2163 - acc: 0.9337 - val_loss: 8.0152 - val_acc: 0.5000\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.2031 - acc: 0.9200 - val_loss: 0.0833 - val_acc: 0.9600\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0499 - acc: 0.9819 - val_loss: 0.0282 - val_acc: 1.0000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0171 - acc: 0.9962 - val_loss: 0.0336 - val_acc: 0.9900\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 9.2493e-04 - acc: 1.0000 - val_loss: 0.0182 - val_acc: 1.0000\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 3.4144e-04 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 126s 79ms/step - loss: 0.2136 - acc: 0.9312 - val_loss: 0.8408 - val_acc: 0.3600\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 107s 67ms/step - loss: 0.1824 - acc: 0.9331 - val_loss: 7.9790 - val_acc: 0.5000\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1120 - acc: 0.9663 - val_loss: 7.9603 - val_acc: 0.5000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1355 - acc: 0.9525 - val_loss: 8.0713 - val_acc: 0.4800\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0811 - acc: 0.9731 - val_loss: 4.7548 - val_acc: 0.5375\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0129 - acc: 0.9969 - val_loss: 7.8733 - val_acc: 0.5050\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 126s 79ms/step - loss: 0.2195 - acc: 0.9256 - val_loss: 0.2237 - val_acc: 0.9775\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1807 - acc: 0.9419 - val_loss: 1.1462 - val_acc: 0.9300\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0512 - acc: 0.9812 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 107s 67ms/step - loss: 0.0685 - acc: 0.9800 - val_loss: 0.4149 - val_acc: 0.7525\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0717 - acc: 0.9744 - val_loss: 0.0033 - val_acc: 1.0000\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 126s 79ms/step - loss: 0.1832 - acc: 0.9350 - val_loss: 0.0028 - val_acc: 1.0000\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1475 - acc: 0.9494 - val_loss: 0.0044 - val_acc: 1.0000\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0916 - acc: 0.9681 - val_loss: 6.8566 - val_acc: 0.5050\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0075 - acc: 0.9987 - val_loss: 2.5293e-04 - val_acc: 1.0000\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 6.1146e-05 - val_acc: 1.0000\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 108s 67ms/step - loss: 5.3829e-04 - acc: 1.0000 - val_loss: 9.9486e-05 - val_acc: 1.0000\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 126s 79ms/step - loss: 0.2200 - acc: 0.9250 - val_loss: 0.0080 - val_acc: 0.9975\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1447 - acc: 0.9438 - val_loss: 0.9035 - val_acc: 0.6950\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1232 - acc: 0.9587 - val_loss: 2.1803 - val_acc: 0.8500\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0062 - acc: 0.9994 - val_loss: 4.3418e-04 - val_acc: 1.0000\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1600 - acc: 0.9456 - val_loss: 0.0036 - val_acc: 1.0000\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0318 - acc: 0.9887 - val_loss: 0.2153 - val_acc: 0.9250\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 79ms/step - loss: 0.1941 - acc: 0.9187 - val_loss: 0.2329 - val_acc: 0.9750\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.2530 - acc: 0.9119 - val_loss: 0.0830 - val_acc: 0.9975\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1066 - acc: 0.9587 - val_loss: 0.0019 - val_acc: 1.0000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0690 - acc: 0.9769 - val_loss: 0.0019 - val_acc: 1.0000\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0053 - acc: 0.9987 - val_loss: 1.6823 - val_acc: 0.7375\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 5.3175e-04 - acc: 1.0000 - val_loss: 1.0777 - val_acc: 0.9025\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 80ms/step - loss: 0.2346 - acc: 0.9225 - val_loss: 0.0170 - val_acc: 1.0000\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 67ms/step - loss: 0.1186 - acc: 0.9600 - val_loss: 0.2374 - val_acc: 0.9350\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 107s 67ms/step - loss: 0.0146 - acc: 0.9975 - val_loss: 7.7303e-04 - val_acc: 1.0000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 5.8128e-04 - acc: 1.0000 - val_loss: 3.7785e-04 - val_acc: 1.0000\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 2.4835e-04 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 1.5388e-04 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 79ms/step - loss: 0.1728 - acc: 0.9450 - val_loss: 0.0833 - val_acc: 0.9575\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1552 - acc: 0.9400 - val_loss: 8.0214 - val_acc: 0.5000\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1537 - acc: 0.9444 - val_loss: 0.0048 - val_acc: 1.0000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1625 - acc: 0.9456 - val_loss: 7.6195 - val_acc: 0.4825\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 107s 67ms/step - loss: 0.0585 - acc: 0.9831 - val_loss: 4.2814 - val_acc: 0.6850\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0438 - acc: 0.9900 - val_loss: 1.9314 - val_acc: 0.8250\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 79ms/step - loss: 0.1926 - acc: 0.9269 - val_loss: 6.9042 - val_acc: 0.5050\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1393 - acc: 0.9537 - val_loss: 0.0107 - val_acc: 1.0000\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 9.6009e-04 - acc: 1.0000 - val_loss: 1.9581e-04 - val_acc: 1.0000\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1399 - acc: 0.9556 - val_loss: 7.7438 - val_acc: 0.5000\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0211 - acc: 0.9944 - val_loss: 1.4963e-04 - val_acc: 1.0000\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 128s 80ms/step - loss: 0.2102 - acc: 0.9269 - val_loss: 0.0271 - val_acc: 1.0000\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1172 - acc: 0.9525 - val_loss: 0.0076 - val_acc: 1.0000\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0596 - acc: 0.9819 - val_loss: 0.0046 - val_acc: 1.0000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 4.1474e-04 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 2.1430e-04 - acc: 1.0000 - val_loss: 2.3858e-04 - val_acc: 1.0000\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 79ms/step - loss: 0.2352 - acc: 0.9237 - val_loss: 0.0566 - val_acc: 1.0000\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 107s 67ms/step - loss: 0.1270 - acc: 0.9550 - val_loss: 8.0087 - val_acc: 0.5000\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0808 - acc: 0.9775 - val_loss: 0.0034 - val_acc: 1.0000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 3.5329e-04 - acc: 1.0000 - val_loss: 5.6090e-04 - val_acc: 1.0000\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 2.6549e-04 - acc: 1.0000 - val_loss: 6.3731e-04 - val_acc: 1.0000\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 79ms/step - loss: 0.2347 - acc: 0.9156 - val_loss: 4.5239 - val_acc: 0.6900\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 67ms/step - loss: 0.0860 - acc: 0.9700 - val_loss: 0.1806 - val_acc: 0.9950\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 1.0000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 107s 67ms/step - loss: 3.0260e-04 - acc: 1.0000 - val_loss: 0.0122 - val_acc: 0.9950\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 67ms/step - loss: 1.8832e-04 - acc: 1.0000 - val_loss: 0.2075 - val_acc: 0.9375\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 6.8277e-05 - acc: 1.0000 - val_loss: 0.0410 - val_acc: 0.9850\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 79ms/step - loss: 0.1984 - acc: 0.9356 - val_loss: 8.0243 - val_acc: 0.5000\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0485 - acc: 0.9844 - val_loss: 0.0012 - val_acc: 1.0000\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 6.4664e-04 - acc: 1.0000 - val_loss: 5.6375e-05 - val_acc: 1.0000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 9.5270e-05 - acc: 1.0000 - val_loss: 2.8952e-05 - val_acc: 1.0000\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 1.0111e-04 - acc: 1.0000 - val_loss: 1.9202e-05 - val_acc: 1.0000\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 108s 67ms/step - loss: 4.0822e-05 - acc: 1.0000 - val_loss: 1.3377e-05 - val_acc: 1.0000\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 79ms/step - loss: 0.1863 - acc: 0.9337 - val_loss: 0.2898 - val_acc: 0.9075\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1809 - acc: 0.9281 - val_loss: 3.0768 - val_acc: 0.7525\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1345 - acc: 0.9406 - val_loss: 0.8428 - val_acc: 0.7575\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1962 - acc: 0.9156 - val_loss: 1.7660 - val_acc: 0.8675\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 67ms/step - loss: 0.1274 - acc: 0.9500 - val_loss: 0.0564 - val_acc: 0.9825\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 1.7664e-04 - val_acc: 1.0000\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 79ms/step - loss: 0.2066 - acc: 0.9287 - val_loss: 0.0877 - val_acc: 0.9725\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 108s 67ms/step - loss: 0.1429 - acc: 0.9475 - val_loss: 0.0104 - val_acc: 1.0000\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1088 - acc: 0.9637 - val_loss: 0.0034 - val_acc: 1.0000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 4.9401e-04 - val_acc: 1.0000\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 8.3364e-04 - acc: 1.0000 - val_loss: 2.0449e-04 - val_acc: 1.0000\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 3.4828e-04 - acc: 1.0000 - val_loss: 8.1008e-05 - val_acc: 1.0000\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 79ms/step - loss: 0.2099 - acc: 0.9219 - val_loss: 1.0960e-07 - val_acc: 1.0000\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1117 - acc: 0.9631 - val_loss: 0.0193 - val_acc: 1.0000\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1594 - acc: 0.9456 - val_loss: 0.0618 - val_acc: 1.0000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 108s 67ms/step - loss: 0.0915 - acc: 0.9663 - val_loss: 0.0044 - val_acc: 1.0000\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0257 - acc: 0.9912 - val_loss: 5.5766 - val_acc: 0.6400\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0238 - acc: 0.9944 - val_loss: 0.0047 - val_acc: 1.0000\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 79ms/step - loss: 0.2143 - acc: 0.9287 - val_loss: 0.2965 - val_acc: 0.8375\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1557 - acc: 0.9375 - val_loss: 0.0031 - val_acc: 1.0000\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1356 - acc: 0.9456 - val_loss: 5.8238 - val_acc: 0.4825\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0972 - acc: 0.9625 - val_loss: 0.4560 - val_acc: 0.7375\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0379 - acc: 0.9831 - val_loss: 1.7843e-04 - val_acc: 1.0000\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 108s 67ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 5.4403e-05 - val_acc: 1.0000\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 79ms/step - loss: 0.2347 - acc: 0.9163 - val_loss: 0.3299 - val_acc: 0.8825\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1076 - acc: 0.9500 - val_loss: 0.0125 - val_acc: 1.0000\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1536 - acc: 0.9375 - val_loss: 0.1054 - val_acc: 0.9975\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0302 - acc: 0.9838 - val_loss: 0.1230 - val_acc: 1.0000\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0107 - acc: 0.9969 - val_loss: 0.0351 - val_acc: 1.0000\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 67ms/step - loss: 5.9834e-04 - acc: 1.0000 - val_loss: 0.0195 - val_acc: 1.0000\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 129s 80ms/step - loss: 0.2816 - acc: 0.9062 - val_loss: 9.7841e-04 - val_acc: 1.0000\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1179 - acc: 0.9581 - val_loss: 0.2471 - val_acc: 0.9300\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 67ms/step - loss: 0.1001 - acc: 0.9706 - val_loss: 7.8210 - val_acc: 0.5000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0607 - acc: 0.9819 - val_loss: 0.0043 - val_acc: 1.0000\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 67ms/step - loss: 9.0678e-04 - acc: 1.0000 - val_loss: 2.4323e-04 - val_acc: 1.0000\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 67ms/step - loss: 0.0801 - acc: 0.9712 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 79ms/step - loss: 0.2356 - acc: 0.9244 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1486 - acc: 0.9488 - val_loss: 0.6530 - val_acc: 0.8025\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 108s 67ms/step - loss: 0.0122 - acc: 0.9975 - val_loss: 0.0059 - val_acc: 1.0000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 3.5887e-04 - acc: 1.0000 - val_loss: 6.7835e-04 - val_acc: 1.0000\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 1.6285e-04 - acc: 1.0000 - val_loss: 6.7078e-05 - val_acc: 1.0000\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 8.8407e-05 - acc: 1.0000 - val_loss: 1.9713e-04 - val_acc: 1.0000\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 80ms/step - loss: 0.2009 - acc: 0.9344 - val_loss: 9.8602e-04 - val_acc: 1.0000\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 67ms/step - loss: 0.1200 - acc: 0.9500 - val_loss: 0.0030 - val_acc: 1.0000\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 5.2495e-04 - val_acc: 1.0000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 5.2198e-04 - acc: 1.0000 - val_loss: 2.0401e-04 - val_acc: 1.0000\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 108s 67ms/step - loss: 2.0666e-04 - acc: 1.0000 - val_loss: 1.6448e-04 - val_acc: 1.0000\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 1.4264e-04 - acc: 1.0000 - val_loss: 1.5516e-04 - val_acc: 1.0000\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 79ms/step - loss: 0.2372 - acc: 0.9356 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1229 - acc: 0.9625 - val_loss: 7.4907 - val_acc: 0.5275\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 2.3808e-04 - val_acc: 1.0000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 3.1836e-04 - acc: 1.0000 - val_loss: 8.6295e-05 - val_acc: 1.0000\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 107s 67ms/step - loss: 1.1683e-04 - acc: 1.0000 - val_loss: 3.9932e-05 - val_acc: 1.0000\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 1.3345e-04 - acc: 1.0000 - val_loss: 5.2985e-05 - val_acc: 1.0000\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 128s 80ms/step - loss: 0.1851 - acc: 0.9312 - val_loss: 0.0086 - val_acc: 1.0000\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 107s 67ms/step - loss: 0.1615 - acc: 0.9419 - val_loss: 0.9388 - val_acc: 0.5050\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0619 - acc: 0.9756 - val_loss: 0.0730 - val_acc: 1.0000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0041 - acc: 0.9987 - val_loss: 0.4761 - val_acc: 0.5025\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 5.8289e-04 - acc: 1.0000 - val_loss: 0.2315 - val_acc: 0.9950\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 107s 67ms/step - loss: 3.5270e-04 - acc: 1.0000 - val_loss: 3.0110 - val_acc: 0.6000\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 79ms/step - loss: 0.2060 - acc: 0.9244 - val_loss: 0.0580 - val_acc: 0.9950\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1773 - acc: 0.9325 - val_loss: 0.2668 - val_acc: 0.9450\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 108s 67ms/step - loss: 0.0338 - acc: 0.9912 - val_loss: 0.2289 - val_acc: 0.9125\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 67ms/step - loss: 0.0066 - acc: 0.9994 - val_loss: 0.0062 - val_acc: 1.0000\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1563 - acc: 0.9450 - val_loss: 0.0538 - val_acc: 1.0000\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0357 - acc: 0.9869 - val_loss: 2.8107 - val_acc: 0.7750\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 79ms/step - loss: 0.2107 - acc: 0.9337 - val_loss: 0.3659 - val_acc: 0.8475\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1804 - acc: 0.9325 - val_loss: 0.0578 - val_acc: 1.0000\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0226 - acc: 0.9950 - val_loss: 7.7487e-04 - val_acc: 1.0000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0189 - acc: 0.9937 - val_loss: 6.5000 - val_acc: 0.5000\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 108s 67ms/step - loss: 0.0977 - acc: 0.9719 - val_loss: 0.0065 - val_acc: 0.9975\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0328 - acc: 0.9900 - val_loss: 0.0013 - val_acc: 1.0000\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 79ms/step - loss: 0.1821 - acc: 0.9413 - val_loss: 8.8043e-04 - val_acc: 1.0000\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0842 - acc: 0.9719 - val_loss: 5.4387 - val_acc: 0.6525\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 67ms/step - loss: 0.0937 - acc: 0.9644 - val_loss: 7.0730e-04 - val_acc: 1.0000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 5.6487e-05 - val_acc: 1.0000\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0499 - acc: 0.9869 - val_loss: 0.0028 - val_acc: 1.0000\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 107s 67ms/step - loss: 0.0689 - acc: 0.9819 - val_loss: 0.0018 - val_acc: 1.0000\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 80ms/step - loss: 0.2173 - acc: 0.9087 - val_loss: 0.1146 - val_acc: 1.0000\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0651 - acc: 0.9725 - val_loss: 0.0037 - val_acc: 1.0000\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 4.3052e-04 - val_acc: 1.0000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 107s 67ms/step - loss: 5.6062e-04 - acc: 1.0000 - val_loss: 6.0992e-04 - val_acc: 1.0000\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 107s 67ms/step - loss: 1.6782e-04 - acc: 1.0000 - val_loss: 1.6982e-04 - val_acc: 1.0000\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 107s 67ms/step - loss: 5.6279e-05 - acc: 1.0000 - val_loss: 8.3948e-05 - val_acc: 1.0000\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 79ms/step - loss: 0.2191 - acc: 0.9250 - val_loss: 5.1524 - val_acc: 0.5025\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 108s 67ms/step - loss: 0.1342 - acc: 0.9494 - val_loss: 1.7720 - val_acc: 0.6375\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 67ms/step - loss: 0.0383 - acc: 0.9869 - val_loss: 0.0243 - val_acc: 0.9950\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 67ms/step - loss: 0.0707 - acc: 0.9800 - val_loss: 0.0454 - val_acc: 1.0000\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 6.3104e-04 - val_acc: 1.0000\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 5.3846e-04 - acc: 1.0000 - val_loss: 1.7353e-04 - val_acc: 1.0000\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 126s 79ms/step - loss: 0.1896 - acc: 0.9456 - val_loss: 0.2673 - val_acc: 0.8800\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1013 - acc: 0.9644 - val_loss: 0.0047 - val_acc: 1.0000\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0047 - acc: 0.9994 - val_loss: 0.0054 - val_acc: 1.0000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 108s 67ms/step - loss: 4.9626e-04 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 1.6678e-04 - acc: 1.0000 - val_loss: 0.0055 - val_acc: 1.0000\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 1.1152e-04 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 79ms/step - loss: 0.1774 - acc: 0.9475 - val_loss: 0.0032 - val_acc: 1.0000\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1501 - acc: 0.9337 - val_loss: 0.0120 - val_acc: 0.9975\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1040 - acc: 0.9637 - val_loss: 4.3666 - val_acc: 0.6350\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0470 - acc: 0.9825 - val_loss: 0.0747 - val_acc: 1.0000\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0582 - acc: 0.9844 - val_loss: 6.0823 - val_acc: 0.5900\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 108s 67ms/step - loss: 0.0154 - acc: 0.9962 - val_loss: 0.5179 - val_acc: 0.8775\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 126s 79ms/step - loss: 0.2341 - acc: 0.9281 - val_loss: 4.0405 - val_acc: 0.5000\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1130 - acc: 0.9594 - val_loss: 0.3252 - val_acc: 0.8725\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1416 - acc: 0.9531 - val_loss: 4.1948 - val_acc: 0.5025\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0856 - acc: 0.9650 - val_loss: 0.0015 - val_acc: 1.0000\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0027 - acc: 0.9987 - val_loss: 0.0010 - val_acc: 1.0000\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 79ms/step - loss: 0.2164 - acc: 0.9262 - val_loss: 0.0328 - val_acc: 1.0000\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 108s 67ms/step - loss: 0.1585 - acc: 0.9488 - val_loss: 3.9618e-04 - val_acc: 1.0000\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0876 - acc: 0.9731 - val_loss: 0.0143 - val_acc: 0.9975\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1108 - acc: 0.9613 - val_loss: 5.5251 - val_acc: 0.5500\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0684 - acc: 0.9775 - val_loss: 3.4346 - val_acc: 0.5125\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0164 - acc: 0.9962 - val_loss: 0.0143 - val_acc: 0.9950\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 79ms/step - loss: 0.1959 - acc: 0.9362 - val_loss: 0.0095 - val_acc: 1.0000\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1658 - acc: 0.9400 - val_loss: 6.7232 - val_acc: 0.5450\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1157 - acc: 0.9556 - val_loss: 1.3531 - val_acc: 0.9100\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 108s 67ms/step - loss: 0.0811 - acc: 0.9762 - val_loss: 6.7135 - val_acc: 0.5175\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0435 - acc: 0.9862 - val_loss: 0.3226 - val_acc: 0.9175\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.7941 - val_acc: 0.9000\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 79ms/step - loss: 0.2032 - acc: 0.9187 - val_loss: 0.4915 - val_acc: 0.6550\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 107s 67ms/step - loss: 0.1755 - acc: 0.9087 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 67ms/step - loss: 0.1382 - acc: 0.9388 - val_loss: 0.0066 - val_acc: 1.0000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1053 - acc: 0.9600 - val_loss: 0.0621 - val_acc: 1.0000\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 67ms/step - loss: 0.0218 - acc: 0.9937 - val_loss: 0.5339 - val_acc: 0.9600\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 107s 67ms/step - loss: 5.3583e-04 - acc: 1.0000 - val_loss: 0.4834 - val_acc: 0.9600\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 79ms/step - loss: 0.2180 - acc: 0.9312 - val_loss: 0.0962 - val_acc: 0.9975\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 67ms/step - loss: 0.0397 - acc: 0.9856 - val_loss: 0.0994 - val_acc: 1.0000\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 8.5972e-04 - acc: 1.0000 - val_loss: 1.4564e-04 - val_acc: 1.0000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 2.8683e-04 - acc: 1.0000 - val_loss: 6.2179e-05 - val_acc: 1.0000\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 1.8867e-04 - acc: 1.0000 - val_loss: 9.6994e-05 - val_acc: 1.0000\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 1.0059e-04 - acc: 1.0000 - val_loss: 4.5621e-05 - val_acc: 1.0000\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 80ms/step - loss: 0.1906 - acc: 0.9375 - val_loss: 7.9348 - val_acc: 0.5000\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 67ms/step - loss: 0.1897 - acc: 0.9287 - val_loss: 0.6303 - val_acc: 0.9500\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0709 - acc: 0.9800 - val_loss: 0.0013 - val_acc: 1.0000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 4.6600e-04 - val_acc: 1.0000\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 2.7672e-04 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 79ms/step - loss: 0.2817 - acc: 0.9306 - val_loss: 7.9549 - val_acc: 0.5000\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0982 - acc: 0.9619 - val_loss: 0.0697 - val_acc: 1.0000\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 107s 67ms/step - loss: 0.1260 - acc: 0.9525 - val_loss: 6.9971 - val_acc: 0.5225\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 67ms/step - loss: 0.0527 - acc: 0.9856 - val_loss: 7.9056 - val_acc: 0.5025\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.4682 - val_acc: 0.9450\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 7.9868e-04 - acc: 1.0000 - val_loss: 1.1637e-04 - val_acc: 1.0000\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 79ms/step - loss: 0.2021 - acc: 0.9356 - val_loss: 0.0041 - val_acc: 1.0000\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1692 - acc: 0.9325 - val_loss: 2.4706 - val_acc: 0.5050\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1231 - acc: 0.9456 - val_loss: 1.3809 - val_acc: 0.5000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1706 - acc: 0.9419 - val_loss: 0.0530 - val_acc: 1.0000\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 108s 67ms/step - loss: 0.1365 - acc: 0.9444 - val_loss: 0.0346 - val_acc: 1.0000\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1065 - acc: 0.9606 - val_loss: 0.0869 - val_acc: 1.0000\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 79ms/step - loss: 0.2444 - acc: 0.9225 - val_loss: 0.0274 - val_acc: 0.9975\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0436 - acc: 0.9825 - val_loss: 0.0012 - val_acc: 1.0000\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 8.8576e-04 - acc: 1.0000 - val_loss: 2.8903e-04 - val_acc: 1.0000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 2.4898e-04 - acc: 1.0000 - val_loss: 2.3717e-04 - val_acc: 1.0000\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 1.3196e-04 - acc: 1.0000 - val_loss: 1.7915e-04 - val_acc: 1.0000\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 67ms/step - loss: 7.8313e-05 - acc: 1.0000 - val_loss: 1.4684e-04 - val_acc: 1.0000\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 128s 80ms/step - loss: 0.2853 - acc: 0.9069 - val_loss: 7.9860e-04 - val_acc: 1.0000\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1587 - acc: 0.9350 - val_loss: 0.3951 - val_acc: 0.8325\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0749 - acc: 0.9781 - val_loss: 0.2010 - val_acc: 0.9425\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0319 - acc: 0.9875 - val_loss: 0.8840 - val_acc: 0.8075\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0131 - acc: 0.9950 - val_loss: 9.7905e-04 - val_acc: 1.0000\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 5.9179e-04 - acc: 1.0000 - val_loss: 8.0569e-04 - val_acc: 1.0000\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 79ms/step - loss: 0.1834 - acc: 0.9362 - val_loss: 5.0800 - val_acc: 0.5775\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 108s 67ms/step - loss: 0.1617 - acc: 0.9431 - val_loss: 0.3132 - val_acc: 0.9125\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0524 - acc: 0.9831 - val_loss: 0.0276 - val_acc: 1.0000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0459 - val_acc: 0.9975\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 107s 67ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0061 - val_acc: 1.0000\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 4.4522e-04 - acc: 1.0000 - val_loss: 0.0081 - val_acc: 1.0000\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 79ms/step - loss: 0.1738 - acc: 0.9456 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 67ms/step - loss: 0.1398 - acc: 0.9594 - val_loss: 0.0653 - val_acc: 0.9900\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 3.4875e-04 - val_acc: 1.0000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 108s 67ms/step - loss: 6.5971e-04 - acc: 1.0000 - val_loss: 2.1603e-04 - val_acc: 1.0000\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 107s 67ms/step - loss: 3.8812e-04 - acc: 1.0000 - val_loss: 9.9835e-05 - val_acc: 1.0000\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 67ms/step - loss: 1.7329e-04 - acc: 1.0000 - val_loss: 7.4695e-05 - val_acc: 1.0000\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 79ms/step - loss: 0.2292 - acc: 0.9156 - val_loss: 0.0019 - val_acc: 1.0000\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1658 - acc: 0.9350 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0622 - acc: 0.9781 - val_loss: 0.0053 - val_acc: 1.0000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 5.5809e-04 - acc: 1.0000 - val_loss: 5.1823e-04 - val_acc: 1.0000\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 108s 67ms/step - loss: 3.3611e-04 - acc: 1.0000 - val_loss: 3.5283e-04 - val_acc: 1.0000\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 79ms/step - loss: 0.1853 - acc: 0.9262 - val_loss: 0.1495 - val_acc: 0.9250\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1262 - acc: 0.9513 - val_loss: 0.5368 - val_acc: 0.9425\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 67ms/step - loss: 0.0593 - acc: 0.9850 - val_loss: 5.4887 - val_acc: 0.5725\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0022 - acc: 0.9994 - val_loss: 0.0034 - val_acc: 1.0000\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 67ms/step - loss: 4.4879e-04 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 1.5318e-04 - acc: 1.0000 - val_loss: 5.7961e-04 - val_acc: 1.0000\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 79ms/step - loss: 0.2214 - acc: 0.9269 - val_loss: 2.9387 - val_acc: 0.5000\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 108s 67ms/step - loss: 0.0653 - acc: 0.9788 - val_loss: 2.9883 - val_acc: 0.7900\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0884 - acc: 0.9681 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1135 - acc: 0.9631 - val_loss: 5.6692 - val_acc: 0.6050\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 67ms/step - loss: 0.1440 - acc: 0.9413 - val_loss: 0.0298 - val_acc: 0.9850\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0131 - acc: 0.9969 - val_loss: 6.3555e-04 - val_acc: 1.0000\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 80ms/step - loss: 0.1559 - acc: 0.9375 - val_loss: 0.0080 - val_acc: 0.9975\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1777 - acc: 0.9362 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0908 - acc: 0.9694 - val_loss: 0.5373 - val_acc: 0.7500\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 107s 67ms/step - loss: 0.0453 - acc: 0.9800 - val_loss: 0.0431 - val_acc: 1.0000\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1101 - acc: 0.9712 - val_loss: 0.3438 - val_acc: 0.8725\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0774 - acc: 0.9788 - val_loss: 0.1275 - val_acc: 0.9775\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 80ms/step - loss: 0.2585 - acc: 0.9350 - val_loss: 0.0701 - val_acc: 0.9900\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 108s 68ms/step - loss: 0.0768 - acc: 0.9756 - val_loss: 0.0037 - val_acc: 1.0000\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0250 - acc: 0.9919 - val_loss: 0.0028 - val_acc: 1.0000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 67ms/step - loss: 0.1234 - acc: 0.9619 - val_loss: 0.0834 - val_acc: 0.9875\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0170 - acc: 0.9987 - val_loss: 0.0039 - val_acc: 1.0000\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 108s 67ms/step - loss: 0.0054 - acc: 0.9987 - val_loss: 0.0063 - val_acc: 1.0000\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 79ms/step - loss: 0.2223 - acc: 0.9406 - val_loss: 6.3375 - val_acc: 0.5000\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1183 - acc: 0.9531 - val_loss: 8.0197 - val_acc: 0.5000\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0913 - acc: 0.9675 - val_loss: 0.0340 - val_acc: 1.0000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0285 - acc: 0.9912 - val_loss: 1.0439 - val_acc: 0.7650\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1271 - acc: 0.9600 - val_loss: 8.0389 - val_acc: 0.5000\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0125 - acc: 0.9969 - val_loss: 0.0081 - val_acc: 0.9975\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 128s 80ms/step - loss: 0.2028 - acc: 0.9406 - val_loss: 0.4662 - val_acc: 0.5450\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1349 - acc: 0.9450 - val_loss: 0.5568 - val_acc: 0.7750\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1113 - acc: 0.9519 - val_loss: 8.0189 - val_acc: 0.5000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0194 - acc: 0.9944 - val_loss: 3.5249 - val_acc: 0.7450\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 4.7669e-04 - acc: 1.0000 - val_loss: 1.9429 - val_acc: 0.8575\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 2.1293e-04 - acc: 1.0000 - val_loss: 2.1366 - val_acc: 0.8450\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 79ms/step - loss: 0.2218 - acc: 0.9225 - val_loss: 0.4840 - val_acc: 0.6450\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1587 - acc: 0.9469 - val_loss: 0.0016 - val_acc: 1.0000\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 108s 67ms/step - loss: 0.1368 - acc: 0.9550 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 67ms/step - loss: 0.0470 - acc: 0.9844 - val_loss: 0.0010 - val_acc: 1.0000\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 9.7171e-04 - acc: 1.0000 - val_loss: 6.3091e-04 - val_acc: 1.0000\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 3.4798e-04 - acc: 1.0000 - val_loss: 3.3100e-04 - val_acc: 1.0000\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 79ms/step - loss: 0.2419 - acc: 0.9394 - val_loss: 0.0555 - val_acc: 0.9750\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 67ms/step - loss: 0.0538 - acc: 0.9838 - val_loss: 0.0012 - val_acc: 1.0000\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 67ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 2.2770e-04 - acc: 1.0000 - val_loss: 3.3449e-04 - val_acc: 1.0000\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 108s 67ms/step - loss: 1.2044e-04 - acc: 1.0000 - val_loss: 8.4113e-04 - val_acc: 1.0000\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 107s 67ms/step - loss: 8.4146e-05 - acc: 1.0000 - val_loss: 4.0112e-04 - val_acc: 1.0000\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 79ms/step - loss: 0.2064 - acc: 0.9281 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 107s 67ms/step - loss: 0.1588 - acc: 0.9369 - val_loss: 0.1025 - val_acc: 0.9725\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0166 - acc: 0.9937 - val_loss: 0.0030 - val_acc: 1.0000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1296 - acc: 0.9625 - val_loss: 0.3614 - val_acc: 0.7325\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 67ms/step - loss: 0.0548 - acc: 0.9831 - val_loss: 0.2517 - val_acc: 0.9450\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0280 - val_acc: 1.0000\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 129s 81ms/step - loss: 0.2208 - acc: 0.9200 - val_loss: 0.5106 - val_acc: 0.9625\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1629 - acc: 0.9306 - val_loss: 0.0022 - val_acc: 1.0000\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1032 - acc: 0.9587 - val_loss: 0.0400 - val_acc: 1.0000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0055 - acc: 0.9994 - val_loss: 0.0122 - val_acc: 1.0000\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 1.6842e-04 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 1.0122e-04 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 1.0000\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 80ms/step - loss: 0.2325 - acc: 0.9187 - val_loss: 0.4067 - val_acc: 0.6925\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1792 - acc: 0.9388 - val_loss: 0.0119 - val_acc: 1.0000\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 108s 67ms/step - loss: 0.0054 - acc: 0.9994 - val_loss: 5.0023e-04 - val_acc: 1.0000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 7.5739e-04 - acc: 1.0000 - val_loss: 2.4208e-04 - val_acc: 1.0000\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 2.9191e-04 - acc: 1.0000 - val_loss: 1.4418e-04 - val_acc: 1.0000\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 67ms/step - loss: 1.7619e-04 - acc: 1.0000 - val_loss: 7.1474e-05 - val_acc: 1.0000\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 79ms/step - loss: 0.2300 - acc: 0.9294 - val_loss: 2.3716 - val_acc: 0.8425\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.2212 - acc: 0.9213 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1053 - acc: 0.9619 - val_loss: 0.0017 - val_acc: 1.0000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0355 - acc: 0.9906 - val_loss: 0.0411 - val_acc: 1.0000\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 108s 67ms/step - loss: 0.0562 - acc: 0.9800 - val_loss: 0.1723 - val_acc: 0.9800\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0032 - acc: 0.9994 - val_loss: 5.2327e-04 - val_acc: 1.0000\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 79ms/step - loss: 0.1814 - acc: 0.9419 - val_loss: 0.2118 - val_acc: 0.9425\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1170 - acc: 0.9481 - val_loss: 0.6037 - val_acc: 0.5000\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1239 - acc: 0.9569 - val_loss: 2.2639 - val_acc: 0.4925\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0432 - acc: 0.9875 - val_loss: 0.3509 - val_acc: 0.9375\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0619 - acc: 0.9838 - val_loss: 0.0185 - val_acc: 0.9950\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 107s 67ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 79ms/step - loss: 0.2656 - acc: 0.9319 - val_loss: 0.8496 - val_acc: 0.5000\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1248 - acc: 0.9550 - val_loss: 0.0243 - val_acc: 1.0000\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0119 - acc: 0.9969 - val_loss: 0.0660 - val_acc: 0.9900\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 107s 67ms/step - loss: 0.0059 - acc: 0.9987 - val_loss: 0.1888 - val_acc: 0.8975\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0112 - val_acc: 1.0000\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 2.7091e-04 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 1.0000\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 79ms/step - loss: 0.1744 - acc: 0.9488 - val_loss: 2.8584 - val_acc: 0.5200\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 108s 67ms/step - loss: 0.1313 - acc: 0.9537 - val_loss: 4.1858e-04 - val_acc: 1.0000\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0588 - acc: 0.9825 - val_loss: 0.0308 - val_acc: 1.0000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 2.8478e-04 - acc: 1.0000 - val_loss: 7.6483e-04 - val_acc: 1.0000\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 106s 67ms/step - loss: 2.7469e-04 - acc: 1.0000 - val_loss: 0.0450 - val_acc: 0.9925\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 80ms/step - loss: 0.2112 - acc: 0.9262 - val_loss: 0.7401 - val_acc: 0.6450\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1095 - acc: 0.9637 - val_loss: 4.1466 - val_acc: 0.6525\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0614 - acc: 0.9781 - val_loss: 0.0034 - val_acc: 1.0000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 108s 67ms/step - loss: 0.0147 - acc: 0.9969 - val_loss: 0.0012 - val_acc: 1.0000\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 107s 67ms/step - loss: 4.3334e-04 - acc: 1.0000 - val_loss: 0.4213 - val_acc: 0.9525\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 127s 79ms/step - loss: 0.2440 - acc: 0.9269 - val_loss: 0.1019 - val_acc: 1.0000\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1022 - acc: 0.9619 - val_loss: 0.0170 - val_acc: 1.0000\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1268 - acc: 0.9563 - val_loss: 0.0071 - val_acc: 1.0000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0408 - acc: 0.9894 - val_loss: 2.8677 - val_acc: 0.7925\n",
            "Epoch 5/6\n",
            " 448/1600 [=======>......................] - ETA: 1:11 - loss: 0.0089 - acc: 0.9978"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "I184FR1dvkb8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG19\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "for i in range(100):\n",
        "    \n",
        "    input_tensor = Input(shape=(224, 224, 3))\n",
        "    \n",
        "    modelVGG19WoTop = None\n",
        "    modelVGG19 = None\n",
        "\n",
        "    modelVGG19WoTop = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "\n",
        "    modelVGG19 = Sequential()\n",
        "\n",
        "    modelVGG19.add(modelVGG19WoTop)\n",
        "    modelVGG19.add(Flatten())\n",
        "    modelVGG19.add(Dense(4096, activation='relu'))\n",
        "    modelVGG19.add(Dropout(0.5))\n",
        "    modelVGG19.add(Dense(4096, activation='relu'))\n",
        "    modelVGG19.add(Dropout(0.5))\n",
        "    \n",
        "#     modelVGG19.add(Dense(128, activation='relu'))\n",
        "#     modelVGG19.add(Dropout(0.5))\n",
        "#     modelVGG19.add(Dense(128, activation='relu'))\n",
        "#     modelVGG19.add(Dropout(0.5))\n",
        "    \n",
        "    modelVGG19.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    modelVGG19.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    modelVGG19.fit(X_train, Y_train,\n",
        "              batch_size=2, epochs=8, verbose=1,\n",
        "              validation_data=(X_test, Y_test))\n",
        "    \n",
        "    K.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qOIMr0c6G3QD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UiWy-nF4RAFM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG16\n",
        "\n",
        "input_tensor = Input(shape=(224, 224, 3))\n",
        "\n",
        "modelVGG16WoTop = None\n",
        "modelVGG16 = None\n",
        "\n",
        "modelVGG16WoTop = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "\n",
        "modelVGG16 = Sequential()\n",
        "\n",
        "modelVGG16.add(modelVGG16WoTop)\n",
        "modelVGG16.add(Flatten())\n",
        "modelVGG16.add(Dense(100, activation='relu'))\n",
        "modelVGG16.add(Dropout(0.5))\n",
        "modelVGG16.add(Dense(100, activation='relu'))\n",
        "modelVGG16.add(Dropout(0.5))\n",
        "\n",
        "modelVGG16.add(Dense(2, activation='softmax'))\n",
        "\n",
        "modelVGG16.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "modelVGG16.fit(X_train, Y_train,\n",
        "          batch_size=2, epochs=2, verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VEDNxMjPT34S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "\n",
        "modelResNet50WoTop = None\n",
        "modelResNet50 = None\n",
        "\n",
        "input_tensor = Input(shape=(224, 224, 3))\n",
        "modelResNet50WoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "\n",
        "modelResNet50 = Sequential()\n",
        "\n",
        "modelResNet50.add(modelResNet50WoTop)\n",
        "modelResNet50.add(Flatten())\n",
        "modelResNet50.add(Dense(2, activation='softmax'))\n",
        "\n",
        "modelResNet50.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "modelResNet50.fit(X_train, Y_train,\n",
        "          batch_size=4, epochs=8, verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IPTFOJh3DTgq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import datetime\n",
        "\n",
        "now = datetime.datetime.now()\n",
        "modelResNet50.save('gdrive/My Drive/Colab/Model/ResNet50 {}.h5'.format(now.strftime('%m-%d %H:%M:%S')))\n",
        "# modelResNet50_ = load_model('gdrive/My Drive/Colab/Model/ResNet50.h5')\n",
        "\n",
        "# Y_pred = modelResNet50_.predict(X_test)\n",
        "# print(confusion_matrix(np.argmax(Y_pred, axis = 1), np.argmax(Y_test, axis = 1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FDhXm3brHs_I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "TgKGs_zL0nwC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# for i in range(1000, 1010):\n",
        "#     plt.figure()\n",
        "#     plt.imshow(X_train[i, :, :, 0]);\n",
        "#     plt.plot()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}