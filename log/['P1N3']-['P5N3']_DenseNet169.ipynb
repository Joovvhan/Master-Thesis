{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning Clean Up.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joovvhan/Master-Thesis/blob/master/log/['P1N3']-['P5N3']_DenseNet169.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "c3821KWLNey6",
        "colab_type": "code",
        "outputId": "c6b14a34-70ff-4d53-989f-7d3b20e90178",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Import necessary modules\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy.io.wavfile as wf\n",
        "import time\n",
        "import glob\n",
        "import datetime\n",
        "\n",
        "from tqdm import trange\n",
        "\n",
        "# Import Keras modules\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.layers import Input, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
        "from keras.models import Sequential\n",
        "from keras import backend as K\n",
        "from keras.models import load_model\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "nxSASpgF7unA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Mount google drive\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "# os.listdir('gdrive/My Drive/Colab')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rw9NU8Xjwcz2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set data directories\n",
        "\n",
        "dataPath = '''D:\\\\0_Joowhan's Paper\\\\Synthesized\\\\Total\\\\Impulse'''\n",
        "modelPath = '''D:\\\\0_Joowhan's Paper\\\\Synthesized\\\\Total\\\\Model'''\n",
        "\n",
        "\n",
        "# Changed variable names to normal and fault\n",
        "# Changed variable names from folder to path\n",
        "# Need to consider multiple folders\n",
        "# Need to add files to be tested\n",
        "\n",
        "folderNormal = ['P1N3']\n",
        "# folderNormal = list()\n",
        "\n",
        "# for x in range(1, 6):\n",
        "#     for y in range(1, 6):\n",
        "#         for z in range(1, 6):\n",
        "#             if (x <= 2 and y <= 2 and z <= 2):\n",
        "#                 folderNormal.append('A{}F{}P{}'.format(x, y, z))\n",
        "\n",
        "# folderFault = list()\n",
        "\n",
        "folderFault = ['P5N3']\n",
        "\n",
        "# for x in range(1, 6):\n",
        "#     for y in range(1, 6):\n",
        "#         for z in range(1, 6):\n",
        "#             if (x == 5 or y == 5 or z == 5):\n",
        "#                 folderFault.append('A{}F{}P{}'.format(x, y, z))\n",
        "\n",
        "\n",
        "pathNormal = list()\n",
        "pathFault = list()\n",
        "\n",
        "for i in range(len(folderNormal)):\n",
        "    pathNormal.append(dataPath + '/' + folderNormal[i])\n",
        "    \n",
        "for i in range(len(folderFault)):\n",
        "    pathFault.append(dataPath + '/' + folderFault[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xgGP7PZO-rTA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Specgram settings\n",
        "\n",
        "nsc = 1470\n",
        "nov = nsc/2\n",
        "nff = nsc \n",
        "imgSize = 224\n",
        "\n",
        "# pretrainedModel = 'VGG19'\n",
        "# pretrainedModel = 'Xception'\n",
        "# pretrainedModel = 'ResNet50'\n",
        "\n",
        "pretrainedModel = 'DenseNet169'\n",
        "\n",
        "\n",
        "lastActivation = 'softmax'\n",
        "sizeBatch = 4\n",
        "numEpochs = 8\n",
        "verb = 1\n",
        "\n",
        "\n",
        "# Learning parameters\n",
        "\n",
        "trainingRatio = 0.8\n",
        "\n",
        "totalDataNum = 1000\n",
        "repeat = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5AskF2qFT2xr",
        "colab_type": "code",
        "outputId": "2ceb6612-6ada-4280-ebbb-180a3db00bcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "startNum = 0\n",
        "\n",
        "pickNum = int(np.ceil(totalDataNum / len(pathNormal)))\n",
        "\n",
        "for i in range(startNum, len(pathNormal)):\n",
        "\n",
        "    npyTestPath = glob.glob(pathNormal[i] + '/' + '*Image_With_Label.npy')\n",
        "    data = np.load(npyTestPath[0])\n",
        "    \n",
        "    pickIdx = np.random.choice(1000, pickNum, replace=False)\n",
        "    pickIdx.sort()\n",
        "    \n",
        "#     imgs = np.moveaxis(np.dstack(data[:, 0]), 2, 0)\n",
        "#     label = data[:, 1:5]\n",
        "\n",
        "    imgs = np.moveaxis(np.dstack(data[pickIdx, 0]), 2, 0)\n",
        "    label = data[pickIdx, 1:5]\n",
        "    \n",
        "    if i == startNum:\n",
        "        labelListNormal = label\n",
        "        imgsNormal = imgs\n",
        "    else:\n",
        "        labelListNormal = np.vstack([labelListNormal, label])\n",
        "        imgsNormal = np.vstack([imgsNormal, imgs])\n",
        "\n",
        "    print('Normal Image Shape From {}: {}:'.format(pathNormal[i], totalDataNum))    \n",
        "    print('Selected {}/{}:'.format(pickNum * (i + 1), len(data)))    \n",
        "    \n",
        "    \n",
        "print('Normal Image Shape: {}'.format(imgsNormal.shape))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P1N3: 1000:\n",
            "Selected 1000/1000:\n",
            "Normal Image Shape: (1000, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P_MZtpk3Br_i",
        "colab_type": "code",
        "outputId": "3a4a13dc-6083-4ca1-921f-f4da11539b76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "startNum = 0\n",
        "\n",
        "pickNum = int(np.ceil(totalDataNum / len(pathFault)))\n",
        "\n",
        "for i in range(startNum, len(pathFault)):\n",
        "\n",
        "    npyTestPath = glob.glob(pathFault[i] + '/' + '*Image_With_Label.npy')\n",
        "    data = np.load(npyTestPath[0])\n",
        "    \n",
        "    pickIdx = np.random.choice(1000, pickNum, replace=False)\n",
        "    pickIdx.sort()\n",
        "    \n",
        "#     imgs = np.moveaxis(np.dstack(data[:, 0]), 2, 0)\n",
        "#     label = data[:, 1:5]\n",
        "    \n",
        "    imgs = np.moveaxis(np.dstack(data[pickIdx, 0]), 2, 0)\n",
        "    label = data[pickIdx, 1:5]\n",
        "    \n",
        "    if i == startNum:\n",
        "        labelListFault = label\n",
        "        imgsFault = imgs\n",
        "    else:\n",
        "        labelListFault = np.vstack([labelListFault, label])\n",
        "        imgsFault = np.vstack([imgsFault, imgs])\n",
        "\n",
        "    print('Fault Image Shape From {}: {}:'.format(pathFault[i], totalDataNum))    \n",
        "    print('Selected {}/{}:'.format(pickNum * (i + 1), len(data)))     \n",
        "    \n",
        "print('Fault Image Shape: {}'.format(imgsFault.shape))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P5N3: 1000:\n",
            "Selected 1000/1000:\n",
            "Fault Image Shape: (1000, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e91QsAurSkIP",
        "colab_type": "code",
        "outputId": "4b47394a-482f-4de4-d361-f50002b681ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "cell_type": "code",
      "source": [
        "# Change name from imgsF1 or imgsF5 to imgsNormal and imgsFault\n",
        "\n",
        "dataNumNormal = len(imgsNormal)\n",
        "dataNumFault = len(imgsFault)\n",
        "dataNumNormalTrain = int(dataNumNormal * trainingRatio)\n",
        "dataNumFaultTrain = int(dataNumFault * trainingRatio)\n",
        "dataNumNormalTest = dataNumNormal - dataNumNormalTrain\n",
        "dataNumFaultTest = dataNumFault - dataNumFaultTrain\n",
        "\n",
        "print('Normal Train:Test = {:d}:{:d}'.format(dataNumNormalTrain, dataNumNormalTest))\n",
        "print('Fault  Train:Test = {:d}:{:d}\\n'.format(dataNumFaultTrain, dataNumFaultTest))\n",
        "\n",
        "trainIdxNormal = np.random.choice(dataNumNormal - 1, dataNumNormalTrain, replace=False)\n",
        "testIdxNormal = list(set(range(0, dataNumNormal)) - set(trainIdxNormal))\n",
        "\n",
        "trainImgsNormal = imgsNormal[trainIdxNormal, :, :]\n",
        "testImgsNormal = imgsNormal[testIdxNormal, :, :]\n",
        "\n",
        "print('Normal Training Image Shape {}'.format(trainImgsNormal.shape))\n",
        "print('Normal Test Image Shape {}\\n'.format(testImgsNormal.shape))\n",
        "\n",
        "trainIdxFault  = np.random.choice(dataNumFault - 1, dataNumFaultTrain, replace=False)\n",
        "testIdxFault = list(set(range(0, dataNumFault)) - set(trainIdxFault))\n",
        "\n",
        "trainImgsFault = imgsFault[trainIdxFault, :, :]\n",
        "testImgsFault = imgsFault[testIdxFault, :, :]\n",
        "\n",
        "print('Fault Training Image Shape {}'.format(trainImgsFault.shape))\n",
        "print('Fault Test Image Shape {}\\n'.format(testImgsFault.shape))\n",
        "\n",
        "trainImgs = np.vstack([trainImgsNormal, trainImgsFault])\n",
        "testImgs = np.vstack([testImgsNormal, testImgsFault])\n",
        "\n",
        "print('Training Image Shape {}'.format(trainImgs.shape))\n",
        "print('Test Image Shape {}'.format(testImgs.shape))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal Train:Test = 800:200\n",
            "Fault  Train:Test = 800:200\n",
            "\n",
            "Normal Training Image Shape (800, 224, 224)\n",
            "Normal Test Image Shape (200, 224, 224)\n",
            "\n",
            "Fault Training Image Shape (800, 224, 224)\n",
            "Fault Test Image Shape (200, 224, 224)\n",
            "\n",
            "Training Image Shape (1600, 224, 224)\n",
            "Test Image Shape (400, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MoE7f_hzs0av",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "feQ_AHAcUgHD",
        "colab_type": "code",
        "outputId": "1d64439a-4d37-46a5-89c5-c39031840584",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "trainMean = np.mean(trainImgs)\n",
        "trainStd = np.std(trainImgs)\n",
        "\n",
        "print('Mean of Training Image: {}'.format(trainMean))\n",
        "print('Standard Deviation of Training Image: {}'.format(trainStd))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean of Training Image: -79.1793607189791\n",
            "Standard Deviation of Training Image: 8.194977204089263\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wUi9IuXNUpir",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Should Change Norm to Normalized\n",
        "\n",
        "trainImgsNorm = (trainImgs - trainMean) / trainStd\n",
        "testImgsNorm = (testImgs - trainMean) / trainStd\n",
        "\n",
        "trainImgsNorm = trainImgsNorm.reshape(list(trainImgsNorm.shape) + [1])\n",
        "testImgsNorm = testImgsNorm.reshape(list(testImgsNorm.shape) + [1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aklxiPz1Ve4n",
        "colab_type": "code",
        "outputId": "63ba3ed0-935e-4a4d-f073-805c004a6944",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = np.stack([trainImgsNorm[:, :, :, 0], trainImgsNorm[:, :, :, 0], trainImgsNorm[:, :, :, 0]], axis = -1)\n",
        "X_test = np.stack([testImgsNorm[:, :, :, 0], testImgsNorm[:, :, :, 0], testImgsNorm[:, :, :, 0]], axis = -1)\n",
        "\n",
        "print('X_train Shape: {}'.format(X_train.shape))\n",
        "print('X_test  Shape: {}'.format(X_test.shape))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train Shape: (1600, 224, 224, 3)\n",
            "X_test  Shape: (400, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sRgIPzT7K_YP",
        "colab_type": "code",
        "outputId": "1305f012-e57e-41b7-a4b5-12ac35de387f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "trainLabelNormal = np.stack((np.ones(dataNumNormalTrain), np.zeros(dataNumNormalTrain)), axis = -1)\n",
        "testLabelNormal = np.stack((np.ones(dataNumNormalTest), np.zeros(dataNumNormalTest)), axis = -1)\n",
        "\n",
        "trainLabelFault = np.stack((np.zeros(dataNumFaultTrain), np.ones(dataNumFaultTrain)), axis = -1)\n",
        "testLabelFault = np.stack((np.zeros(dataNumFaultTest), np.ones(dataNumFaultTest)), axis = -1)\n",
        "\n",
        "Y_train = np.vstack((trainLabelNormal, trainLabelFault))\n",
        "Y_test = np.vstack((testLabelNormal, testLabelFault))\n",
        "\n",
        "print('Y_train Normal:Fault = {:d}:{:d}'.format(len(trainLabelNormal), len(trainLabelFault)))\n",
        "print('Y_test  Normal:Fault = {:d}:{:d}'.format(len(testLabelNormal), len(testLabelFault)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Y_train Normal:Fault = 800:800\n",
            "Y_test  Normal:Fault = 200:200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kczwZk7Tbp5C",
        "colab_type": "code",
        "outputId": "b2cf78d3-9322-4644-d54b-2edbc2e94aee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1927
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG19\n",
        "from keras.applications import VGG16\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications.densenet import DenseNet169\n",
        "from keras.applications.densenet import DenseNet201\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# pretrainedModel = 'ResNet50'\n",
        "# lastActivation = 'softmax'\n",
        "# lossFunction = 'binary_crossentropy'\n",
        "# sizeBatch = 2\n",
        "# numEpochs = 2\n",
        "# verb = 1\n",
        "\n",
        "for rp in range(repeat):\n",
        "\n",
        "    # Refresh all background variables\n",
        "    K.clear_session()\n",
        "\n",
        "    input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "    # Building sequential model with name 'model'\n",
        "    model = Sequential()\n",
        "\n",
        "    # Model selection\n",
        "\n",
        "    if (pretrainedModel == 'VGG16'):\n",
        "\n",
        "        modelWoTop = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'VGG19'):\n",
        "\n",
        "        modelWoTop = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif pretrainedModel == 'ResNet50':\n",
        "\n",
        "        modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'InceptionV3'):\n",
        "        modelWoTop = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'Xception'):\n",
        "        modelWoTop = Xception(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet169'):\n",
        "\n",
        "        modelWoTop = DenseNet169(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet201'):\n",
        "        modelWoTop = DenseNet201(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    else:\n",
        "        print('Invalid Pretrained Model Selection')\n",
        "\n",
        "\n",
        "\n",
        "    # Model compiling\n",
        "\n",
        "    print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "    print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "    model.fit(X_train, Y_train,\n",
        "              batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "              validation_data=(X_test, Y_test))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compiling Pretrained densenet169 Model\n",
            "Training Pretrained densenet169 Model\n",
            "Batch Size: 4\t Epochs: 8\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/8\n",
            "1600/1600 [==============================] - 116s 73ms/step - loss: 0.2367 - acc: 0.9388 - val_loss: 0.1038 - val_acc: 0.9550\n",
            "Epoch 2/8\n",
            "1600/1600 [==============================] - 83s 52ms/step - loss: 0.1616 - acc: 0.9444 - val_loss: 6.7518e-04 - val_acc: 1.0000\n",
            "Epoch 3/8\n",
            "1600/1600 [==============================] - 83s 52ms/step - loss: 0.1117 - acc: 0.9475 - val_loss: 2.5051e-05 - val_acc: 1.0000\n",
            "Epoch 4/8\n",
            "1600/1600 [==============================] - 83s 52ms/step - loss: 0.1231 - acc: 0.9369 - val_loss: 2.5792e-05 - val_acc: 1.0000\n",
            "Epoch 5/8\n",
            "1600/1600 [==============================] - 83s 52ms/step - loss: 0.0849 - acc: 0.9481 - val_loss: 1.9477e-06 - val_acc: 1.0000\n",
            "Epoch 6/8\n",
            "1600/1600 [==============================] - 83s 52ms/step - loss: 0.1167 - acc: 0.9356 - val_loss: 9.0717e-07 - val_acc: 1.0000\n",
            "Epoch 7/8\n",
            "1600/1600 [==============================] - 83s 52ms/step - loss: 0.1092 - acc: 0.9406 - val_loss: 1.5017e-06 - val_acc: 1.0000\n",
            "Epoch 8/8\n",
            "1600/1600 [==============================] - 83s 52ms/step - loss: 0.1024 - acc: 0.9388 - val_loss: 2.1614e-07 - val_acc: 1.0000\n",
            "Compiling Pretrained densenet169 Model\n",
            "Training Pretrained densenet169 Model\n",
            "Batch Size: 4\t Epochs: 8\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/8\n",
            "1600/1600 [==============================] - 116s 73ms/step - loss: 0.2627 - acc: 0.9281 - val_loss: 1.8207 - val_acc: 0.5800\n",
            "Epoch 2/8\n",
            "1600/1600 [==============================] - 85s 53ms/step - loss: 0.1513 - acc: 0.9213 - val_loss: 1.5516e-05 - val_acc: 1.0000\n",
            "Epoch 3/8\n",
            "1600/1600 [==============================] - 85s 53ms/step - loss: 0.1101 - acc: 0.9456 - val_loss: 1.9285e-05 - val_acc: 1.0000\n",
            "Epoch 4/8\n",
            "1600/1600 [==============================] - 84s 53ms/step - loss: 0.1183 - acc: 0.9413 - val_loss: 4.2672e-05 - val_acc: 1.0000\n",
            "Epoch 5/8\n",
            "1600/1600 [==============================] - 85s 53ms/step - loss: 0.1038 - acc: 0.9281 - val_loss: 1.7465e-05 - val_acc: 1.0000\n",
            "Epoch 6/8\n",
            "1600/1600 [==============================] - 85s 53ms/step - loss: 0.1162 - acc: 0.9400 - val_loss: 1.2206e-05 - val_acc: 1.0000\n",
            "Epoch 7/8\n",
            "1600/1600 [==============================] - 84s 53ms/step - loss: 0.1236 - acc: 0.9331 - val_loss: 1.1540e-05 - val_acc: 1.0000\n",
            "Epoch 8/8\n",
            "1600/1600 [==============================] - 84s 53ms/step - loss: 0.1058 - acc: 0.9438 - val_loss: 6.7661e-05 - val_acc: 1.0000\n",
            "Compiling Pretrained densenet169 Model\n",
            "Training Pretrained densenet169 Model\n",
            "Batch Size: 4\t Epochs: 8\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/8\n",
            "1600/1600 [==============================] - 119s 74ms/step - loss: 0.2947 - acc: 0.9300 - val_loss: 0.0571 - val_acc: 1.0000\n",
            "Epoch 2/8\n",
            "1600/1600 [==============================] - 85s 53ms/step - loss: 0.1380 - acc: 0.9300 - val_loss: 3.6963e-05 - val_acc: 1.0000\n",
            "Epoch 3/8\n",
            "1600/1600 [==============================] - 85s 53ms/step - loss: 0.1167 - acc: 0.9419 - val_loss: 1.4329e-05 - val_acc: 1.0000\n",
            "Epoch 4/8\n",
            "1600/1600 [==============================] - 85s 53ms/step - loss: 0.1080 - acc: 0.9369 - val_loss: 1.2796e-05 - val_acc: 1.0000\n",
            "Epoch 5/8\n",
            "1600/1600 [==============================] - 84s 53ms/step - loss: 0.0915 - acc: 0.9463 - val_loss: 1.3295e-05 - val_acc: 1.0000\n",
            "Epoch 6/8\n",
            "1600/1600 [==============================] - 85s 53ms/step - loss: 0.0863 - acc: 0.9431 - val_loss: 3.4644e-05 - val_acc: 1.0000\n",
            "Epoch 7/8\n",
            "1600/1600 [==============================] - 85s 53ms/step - loss: 0.1111 - acc: 0.9425 - val_loss: 2.5861e-05 - val_acc: 1.0000\n",
            "Epoch 8/8\n",
            "1600/1600 [==============================] - 86s 54ms/step - loss: 0.0853 - acc: 0.9450 - val_loss: 1.2961e-05 - val_acc: 1.0000\n",
            "Compiling Pretrained densenet169 Model\n",
            "Training Pretrained densenet169 Model\n",
            "Batch Size: 4\t Epochs: 8\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/8\n",
            "1600/1600 [==============================] - 118s 74ms/step - loss: 0.3274 - acc: 0.9319 - val_loss: 1.4338 - val_acc: 0.5000\n",
            "Epoch 2/8\n",
            "1600/1600 [==============================] - 85s 53ms/step - loss: 0.1200 - acc: 0.9550 - val_loss: 1.3775e-04 - val_acc: 1.0000\n",
            "Epoch 3/8\n",
            "1600/1600 [==============================] - 85s 53ms/step - loss: 0.1095 - acc: 0.9394 - val_loss: 1.3812e-04 - val_acc: 1.0000\n",
            "Epoch 4/8\n",
            "1600/1600 [==============================] - 85s 53ms/step - loss: 0.1138 - acc: 0.9325 - val_loss: 1.3439e-04 - val_acc: 1.0000\n",
            "Epoch 5/8\n",
            "1600/1600 [==============================] - 85s 53ms/step - loss: 0.0997 - acc: 0.9406 - val_loss: 5.1607e-04 - val_acc: 1.0000\n",
            "Epoch 6/8\n",
            "1600/1600 [==============================] - 85s 53ms/step - loss: 0.0954 - acc: 0.9544 - val_loss: 9.8893e-05 - val_acc: 1.0000\n",
            "Epoch 7/8\n",
            "1600/1600 [==============================] - 84s 52ms/step - loss: 0.1032 - acc: 0.9375 - val_loss: 6.7130e-04 - val_acc: 1.0000\n",
            "Epoch 8/8\n",
            "1600/1600 [==============================] - 84s 52ms/step - loss: 0.1030 - acc: 0.9362 - val_loss: 2.8679e-04 - val_acc: 1.0000\n",
            "Compiling Pretrained densenet169 Model\n",
            "Training Pretrained densenet169 Model\n",
            "Batch Size: 4\t Epochs: 8\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/8\n",
            "1600/1600 [==============================] - 117s 73ms/step - loss: 0.2180 - acc: 0.9425 - val_loss: 0.0394 - val_acc: 0.9950\n",
            "Epoch 2/8\n",
            "1600/1600 [==============================] - 84s 52ms/step - loss: 0.1612 - acc: 0.9419 - val_loss: 0.0038 - val_acc: 1.0000\n",
            "Epoch 3/8\n",
            "1600/1600 [==============================] - 84s 52ms/step - loss: 0.1264 - acc: 0.9231 - val_loss: 3.6609e-05 - val_acc: 1.0000\n",
            "Epoch 4/8\n",
            "1600/1600 [==============================] - 84s 53ms/step - loss: 0.1194 - acc: 0.9362 - val_loss: 2.0760e-05 - val_acc: 1.0000\n",
            "Epoch 5/8\n",
            "1600/1600 [==============================] - 84s 53ms/step - loss: 0.0822 - acc: 0.9556 - val_loss: 9.9711e-05 - val_acc: 1.0000\n",
            "Epoch 6/8\n",
            "1600/1600 [==============================] - 84s 52ms/step - loss: 0.1292 - acc: 0.9194 - val_loss: 1.6657e-05 - val_acc: 1.0000\n",
            "Epoch 7/8\n",
            "1600/1600 [==============================] - 84s 52ms/step - loss: 0.1087 - acc: 0.9388 - val_loss: 1.8236e-04 - val_acc: 1.0000\n",
            "Epoch 8/8\n",
            "1600/1600 [==============================] - 84s 52ms/step - loss: 0.1062 - acc: 0.9275 - val_loss: 2.2382e-04 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qexmaPZVz04q",
        "colab_type": "code",
        "outputId": "15884313-3b50-4632-ac71-1e2d0cab4fa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.plot(Y_test[:, 1], 'r')\n",
        "\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.plot(Y_pred[:, 1], 'b')\n",
        "\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.plot(Y_test[:, 1] - Y_pred[:, 1], 'g')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "IPTFOJh3DTgq",
        "colab_type": "code",
        "outputId": "3f96a735-d5d7-490e-eb70-3b1f511a3941",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "now = datetime.datetime.now()\n",
        "\n",
        "# modelSaved = '{}-{}_{}_{}.h5'.format(folderNormal, folderFault, pretrainedModel, now.strftime('%m-%d-%H:%M:%S'))\n",
        "\n",
        "modelSaved = '{}-{}_{}_{}.h5'.format(folderNormal, folderFault, pretrainedModel, now.strftime('%m-%d-%H-%M-%S'))\n",
        "meanSaved = 'mean_{}.npy'.format(now.strftime('%m-%d-%H-%M-%S'))\n",
        "stdSaved = 'std_{}.npy'.format(now.strftime('%m-%d-%H-%M-%S'))\n",
        "\n",
        "inputStr = input('''Save Model as '{}'? (y/n)\\n'''.format(modelSaved))\n",
        "\n",
        "if (inputStr == 'y' or inputStr == 'Y'):  \n",
        "    model.save(modelPath + '/{}'.format(modelSaved))\n",
        "    np.save(modelPath + '/{}'.format(meanSaved), trainMean)\n",
        "    np.save(modelPath + '/{}'.format(stdSaved), trainStd)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Save Model as '['P1N3']-['P5N3']_DenseNet169_11-16-15-02-05.h5'? (y/n)\n",
            "n\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}