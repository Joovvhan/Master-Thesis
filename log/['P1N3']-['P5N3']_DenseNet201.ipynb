{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning Clean Up.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joovvhan/Master-Thesis/blob/master/log/['P1N3']-['P5N3']_DenseNet201.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "c3821KWLNey6",
        "colab_type": "code",
        "outputId": "6690556a-bb55-4b7b-f132-94ede6e2127c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Import necessary modules\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy.io.wavfile as wf\n",
        "import time\n",
        "import glob\n",
        "import datetime\n",
        "\n",
        "from tqdm import trange\n",
        "\n",
        "# Import Keras modules\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.layers import Input, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
        "from keras.models import Sequential\n",
        "from keras import backend as K\n",
        "from keras.models import load_model\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "nxSASpgF7unA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Mount google drive\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "# os.listdir('gdrive/My Drive/Colab')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rw9NU8Xjwcz2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set data directories\n",
        "\n",
        "dataPath = '''D:\\\\0_Joowhan's Paper\\\\Synthesized\\\\Total\\\\Impulse'''\n",
        "modelPath = '''D:\\\\0_Joowhan's Paper\\\\Synthesized\\\\Total\\\\Model'''\n",
        "\n",
        "\n",
        "# Changed variable names to normal and fault\n",
        "# Changed variable names from folder to path\n",
        "# Need to consider multiple folders\n",
        "# Need to add files to be tested\n",
        "\n",
        "folderNormal = ['P1N3']\n",
        "# folderNormal = list()\n",
        "\n",
        "# for x in range(1, 6):\n",
        "#     for y in range(1, 6):\n",
        "#         for z in range(1, 6):\n",
        "#             if (x <= 2 and y <= 2 and z <= 2):\n",
        "#                 folderNormal.append('A{}F{}P{}'.format(x, y, z))\n",
        "\n",
        "# folderFault = list()\n",
        "\n",
        "folderFault = ['P5N3']\n",
        "\n",
        "# for x in range(1, 6):\n",
        "#     for y in range(1, 6):\n",
        "#         for z in range(1, 6):\n",
        "#             if (x == 5 or y == 5 or z == 5):\n",
        "#                 folderFault.append('A{}F{}P{}'.format(x, y, z))\n",
        "\n",
        "\n",
        "pathNormal = list()\n",
        "pathFault = list()\n",
        "\n",
        "for i in range(len(folderNormal)):\n",
        "    pathNormal.append(dataPath + '/' + folderNormal[i])\n",
        "    \n",
        "for i in range(len(folderFault)):\n",
        "    pathFault.append(dataPath + '/' + folderFault[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xgGP7PZO-rTA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Specgram settings\n",
        "\n",
        "nsc = 1470\n",
        "nov = nsc/2\n",
        "nff = nsc \n",
        "imgSize = 224\n",
        "\n",
        "# pretrainedModel = 'VGG19'\n",
        "# pretrainedModel = 'Xception'\n",
        "# pretrainedModel = 'ResNet50'\n",
        "\n",
        "pretrainedModel = 'DenseNet201'\n",
        "\n",
        "\n",
        "lastActivation = 'softmax'\n",
        "sizeBatch = 4\n",
        "numEpochs = 8\n",
        "verb = 1\n",
        "\n",
        "\n",
        "# Learning parameters\n",
        "\n",
        "trainingRatio = 0.8\n",
        "\n",
        "totalDataNum = 1000\n",
        "repeat = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5AskF2qFT2xr",
        "colab_type": "code",
        "outputId": "598fc899-c943-4532-9939-7536d394d471",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "startNum = 0\n",
        "\n",
        "pickNum = int(np.ceil(totalDataNum / len(pathNormal)))\n",
        "\n",
        "for i in range(startNum, len(pathNormal)):\n",
        "\n",
        "    npyTestPath = glob.glob(pathNormal[i] + '/' + '*Image_With_Label.npy')\n",
        "    data = np.load(npyTestPath[0])\n",
        "    \n",
        "    pickIdx = np.random.choice(1000, pickNum, replace=False)\n",
        "    pickIdx.sort()\n",
        "    \n",
        "#     imgs = np.moveaxis(np.dstack(data[:, 0]), 2, 0)\n",
        "#     label = data[:, 1:5]\n",
        "\n",
        "    imgs = np.moveaxis(np.dstack(data[pickIdx, 0]), 2, 0)\n",
        "    label = data[pickIdx, 1:5]\n",
        "    \n",
        "    if i == startNum:\n",
        "        labelListNormal = label\n",
        "        imgsNormal = imgs\n",
        "    else:\n",
        "        labelListNormal = np.vstack([labelListNormal, label])\n",
        "        imgsNormal = np.vstack([imgsNormal, imgs])\n",
        "\n",
        "    print('Normal Image Shape From {}: {}:'.format(pathNormal[i], totalDataNum))    \n",
        "    print('Selected {}/{}:'.format(pickNum * (i + 1), len(data)))    \n",
        "    \n",
        "    \n",
        "print('Normal Image Shape: {}'.format(imgsNormal.shape))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P1N3: 1000:\n",
            "Selected 1000/1000:\n",
            "Normal Image Shape: (1000, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P_MZtpk3Br_i",
        "colab_type": "code",
        "outputId": "43f34fba-9ef7-4a13-8026-20f0b9d18f82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "startNum = 0\n",
        "\n",
        "pickNum = int(np.ceil(totalDataNum / len(pathFault)))\n",
        "\n",
        "for i in range(startNum, len(pathFault)):\n",
        "\n",
        "    npyTestPath = glob.glob(pathFault[i] + '/' + '*Image_With_Label.npy')\n",
        "    data = np.load(npyTestPath[0])\n",
        "    \n",
        "    pickIdx = np.random.choice(1000, pickNum, replace=False)\n",
        "    pickIdx.sort()\n",
        "    \n",
        "#     imgs = np.moveaxis(np.dstack(data[:, 0]), 2, 0)\n",
        "#     label = data[:, 1:5]\n",
        "    \n",
        "    imgs = np.moveaxis(np.dstack(data[pickIdx, 0]), 2, 0)\n",
        "    label = data[pickIdx, 1:5]\n",
        "    \n",
        "    if i == startNum:\n",
        "        labelListFault = label\n",
        "        imgsFault = imgs\n",
        "    else:\n",
        "        labelListFault = np.vstack([labelListFault, label])\n",
        "        imgsFault = np.vstack([imgsFault, imgs])\n",
        "\n",
        "    print('Fault Image Shape From {}: {}:'.format(pathFault[i], totalDataNum))    \n",
        "    print('Selected {}/{}:'.format(pickNum * (i + 1), len(data)))     \n",
        "    \n",
        "print('Fault Image Shape: {}'.format(imgsFault.shape))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P5N3: 1000:\n",
            "Selected 1000/1000:\n",
            "Fault Image Shape: (1000, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e91QsAurSkIP",
        "colab_type": "code",
        "outputId": "894a69ae-3f4e-46e6-d5a7-998ae4e476e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "cell_type": "code",
      "source": [
        "# Change name from imgsF1 or imgsF5 to imgsNormal and imgsFault\n",
        "\n",
        "dataNumNormal = len(imgsNormal)\n",
        "dataNumFault = len(imgsFault)\n",
        "dataNumNormalTrain = int(dataNumNormal * trainingRatio)\n",
        "dataNumFaultTrain = int(dataNumFault * trainingRatio)\n",
        "dataNumNormalTest = dataNumNormal - dataNumNormalTrain\n",
        "dataNumFaultTest = dataNumFault - dataNumFaultTrain\n",
        "\n",
        "print('Normal Train:Test = {:d}:{:d}'.format(dataNumNormalTrain, dataNumNormalTest))\n",
        "print('Fault  Train:Test = {:d}:{:d}\\n'.format(dataNumFaultTrain, dataNumFaultTest))\n",
        "\n",
        "trainIdxNormal = np.random.choice(dataNumNormal - 1, dataNumNormalTrain, replace=False)\n",
        "testIdxNormal = list(set(range(0, dataNumNormal)) - set(trainIdxNormal))\n",
        "\n",
        "trainImgsNormal = imgsNormal[trainIdxNormal, :, :]\n",
        "testImgsNormal = imgsNormal[testIdxNormal, :, :]\n",
        "\n",
        "print('Normal Training Image Shape {}'.format(trainImgsNormal.shape))\n",
        "print('Normal Test Image Shape {}\\n'.format(testImgsNormal.shape))\n",
        "\n",
        "trainIdxFault  = np.random.choice(dataNumFault - 1, dataNumFaultTrain, replace=False)\n",
        "testIdxFault = list(set(range(0, dataNumFault)) - set(trainIdxFault))\n",
        "\n",
        "trainImgsFault = imgsFault[trainIdxFault, :, :]\n",
        "testImgsFault = imgsFault[testIdxFault, :, :]\n",
        "\n",
        "print('Fault Training Image Shape {}'.format(trainImgsFault.shape))\n",
        "print('Fault Test Image Shape {}\\n'.format(testImgsFault.shape))\n",
        "\n",
        "trainImgs = np.vstack([trainImgsNormal, trainImgsFault])\n",
        "testImgs = np.vstack([testImgsNormal, testImgsFault])\n",
        "\n",
        "print('Training Image Shape {}'.format(trainImgs.shape))\n",
        "print('Test Image Shape {}'.format(testImgs.shape))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal Train:Test = 800:200\n",
            "Fault  Train:Test = 800:200\n",
            "\n",
            "Normal Training Image Shape (800, 224, 224)\n",
            "Normal Test Image Shape (200, 224, 224)\n",
            "\n",
            "Fault Training Image Shape (800, 224, 224)\n",
            "Fault Test Image Shape (200, 224, 224)\n",
            "\n",
            "Training Image Shape (1600, 224, 224)\n",
            "Test Image Shape (400, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MoE7f_hzs0av",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "feQ_AHAcUgHD",
        "colab_type": "code",
        "outputId": "7599a0d7-8ead-44ad-85aa-3584f520b0d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "trainMean = np.mean(trainImgs)\n",
        "trainStd = np.std(trainImgs)\n",
        "\n",
        "print('Mean of Training Image: {}'.format(trainMean))\n",
        "print('Standard Deviation of Training Image: {}'.format(trainStd))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean of Training Image: -79.17100818010121\n",
            "Standard Deviation of Training Image: 8.201575846069998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wUi9IuXNUpir",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Should Change Norm to Normalized\n",
        "\n",
        "trainImgsNorm = (trainImgs - trainMean) / trainStd\n",
        "testImgsNorm = (testImgs - trainMean) / trainStd\n",
        "\n",
        "trainImgsNorm = trainImgsNorm.reshape(list(trainImgsNorm.shape) + [1])\n",
        "testImgsNorm = testImgsNorm.reshape(list(testImgsNorm.shape) + [1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aklxiPz1Ve4n",
        "colab_type": "code",
        "outputId": "22d848cc-3e9f-4e98-dd2f-105ba14d46f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = np.stack([trainImgsNorm[:, :, :, 0], trainImgsNorm[:, :, :, 0], trainImgsNorm[:, :, :, 0]], axis = -1)\n",
        "X_test = np.stack([testImgsNorm[:, :, :, 0], testImgsNorm[:, :, :, 0], testImgsNorm[:, :, :, 0]], axis = -1)\n",
        "\n",
        "print('X_train Shape: {}'.format(X_train.shape))\n",
        "print('X_test  Shape: {}'.format(X_test.shape))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train Shape: (1600, 224, 224, 3)\n",
            "X_test  Shape: (400, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sRgIPzT7K_YP",
        "colab_type": "code",
        "outputId": "83409ec9-e7a2-4cfa-b4ff-6d9986ecca23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "trainLabelNormal = np.stack((np.ones(dataNumNormalTrain), np.zeros(dataNumNormalTrain)), axis = -1)\n",
        "testLabelNormal = np.stack((np.ones(dataNumNormalTest), np.zeros(dataNumNormalTest)), axis = -1)\n",
        "\n",
        "trainLabelFault = np.stack((np.zeros(dataNumFaultTrain), np.ones(dataNumFaultTrain)), axis = -1)\n",
        "testLabelFault = np.stack((np.zeros(dataNumFaultTest), np.ones(dataNumFaultTest)), axis = -1)\n",
        "\n",
        "Y_train = np.vstack((trainLabelNormal, trainLabelFault))\n",
        "Y_test = np.vstack((testLabelNormal, testLabelFault))\n",
        "\n",
        "print('Y_train Normal:Fault = {:d}:{:d}'.format(len(trainLabelNormal), len(trainLabelFault)))\n",
        "print('Y_test  Normal:Fault = {:d}:{:d}'.format(len(testLabelNormal), len(testLabelFault)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Y_train Normal:Fault = 800:800\n",
            "Y_test  Normal:Fault = 200:200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kczwZk7Tbp5C",
        "colab_type": "code",
        "outputId": "1d4ad3a9-4afa-483f-c361-7e8daa54e7bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1927
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG19\n",
        "from keras.applications import VGG16\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications.densenet import DenseNet169\n",
        "from keras.applications.densenet import DenseNet201\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# pretrainedModel = 'ResNet50'\n",
        "# lastActivation = 'softmax'\n",
        "# lossFunction = 'binary_crossentropy'\n",
        "# sizeBatch = 2\n",
        "# numEpochs = 2\n",
        "# verb = 1\n",
        "\n",
        "for rp in range(repeat):\n",
        "\n",
        "    # Refresh all background variables\n",
        "    K.clear_session()\n",
        "\n",
        "    input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "    # Building sequential model with name 'model'\n",
        "    model = Sequential()\n",
        "\n",
        "    # Model selection\n",
        "\n",
        "    if (pretrainedModel == 'VGG16'):\n",
        "\n",
        "        modelWoTop = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'VGG19'):\n",
        "\n",
        "        modelWoTop = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif pretrainedModel == 'ResNet50':\n",
        "\n",
        "        modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'InceptionV3'):\n",
        "        modelWoTop = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'Xception'):\n",
        "        modelWoTop = Xception(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet169'):\n",
        "\n",
        "        modelWoTop = DenseNet169(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet201'):\n",
        "        modelWoTop = DenseNet201(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    else:\n",
        "        print('Invalid Pretrained Model Selection')\n",
        "\n",
        "\n",
        "\n",
        "    # Model compiling\n",
        "\n",
        "    print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "    print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "    model.fit(X_train, Y_train,\n",
        "              batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "              validation_data=(X_test, Y_test))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compiling Pretrained densenet201 Model\n",
            "Training Pretrained densenet201 Model\n",
            "Batch Size: 4\t Epochs: 8\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/8\n",
            "1600/1600 [==============================] - 147s 92ms/step - loss: 0.2526 - acc: 0.9150 - val_loss: 0.0023 - val_acc: 1.0000\n",
            "Epoch 2/8\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1226 - acc: 0.9500 - val_loss: 9.2494e-06 - val_acc: 1.0000\n",
            "Epoch 3/8\n",
            "1600/1600 [==============================] - 107s 67ms/step - loss: 0.1214 - acc: 0.9506 - val_loss: 1.5560e-04 - val_acc: 1.0000\n",
            "Epoch 4/8\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1060 - acc: 0.9388 - val_loss: 6.3676e-07 - val_acc: 1.0000\n",
            "Epoch 5/8\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0862 - acc: 0.9381 - val_loss: 1.9941e-06 - val_acc: 1.0000\n",
            "Epoch 6/8\n",
            "1600/1600 [==============================] - 106s 67ms/step - loss: 0.1329 - acc: 0.9194 - val_loss: 2.5810e-06 - val_acc: 1.0000\n",
            "Epoch 7/8\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0799 - acc: 0.9575 - val_loss: 7.7932e-07 - val_acc: 1.0000\n",
            "Epoch 8/8\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0959 - acc: 0.9406 - val_loss: 1.1373e-06 - val_acc: 1.0000\n",
            "Compiling Pretrained densenet201 Model\n",
            "Training Pretrained densenet201 Model\n",
            "Batch Size: 4\t Epochs: 8\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/8\n",
            "1600/1600 [==============================] - 146s 91ms/step - loss: 0.2382 - acc: 0.9225 - val_loss: 1.5460 - val_acc: 0.6075\n",
            "Epoch 2/8\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1308 - acc: 0.9394 - val_loss: 6.6212e-06 - val_acc: 1.0000\n",
            "Epoch 3/8\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1141 - acc: 0.9444 - val_loss: 0.0017 - val_acc: 1.0000\n",
            "Epoch 4/8\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1336 - acc: 0.9269 - val_loss: 3.1324e-04 - val_acc: 1.0000\n",
            "Epoch 5/8\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1078 - acc: 0.9244 - val_loss: 1.9527e-06 - val_acc: 1.0000\n",
            "Epoch 6/8\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1052 - acc: 0.9488 - val_loss: 1.0926e-05 - val_acc: 1.0000\n",
            "Epoch 7/8\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1182 - acc: 0.9294 - val_loss: 1.9357e-06 - val_acc: 1.0000\n",
            "Epoch 8/8\n",
            "1600/1600 [==============================] - 107s 67ms/step - loss: 0.0834 - acc: 0.9419 - val_loss: 4.1585e-07 - val_acc: 1.0000\n",
            "Compiling Pretrained densenet201 Model\n",
            "Training Pretrained densenet201 Model\n",
            "Batch Size: 4\t Epochs: 8\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/8\n",
            "1600/1600 [==============================] - 149s 93ms/step - loss: 0.2854 - acc: 0.9237 - val_loss: 2.9622e-05 - val_acc: 1.0000\n",
            "Epoch 2/8\n",
            "1600/1600 [==============================] - 107s 67ms/step - loss: 0.1250 - acc: 0.9463 - val_loss: 0.0084 - val_acc: 1.0000\n",
            "Epoch 3/8\n",
            "1600/1600 [==============================] - 107s 67ms/step - loss: 0.0941 - acc: 0.9475 - val_loss: 2.1150e-05 - val_acc: 1.0000\n",
            "Epoch 4/8\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1163 - acc: 0.9388 - val_loss: 2.3739e-05 - val_acc: 1.0000\n",
            "Epoch 5/8\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1103 - acc: 0.9300 - val_loss: 1.9754e-05 - val_acc: 1.0000\n",
            "Epoch 6/8\n",
            "1600/1600 [==============================] - 105s 66ms/step - loss: 0.1000 - acc: 0.9312 - val_loss: 3.4885e-06 - val_acc: 1.0000\n",
            "Epoch 7/8\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.0912 - acc: 0.9625 - val_loss: 3.4697e-05 - val_acc: 1.0000\n",
            "Epoch 8/8\n",
            "1600/1600 [==============================] - 107s 67ms/step - loss: 0.0917 - acc: 0.9469 - val_loss: 5.5921e-06 - val_acc: 1.0000\n",
            "Compiling Pretrained densenet201 Model\n",
            "Training Pretrained densenet201 Model\n",
            "Batch Size: 4\t Epochs: 8\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/8\n",
            "1600/1600 [==============================] - 148s 93ms/step - loss: 0.2280 - acc: 0.9281 - val_loss: 0.0078 - val_acc: 1.0000\n",
            "Epoch 2/8\n",
            "1600/1600 [==============================] - 107s 67ms/step - loss: 0.1019 - acc: 0.9613 - val_loss: 0.0193 - val_acc: 0.9950\n",
            "Epoch 3/8\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1123 - acc: 0.9550 - val_loss: 6.6683e-07 - val_acc: 1.0000\n",
            "Epoch 4/8\n",
            "1600/1600 [==============================] - 107s 67ms/step - loss: 0.1007 - acc: 0.9438 - val_loss: 9.7740e-07 - val_acc: 1.0000\n",
            "Epoch 5/8\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1031 - acc: 0.9306 - val_loss: 2.9828e-07 - val_acc: 1.0000\n",
            "Epoch 6/8\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 0.1053 - acc: 0.9275 - val_loss: 2.2908e-07 - val_acc: 1.0000\n",
            "Epoch 7/8\n",
            "1600/1600 [==============================] - 107s 67ms/step - loss: 0.0837 - acc: 0.9525 - val_loss: 1.6166e-07 - val_acc: 1.0000\n",
            "Epoch 8/8\n",
            "1600/1600 [==============================] - 107s 67ms/step - loss: 0.0943 - acc: 0.9475 - val_loss: 2.1408e-07 - val_acc: 1.0000\n",
            "Compiling Pretrained densenet201 Model\n",
            "Training Pretrained densenet201 Model\n",
            "Batch Size: 4\t Epochs: 8\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/8\n",
            "1600/1600 [==============================] - 148s 93ms/step - loss: 0.3033 - acc: 0.9262 - val_loss: 0.0218 - val_acc: 0.9975\n",
            "Epoch 2/8\n",
            "1600/1600 [==============================] - 107s 67ms/step - loss: 0.1423 - acc: 0.9406 - val_loss: 4.2249e-04 - val_acc: 1.0000\n",
            "Epoch 3/8\n",
            "1600/1600 [==============================] - 107s 67ms/step - loss: 0.1161 - acc: 0.9344 - val_loss: 4.5263e-05 - val_acc: 1.0000\n",
            "Epoch 4/8\n",
            "1600/1600 [==============================] - 107s 67ms/step - loss: 0.1112 - acc: 0.9431 - val_loss: 7.9853e-06 - val_acc: 1.0000\n",
            "Epoch 5/8\n",
            "1600/1600 [==============================] - 107s 67ms/step - loss: 0.1119 - acc: 0.9244 - val_loss: 2.7835e-06 - val_acc: 1.0000\n",
            "Epoch 6/8\n",
            "1600/1600 [==============================] - 107s 67ms/step - loss: 0.0917 - acc: 0.9475 - val_loss: 3.3787e-06 - val_acc: 1.0000\n",
            "Epoch 7/8\n",
            "1600/1600 [==============================] - 107s 67ms/step - loss: 0.1175 - acc: 0.9325 - val_loss: 7.8631e-06 - val_acc: 1.0000\n",
            "Epoch 8/8\n",
            "1600/1600 [==============================] - 107s 67ms/step - loss: 0.1263 - acc: 0.9187 - val_loss: 2.0711e-05 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qexmaPZVz04q",
        "colab_type": "code",
        "outputId": "0f83bd83-a8a2-44c1-a5e0-43ab9f74a044",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.plot(Y_test[:, 1], 'r')\n",
        "\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.plot(Y_pred[:, 1], 'b')\n",
        "\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.plot(Y_test[:, 1] - Y_pred[:, 1], 'g')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "IPTFOJh3DTgq",
        "colab_type": "code",
        "outputId": "deaceccd-705b-4aa5-eeff-4569333726ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "now = datetime.datetime.now()\n",
        "\n",
        "# modelSaved = '{}-{}_{}_{}.h5'.format(folderNormal, folderFault, pretrainedModel, now.strftime('%m-%d-%H:%M:%S'))\n",
        "\n",
        "modelSaved = '{}-{}_{}_{}.h5'.format(folderNormal, folderFault, pretrainedModel, now.strftime('%m-%d-%H-%M-%S'))\n",
        "meanSaved = 'mean_{}.npy'.format(now.strftime('%m-%d-%H-%M-%S'))\n",
        "stdSaved = 'std_{}.npy'.format(now.strftime('%m-%d-%H-%M-%S'))\n",
        "\n",
        "inputStr = input('''Save Model as '{}'? (y/n)\\n'''.format(modelSaved))\n",
        "\n",
        "if (inputStr == 'y' or inputStr == 'Y'):  \n",
        "    model.save(modelPath + '/{}'.format(modelSaved))\n",
        "    np.save(modelPath + '/{}'.format(meanSaved), trainMean)\n",
        "    np.save(modelPath + '/{}'.format(stdSaved), trainStd)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Save Model as '['P1N3']-['P5N3']_DenseNet201_11-16-16-32-12.h5'? (y/n)\n",
            "y\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}