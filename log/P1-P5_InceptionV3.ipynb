{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning Clean Up.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joovvhan/Master-Thesis/blob/master/log/P1-P5_InceptionV3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "c3821KWLNey6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import necessary modules\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy.io.wavfile as wf\n",
        "import time\n",
        "import glob\n",
        "import datetime\n",
        "\n",
        "from tqdm import trange\n",
        "\n",
        "# Import Keras modules\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.layers import Input, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
        "from keras.models import Sequential\n",
        "from keras import backend as K\n",
        "from keras.models import load_model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nxSASpgF7unA",
        "colab_type": "code",
        "outputId": "8279ab74-5ec7-467c-de30-e5c803fae487",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "cell_type": "code",
      "source": [
        "# Mount google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "os.listdir('gdrive/My Drive/Colab')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Data', 'Model', 'Data_']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "rw9NU8Xjwcz2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set data directories\n",
        "\n",
        "dataPath = 'gdrive/My Drive/Colab/Data'\n",
        "\n",
        "# Changed variable names to normal and fault\n",
        "# Changed variable names from folder to path\n",
        "# Need to consider multiple folders\n",
        "# Need to add files to be tested\n",
        "\n",
        "#folderNormal = ['A1F3P3']\n",
        "folderNormal = list()\n",
        "\n",
        "for x in range(1, 6):\n",
        "    for y in range(1, 6):\n",
        "        for z in range(1, 2):\n",
        "            #if (x <= 2 and y <= 2 and z <= 2):\n",
        "            folderNormal.append('A{}F{}P{}'.format(x, y, z))\n",
        "\n",
        "folderFault = list()\n",
        "\n",
        "# folderFault = ['A5F3P3']\n",
        "\n",
        "for x in range(1, 6):\n",
        "    for y in range(1, 6):\n",
        "        for z in range(5, 6):\n",
        "            #if (x == 5 or y == 5 or z == 5):\n",
        "            folderFault.append('A{}F{}P{}'.format(x, y, z))\n",
        "\n",
        "\n",
        "pathNormal = list()\n",
        "pathFault = list()\n",
        "\n",
        "for i in range(len(folderNormal)):\n",
        "    pathNormal.append(dataPath + '/' + folderNormal[i])\n",
        "    \n",
        "for i in range(len(folderFault)):\n",
        "    pathFault.append(dataPath + '/' + folderFault[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xgGP7PZO-rTA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Specgram settings\n",
        "\n",
        "nsc = 1470\n",
        "nov = nsc/2\n",
        "nff = nsc \n",
        "imgSize = 224\n",
        "\n",
        "# pretrainedModel = 'VGG19'\n",
        "# pretrainedModel = 'Xception'\n",
        "# pretrainedModel = 'ResNet50'\n",
        "\n",
        "# pretrainedModel = 'VGG19'\n",
        "pretrainedModel = 'InceptionV3'\n",
        "#pretrainedModel = 'DenseNet169'\n",
        "#pretrainedModel = 'DenseNet201'\n",
        "\n",
        "\n",
        "lastActivation = 'softmax'\n",
        "sizeBatch = 4\n",
        "numEpochs = 16\n",
        "verb = 1\n",
        "\n",
        "\n",
        "# Learning parameters\n",
        "\n",
        "trainingRatio = 0.8\n",
        "\n",
        "totalDataNum = 1000\n",
        "repeat = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5AskF2qFT2xr",
        "colab_type": "code",
        "outputId": "485a41ce-1175-40d4-c410-906d01bade96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "cell_type": "code",
      "source": [
        "startNum = 0\n",
        "\n",
        "pickNum = int(np.ceil(totalDataNum / len(pathNormal)))\n",
        "\n",
        "for i in range(startNum, len(pathNormal)):\n",
        "\n",
        "    npyTestPath = glob.glob(pathNormal[i] + '/' + '*Image_With_Label.npy')\n",
        "    data = np.load(npyTestPath[0])\n",
        "    \n",
        "    pickIdx = np.random.choice(1000, pickNum, replace=False)\n",
        "    pickIdx.sort()\n",
        "    \n",
        "#     imgs = np.moveaxis(np.dstack(data[:, 0]), 2, 0)\n",
        "#     label = data[:, 1:5]\n",
        "\n",
        "    imgs = np.moveaxis(np.dstack(data[pickIdx, 0]), 2, 0)\n",
        "    label = data[pickIdx, 1:5]\n",
        "    \n",
        "    if i == startNum:\n",
        "        labelListNormal = label\n",
        "        imgsNormal = imgs\n",
        "    else:\n",
        "        labelListNormal = np.vstack([labelListNormal, label])\n",
        "        imgsNormal = np.vstack([imgsNormal, imgs])\n",
        "\n",
        "    print('Normal Image Shape From {}: {}:'.format(pathNormal[i], totalDataNum))    \n",
        "    print('Selected {}/{}:'.format(pickNum * (i + 1), len(data)))    \n",
        "    \n",
        "    \n",
        "print('Normal Image Shape: {}'.format(imgsNormal.shape))\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A1F1P1: 1000:\n",
            "Selected 40/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A1F2P1: 1000:\n",
            "Selected 80/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A1F3P1: 1000:\n",
            "Selected 120/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A1F4P1: 1000:\n",
            "Selected 160/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A1F5P1: 1000:\n",
            "Selected 200/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A2F1P1: 1000:\n",
            "Selected 240/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A2F2P1: 1000:\n",
            "Selected 280/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A2F3P1: 1000:\n",
            "Selected 320/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A2F4P1: 1000:\n",
            "Selected 360/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A2F5P1: 1000:\n",
            "Selected 400/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A3F1P1: 1000:\n",
            "Selected 440/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A3F2P1: 1000:\n",
            "Selected 480/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A3F3P1: 1000:\n",
            "Selected 520/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A3F4P1: 1000:\n",
            "Selected 560/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A3F5P1: 1000:\n",
            "Selected 600/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A4F1P1: 1000:\n",
            "Selected 640/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A4F2P1: 1000:\n",
            "Selected 680/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A4F3P1: 1000:\n",
            "Selected 720/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A4F4P1: 1000:\n",
            "Selected 760/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A4F5P1: 1000:\n",
            "Selected 800/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A5F1P1: 1000:\n",
            "Selected 840/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A5F2P1: 1000:\n",
            "Selected 880/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A5F3P1: 1000:\n",
            "Selected 920/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A5F4P1: 1000:\n",
            "Selected 960/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A5F5P1: 1000:\n",
            "Selected 1000/1000:\n",
            "Normal Image Shape: (1000, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P_MZtpk3Br_i",
        "colab_type": "code",
        "outputId": "fd5422e3-fcec-4b66-8c15-230d54ddf3c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "cell_type": "code",
      "source": [
        "startNum = 0\n",
        "\n",
        "pickNum = int(np.ceil(totalDataNum / len(pathFault)))\n",
        "\n",
        "for i in range(startNum, len(pathFault)):\n",
        "\n",
        "    npyTestPath = glob.glob(pathFault[i] + '/' + '*Image_With_Label.npy')\n",
        "    data = np.load(npyTestPath[0])\n",
        "    \n",
        "    pickIdx = np.random.choice(1000, pickNum, replace=False)\n",
        "    pickIdx.sort()\n",
        "    \n",
        "#     imgs = np.moveaxis(np.dstack(data[:, 0]), 2, 0)\n",
        "#     label = data[:, 1:5]\n",
        "    \n",
        "    imgs = np.moveaxis(np.dstack(data[pickIdx, 0]), 2, 0)\n",
        "    label = data[pickIdx, 1:5]\n",
        "    \n",
        "    if i == startNum:\n",
        "        labelListFault = label\n",
        "        imgsFault = imgs\n",
        "    else:\n",
        "        labelListFault = np.vstack([labelListFault, label])\n",
        "        imgsFault = np.vstack([imgsFault, imgs])\n",
        "\n",
        "    print('Fault Image Shape From {}: {}:'.format(pathFault[i], totalDataNum))    \n",
        "    print('Selected {}/{}:'.format(pickNum * (i + 1), len(data)))     \n",
        "    \n",
        "print('Fault Image Shape: {}'.format(imgsFault.shape))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A1F1P5: 1000:\n",
            "Selected 40/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A1F2P5: 1000:\n",
            "Selected 80/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A1F3P5: 1000:\n",
            "Selected 120/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A1F4P5: 1000:\n",
            "Selected 160/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A1F5P5: 1000:\n",
            "Selected 200/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A2F1P5: 1000:\n",
            "Selected 240/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A2F2P5: 1000:\n",
            "Selected 280/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A2F3P5: 1000:\n",
            "Selected 320/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A2F4P5: 1000:\n",
            "Selected 360/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A2F5P5: 1000:\n",
            "Selected 400/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A3F1P5: 1000:\n",
            "Selected 440/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A3F2P5: 1000:\n",
            "Selected 480/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A3F3P5: 1000:\n",
            "Selected 520/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A3F4P5: 1000:\n",
            "Selected 560/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A3F5P5: 1000:\n",
            "Selected 600/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A4F1P5: 1000:\n",
            "Selected 640/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A4F2P5: 1000:\n",
            "Selected 680/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A4F3P5: 1000:\n",
            "Selected 720/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A4F4P5: 1000:\n",
            "Selected 760/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A4F5P5: 1000:\n",
            "Selected 800/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A5F1P5: 1000:\n",
            "Selected 840/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A5F2P5: 1000:\n",
            "Selected 880/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A5F3P5: 1000:\n",
            "Selected 920/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A5F4P5: 1000:\n",
            "Selected 960/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A5F5P5: 1000:\n",
            "Selected 1000/1000:\n",
            "Fault Image Shape: (1000, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e91QsAurSkIP",
        "colab_type": "code",
        "outputId": "79dfe4e5-a3d8-411e-eab6-6a9596054fb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "cell_type": "code",
      "source": [
        "# Change name from imgsF1 or imgsF5 to imgsNormal and imgsFault\n",
        "\n",
        "dataNumNormal = len(imgsNormal)\n",
        "dataNumFault = len(imgsFault)\n",
        "dataNumNormalTrain = int(dataNumNormal * trainingRatio)\n",
        "dataNumFaultTrain = int(dataNumFault * trainingRatio)\n",
        "dataNumNormalTest = dataNumNormal - dataNumNormalTrain\n",
        "dataNumFaultTest = dataNumFault - dataNumFaultTrain\n",
        "\n",
        "print('Normal Train:Test = {:d}:{:d}'.format(dataNumNormalTrain, dataNumNormalTest))\n",
        "print('Fault  Train:Test = {:d}:{:d}\\n'.format(dataNumFaultTrain, dataNumFaultTest))\n",
        "\n",
        "trainIdxNormal = np.random.choice(dataNumNormal - 1, dataNumNormalTrain, replace=False)\n",
        "testIdxNormal = list(set(range(0, dataNumNormal)) - set(trainIdxNormal))\n",
        "\n",
        "trainImgsNormal = imgsNormal[trainIdxNormal, :, :]\n",
        "testImgsNormal = imgsNormal[testIdxNormal, :, :]\n",
        "\n",
        "print('Normal Training Image Shape {}'.format(trainImgsNormal.shape))\n",
        "print('Normal Test Image Shape {}\\n'.format(testImgsNormal.shape))\n",
        "\n",
        "trainIdxFault  = np.random.choice(dataNumFault - 1, dataNumFaultTrain, replace=False)\n",
        "testIdxFault = list(set(range(0, dataNumFault)) - set(trainIdxFault))\n",
        "\n",
        "trainImgsFault = imgsFault[trainIdxFault, :, :]\n",
        "testImgsFault = imgsFault[testIdxFault, :, :]\n",
        "\n",
        "print('Fault Training Image Shape {}'.format(trainImgsFault.shape))\n",
        "print('Fault Test Image Shape {}\\n'.format(testImgsFault.shape))\n",
        "\n",
        "trainImgs = np.vstack([trainImgsNormal, trainImgsFault])\n",
        "testImgs = np.vstack([testImgsNormal, testImgsFault])\n",
        "\n",
        "print('Training Image Shape {}'.format(trainImgs.shape))\n",
        "print('Test Image Shape {}'.format(testImgs.shape))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal Train:Test = 800:200\n",
            "Fault  Train:Test = 800:200\n",
            "\n",
            "Normal Training Image Shape (800, 224, 224)\n",
            "Normal Test Image Shape (200, 224, 224)\n",
            "\n",
            "Fault Training Image Shape (800, 224, 224)\n",
            "Fault Test Image Shape (200, 224, 224)\n",
            "\n",
            "Training Image Shape (1600, 224, 224)\n",
            "Test Image Shape (400, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MoE7f_hzs0av",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "feQ_AHAcUgHD",
        "colab_type": "code",
        "outputId": "31aa0518-0e1e-4fe2-a8d1-78be5417fe84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "trainMean = np.mean(trainImgs)\n",
        "trainStd = np.std(trainImgs)\n",
        "\n",
        "print('Mean of Training Image: {}'.format(trainMean))\n",
        "print('Standard Deviation of Training Image: {}'.format(trainStd))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean of Training Image: -78.34373686138501\n",
            "Standard Deviation of Training Image: 9.312164965200308\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wUi9IuXNUpir",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Should Change Norm to Normalized\n",
        "\n",
        "trainImgsNorm = (trainImgs - trainMean) / trainStd\n",
        "testImgsNorm = (testImgs - trainMean) / trainStd\n",
        "\n",
        "trainImgsNorm = trainImgsNorm.reshape(list(trainImgsNorm.shape) + [1])\n",
        "testImgsNorm = testImgsNorm.reshape(list(testImgsNorm.shape) + [1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aklxiPz1Ve4n",
        "colab_type": "code",
        "outputId": "cdf69236-6eb8-47ff-9f38-ce1bb5c72e38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = np.stack([trainImgsNorm[:, :, :, 0], trainImgsNorm[:, :, :, 0], trainImgsNorm[:, :, :, 0]], axis = -1)\n",
        "X_test = np.stack([testImgsNorm[:, :, :, 0], testImgsNorm[:, :, :, 0], testImgsNorm[:, :, :, 0]], axis = -1)\n",
        "\n",
        "print('X_train Shape: {}'.format(X_train.shape))\n",
        "print('X_test  Shape: {}'.format(X_test.shape))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train Shape: (1600, 224, 224, 3)\n",
            "X_test  Shape: (400, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sRgIPzT7K_YP",
        "colab_type": "code",
        "outputId": "b242fac9-dfd3-4df7-ed0e-8bbe001ddcf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "trainLabelNormal = np.stack((np.ones(dataNumNormalTrain), np.zeros(dataNumNormalTrain)), axis = -1)\n",
        "testLabelNormal = np.stack((np.ones(dataNumNormalTest), np.zeros(dataNumNormalTest)), axis = -1)\n",
        "\n",
        "trainLabelFault = np.stack((np.zeros(dataNumFaultTrain), np.ones(dataNumFaultTrain)), axis = -1)\n",
        "testLabelFault = np.stack((np.zeros(dataNumFaultTest), np.ones(dataNumFaultTest)), axis = -1)\n",
        "\n",
        "Y_train = np.vstack((trainLabelNormal, trainLabelFault))\n",
        "Y_test = np.vstack((testLabelNormal, testLabelFault))\n",
        "\n",
        "print('Y_train Normal:Fault = {:d}:{:d}'.format(len(trainLabelNormal), len(trainLabelFault)))\n",
        "print('Y_test  Normal:Fault = {:d}:{:d}'.format(len(testLabelNormal), len(testLabelFault)))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Y_train Normal:Fault = 800:800\n",
            "Y_test  Normal:Fault = 200:200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kczwZk7Tbp5C",
        "colab_type": "code",
        "outputId": "7dc100be-15ab-479c-a60d-66b3add59c84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG19\n",
        "from keras.applications import VGG16\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications.densenet import DenseNet169\n",
        "from keras.applications.densenet import DenseNet201\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# pretrainedModel = 'ResNet50'\n",
        "# lastActivation = 'softmax'\n",
        "# lossFunction = 'binary_crossentropy'\n",
        "# sizeBatch = 2\n",
        "# numEpochs = 2\n",
        "# verb = 1\n",
        "\n",
        "for rp in range(repeat):\n",
        "\n",
        "    # Refresh all background variables\n",
        "    K.clear_session()\n",
        "\n",
        "    input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "    # Building sequential model with name 'model'\n",
        "    model = Sequential()\n",
        "\n",
        "    # Model selection\n",
        "\n",
        "    if (pretrainedModel == 'VGG16'):\n",
        "\n",
        "        modelWoTop = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'VGG19'):\n",
        "\n",
        "        modelWoTop = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif pretrainedModel == 'ResNet50':\n",
        "\n",
        "        modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'InceptionV3'):\n",
        "        modelWoTop = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'Xception'):\n",
        "        modelWoTop = Xception(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet169'):\n",
        "\n",
        "        modelWoTop = DenseNet169(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet201'):\n",
        "        modelWoTop = DenseNet201(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    else:\n",
        "        print('Invalid Pretrained Model Selection')\n",
        "\n",
        "\n",
        "\n",
        "    # Model compiling\n",
        "\n",
        "    print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "    print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "    model.fit(X_train, Y_train,\n",
        "              batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "              validation_data=(X_test, Y_test))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 7s 0us/step\n",
            "Compiling Pretrained inception_v3 Model\n",
            "Training Pretrained inception_v3 Model\n",
            "Batch Size: 4\t Epochs: 16\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/16\n",
            "1600/1600 [==============================] - 120s 75ms/step - loss: 0.5641 - acc: 0.7494 - val_loss: 0.4623 - val_acc: 0.7550\n",
            "Epoch 2/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.4895 - acc: 0.7856 - val_loss: 0.5484 - val_acc: 0.8525\n",
            "Epoch 3/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.4438 - acc: 0.8206 - val_loss: 0.9298 - val_acc: 0.8975\n",
            "Epoch 4/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.3455 - acc: 0.8644 - val_loss: 1.8283 - val_acc: 0.6075\n",
            "Epoch 5/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.2703 - acc: 0.9031 - val_loss: 7.8602 - val_acc: 0.5000\n",
            "Epoch 6/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.2488 - acc: 0.9075 - val_loss: 5.3982 - val_acc: 0.6150\n",
            "Epoch 7/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.2658 - acc: 0.9106 - val_loss: 0.1524 - val_acc: 0.9575\n",
            "Epoch 8/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.2141 - acc: 0.9206 - val_loss: 1.4068 - val_acc: 0.8150\n",
            "Epoch 9/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.2155 - acc: 0.9269 - val_loss: 0.1513 - val_acc: 0.9525\n",
            "Epoch 10/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.1730 - acc: 0.9456 - val_loss: 0.1956 - val_acc: 0.9150\n",
            "Epoch 11/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.1755 - acc: 0.9356 - val_loss: 0.1606 - val_acc: 0.9550\n",
            "Epoch 12/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.1822 - acc: 0.9356 - val_loss: 5.4443 - val_acc: 0.5225\n",
            "Epoch 13/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.2029 - acc: 0.9337 - val_loss: 7.0965 - val_acc: 0.5150\n",
            "Epoch 14/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.1742 - acc: 0.9450 - val_loss: 0.3001 - val_acc: 0.8850\n",
            "Epoch 15/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.1589 - acc: 0.9463 - val_loss: 0.1531 - val_acc: 0.9650\n",
            "Epoch 16/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.1360 - acc: 0.9569 - val_loss: 0.1050 - val_acc: 0.9625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-aE0MIEjuC_k",
        "colab_type": "code",
        "outputId": "2f146f96-ac35-4b45-b327-c31b2b9f6116",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "for rp in range(repeat):\n",
        "\n",
        "    # Refresh all background variables\n",
        "    K.clear_session()\n",
        "\n",
        "    input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "    # Building sequential model with name 'model'\n",
        "    model = Sequential()\n",
        "\n",
        "    # Model selection\n",
        "\n",
        "    if (pretrainedModel == 'VGG16'):\n",
        "\n",
        "        modelWoTop = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'VGG19'):\n",
        "\n",
        "        modelWoTop = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif pretrainedModel == 'ResNet50':\n",
        "\n",
        "        modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'InceptionV3'):\n",
        "        modelWoTop = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'Xception'):\n",
        "        modelWoTop = Xception(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet169'):\n",
        "\n",
        "        modelWoTop = DenseNet169(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet201'):\n",
        "        modelWoTop = DenseNet201(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    else:\n",
        "        print('Invalid Pretrained Model Selection')\n",
        "\n",
        "\n",
        "\n",
        "    # Model compiling\n",
        "\n",
        "    print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "    print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "    model.fit(X_train, Y_train,\n",
        "              batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "              validation_data=(X_test, Y_test))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compiling Pretrained inception_v3 Model\n",
            "Training Pretrained inception_v3 Model\n",
            "Batch Size: 4\t Epochs: 16\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/16\n",
            "1600/1600 [==============================] - 120s 75ms/step - loss: 0.6003 - acc: 0.7338 - val_loss: 6.4519 - val_acc: 0.4950\n",
            "Epoch 2/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.5781 - acc: 0.7094 - val_loss: 6.1144 - val_acc: 0.5475\n",
            "Epoch 3/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.4301 - acc: 0.8244 - val_loss: 2.1358 - val_acc: 0.7500\n",
            "Epoch 4/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.4031 - acc: 0.8387 - val_loss: 6.9581 - val_acc: 0.5600\n",
            "Epoch 5/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.3183 - acc: 0.8806 - val_loss: 0.8375 - val_acc: 0.7850\n",
            "Epoch 6/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.2994 - acc: 0.8800 - val_loss: 5.0016 - val_acc: 0.5000\n",
            "Epoch 7/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.3132 - acc: 0.8806 - val_loss: 4.7965 - val_acc: 0.4450\n",
            "Epoch 8/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.2603 - acc: 0.8981 - val_loss: 0.2252 - val_acc: 0.9225\n",
            "Epoch 9/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.2711 - acc: 0.8962 - val_loss: 0.1409 - val_acc: 0.9475\n",
            "Epoch 10/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.2089 - acc: 0.9256 - val_loss: 0.2378 - val_acc: 0.9075\n",
            "Epoch 11/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.2247 - acc: 0.9137 - val_loss: 0.4867 - val_acc: 0.8725\n",
            "Epoch 12/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.1903 - acc: 0.9306 - val_loss: 0.1350 - val_acc: 0.9425\n",
            "Epoch 13/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.1481 - acc: 0.9500 - val_loss: 0.4802 - val_acc: 0.8250\n",
            "Epoch 14/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.2258 - acc: 0.9163 - val_loss: 0.1819 - val_acc: 0.9325\n",
            "Epoch 15/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.1603 - acc: 0.9438 - val_loss: 0.1456 - val_acc: 0.9550\n",
            "Epoch 16/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.1770 - acc: 0.9381 - val_loss: 0.9563 - val_acc: 0.8000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "15t3_glRqbHT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        },
        "outputId": "0a5f70ce-0b82-4533-910b-6873eeb5e073"
      },
      "cell_type": "code",
      "source": [
        "# Refresh all background variables\n",
        "K.clear_session()\n",
        "\n",
        "input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "# Building sequential model with name 'model'\n",
        "model = Sequential()\n",
        "\n",
        "# Model selection\n",
        "\n",
        "if (pretrainedModel == 'VGG16'):\n",
        "\n",
        "    modelWoTop = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'VGG19'):\n",
        "\n",
        "    modelWoTop = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif pretrainedModel == 'ResNet50':\n",
        "\n",
        "    modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'InceptionV3'):\n",
        "    modelWoTop = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'Xception'):\n",
        "    modelWoTop = Xception(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'DenseNet169'):\n",
        "\n",
        "    modelWoTop = DenseNet169(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'DenseNet201'):\n",
        "    modelWoTop = DenseNet201(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "else:\n",
        "    print('Invalid Pretrained Model Selection')\n",
        "\n",
        "\n",
        "\n",
        "# Model compiling\n",
        "\n",
        "print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compiling Pretrained inception_v3 Model\n",
            "Training Pretrained inception_v3 Model\n",
            "Batch Size: 4\t Epochs: 16\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/16\n",
            "1600/1600 [==============================] - 120s 75ms/step - loss: 0.5943 - acc: 0.7494 - val_loss: 6.4394 - val_acc: 0.5575\n",
            "Epoch 2/16\n",
            "1600/1600 [==============================] - 101s 63ms/step - loss: 0.5115 - acc: 0.7719 - val_loss: 0.3909 - val_acc: 0.8975\n",
            "Epoch 3/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.4870 - acc: 0.7688 - val_loss: 0.2405 - val_acc: 0.9300\n",
            "Epoch 4/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.4062 - acc: 0.8300 - val_loss: 0.2703 - val_acc: 0.8900\n",
            "Epoch 5/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.3265 - acc: 0.8769 - val_loss: 4.0080 - val_acc: 0.5025\n",
            "Epoch 6/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.3542 - acc: 0.8606 - val_loss: 0.2093 - val_acc: 0.9175\n",
            "Epoch 7/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.3426 - acc: 0.8619 - val_loss: 4.5306 - val_acc: 0.3325\n",
            "Epoch 8/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.3181 - acc: 0.8731 - val_loss: 4.2996 - val_acc: 0.5000\n",
            "Epoch 9/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.2752 - acc: 0.8900 - val_loss: 0.2100 - val_acc: 0.9250\n",
            "Epoch 10/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.2361 - acc: 0.9056 - val_loss: 0.1666 - val_acc: 0.9250\n",
            "Epoch 11/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.2936 - acc: 0.8863 - val_loss: 2.5078 - val_acc: 0.6075\n",
            "Epoch 12/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.2490 - acc: 0.8994 - val_loss: 1.2923 - val_acc: 0.7950\n",
            "Epoch 13/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.3107 - acc: 0.8831 - val_loss: 0.2227 - val_acc: 0.9225\n",
            "Epoch 14/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.2101 - acc: 0.9169 - val_loss: 2.0016 - val_acc: 0.7975\n",
            "Epoch 15/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.1768 - acc: 0.9344 - val_loss: 0.5776 - val_acc: 0.8375\n",
            "Epoch 16/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.1815 - acc: 0.9306 - val_loss: 0.2293 - val_acc: 0.9300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f99774469e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "JJoK167dqbdS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        },
        "outputId": "bd010451-4ac0-4dc8-da73-a6f503e2a7af"
      },
      "cell_type": "code",
      "source": [
        "K.clear_session()\n",
        "\n",
        "input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "# Building sequential model with name 'model'\n",
        "model = Sequential()\n",
        "\n",
        "# Model selection\n",
        "\n",
        "if (pretrainedModel == 'VGG16'):\n",
        "\n",
        "    modelWoTop = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'VGG19'):\n",
        "\n",
        "    modelWoTop = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif pretrainedModel == 'ResNet50':\n",
        "\n",
        "    modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'InceptionV3'):\n",
        "    modelWoTop = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'Xception'):\n",
        "    modelWoTop = Xception(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'DenseNet169'):\n",
        "\n",
        "    modelWoTop = DenseNet169(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'DenseNet201'):\n",
        "    modelWoTop = DenseNet201(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "else:\n",
        "    print('Invalid Pretrained Model Selection')\n",
        "\n",
        "\n",
        "\n",
        "# Model compiling\n",
        "\n",
        "print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compiling Pretrained inception_v3 Model\n",
            "Training Pretrained inception_v3 Model\n",
            "Batch Size: 4\t Epochs: 16\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/16\n",
            "1600/1600 [==============================] - 120s 75ms/step - loss: 0.7091 - acc: 0.7331 - val_loss: 7.2048 - val_acc: 0.5125\n",
            "Epoch 2/16\n",
            "1600/1600 [==============================] - 102s 63ms/step - loss: 0.4870 - acc: 0.7875 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 3/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.5075 - acc: 0.7712 - val_loss: 6.3553 - val_acc: 0.5525\n",
            "Epoch 4/16\n",
            "1600/1600 [==============================] - 102s 63ms/step - loss: 0.4587 - acc: 0.7887 - val_loss: 3.4481 - val_acc: 0.4450\n",
            "Epoch 5/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.3832 - acc: 0.8481 - val_loss: 0.3242 - val_acc: 0.8875\n",
            "Epoch 6/16\n",
            "1600/1600 [==============================] - 102s 63ms/step - loss: 0.3576 - acc: 0.8644 - val_loss: 0.3798 - val_acc: 0.9000\n",
            "Epoch 7/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.2869 - acc: 0.8938 - val_loss: 0.3986 - val_acc: 0.8200\n",
            "Epoch 8/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.2953 - acc: 0.8894 - val_loss: 0.1924 - val_acc: 0.9300\n",
            "Epoch 9/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.2619 - acc: 0.9100 - val_loss: 8.0071 - val_acc: 0.5000\n",
            "Epoch 10/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.2572 - acc: 0.8981 - val_loss: 0.3440 - val_acc: 0.8300\n",
            "Epoch 11/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.1888 - acc: 0.9312 - val_loss: 1.4722 - val_acc: 0.8125\n",
            "Epoch 12/16\n",
            "1600/1600 [==============================] - 102s 63ms/step - loss: 0.1864 - acc: 0.9319 - val_loss: 0.1825 - val_acc: 0.9325\n",
            "Epoch 13/16\n",
            "1600/1600 [==============================] - 100s 63ms/step - loss: 0.1661 - acc: 0.9413 - val_loss: 0.1075 - val_acc: 0.9625\n",
            "Epoch 14/16\n",
            "1600/1600 [==============================] - 100s 63ms/step - loss: 0.2131 - acc: 0.9194 - val_loss: 1.5446 - val_acc: 0.8325\n",
            "Epoch 15/16\n",
            "1600/1600 [==============================] - 101s 63ms/step - loss: 0.1717 - acc: 0.9375 - val_loss: 0.6088 - val_acc: 0.9325\n",
            "Epoch 16/16\n",
            "1600/1600 [==============================] - 101s 63ms/step - loss: 0.1777 - acc: 0.9381 - val_loss: 0.3073 - val_acc: 0.8550\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f98675f6ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "z-sV54Vuqbl1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        },
        "outputId": "30b7070e-ae81-4008-995b-b44be0386ddf"
      },
      "cell_type": "code",
      "source": [
        "K.clear_session()\n",
        "\n",
        "input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "# Building sequential model with name 'model'\n",
        "model = Sequential()\n",
        "\n",
        "# Model selection\n",
        "\n",
        "if (pretrainedModel == 'VGG16'):\n",
        "\n",
        "    modelWoTop = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'VGG19'):\n",
        "\n",
        "    modelWoTop = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif pretrainedModel == 'ResNet50':\n",
        "\n",
        "    modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'InceptionV3'):\n",
        "    modelWoTop = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'Xception'):\n",
        "    modelWoTop = Xception(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'DenseNet169'):\n",
        "\n",
        "    modelWoTop = DenseNet169(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'DenseNet201'):\n",
        "    modelWoTop = DenseNet201(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "else:\n",
        "    print('Invalid Pretrained Model Selection')\n",
        "\n",
        "\n",
        "\n",
        "# Model compiling\n",
        "\n",
        "print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compiling Pretrained inception_v3 Model\n",
            "Training Pretrained inception_v3 Model\n",
            "Batch Size: 4\t Epochs: 16\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/16\n",
            "1600/1600 [==============================] - 121s 76ms/step - loss: 0.6636 - acc: 0.6869 - val_loss: 0.4237 - val_acc: 0.8750\n",
            "Epoch 2/16\n",
            "1600/1600 [==============================] - 103s 64ms/step - loss: 0.5084 - acc: 0.7656 - val_loss: 0.5999 - val_acc: 0.7675\n",
            "Epoch 3/16\n",
            "1600/1600 [==============================] - 103s 64ms/step - loss: 0.4786 - acc: 0.7913 - val_loss: 3.1675 - val_acc: 0.5000\n",
            "Epoch 4/16\n",
            "1600/1600 [==============================] - 103s 64ms/step - loss: 0.4941 - acc: 0.7806 - val_loss: 0.9041 - val_acc: 0.5350\n",
            "Epoch 5/16\n",
            "1600/1600 [==============================] - 103s 64ms/step - loss: 0.3663 - acc: 0.8600 - val_loss: 0.2711 - val_acc: 0.8900\n",
            "Epoch 6/16\n",
            "1600/1600 [==============================] - 103s 64ms/step - loss: 0.2429 - acc: 0.9219 - val_loss: 0.2757 - val_acc: 0.9075\n",
            "Epoch 7/16\n",
            "1600/1600 [==============================] - 103s 64ms/step - loss: 0.2226 - acc: 0.9225 - val_loss: 0.1649 - val_acc: 0.9375\n",
            "Epoch 8/16\n",
            "1600/1600 [==============================] - 103s 64ms/step - loss: 0.1890 - acc: 0.9388 - val_loss: 0.1431 - val_acc: 0.9525\n",
            "Epoch 9/16\n",
            "1600/1600 [==============================] - 103s 64ms/step - loss: 0.2605 - acc: 0.9106 - val_loss: 0.4750 - val_acc: 0.8750\n",
            "Epoch 10/16\n",
            "1600/1600 [==============================] - 103s 64ms/step - loss: 0.2736 - acc: 0.8906 - val_loss: 5.2690 - val_acc: 0.6225\n",
            "Epoch 11/16\n",
            "1600/1600 [==============================] - 103s 64ms/step - loss: 0.2464 - acc: 0.9081 - val_loss: 0.2773 - val_acc: 0.9125\n",
            "Epoch 12/16\n",
            "1600/1600 [==============================] - 103s 64ms/step - loss: 0.2035 - acc: 0.9306 - val_loss: 0.4531 - val_acc: 0.8975\n",
            "Epoch 13/16\n",
            "1600/1600 [==============================] - 103s 64ms/step - loss: 0.1935 - acc: 0.9350 - val_loss: 0.7050 - val_acc: 0.7550\n",
            "Epoch 14/16\n",
            "1600/1600 [==============================] - 103s 64ms/step - loss: 0.2056 - acc: 0.9325 - val_loss: 0.3214 - val_acc: 0.9125\n",
            "Epoch 15/16\n",
            "1600/1600 [==============================] - 103s 64ms/step - loss: 0.1889 - acc: 0.9362 - val_loss: 0.9955 - val_acc: 0.6825\n",
            "Epoch 16/16\n",
            "1600/1600 [==============================] - 103s 64ms/step - loss: 0.1855 - acc: 0.9394 - val_loss: 0.1766 - val_acc: 0.9425\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f98501b3e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "c-TT_erUqbso",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        },
        "outputId": "3d3f6e41-2ecd-4084-b775-0e06e0375fb8"
      },
      "cell_type": "code",
      "source": [
        "K.clear_session()\n",
        "\n",
        "input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "# Building sequential model with name 'model'\n",
        "model = Sequential()\n",
        "\n",
        "# Model selection\n",
        "\n",
        "if (pretrainedModel == 'VGG16'):\n",
        "\n",
        "    modelWoTop = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'VGG19'):\n",
        "\n",
        "    modelWoTop = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif pretrainedModel == 'ResNet50':\n",
        "\n",
        "    modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'InceptionV3'):\n",
        "    modelWoTop = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'Xception'):\n",
        "    modelWoTop = Xception(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'DenseNet169'):\n",
        "\n",
        "    modelWoTop = DenseNet169(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'DenseNet201'):\n",
        "    modelWoTop = DenseNet201(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "else:\n",
        "    print('Invalid Pretrained Model Selection')\n",
        "\n",
        "\n",
        "\n",
        "# Model compiling\n",
        "\n",
        "print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compiling Pretrained inception_v3 Model\n",
            "Training Pretrained inception_v3 Model\n",
            "Batch Size: 4\t Epochs: 16\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/16\n",
            "1600/1600 [==============================] - 120s 75ms/step - loss: 0.5769 - acc: 0.7494 - val_loss: 0.8580 - val_acc: 0.6525\n",
            "Epoch 2/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.4396 - acc: 0.8225 - val_loss: 0.3141 - val_acc: 0.8975\n",
            "Epoch 3/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.3888 - acc: 0.8419 - val_loss: 0.3830 - val_acc: 0.8150\n",
            "Epoch 4/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.3216 - acc: 0.8831 - val_loss: 0.2264 - val_acc: 0.9225\n",
            "Epoch 5/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.3063 - acc: 0.8838 - val_loss: 0.3543 - val_acc: 0.8500\n",
            "Epoch 6/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.2686 - acc: 0.9006 - val_loss: 0.4878 - val_acc: 0.8450\n",
            "Epoch 7/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.2532 - acc: 0.9081 - val_loss: 1.2150 - val_acc: 0.5400\n",
            "Epoch 8/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.3157 - acc: 0.8806 - val_loss: 0.7998 - val_acc: 0.7850\n",
            "Epoch 9/16\n",
            "1600/1600 [==============================] - 103s 64ms/step - loss: 0.2458 - acc: 0.9150 - val_loss: 1.6078 - val_acc: 0.5875\n",
            "Epoch 10/16\n",
            "1600/1600 [==============================] - 103s 64ms/step - loss: 0.2936 - acc: 0.8800 - val_loss: 0.5136 - val_acc: 0.7475\n",
            "Epoch 11/16\n",
            "1600/1600 [==============================] - 103s 64ms/step - loss: 0.2745 - acc: 0.8875 - val_loss: 0.8760 - val_acc: 0.8450\n",
            "Epoch 12/16\n",
            "1600/1600 [==============================] - 103s 64ms/step - loss: 0.2002 - acc: 0.9237 - val_loss: 1.7217 - val_acc: 0.7750\n",
            "Epoch 13/16\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.1943 - acc: 0.9319 - val_loss: 0.1672 - val_acc: 0.9350\n",
            "Epoch 14/16\n",
            "1600/1600 [==============================] - 103s 64ms/step - loss: 0.1920 - acc: 0.9275 - val_loss: 0.4416 - val_acc: 0.7775\n",
            "Epoch 15/16\n",
            "1600/1600 [==============================] - 103s 64ms/step - loss: 0.1738 - acc: 0.9394 - val_loss: 0.5489 - val_acc: 0.9075\n",
            "Epoch 16/16\n",
            "1600/1600 [==============================] - 103s 64ms/step - loss: 0.2448 - acc: 0.9094 - val_loss: 0.7523 - val_acc: 0.7900\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f983d26ffd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "id": "eA9GZhLGe5X9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "# print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "# model.fit(X_train, Y_train,\n",
        "#           batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "#           validation_data=(X_test, Y_test))\n",
        "\n",
        "# Y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qexmaPZVz04q",
        "colab_type": "code",
        "outputId": "f6abc058-c5c9-4e3f-b614-1f98dad3138f",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "cell_type": "code",
      "source": [
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.plot(Y_test[:, 1], 'r')\n",
        "\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.plot(Y_pred[:, 1], 'b')\n",
        "\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.plot(Y_test[:, 1] - Y_pred[:, 1], 'g')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFKCAYAAAAqkecjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzsnXmYFcW5/799zpl9hmGAGQRRRBZZ\nZBWiSABFREWjxKuAG5rgdsHlmrjwQ3PlJsZEJXqjiVFQE6NRcYsx0SsmQhQRcSFBQSICBhFZZthm\nnzlL/f4o6nR1dXWfPjNn6TPzfp5nnjlLn+5auuutd6m3DMYYA0EQBEEQGSeQ7QIQBEEQRGeFhDBB\nEARBZAkSwgRBEASRJUgIEwRBEESWICFMEARBEFmChDBBEARBZImQl4M2b96MefPm4YorrsCll15q\n+e69997D/fffj2AwiEmTJmH+/Pmu56qurmt7aTVUVBTjwIHGlJ4zW1Bd/AnVxZ9QXfxHR6kHkPq6\nVFaWaT9PqAk3NjbiJz/5CcaPH6/9/q677sJDDz2EZ599FqtXr8aWLVvaV9IkCYWCGb1eOqG6+BOq\niz+huviPjlIPIHN1SagJ5+fnY+nSpVi6dKntux07dqC8vBy9evUCAEyePBlr1qzBgAEDUl9SgiDa\nRzQKHDoEoza11qiskR+juviNDlIPVliUsWslFMKhUAihkP6w6upqdOvWLf6+W7du2LFjR+pKRxBE\nyuh61hTgn/9Aj2wXJIVQXfxHR6hHrLwrsG0rgLy0X8uTTziVVFQUp1zNd7K15yJUF3/SIeqycQNQ\nUQFMnJjtkhCErwn07g106YJKBwU0lbTrClVVVaipqYm/37NnD6qqqlx/k2qnfWVlWcqDvbIF1cWf\ndJS69IhGYQwbhurHns52UVJCR+kXoOPUpaPUAwAqQ6GU1qXNgVlu9OnTB/X19fj6668RiUSwcuVK\nTJgwoT2nJAgiHTAGIxYDgh0ncIYgOgIJNeENGzbgnnvuwc6dOxEKhbB8+XJMmTIFffr0wemnn45F\nixbhhz/8IQBg+vTp6NevX9oLTRBEkkSj/D8JYYLwFQmF8PHHH4+nnnrK8ftx48Zh2bJlKS0UQRAp\nRgjhDPi4CILwDmXMIojOAGnCBOFLSAgTRCfAiEb4CxLCBOErSAgTRGeANGGC8CUkhAmiMxCN8f/k\nEyYIX0FCmCA6AxEyRxOEHyEhTBCdACNG5miC8CMkhAmiM0A+YYLwJSSECaIzQOuECcKXkBAmiE4A\nLVEiCH9CQpggOgMiOpqEMEH4ChLCBNEZIJ8wQfgSEsIE0RkgnzBB+BISwgTRCSCfMEH4ExLCBNEZ\nIHM0QfgSEsIE0RkgIUwQvoSEMEF0Bih3NEH4EhLCBNEJIJ8wQfgTEsIE0RkgczRB+BISwgTRGaAl\nSgThS0gIE0RngHZRIghfQkKYIDoBBu0nTBC+hIQwQXQGKHc0QfgSEsIE0RkgnzBB+BISwgTRGSCf\nMEH4EhLCBNEJIJ8wQfgTEsIE0RmgdcIE4UtICBNEZ4B8wgThS0gIE0QnwCBNmCB8CQlhgugMkBAm\nCF9CQpggOgMkhAnCl5AQJojOQIx8wgThRzw9kXfffTfWr18PwzCwcOFCjBgxIv7dlClTcMQRRyB4\neIa9ePFi9OzZMz2lJQiiTdASJYLwJwmF8AcffIDt27dj2bJl2Lp1KxYuXIhly5ZZjlm6dClKSkrS\nVkiCINoJpa0kCF+S0By9Zs0aTJ06FQDQv39/HDp0CPX19WkvGEEQKYR8wgThSxIK4ZqaGlRUVMTf\nd+vWDdXV1ZZj7rzzTlx00UVYvHgxGGOpLyVBEO2DfMIE4UuSfiJVIXvDDTdg4sSJKC8vx/z587F8\n+XKceeaZjr+vqChGKJTa2XhlZVlKz5dNqC7+JOfrUnD4mQsGc78uElQX/9FR6gFkpi4JhXBVVRVq\namri7/fu3YvKysr4+xkzZsRfT5o0CZs3b3YVwgcONLa1rFoqK8tQXV2X0nNmC6qLP+kIdSmubUQJ\nAASDOV8XQUfoF0FHqUtHqQeQ+ro4CfSE5ugJEyZg+fLlAICNGzeiqqoKpaWlAIC6ujrMnTsXra2t\nAIAPP/wQAwcOTFWZCYJIFWSOJghfkvCJHDNmDIYNG4bZs2fDMAzceeedePnll1FWVobTTz8dkyZN\nwqxZs1BQUIChQ4e6asEEQWQHg6KjCcKXeJoW33zzzZb3gwcPjr++/PLLcfnll6e2VARBpBZaJ0wQ\nvoQyZhFEZ4CWKBGELyEhTBCdAfIJE4QvISFMEJ0A2sqQIPwJCWGC6AxESAgThB8hIUwQnYEYCWGC\n8CMkhAmiMxAlnzBB+BESwgTRCaCtDAnCn5AQJojOAAVmEYQvISFMEJ0B8gkThC8hIUwQnQGRtpJ8\nwgThK0gIE0QngHzCBOFPSAgTRGeAzNEE4UtICBNEZ4ACswjCl5AQJohOgEHrhAnCl5AQJojOAKWt\nJAhfQkKYIDoD5BMmCF9CQpggOgPCHB2gR54g/AQ9kQTRCTCiUbBgEDCMbBeFIAgJEsIE0RmIRsgU\nTRA+hIQwQXQGolESwgThQ0gIE0RnIBoDC9LyJILwGySECaITYJAmTBC+hIQwQXQGohEgSI87QfgN\neioJojMQjQIB0oQJwm+QECaIzkA0CkYpKwnCd5AQJohOAPmECcKfkBAmiM4ACWGC8CUkhAmiMxCN\nUspKgvAh9FQSRCfAIJ8wQfgSEsIE0RmgtJUE4UtICBNEZyAaoyVKBOFDPAnhu+++G7NmzcLs2bPx\nySefWL577733cMEFF2DWrFn49a9/nZZCEgTRTsQuSgRB+IqEQviDDz7A9u3bsWzZMvz0pz/FT3/6\nU8v3d911Fx566CE8++yzWL16NbZs2ZK2whIE0TaMWBQIkRAmCL+RMFJjzZo1mDp1KgCgf//+OHTo\nEOrr61FaWoodO3agvLwcvXr1AgBMnjwZa9aswYABA9JbapmaGgS+3pu566WTplIE9tVnuxSpgeri\nLyLkEyYIP5JQCNfU1GDYsGHx9926dUN1dTVKS0tRXV2Nbt26Wb7bsWNHekqqIe+9d4Hvno3ujGXs\nmumme7YLkEKoLv6C5eVnuwgEQSgkvWaBtVPgVVQUI5Qqs9jJY4FrrwXqc1xLIYgMkH/JJQCAysqy\nLJckdVBd/EdHqQeQmbokFMJVVVWoqamJv9+7dy8qKyu13+3ZswdVVVWu5ztwoLGtZdVQiMqHH0Z1\ndV0Kz5k9KivLqC4+pEPVBeg4delI/dJB6tJR6gGkvi5OAj1hYNaECROwfPlyAMDGjRtRVVWF0tJS\nAECfPn1QX1+Pr7/+GpFIBCtXrsSECRNSVmiCIAiC6Mgk1ITHjBmDYcOGYfbs2TAMA3feeSdefvll\nlJWV4fTTT8eiRYvwwx/+EAAwffp09OvXL+2FJgiCIIiOgMHa6+QlCIIgCKJNUMYsgiAIgsgSJIQJ\ngiAIIkuQECYIgiCILEFCmCAIgiCyBAlhgiAIgsgSJIQJgiAIIksknbbST9x9991Yv349DMPAwoUL\nMWLEiGwXyTNr167FjTfeiIEDBwIABg0ahCuvvBK33norotEoKisrcd999yE/37/5fjdv3ox58+bh\niiuuwKWXXopdu3Zpy//qq6/iySefRCAQwMyZM3HhhRdmu+g21LosWLAAGzduRNeuXQEAc+fOxSmn\nnJITdbn33nvx8ccfIxKJ4JprrsHw4cNztl/UuqxYsSIn+6WpqQkLFizAvn370NLSgnnz5mHw4ME5\n1y+6eixfvjwn+0TQ3NyMc845B/PmzcP48eMz3ycsR1m7di27+uqrGWOMbdmyhc2cOTPLJUqO999/\nn11//fWWzxYsWMBef/11xhhjv/jFL9gf/vCHbBTNEw0NDezSSy9ld9xxB3vqqacYY/ryNzQ0sGnT\nprHa2lrW1NTEzj77bHbgwIFsFt2Gri633XYbW7Fihe04v9dlzZo17Morr2SMMbZ//342efLknO0X\nXV1ytV9ee+01tmTJEsYYY19//TWbNm1aTvaLrh652ieC+++/n51//vnspZdeykqf5Kw52mmLxVxm\n7dq1OO200wAAp556KtasWZPlEjmTn5+PpUuXWnKF68q/fv16DB8+HGVlZSgsLMSYMWOwbt26bBVb\ni64uOnKhLuPGjcMvf/lLAECXLl3Q1NSUs/2iq0s0GrUdlwt1mT59Oq666ioAwK5du9CzZ8+c7Bdd\nPXT4vR6CrVu3YsuWLTjllFMAZGcMy1khXFNTg4qKivh7scViLrFlyxZce+21uOiii7B69Wo0NTXF\nzc/du3f3dX1CoRAKCwstn+nKX1NTY9vu0m/10tUFAJ5++mnMmTMHN910E/bv358TdQkGgyguLgYA\nvPjii5g0aVLO9ouuLsFgMCf7RTB79mzcfPPNWLhwYc72C2CtB5CbzwoA3HPPPViwYEH8fTb6JKd9\nwjIsx7JvHnPMMbjuuutw1llnYceOHZgzZ45llp9r9VFxKn+u1Ou8885D165dMWTIECxZsgS/+tWv\nMHr0aMsxfq7L3/72N7z44ot44oknMG3atPjnudgvcl02bNiQ0/3y3HPPYdOmTbjlllss5cy1fpHr\nsXDhwpzsk1deeQWjRo3CUUcdpf0+U32Ss5qw2xaLuUDPnj0xffp0GIaBo48+Gj169MChQ4fQ3NwM\nwNu2kH6juLjYVn5dP+VCvcaPH48hQ4YAAKZMmYLNmzfnTF1WrVqFRx55BEuXLkVZWVlO94tal1zt\nlw0bNmDXrl0AgCFDhiAajaKkpCTn+kVXj0GDBuVkn/z973/HW2+9hZkzZ+KFF17Aww8/nJVnJWeF\nsNsWi7nAq6++iscffxwAUF1djX379uH888+P1+nNN9/ExIkTs1nEpDn55JNt5R85ciQ+/fRT1NbW\noqGhAevWrcPYsWOzXNLEXH/99dixYwcA7icaOHBgTtSlrq4O9957Lx599NF4tGqu9ouuLrnaLx99\n9BGeeOIJANyV1tjYmJP9oqvHf//3f+dkn/zv//4vXnrpJTz//PO48MILMW/evKz0SU7vorR48WJ8\n9NFH8S0WBw8enO0ieaa+vh4333wzamtrEQ6Hcd1112HIkCG47bbb0NLSgt69e+NnP/sZ8vLysl1U\nLRs2bMA999yDnTt3IhQKoWfPnli8eDEWLFhgK/8bb7yBxx9/HIZh4NJLL8W5556b7eJb0NXl0ksv\nxZIlS1BUVITi4mL87Gc/Q/fu3X1fl2XLluGhhx6ybCn685//HHfccUfO9YuuLueffz6efvrpnOuX\n5uZm3H777di1axeam5tx3XXX4fjjj9c+736ui64excXFuO+++3KuT2QeeughHHnkkfj2t7+d8T7J\naSFMEARBELlMzpqjCYIgCCLXyXh0dHV1XUrPV1FRjAMHGlN6zmxBdfEnVBd/QnXxHx2lHkDq61JZ\nWab93JMmvHnzZkydOhVPP/207bv33nsPF1xwAWbNmoVf//rX7StlGwiFghm/ZrqguvgTqos/obr4\nj45SDyBzdUkohBsbG/GTn/wE48eP135/11134aGHHsKzzz6L1atXY8uWLSkvJEEQBEF0RBKao0VK\nv6VLl9q+27FjB8rLy9GrVy8AwOTJk7FmzRoMGDAg9SVNEatWBREOA9/+dhQ+3hshbaxdG0T//jEU\nFjIUFwOBBNOwL74IIBhkOPZY7/F7X39t4B//AJT1+hYYA6qrDVRVpT8usKbGQHk5QzYDzQ8cAFas\nCGHKlAhefDEPgQBw0klRDBsWQ20t0KWLeWxrK/CXv4QwbVoE8qo7xoD33w9i+PAoSkuBlSuDGDky\ninXrghg+PIaePb215bZtBoqKgF69GN54I4gdOwLIywP69YuhrIzhX/8KgDED27YZKCkB8vMZDh40\ncPzxMQwfHsUf/5iHSASIxYBolJdLh2HYPysqAsaNi+L994MwDGDy5ChWrQqipQUIBvn9GAwCRUUM\ns2ZF0L07w4oVQXzzTQCtrfwcZ58didd1504D3boxfPZZAEceybBpUwAffRRE164MM2ZEsGuXgdWr\ngwiHDZSUMDQ0GBg9OgrDAN5+O4iCAuDEE6OYODGKAweADz8MoksXoH//GHbvNjB8eAwA8NVXBtav\nD+K00yJ4++0QPv44gKoqhquuCmvrCQCHDgG/+10+6uqA/HzgkkvCeO65PDQ28jYrLAS+970wPv44\ngJ07gbPPNvB//xfCoUO8rKedFsHKlSGccEIUO3cGMHJkFF9+GcCHHwYxZUoE//pXAF98YX2AR46M\n4ZxzInj33SDefptrcsOHx5CXB3z8MT923LgYRo6M4pNPAhgzJmZ5Bj//PIBXXglh8OAYzjsvgu3b\nDbzwQh769ePv33sviE8/DSAQAK6+OoxIhN+TkybxREObNgGNjQb+9rcQBg2K4fPPA5g1K4z8fOCR\nR/LR2grMmRNGVRVDJAI8+mge9u834vdLKARccEEYH3wQxNixMQwaFMOyZSFs3hzAjBkR/PvfAaxf\nz69/xhkRNDYa2LnTwNlnR1BWxu/JP/85hE8+cR7YhgyJYfz4KD79NIBJk6IIhYDly0PYvt3AGWdE\nMXBgzPG3acFrkukHH3wwntxe8PHHH7N58+bF3z///PPsF7/4het5wuGI10u2iV27GDvvPMY2bLB/\nt3UrY/z2Z+z22xlraGDszDMZe+YZ/bnOOYexH/84rcXNKNu387p37cpYRQVjN9xgP+bee/nnX3zB\n3w8axNiYMcld55JLGAsEGDt0yPmYBx/kZRHXSSXRKK/DO+8w1tjIWGkpY/Pn24+75RbGHnvM/vmX\nX/I/lUOHGPv6a/vnS5cyduGFjG3c6FymOXN4fYcNM+9BgLE77uD/333XPPYvf+GfHc6TH+fTT/nn\nd9/N2LZt/PUll/D/av3q63k76Ojbl7GJExn7858ZMwyzLIWFjPXoYS2f/BcIMDZjhvP3qf77yU8Y\n+9e/7J/fcAOv23e/y99Pn67//eDBvO/Vz/v25d+J94bB65WXZ74X3+3Zw/umWzf+PhSynmv1asY+\n+4yXqbGRjymrVzMWi/H7Qj62osJelosuMl9fcIF7e3Ttar4uL3c+buxYxoJB9/OINquq4mV99lnG\nrriCsYsvNo/bu5exefPM94MGWc/z+uuM/epX/PWKFfwcuustXGje0wAfT77zHcZOOsm9vqedxsdz\n8X7qVGv7n3QSY5WVZp/OmGFtI7e/SZPM+k+YYH5eXMzYokWMDRjA2MGDzs9zKsl4YFaqnfaVlWWW\nYK+ZM4uwalUILS1h/P73zZZjv/wyAKAEAPDVV61YvDiGN94oxBtvAFOnWgPGGAP+8pcy7N0bwWWX\nNSE/H2nXpNS6pJqNG3n9Dx7k7zdvDqO62tpGt97KgwfWro3gz39uwv79JWhpAaqrGzxfZ9++QsRi\nefj3v+vRqxfTHrN5cz6AAmza1IjycntS/o0bA7j++kL85jfNOO645Gam27cbePDBUuzdG8btt7eg\nvr4U27bZ6/rAA6UYOTKGc89txO23F6CqiuHGG1txzjnFiMWAt9/m96rolzlzCrFuXRC3396Cjz8O\n4r77WvDHP4Zw7bVFAIC33oph3boGHE53HKe62sBzz5UAMLBxI/9s5Mgo1q8P4u23IwBC+PTTJgwa\nFAEA7NwZAlCE3bubUV0djp/nyy+DAIqxc2crvvwyDKAE27bx3+/ZY9YvHAZGjizBuedG8POft8R/\n/53vFGHcuBBqahiKimL4r/8ykJ9v4I47WvDss3n47LMgmpuBigqGH/ygBaNHR1FXZ6C11cBNNxVg\n//4Aqqv59Z55phGlpUAwyLTWFKbvdnz1VQCrVwdxyilRNDQAL7yQhxkzIhg0KBbXrLdtC+Dmmwvx\n1VdmPadNi+CUUyJYuLAQ1dVhbNjQgj/+kZsJXn/dPH9hIcOvf92MZcvy8OabfHibO7cVU6dGUF9v\n4KqrirBrF0NREdC3L8Ptt7fguusK8corBgYOjOLMMyN49NF8tLZy7ezaa8N4/fUQIhHgjDOi+Pe/\nDZx6ahS1tcAzz+Rj5cpmPPVUHj7/PIiDB1uxenUIW7cGcPPNLaioYAAKsXAhv082beJWqAcfbMI/\n/hHEHXcU4quveHsCwK5d/PW554YxfnwUDzyQjxNPjGLDhiAqK2P44IMQqqq4dvjuuyEEAgyPPdaM\nI46IHe53Aw8/nI/ly/n5HnywCX37MjzySB7CYQPz57di4cICbNsWwJ49MQBB7N0L7N5dhyeeKMJf\n/xrCxIlmebZvr8fu3QUA+MC3eTNwwglRHHdcFM88k4+//70FBw8aAPLxySdNWLcuCCAfxcUM11/f\nii++CODll/Pwu9/F0LVrKwCen33dOv4HAGVlDE8/3YRQiN8wq1aF8POfFwAAvvgihrffbgZQfPj6\nMUQiAYwfH8GmTUHs2xdDdXXwcFn53zHHxDB9egSzZkWQl2e/CX/3u3w8/3we3nmHv9+7l/+ddloE\nAwbE8Oij+Vi0CIfLY6R0PHYKzGqXEFbTefkh1eKqVbxKOvNpJGK+jkaBV1/lN9eQIXYhINI4R6MG\n+vUrQ+/eMfzzn1wQff45N4dk3GzRTqJRq90sEnGwowGorzfix0SjDiOqA+K8LS3Ox4iyaDbFAQDc\nckshNmwI4r//uwDLljUleX3zf/iwDIvF7HXldQP27jWwdCn3Tdx4Y2vcPKayd28A1dUGbryRC93r\nr2/FK6/w+2348Cg+/TSIAwcMFBdb2+uFF0LxQR0ALrwwjDFjuBAWbSS3g3gt369qvcQxzc2G7dja\nWgM1NQFs3WqVjmvXhrB2LTeDRiLcXNq3bwzXXBPG7NlhjBxZipYW4K23GtCnj7UOzz4bwhtvBNDS\nwq930klRtCVB3dixMZx/vlnY2bMjtmOOOoo/V4cOGfF7aejQKM44I4KFC3nZhWla5uKLW/Hd70Yw\neXIUffrE8OabIRQWMtxySwtE/v1nn41gxYoQWluBYcOimDEjgq5dm/DVVwFcfHEYoRAwYUIUL72U\nhxdeyMMf/5iHoiKGP/yhCVOmmJ30xRcBPPNMPtav5+Z8APj97/k9VFbGsHhxAWbN4jffccfFcN99\nzZg/vwiLFzdj3LgYmpp4vUT/AYi37YABMcydG8b3v281db/zThADBsTQrRvD979fhBNPjOKcc6zt\nN25cE372s3x0787ibTt+vFnusjJmuX8A/lrcP/IzG4kAjYd1piefbMJrr4WwaFELolHE615QwO+T\nmpoAPv00iLw8YPPm+rirr7iY4emn8+PPyWOPNeGjj4IYPDiKV17JwzXXtFrKN3ZsK0aNiuJ73ytC\nSwuwYYMZHLVzJ2+Mvn0Zdu5kOHSIv584MYJLLgkjGgUuuCDi6B4AgC1bInj+eT7un3JKBBdfHMbq\n1UEsWtSCmhoDjz7KC37iiVGUl4eQiT0n2iWE+/Tpg/r6enz99dc44ogjsHLlSixevDhVZUuaffvM\n1u/SxS445Bvv4EEDH3/MO/jYY+3CVNyU4jfffGMOaBMncm167970aa3pQNVO1EFe/t6chNiPS4T4\nLRc8egEei+nLoJbF7YFyQgzc0agphNXriOtHo8C771qjIJ3KFIkAjJkF2rgxGL9W374xfPppUDup\n2LuX3zsTJkSwenUIM2aE8fXX/DMhnOXfmfeetfLiGKExAsDhNLcWoSReN0uKv9q30SgXcMEg/6K8\nHHjkkSbU1xs2AQxwX5187lAabWji2a2tNesZCJjXjEbNduvbN4bt2wPo3TuGBx5oid8vo0fHcP31\nLTjySAZpA5zD2qn19SmnRAGYHTBlShSnnhrFCy/wwXrevFaLAAa4z7ikhGH9+oClLY4+Oobvf78V\nixYVYts23sfBIMO3vhXDhx+a1iS1PQFTAArLgnrvC78rADzzjH5iGgoBP/qRZoYifR+NGvHnAuD3\nm7jn5Mlia6uBhgb+/vTTIzjrLPPBOOKIGNavD+Doo/mDtGePgc8+C2D4cFhibc46K4Knn87He+/x\nCvfvH8O55/LzXHyx/UEzDN7+o0bxuIF//IM3RlERi09cyssZiosZdu7k35WUMMvEzo3Bg2OW1zNm\nRDBjRiR+nmOPjWHbtgCmTjUtAukm4VXUlH7Lly/HlClT0KdPH5x++ulYtGgRfvjDHwLge03KKeYy\nzUcfmYJSN5DKg9qePQHpc/uxqhAWNCWnlPkKtS7i/e7dBsrKGAoKzO/k+icrhHWzaqdjnDRhISQT\nBY7pkDVJeTKhu34kwoP11N/rhL96jk8/DcTPI9pOf9/x/7fd1orGxlacemoUTz/NKybaSLZKOE1Q\n5HqJ4xsb+f9w2Py9EL7NzQYefjgPQ4fGcPLJZuFFu0SjPAhKcOaZDp0B8zghNIJpXL1RdthqV1dn\nxOscCpn3AhfC/PXkyRFs2xbA6afbNSCdMOrWjWlfqxgGcOedzXjttTzMn28/TyAAjBgRxZo11iH0\nwgvDcSHkNmERddFNntI5wVH7EbBO6lRNuKHBQGEhs5Vp1Kgo3ngjLy6k33sviJYWAyecYD2ub19r\nG1dWerOq9e7NwJiBFStCKCtjGDw4hg8/5IXnQtgcz1X3jxuy9VJnAT333DAefjjfMuFINwm7+/jj\nj8dTTz3l+P24ceOwbNmylBaqrcimnZjGUiwPotabzT7iOpkEhQbjZxgDXn89hHHjorjvvnzMmhXG\n2LExW5uEw7ydJk0qwamnRvDgg6bqJJuLVY1Mx/LlQaxfH8Stt7bGr+Nujrb+V0mFEOaasN7sLWuV\n777LHwPDYGCM3w9uQriyMobq6gA2bDA138JCZim37nelpQwnncQPEBqoThMW7b1tWwDjxpXg/vub\nMXFi1FIvcR0hcGXNRpg1Dx0ysGhRISZOjGDcOHP2yBh3MahC2A1xnDh3OoVwKMS1Em6ONj+TNWFR\n35IS4OWXvc+MvQphAJg/P4z588OO359wgimEx42LIhIBLrssHPfJCkGnu4eFD1Rnjk5328rXApw1\n4XAYaGjgfaEyYkQMb7zBJ0oAtwoBwJgx1uOOPNJ8IAIBhu7dvQph/rumJgMnnRSJT8wAoGtXZnH5\nqO4fN0pKuLXiq68CFq1YcMtlrmyCAAAgAElEQVQtrZg7N+x5pUEq8L9ESQKdSU9G/kyeCbppL2Hl\nGdyxow320QyzalUQ3/teEY4/vhRPPpmP6dO5+dyuDRpobeWm+b17DUs7yAO+k6CUueyyYixeXID6\nev0DrZJICLfPHC3ObThq3OYky0B1tXH4mgZaWkxNcfduA3PnFuKKK6znFcuJhCZsGObyJ92EThYk\nAlUj0d27GzYEsH17AP/4R9Bybtk6IQZxqxDm/4Vvu7HRsN3joo5etS65vIahD8ZKJV26MNTWmpow\nX7rEbwrZJ5yfn9xgqTNHt5WrrzYb/aqrWrF8eSN692Y2QadrY5052k1opwpxXdlVEY0a8YmftTzc\nHK3TNEeN0j+4xx9vfV9SAvTowYVd9+7M8wSjd2+zb046KYrycvN9ly7MUqZkNGH5fIMG2YVwXh4y\nKoCBDiaErULEWbsFrDNBvTnasB0H8OhOvyOEioqqpcmDuVj3KX/HP7cP4G40NJgPtBdN2Ck4TJTF\nMJJ/IKyasLiO0/Wt/d/QYMQ/u/76Qvz5z3l48klrWcVA9c03ATQ0GAiFTCHlNqET2g8ga5b235la\nrjXoSg4WVH3COiFcWyuEsH1CJPre64AvC410mksF5eVMMUebwi0WM+IWjmTX+suaWCJNOBFHHMHw\n4INNOPZYq7lfTBZEP+gEj84sbJqj0ycEzLJZxz83c7STJqxj4ED7ZyLGwKspGrAK4VNPtQrh9mjC\nAHDPPc14990GlJQk9bO04X+JkgSJNGH5e/nm1wlh3U0ZjfJF+35HvmFldH5RM0DJKmyt33m/dn29\nHJjF/z//fAhTpxbHIy3F9QC9+Vb+vC1agRCWPDpaaI/6yPBYzHqvNDSYgllEvYqBXmdmb262mkrd\nzNFyXUyh5hyYpQpY3cRBDKayT1idODY12SdSQvvxOuDL5vN0mksFZWU8MEvUS/YJRyJmHyQrhGXt\nt71CGODR3e+/32BJeKFOsETbyYhjZHO0uBcyY442P5Mn49bALD6B0wmrqiqGXr2sN3tZGYNucUyf\nPrH4b7wim7FPOEHVhKEIYc+nBcDrk2lt140OJYR1wS0yTkLYTWDLN2VTkzkw+5nCQvW91f8okH1B\nqu9X1ZK9Ul9v2ATE6tUhfPJJEN98Y7c+pCM6Wp48OJm9rQLNvEh9vYFYzLC0TTiMw75i/l5ux+Zm\nLpTcNGFxX7qZo+V7V50AqpqwHEgj0EXZCpqa7G6VZAOs5ECidJuiAW5yjEYN1Nfz98Gg3iesWwvq\nRirN0U6oEyw3c7TcV5kIejPN0VafsDpxFse0tNiX3AlGjrTehEccEdM+r23RhMUytSOOiCE/HxpN\n2DxWp6nnEv6XKEmQWBPWaws607U54JqfNTcbcSEs1sf5EXWALisTQth+nKw1qsFBsvnTKfmCSn29\nqXWpQkQnaBL5hNumCZvnVrVI9fqqcBImXCGIRVms2oJ5vNCEhbbjZlWRB1dVW7Leu9Y1pHIfif+q\nGV++3+UBFuA+4fYK4WyYowHTry1PdOQlSu0xR3sNEkoWL5HkwgIh96Pot3QKYd255XtbnhQcOsT/\nOwm5E0/kN62oi5x6VUYI1GSEcEUFsHJlA95+my/r6trV/K1YoiRIVhP2Gx1WCLsNhoB3TVi+KZua\nENfmnMyofkCtu3g4VCEcDpuCVhXC6nuv9a2rM49VTa1OgV86UhUd7aTNmz5Vq8CqrTVfq9qlzhzd\n0mJY/JVusQhWTZhZjte1tVgOJ8qu0/DNslrNiDJcE7aWS7xPNjo6Gs2UOZq3z4EDdnO0VRNO7ryZ\n0IRVU7Ouvdzu63ROcnTnlifj8v0r2t5JyF11VRh/+lNjPMBJFpQyIuOdLh+DG8OGxVBRwV/LAl4s\nURIk6xP2Gx1KCOsGeRmrELaaY+znst+Uzc2GNprVb6j1EckP1IFYHsxV36g60Hs1SbtpwrrzOS1/\nMgOzvF1XRg76MjNmWY/RabUA4ll4AKu1JBzW3xNi4wF3czT/Lw/G6mCo+uMBMzGIaknQCWFdYJZ5\nPsNxfXuy0dH8dfoHPXHPmpowg2Hw/yKqH0jeIlVUxBM/BAIM5eUpLXIctU31mrDz79PZvroYANnq\nJSOeBSdNOD+fZ+Pq25c/XEOH6gfFiROj+NOfGjF7tvNyr0QIAZ+Xx1OOymXKdSGc8dzR6SRRdLST\nIEkksAVNTXJAj4FYLDP+sWRR6+5kjpb9niKFo3kOq6ksEoElmYcTPKLVGh2t03oTZ8zi52iPJhyL\nmRMP1Xyr8/kDViFs1YT1UeLNzYZl6YW7OdocLNR6uVlxVJO6btCUhbCq3QPWesl4HfB1pvR0IgSk\n0MbENUMh3q+i39qSz717d4ampvQ9u2qbuvmE9b9PcYESnFu1egl4Xmh9YJbMAw80Y/ToGP7zP1sB\n2AcJw7CmzmwLYlJWXs4nY+1ZouQ3OpQQloVPoujoRJ/rhbB9La0fhbBad+E3U/2C8sOXyBztVfOX\nA7PczdH6JBqC9mjCOj+33SesP7GbJuxUVjVoSEVcSx547Zqw85I51ZIgT57k8pnltpdBJFXQld0L\nuuVV6URnjhbX5lHv/H1btiP90Y9atLmnU4VdE7ZPdNzGjUwLYdUKJkikCQu6dQP+67/S2KAwNWEx\nOWvPEiW/0cGEsPlaHx2tH4jcEizINDXZBVM296h1wmkQ168VlU2c1mC1tpmjddG9djNuOtNWyr5T\np8AstT4FBQwtLUY8MEultdW5rOryGRXdEiV1MHSb8Mh9JP6r97ea81fFqV5tMUdnIjDLbo42y8ED\ns/j7ZKOjAeC7301vSkK1b90Cs3Rk2iecSBP2g6YpAvXE/46kCftQj2s7Or+aTDKasF4I29fS+hGn\nICS7JmxYBnb1d9bgNW8qqewTNpff2MuVqejoRBmzBELzkgOzZFpbnZOW8MAsa6CVrjy6JUq68jhF\nPlv7yi062l5GEemq4rV95eMytUQJsJujTSHctujoTOBNCDv/Pp3t6xwdbb9vTXN09jXNsjKeGpRv\ntUiasG9JZD51GkQjER7VW1IiR2Dab0quCbuvRfYDzpqw9XPZxKpmzOLHJ19X3TphnTk6nbsoycLK\n9AnrjxF06QLU1Dj7Tnl0tLNJVwyq7hmz5N9YBw5d2wjUrF/66GhrWVXaqwlbTenpH/RErmDRH+Ka\nwSCzaMJ+FMJqm7pt4ODl96lE13dOWfH8JIQNA3jtNTPbDy1R8imJoqOdBMnBgwb69y/DhRcWuf5e\n7LGru56fcDJnqpqwqimq9VFT2Hmhrs6cqHiJjnYSbKY5OvkBQA42c4qOVttImLmchLDYRk2HbI5O\nNmOWrjxqW6ttpQvMisXskx8ZJyGc7BKlZH7THoSZWbS7rAnL/epHd5B6z+o3cHD+fXqjo+2f6ZK/\nAPI64bQVp83QEiWfovo0VZwEidgObtWqkOuxInuPeUwb1LQM4DUS2C06mh9vPdYJOZGHNTDLWh5d\nYJbTedtjZdCtp7Wbb63vhfnTWQg7X09OW+m03E0ssRG0xSfspgkD5iRLpwk71SvZtJX8taeftAtV\nuDqbo/03ANs1YXsZ3YRwJrYylEnsE/ZfG8tlKipyOTAH6FBCuK0+YR26Y9UIU7+ao00fJLO8t2vC\n5nIinV9IFtpubSeft65OXiesmqPt5u1EgVletlFUkQOZnAKz1L4TmrCTxigmajoSmaNjscR+wmSi\no3VWC0AWwvay1tXpy+7V/5hpTdjJpMs3pZcDs9JflmTxYo52a8NM7KIk43Q/iWfPz5pwcXH6d/RK\nNzlefCuJfMLJDOgdwRy9ZEkzysuZoxAGrGt5VcGUaM9lgawxNzTYM0u5J+vQn1No121pY+tSHv1S\nKKeEJk6BWe6aMItrirqJWSSSOIGDuyZs/ZxrLvb+cNOEU+kTzqYmHAhYhbCXteuZRhUKOiFhGM6u\nlmxERzu5hQB/+IRVRJn8qKUnS4cSwslkzEp8LvtN2dDgfD0/YQYC8ahdN1+hLCjdfMJubSf/zhod\nrWZ8sp8vsSbsfF0nxG94sg79edT3RUXc5OpkttUlwBBYtzLUu0FUwaWaKN2io9U6xGJ6YS+C0PTR\n0e3zCbstr0oHql9UTtYhB9y1ZYlSuvGiCbt9nt51wvb2UscFNQuZHwWdMEHnelAW0MGEcFujo3Xo\nfcLZM0fv2GHgP/+zELt3J9bm5SUxIpAFcNKEzYxS9iVKXs3R5nHyHrBqxiydEHbSsIUm3B4hLNcp\nUXR0KMTNbk7WEnkbRhV1cwEVnTla1Y7cJpCmT9ic1Ojuz9ZW4KOPAti50/5YpzYwK/2DsqoJ51Z0\ntH4CYT9O/3mmA7NUy4m6C5sfzdHBIN8dzo8ThGTpsEJYN7gnM6DrBKzqE85kYNaKFSG89FIe3nkn\n8agpBEkgwB86pyVKgFVrcl8n7Hw9+bvaWjPlpD1Zh1xG2D6TaY85Wr9O2LoTlF0IMxQVOT/QiaKj\n3TJmcXO0eyrDZMzRTrl+d+0yMH16CT75xH6POJujvQ1ibtm+0oF7YJbfo6Ot752EsJMvMxNbGcqo\n44LY+tTpvV+4+upWXH552/NR+4UOJYST2U848bnsn6nR0W3R0tqKmvjCDVkTFuY7wL6BA2A1Ralm\nKa9LlOSHWAhg/rka1WuPXhdle++9IE4+uRjbt/PP5eU4ySKfW66zfE+oE6hQyF2rShQd7baBQzRq\nJByY1b2cZVRztFM0q1NqSsDZ1+1dE85sdLSTSVekrTQ1Yf8JCLnshuEcOJSsmToV6PpOfe5VTdiv\n0cd33NGKuXNJCPuKVEZH635v14S9n6+9CIGoE6QqcnIIMWgBek3Yui2f+p37ki+BUzu4maNV7e6j\nj4LYsiWIzz7jo0QqfMJq1KebthkM6oWw0I7do6PNwCxnTdh+PfUY3Wv5nLJPWHcdN7+1PDlyK4cT\n8nGZiEZVfb1OGzj40xytf20/Tj+ByFTGLHHPquOCbBEKBpkvrQ0diQ4lhFMZHa3TpFWfcCY1YafM\nTzpEufjSGW/R0YD9YZTfe/UJ636vMz2rGbPUrFCJMmq5IQt9uc5uflcuhO2DovA5eV8nrHeDJBMd\nrUaqqn0vR33L6PzWiTTFtgjhTJijnZZ0pWIDh3TjdTmXLGxlQZepjFkislydvMmacFFR27LWEd7p\nZEKY/5dn2U6DlG6Q84M5WidIVcRgHQyywz5hA7/4RT7WrbOPCPIDKDRf0T6yJuwmDJ3KZAZ92c8h\na3XyOUQ926MJy+Zvp3SQusAs3YAuBqREPuFEWxmq2o17dLT1WHVi4pSsQ1fGbt3chXCuLFHSBWYF\nApkpS7J4FcJym8qCL1O7KAkh7OYTdouTIFJDhxLCYrDKy2OuQlgebJ3WGXozR2duimgKYS/R0SLf\nLn/oDh40cM89BdpBWmeOFu3jXRPWf+7FHK1GbqtpJtsihGVh6zSRUPvXyewmBiFVE5Yncomio3WB\nWW7maKfALOuOV/br6DThREK4LRs4ZCM6Wg3Mam01fKkFA963fZSFsDwOpTM3t3xNoYC4RUf71R/c\nkehQQliYm/PznddrAtZ1cOqaOLeoXVUAZnKJkvCBedGEreZo92NlTVhcQ8yEvUZHO5ujrUtrdJtf\nqEFjqlBuy0RHLqt1rbNz4F4oZL8XAHMdouoTtg6aiTNmJfYJew/McoqObmiwljE/n+GooxJpwl7T\nVupfp4tAwJrMQvYJAzyq34+JOgDVdO/cvvLERq5LpjJmiWvaA7M6zg5FuUCHEsJiACws1GvCYuCV\nZ9DqbFrV3rxcLxOomqIbamCWG7rdd0SbWLXItgdm6c3RakpL/j8cFoFH+kxXXpCFrbMmbI+OTkYT\nlgeqUIi5buAQiSSOjnYzlasTQ6d1wmoZX365Effc0+ya0MKrQPWq3aUSnZ9UtGNjo381Ye/maLt/\nln+ehkJpyiMmnao5Oj+fR3UDpAlngg4lhGVzs94saI+oVGfTbVkKlAnUwCU3rEuU3GeyusCsZM3R\nuqhr+dxeoqPlSYY80WhPdDRgFUzWJUrW3wQCes1KaMKqKV8+VgTA6c4rPkuURcnNVC6sBIkyZqna\n+re+FUPv3gylpfZjncrhRKY1YUDvh5Y1Yb8KYa/+82z4hHWCX31+ZQuaX9cIdyQ6lRAWn7mZo81N\nB5w1P/GbTJqjRbmSWaIkArPckM3R4rWoX1vSVlrLYSgJM+znU6OjVSHcnuhowHmts84crdMYnTRh\nZ3O0vX+Sz5ilXwrXluhoACgt9WYSdcMvQlj8b2rKDU3YfctC87U6qUsXOnO0Gh0tdqoCSBPOBB1K\nCEci3IySl8ccNRLAXRP2Yo4Wv/evJswfKjlgyAl3TVhvyn3llRAef9y0FYqJgW7W3NJiChWdENT5\nhNurCVt9wnpfq9qOoRBzWCfM/9t9wvrALKcNHNR+MAxrgJObOdqeMcspMEs/QXMTwm3RhDOxRAmw\nTork6GiAT4r8KoTliY3bJEduU7kumYuO1pujg0FzmRxFR6efDiaEjbhWohsMxWey4FU1YS/maPGb\n7ERHJz5W9gknGjBlIaXuTOMUmPW//5uPu+8usH2nmzXLgkFuLzWLlpxQRNb22xsdLaflbEuyDhGY\nomqZsvkwccYsvVtAHhDdoqPNwCwzm5juOnJbH3eceRK33L9tSVuZieho+zWt/8Nhw7eBWYZhtquX\nfYNVi1XmoqP5fzUwS+5f0oTTT4cSwiIKNRBwj46W1wbbNeHEAUHiN9mIjk4mWYcXISwLKVF3Mcmw\nCjBrsJMsoMVrXSSlvPOUTttTfcL2BBttiY62m9jVz/VpK52jo+0+YauW5pQ7Ohbj2ap02o3cN7oJ\nioAxw6b96vzwwmR+7bWteO01c9aQCnN0pndRAqyBWapPGPCvJgzIk4bEQXHqKoZMm6PVJUry9UkT\nTj8dSggLs5+cL1lGt07YKTraTdhlwxyd3Dph/p9v4OA9MMu+Tlivkba2ckGsbrKgE8JWTZj/F4JJ\n/kzUK9WBWU6asDqBSpS2Ut0eUDUfOqWtNBOn2M8tCza3sonzyPeb3DcC0dYDBsTQpYv5eWrM0ZmP\njtalf5TbLBeEsLtP2NSWM+Vzl/tRTDp15mhBR9gq0O90SCEsBxbICG1O1n5V7UcMbm6BWcL3mdm0\nldb/bpjR0YkDs6zmaGv7OJmjVZO9EKB6c7T9HDqBY9bPcDXNeqEtPmFnISx+65zaz20/YXnNtorc\nN9ay2e89sXRLoGovgNnW6j3tFh3tfYlS8r9pL7plUU5+VL8hyulmaZA3pchU++raTzVHy2UhTTj9\ndCghLHxvzkKY/5cHKXXHEC+asBBSmd3AwdkczRjw/vvBuLYmBIY3n7D9tS6TjlUTNizfCwGqe2Bl\nTViXCEUXHe0UEOYVJ2Hl5hN2Mkc7DULWdcLOGbNk14CKrJUkmniom1HozNEiWYd6LTdNuG37CXv7\nTXsR9ZB3IsoVc7Qop5foaDWAMr25o83X4h52N0enrywEx5MQvvvuuzFr1izMnj0bn3zyieW7KVOm\n4OKLL8Zll12Gyy67DHv27ElLQb0QiRhx02Cqo6N1+abbss2eyquvhnDWWcW2vNQqbprwRx8FcO65\nxXj66bzD5eKfe4mOtmbM4v8TRUerwlf815murJqwfSKhBmaFw4kFUiLk3zvtl2wXwvro6Px8fRva\n1wnbz/v++0HMnVt0+Bj3wKxEec/DYcNyv+nN0fy/mnQkV4WwqIdTUJhfA7MAs5xubWWarK0Wq0zt\noqTLB6AeQ5pw+kk45/rggw+wfft2LFu2DFu3bsXChQuxbNkyyzFLly5FiVsIZoYQu9WEQtznGItZ\nb2h9xiyndcLWcxcWmsJGPPztNUeHw8CVV/JB+l//CqBfP/dj+X/74Ltvn2H5L/shk9OEndcJyyZS\nc7MFAwCThLB3n7BAtKGc4tKaJMTAvn0Gunf3Phg47UjktmevkzlabOyQKGOWLjr6T38KYeXKUPz8\nKlYh7B4RHok4r38WiLa2a8L2Y+Wye8FrKsZUohfC5ms/a8I687mKbI6WBXI68bZO2NlSSKSehHOu\nNWvWYOrUqQCA/v3749ChQ6hPpLZlCSGEheB1CpJxM0c7LVGSB91UmaP/9CfziUgUBeyWO1oIT1WL\nTzZjlltglhCcsZg5ETDbyu4TltMLCnTmaDVpR2urtS0OHDAwZEgp3nzTu/rlZKFw87tyIWxvq1CI\naTUuWQA4maPlttVNhqzR0frX8meJoqNFW6tJR0pKcjNtpbimU2S2n4WwvPzICTkwSxbI6S2XPVGR\nei+RTzizJBTCNTU1qKioiL/v1q0bqqurLcfceeeduOiii7B48WIwlr1Oi0RERDB/r/PPBQJW049d\nE9b/VhYwqcqY9f775hOn02xk3NYvC5OruozJy1Zvya4TlicB6vaD8gMrDCO6wCzdchynJUqCHTu8\n2+icLBRuEchOWxk6achOaSutkdmG5RiVZKKjVTO9zhwtSIc52msCilSi04RzxSfsLTra/O9Fc05l\nuQDntJVOG0sQ6SHpEABVyN5www2YOHEiysvLMX/+fCxfvhxnnnmm4+8rKooRCqX2TqusLAPAB6+C\nAqCoKHD4WmUWU5wQ0KWl5tNbUWG9y/Lzi1BZaX94SkrMO7O8nI8OhYWFqKxsu71G3iy7qKjYUhcV\ncwAO2Y4RD4ph5KOyMj9ez6qqMpRJh/7ud8CmTcA995ifWTc44P1SUcHbJxw261xQUIDKygLU1pq/\nLSkpRWWlORj26JEvfQfU1QGA2T7BYB4qK/MswsQwgqisLIsvdwoE8lBcbN9JIRTy3tZOQqK0tBiV\nlfy1Kqh69ChGTY39NxUVRdqBqFs3+R4qxBFH8LKJOgLW/i0pMT8XyOeNRo14v+omEbt3l1qEs9w3\ngYBVcFdWmvUEgCOPtJ9P0L279Vgn5PXe5eX8Xkg3YuKbl2e2jfw8FxU5Py/ZRjwTRUX251UgJqr5\n+QEpkMtIa53kSXG3brwPW1utD0x5eYF0TJGn+0PGr33SFjJRl4RCuKqqCjXS6LR3715USr0yY8aM\n+OtJkyZh8+bNrkL4wAGHBLdtpLKyDNXVdQCASKQEhsEQi8UA5GHPnjqLL6+5uRjBYACtrWEA/CmJ\nRlsAmDfdvn3NqK4Oo6GhEIA5aOblRQFwIcVYGEAeDh7kx7aVgwfNa+zZ0wSgKF4XlZaWEgABNDVF\nUV1tbcOamjwAhTh0KIzq6mY0NxcjFAqguroera0F8bpWVTXgs89ClvrKWmdjYwxAAJEIb5PmZgaA\nS5La2hZUV7ce9juXHi5zA3r2jOHQIX4NwzDbUgRpVVebnzU2RlBd3YS9e81ztLTw+jQ18fo1NERQ\nU9MKwBrltW8fv74XmpuLoLu19+9vRHU1l3D19Wa7AEBdXQNaWgIArOGgjY1NyM+3h4jK901TUxP2\n748AKIvXEQBqa81yRCK8b6wUQ9xTkQhDdXX94delEO0uOO88tY5m3xQVMcs2hvX1Zj15WYNQ29Pp\nWCcOHTL7rLnZe1+0B8Z4+xlGDNXVfBbQ2poP0e6FhXB8XrKNYfC+jUbN+0ElEuHPv2FEETysogaD\n5n2QDuR+jESaARRa7iWA96/5zHq7PwTyeJzrpLouTgI9oWFpwoQJWL58OQBg48aNqKqqQunh6Whd\nXR3mzp2L1sP2jA8//BADBw5MVZmTRkRHC01INd1Go/aIYecNHKy/tfqEhTm6fdHROn+s87FuPmH+\nXzZZ65Z0FBS4m8e8mKN1Wx/q0laa5mi76dktOlpNWylQk2W44eSrd4+OTtYcbfWR6vYTlvs0cXS0\nmfzES8CffG7Vb6f6hN3N0W3ZTzhTaSvtqR9zZfmMlyVKunXC6W5bnU9dFx8hyFSe8M5MwiYeM2YM\nhg0bhtmzZ8MwDNx55514+eWXUVZWhtNPPx2TJk3CrFmzUFBQgKFDh7pqwelGzpgFiAGeab6XlxtZ\nz+G0TlgO4EpVYJbsM1QXzKu4LVESvxWCSt46T65rXp67P0+cR/jJrct7rMFYvCzWz7z6hN3WCTv5\nhNUITjecfcJti47WmaPVXZR0GzhYhbD9HOpnYrclL0JY7ofSUlhM6Wo9UpGswz9LlMzXfo7cFc9Z\nIJB4ApRJn7A8HjhtUyhPBEgIpx9PTXzzzTdb3g8ePDj++vLLL8fll1+e2lK1EREd7ZQ4geeWNpeT\nBALM5hsUg5uXwKz2CmF5kHbT9Bhzzx1tasKmFm/uOmMel5/PXKOl1ehoWdMXwkUOCFInLPI6YSGE\nZTOpHGGtfiYLYzdt3wupjo7WrX9WM2YFAjyphFPwVKKMWbxM3oWwXP6yMmu5k0nW0Za0lZnbRYn/\nd4qO9rMQTiZZR2ajo83XToFt8jHqvUWkng41z1HNzfYlSoYlYliXzEJoXPY0hXbtub3R0bL26yZk\nrBHJdgGjW6Kki87My3N/yMXArhvcdOZode2yvE5YCC69Odr+mbkEy3Coo3O5VbxERydjjtYtgVfN\n0eIc1o0urOfXnVsmEuEadrKbVqgDZTLmaK+RzplKJqG7plN0dC4I4eTXCae3XF6WeAWDwJtvNuCv\nfw1hzJgM7lLTSekwQpgxsZWhPnECYNeU+WtvWxmmxxwtX9d54HXK4SwQg72pmRrahzo/39tDrtMI\n9T5hq59a7xOWz2H3t6vrhHnaSnuZkjFHt80nzJCfb79GKKQXwuLeiUYNi9XBaZ2w3hxtbedYrG0T\nu8JCXn7Rvskl6/B2jWzsomT6hPVrlP0shEV7ecmYJbvQ0j3BcYuHkY8ZNSqGUaPSH3xHdKDc0WLw\nkhNU6NYJW4Mg7IOQt2QdqUlbKWvCbuZoWRPWCShTCMvmaP6Zao728pDrfKBqZiu5XLrc0brALLdk\nHbJPuK7O6psGUq8J6zdw0Jmj9UJYvnfktnbaPCJRYJYoU1smdnl5VoGkajjBIDBnTiu+8x27nb8t\nPuFMmaN1gilXsjnp3GetpgEAACAASURBVEEqcpasbGbMcioXkRk6jBCWE1SYGbPsO9rI0dM6ISwG\nTlUjSYcmrEsZqSPRhgbit/IEQvdQ5+W1RxO2B2aZ2yvy/7I52vQJy+fg/61C2IhbMfg5jcPri4GK\nClkIpyIwy/mYUMi+dhhwNkerkzlxjrZmzAJ4G7QlFWooxCwTIN21Fi9uwVVX2YWw10HfKX9zOsnl\nwKxkoqMz6RP2Yo7OVFpSgtPhhLB8Q+vSVsrR0fIMVOAUHS0PcqYm3L4yy9qvm6ani0iWEb81/dn6\nQYBvRpD4AXPThK1auZnvGbAGZul8wrt3G3jjjaBNI1WzcNXW8t9YhXDCYktldQrM0ueRBvh9oat3\nMMgchDCztTE3T5vHyJMnnQVC/SwWa9s9FQpZXQGqT1guc6IyOJGN6Ohc9gmbE/3E0dFqnEo6MQzz\nuk7R0Zny+ROcDtPcsjnaySesRkfrNGEhyNTgGJ0m3H4hbMSFu9fALC+aMNf47eawRIFZAjchrEtz\n6aYJyz7hmpoA5swpxubN5m3Hc1Gbx0QieiGcbp9wMKgXXqGQfncorjlb17Fyc7T3wCxddHTbhbDV\n4qHDS4S2E4ZhLrfJ3BIle+5o+bWfhXAygVmZ1ITl63qJjibST4cRwubOQaaQVU3K5laH4lhTWHXp\nwv8LoWE3R9ujo1NhjhbXdRMyOj+seh75v1NgFp8FJy6XW2CWzj9trhM2v9P5hAXffGPedqofNBw2\nfcJdu6bGJywmB3Kfqn3ntFGDmznavI9MYZyMOVrvE3be0cYJ1SfsJIS9TATcyJS2JtCtdc8VTTjZ\nJUqZio6Wr+sWmEVkjg4khPngJQ+Ouuho2fQjz0ALCrhfrb5evx5XFjBCILdniVI0yk3L5eX6nUxk\nrNHRZmYlgRqY5ZSsg79PXDadMBLtIQsWYRpvaOAavfxQuwnhAweswVqyiT0cNlBby9fcdu1q/qY9\nQli0sdynug0cdMIr2cAsOdpbNnnrTHyqgI1G9VtoOiG7VdqqCSdjesyktiZfLxd9wl6sBnK+gkxF\nRwPWdtUlEyEhnFk6jBDWbd+ni46WZ52yQM7L41u+iUAid5+wOKbt0dFCqHTpYn2vEo0C69ZZnwq1\nbLp1wk4DpjdNWFcOM3DKvC7/X19voKTEmvhEZ8IViH2PAZ4QRF17XFtroLTUOoFoamq7OVpo1Imi\no3WagdsSJTchrPanLthF7Yto1B6Y5eS3A4Cjj2Y4+ugYxoyJWQSS00Cu14S9B+F4WXaTSvTJOnIl\nOpr/T9YcnYmgKDkdqBcLDZFeOoz1Xwxe1mQd+uho3U2Yl8f/RIYndTCUtcNUmKPFIC20NCdz9IMP\n5uNnP7OqpuGwVduRM2Yx5pysA/D2gOl8o+YSJWs5AKC+Higrs15LJ7gEsiYMqOkxuVDv0sW65WQy\nmrCq5QqTvzxp0vmEDU0XOAVmyVtmymZasWGIatnwmjHLnuXNefJRXs7wxhuNMAzgr39N3LFelkm5\n/57/z1T0bC5rwnKwnhOyGyOTpn6dGVxXLiIzdBhNWI6OdsqYpS5RkoO08vIYSkpMc7SbEE6FOVpo\nr0JAOAmZ//s/+zzJrglbX/MocHvye8D83DD0D5ouYly+pi5ZR329gdJS75qwKoTVYK/aWp0QTkYT\nth4rzNpyf6kTNKeMWc6aMLNM5sRnugA2+RgZVWPVrRN2m3zIEwcvmxnoB9zEvxN4WfuaStTAN/W1\nn4WwbgMVFdkil43ALF3GQPl7IjN0GCFsmqOdM2bxgCWr/0UMLHl5PL1fQwMs61bFOWXtMBWasND+\nCgu5GdRJyPToYReW6jIl1UQcixmOD7X43GkA00WMA87JOmIxbj0oLbUKb25Z0At62RwNWDVhxgwc\nPMjN0bKQOnjQwJw5hdi2LbEwVidQpibsfIzsmpDx5hOWM2ZZXQPy8bpzy8gZs4RpXBeIZ57TbF91\nJyUd7TU9mpsSeP9NexCTOrmeuaYJu7WVrOlnUhOW79v2xgkQ7afDNLcQmvKsUh5odUuY1NclJVyA\nNTdbf6sG7QhN2E0I79hhYN065+YV5ueCAh6V66TxCHO1jDowy0JMBEI5mQ7FA+aWLUc3WOs04b/8\nJYRf/YrPSEpLreZcJ80S4ALVWn67YFU1YQB44408/OUvDlFHEqqATeQTDoWY1hQNJJesQ86YpU6q\nvGihcnS0aDvdunCz3OZrLwKpvVqPl4jfVKITTLKA8PNWhk6WKOsxOHyMfc15OrEu0dTHQRCZowMJ\nYf6fR/zx17pB1yk6WgRmAdy8Kg/SgYBVCAsB5uavGzu2BGeeWWLJGCUjhG5BgdCE9cc1afYDF0K4\npsbARRcVYe9esxvFEiunh9pcI+i8PEE3ExbCQZ4A7NkTwF138cZQNwlwCnQCzHXAAl0du3RhWpP5\nwYPaU1pwio52ypiVaKD0Gh0dCpmTPS+BWepncsYs0XbTpjnP9KwCKbEm3F5zdKaXKOkyZlm34stM\nOdqCl7bSmYUz6RNWn3VdbgEi/XQYIZwoOlr+Xh8dzeKJ7hsarNsByokZAG/maMa4oNm2Td/EQvsr\nLBSasIEPPwSuuKIQ9fXmcYcO2QW9EIRvvx3EW29ZJYiqCTtFRzsFTsntJygoYJJw0U88VCHspgmr\n6M5ZVsa0WqCqRevwEh0tv3Y3GeoDs+R2sibr4K/VwCy3jFli8IvFzN8LAXPyyRF88UUdJk+232zJ\nasLqZMMwvOUSF2R+nbBdKMiv/ayxefHxykLPSyBXqnCKjhbKBQnhzNLhhLB1nbA9GtYaHW2agWRN\nuKGBayRCiASDqibsPW3lli36JrZqwtyk/MwzwOuv5+GDD8ynQCeERb1U36ooOy+zflZrCmFmyXBl\nfm81A4s1jLpkHTLqTj1cE9Yfq6LbvKJLF6ad5Ozf7y6EGbNbKMx1wvq0lXJ9581rxU03tVi+k4Ww\n6Hv53pGTdjiZo90SZci5yMVkZ/z4KGbMCGPatAjKy53zWgu8BWYxSx2SHWzV5CTpxvQJ28sA6KPZ\n/YKXttK5xbIZHW2OdxQdnUk6jBDWZczSaT7y96o2YwphPmCbM0OmNUc7CWE5mcYXX3gRwjwwa/du\n/tneveboIptuu3fnI7QQhDohrJqjVWRflS7oy26igkUIO5nNdZqwkzlaRS+E9QI/kSYs+kS2XAgh\nrGbMkgWqYNGiFvy//9dqSbYgC2ExUMmxB/I9FIvxZWJ2c7S9rOI+lC0rop2rqhiWLGnGgAH2Mprn\nbFtglrhespqkFz9nKkm0gYOfcVoiKCNP4jLpEw6FTCuI3J7m85D+MhAmHUgIm3up6oSwLqOWmqxD\naHP19UITls3R5rkSmaPFLkCAsyYszNFFRQyFhXzQ3rOHf1dTYwqaQ4cMDBkSxcqVDbjwwojluvJx\nAqEJ64LT5M+DQaB7dxEZbo0+VZeEyEtvnDVhu084kTla+Hx1iTjKyph2kqMub1IRv5GvLZYoqRmz\nZEuHijwoylqmPFDpknWIMqhCWJ8xS5TVnCTIUf4yurZMNkhJXK+tmnAml9HI15E1s1wREN7M0eZ/\neUxKN/JualYhbP+MSD85cksnRmg5shDRLUlRI6JlbUY1R8s3pRBUwSCL70TipAnLGmoymvCuXfyz\n6upAvE61tcCQIQzDhsXiZfCiCYuHWU1xKQ9s3brh8PmsplmrOVr4OsXSGyefsPU914S1h8YRZnid\ndt2li94nnEgIiz4vKGDxCUlZmT46uqCAoa7O0A7sTsEr8j1xzjkRFBebsQTy0jh5KRfgpAnzcgl/\nrpzq0mlpmdNnbpm11OPdJh9uZH6JkrtP2M94CXLKVnT0Nde0Yvv2QPzagrZOzoj20WGEsPAVciFr\nNz9afcLma6HhFhaq5mjrTamaxuQ1oU5lAYCtWwOWDFYCdYkSAHz1Ff9fXc2/q6vjAV4isEiUwYtP\nWJRTTSgiCxehCcvI+zGL84RCpuB30oSFoJOvk8gcnZ/PhbBoC8Ng8YC2qiq9TziROVrUV9YcdT58\n1eevwoWvPXBJ/s0ll4RxySVmg8jWB9XErsvRq0aq8+ho/UCo04ST9wlbz5Vs5qtML1HSXS9X/JVe\n2kofHZ3++s2YYT5Yep9w2otASHQIc/Q77wTx/e/zUUjWdJ0Cs+SMWVVVDAsWtODKK1vjvr8bbihC\nOGzEAz9kISxr0V404eZmA9u32wWH0P54sg7+WmixQgiLoCyRX1o8tN58wvqsXnL5e/Swp/wSa2bN\nmTxvoz17uHXAaaOJtkRHC+EjBJYsSI49NqYV+M3NhnZJk0AIbvnaTjECiYSw7nOddqZeZ8WKkE0T\n1uUZF/ehKIccHa2eX5f4ROfPcyMQ4MFMeXks6cho+Xp+CczyM94Cs3TR0ekumVoG/r9LFxafSGcq\nLSnB6RBC+MknTYet7OfVrROWo6PFcT/4QSvGjYvZBInwufKMWTj82jyPk09YaMIDB/ICbNxof7KE\n4OGasPW6qhAWgUWiDKYQtnefukTJvlsQP1cgoNeE1SjNQAAYMCCGlhYDO3YYNuEiaEt0tPhe+ITl\naO0jj9RrwgBw//35OHCAv66vt5rchXVCblNRl2eeycejj/JG5IF3zoEosolQrZf43v4d/2zu3CJ8\n/rm1b3QTNjU6WmQg05UpUXS018FbWDZUt4MXMr9EyX69XPEJe2kreWVGpttWIJ6dgQNj8fJQxqzM\n0iGaWx6E5W3BdFvXydHR6g2vrgddtIirq/I6YWuKQn15hIY6caIQwvZmFr5VsURJRgh/ERkt0i6K\na4fDvG46/6gQwqINJk2KYtSoKB55hKuPck5bNyEsm9MGDuSNt2VLwFETFqZ8AdeE7eeXtW+hAcpW\nAUEg4LxL1S9/WYBf/zofn38ewODBpXjiCVNC6QKz5IH7scfy48eZEyu9Wd5N29V9J/uw1fXhugmF\nOEe/frxN/vjHPCmpjLVMeiGcfMCSsAQ5afruv82sz7CqireLHMWvxjj4FS+a7be+FcWcOa34znfC\nGTf1C8Te3gMGxDzluyZST4cQwrLWsWlTMH4zbdoUwJAhJXjuuZA2Olq92WRB8uKLjfFoZDljlqwJ\nOQlhoQkLIfzZZzohzP8XFtqDavbtMxCLmf5P1Se8e3cAF1+sdwKKDF2inMXFwJtvNuL88yOWOgeD\n+iVK9rWv/AEFeJBZa6vev6laEZw07eOOk4Uw//63v+WCUVgHRD+45U1+990QXnuNm31ffpk3TGsr\n8NOfFhw+t3msPBBu3x7Arl2GtK2lPn+uqimuX1+Pd99tcBXCq1aZHyYjhKdOjeDkkyNYvjyElStD\n8eur5XH6vdP3Oo46Cujdm7VRCNuvm06OPZZh9eoGXHONOfNrT772TOJlOVdpKbB4cQv693dWDNKN\nmMjLmnCumPw7CjkvhFtarAPeuHHR+M30+9/nY9++AH7844L4siFrEIT1XLIQHjrUOjNUzdGBANd8\ndIJYaMKDB0fRo0cMn32mM0dbM2bJRKMGHnssD9/7Hhe0whwtrv3YY3n4+9/1T7dqjlaxRkc7a8KV\nlfy71lZVEza0ZuayMuv7WEyfctEqhK3f1dTwBj/6aH7MlCnOI+769QG8+ipvg48/DuDgQeCpp/Lw\n3HOmQFbrJHj//aC0raWzgJM15F69GAYNirlqLH37mnX78kv7Npr2a5j9euedfFb2+OP52jIn8gl7\n9eN9+CHw+ONN7RLCmdSUBg6MWe4Tt1zafiJZoZptAdi/PwnhbJHThoeGBuC227jQuuyyVlxzTRj9\n+8fw1lvmXRQIMNTUBHDWWdzW7JadRjZHCy1RaErqAFRTY2DvXgN9+pTiyCMZ+vaN4ZhjYti9O4C/\n/pUf1L07w/DhMaxcGcLFFxehtRUYMiSG4mKG3/yGjywFBVbBdMwxMfz73wHccYdpmzXX8/L3e/bY\n5049esRQUxPwkKzD/C80bN33550XxgMPFKC6OoB+/WIIBFhcE87Ls+d7VjVhxkxLgMygQWZdnVJ6\n9unDz3X11WFMmBDFkiX5WLbMao+NRo345CYWMzBokHUWIPvhVc39pz8tQGsr31Hr2GNjOPZYe4Ca\nk5By29j+979vwgsv5GHx4gJb1i6daV0e9EaPjmHUqCj++c+g9vw6c7Tcx0OHxtC9ewxXX+1iPgBQ\nXs4nKPJWjF6R4wSyhZcsdX5g7NgohgyJYtgwbwV2c41kgv79Y5YENUTmyGlN+IMPgvjtb/nroUNj\nGDQohmAQOPpo80ZesqQZ555rDkzdu5vrgdW0jcL3Kv4DwLnnRnDGGREYBjefiht02DA+cI8cGUNz\nM7BqVQhPPZUfF8A9e8bQpQv3Kx91VAx/+1sI77wTwqOP5uOBB7gq2bUrQ+/eMcyZE8Ztt7Vg6FBg\nxgxe1kCA4be/bcJDDzVh8uRo/HjAukznvvua8fvfN2LJEm7L/eQTXkDVRyvo0YNh2rQIzjorgp49\nWbysI0fyawiB9B//YWqhBQVAv34MmzYFsWtXwKJBDxoUjR8DAHfc0YJRo6Lo1Yt/NmAA//6EE/h/\nOQfyd7/L6yrM0j/6UQuOOy6Kn/yk+XAbAMOHx3DbbS045ZQIHniAf37GGeY5LrggjGCQp+AMhRhm\nzw7Hz3XddS149dVGdO3KTb6LFjXjmGNi+OqrAAIBhpNPjuLNNxvxm9/YU3Z9//utuPJKu0CrquLC\nTieI+vVjmDfP6jS/5ppW9OgRw1ln2bX6b387iokTIxgzJhq/pkDWqgHgP/6Dl+WOO1pw5JExBIMM\nI0aYA3xxMbBpUwNuusnBaa8wb14YV13lLrBV1Axh2WDIEF7nyy7zVs9sMXZsDG+/3Yhjj/XWVqNH\nA5df3orvfjez9vaJE/n1+vWLYfz4KEaMiGon50T6MBjLbKhDdXVd4oOS4B//KMPKlS24+upWS4Tu\n/v3c5yJMWfv3A59/HsSIEVGUlAB/+lMIY8dGceSR1upv2WKge3eGigr7tY45phS9e8fw3nuN2LuX\n+22POIL/vrER2LEjgMJCFhfi4hyNjcA33xjo0YPhyy8DaGkxEAoxDB0aQ3Gxef7KyjLs2FGH9euD\nGDkyakvK/803BkaN4pXs2TOGP/yhCUOHxuLLpUaPLsHu3Vw6vPVWA4YPt2t4Klu38nJ16cJ92RUV\n5tKVm28uQFUVw623tuLaawvjvtdzzw3jxz9uQV2dgWOO4UuJ1OjoysoyVFfXoaGBB39wK4GBo45i\nqKriWuurrzbGBdCaNUFMmhRNmA+4pob3z4YNXCsfOTKGPXv4Z/n5XHC3tDhHZkej3K+Yn+8997Co\nC8CjsevrjXi/6xgwoDQeVLd+fT169fL2iDEG/POfAfTowXDUUfbfMGaWORZrm0Yq1yVZrr22EH/+\ncwhffFFvuW8zTWsr77/21MVvZKsu4TB/XtTnt61Qn7ifT0dOm6MBYNo0YPRo+6xYZIOS348fb2oO\n552nn3GKXL06iorMpUpVVdbjioutZmX1O3He0aPdBWNhIXDiiXoTVu/eDN27x7BvXwADB8YwYoR5\nrmAQOP/8CB5+OB9Dh0Y9CWAA6N/frIcaSLV4sZnKatSoaFwIjxgRQ+/eDAA/3m0pUkmJ6VNWBcv+\n/UZ8kiS0/UQIN4FcP3Ui5VaetvhCZUpL7aZ3+zEMtbUGRoyIehbAABewbveHPGnIhkn4zjtbcMUV\n4awKYMD77lxEYvLy9K4OInPktDk60/zP/7Rg4UKHHQwyhDAF6wTJpZe2oqyM4dprU2+qGzXKFA6y\nGbQtnHYanwAdeaS3iUKuIZZ9TJqUI6G8HunVi+Gkk3LEKUsQOULOa8KZZObM7A+qEyZE8cUXQfTv\nbxdgAwYwbN1ar/lV+xk+PIpAgCEWM9othH/72yZs2RLA8cd3TCE8c2YYzz+fl3H/HkEQuQcJ4Rzj\nf/6nBX37xnD55ckF1bSXkhI+AairM2ym/mQpLESHFcAAcO+9zfjBD1o8B+UQBNF5ISGcYxQVAfPn\nZ1YAC555pilnMhZlk+JikAAmCMITJIQJzyTKBU0QBEEkBwVmEQRBEESWyPg6YYIgCIIgOKQJEwRB\nEESWICFMEARBEFmChDBBEARBZAkSwgRBEASRJUgIEwRBEESWICFMEARBEFmChDBBEARBZImczph1\n9913Y/369TAMAwsXLsSIESOyXSTPrF27FjfeeCMGDhwIABg0aBCuvPJK3HrrrYhGo6isrMR9992H\nfB/v27Z582bMmzcPV1xxBS699FLs2rVLW/5XX30VTz75JAKBAGbOnIkLL7ww20W3odZlwYIF2Lhx\nI7p27QoAmDt3Lk455ZScqMu9996Ljz/+GJFIBNdccw2GDx+es/2i1mXFihU52S9NTU1YsGAB9u3b\nh5aWFsybNw+DBw/OuX7R1WP58uU52SeC5uZmnHPOOZg3bx7Gjx+f+T5hOcratWvZ1VdfzRhjbMuW\nLWzmzJlZLlFyvP/+++z666+3fLZgwQL2+uuvM8YY+8UvfsH+8Ic/ZKNonmhoaGCXXnopu+OOO9hT\nTz3FGNOXv6GhgU2bNo3V1taypqYmdvbZZ7MDBw5ks+g2dHW57bbb2IoVK2zH+b0ua9asYVdeeSVj\njLH9+/ezyZMn52y/6OqSq/3y2muvsSVLljDGGPv666/ZtGnTcrJfdPXI1T4R3H///ez8889nL730\nUlb6JGfN0WvWrMHUqVMBAP3798ehQ4dQX5+ebfwyxdq1a3HaaacBAE499VSsWbMmyyVyJj8/H0uX\nLkVVVVX8M135169fj+HDh6OsrAyFhYUYM2YM1q1bl61ia9HVRUcu1GXcuHH45S9/CQDo0qULmpqa\ncrZfdHWJRu3baOZCXaZPn46rrroKALBr1y707NkzJ/tFVw8dfq+HYOvWrdiyZQtOOeUUANkZw3JW\nCNfU1KCioiL+vlu3bqiurs5iiZJny5YtuPbaa3HRRRdh9erVaGpqipufu3fv7uv6hEIhFBYWWj7T\nlb+mpgbdpL0P/dhPuroAwNNPP405c+bgpptuwv79+3OiLsFgEMXFxQCAF198EZMmTcrZftHVJRgM\n5mS/CGbPno2bb74ZCxcuzNl+Aaz1AHLzWQGAe+65BwsWLIi/z0af5LRPWIblWArsY445Btdddx3O\nOuss7NixA3PmzLHM8nOtPipO5c+Vep133nno2rUrhgwZgiVLluBXv/oVRo8ebTnGz3X529/+hhdf\nfBFPPPEEpk2bFv88F/tFrsuGDRtyul+ee+45bNq0CbfccoulnLnWL3I9Fi5cmJN98sorr2DUqFE4\n6qijtN9nqk9yVhOuqqpCTU1N/P3evXtRWVmZxRIlR8+ePTF9+nQYhoGjjz4aPXr0wKFDh9Dc3AwA\n2LNnT0LzqN8oLi62lV/XT7lQr/Hjx2PIkCEAgClTpmDz5s05U5dVq1bhkUcewdKlS1FWVpbT/aLW\nJVf7ZcOGDdi1axcAYMiQIYhGoygpKcm5ftHVY9CgQTnZJ3//+9/x1ltvYebMmXjhhRfw8MMPZ+VZ\nyVkhPGHCBCxfvhwAsHHjRlRVVaG0tDTLpfLOq6++iscffxwAUF1djX379uH888+P1+nNN9/ExIkT\ns1nEpDn55JNt5R85ciQ+/fRT1NbWoqGhAevWrcPYsWOzXNLEXH/99dixYwcA7icaOHBgTtSlrq4O\n9957Lx599NF4tGqu9ouuLrnaLx/9//bOPECK6mr7T+/L7DPMDNsAw77KooIoCKKCimJCBNEASRSj\nEogxceFTInkTFY2Y14ivCwbc0IgILolsCoIom4AgA8g+G8y+T3dX9VbfH9W3+tbSPT1798z9/UNP\ndXX1vXWbeu4599xzDh7EmjVrAIhLaU6nMybHRasfTz31VEyOyUsvvYQNGzbgo48+wqxZs7Bw4cJ2\nGZOYLmW4YsUKHDx4EDqdDsuWLcPgwYPbu0kRU19fj0ceeQS1tbXweDxYtGgRhgwZgscffxw8z6N7\n9+5Yvnw5TCZTezdVk5ycHDz//PO4ePEijEYjMjMzsWLFCixZskTV/i1btmD16tXQ6XSYO3cuZsyY\n0d7Nl6HVl7lz52LVqlWw2Wyw2+1Yvnw50tLSor4v69atw8qVK5GdnS0de+6557B06dKYGxetvsyc\nORNr166NuXHhOA5PPvkkioqKwHEcFi1ahOHDh2v+f4/mvmj1w26344UXXoi5MaFZuXIlevTogQkT\nJrT5mMS0CDMYDAaDEcvErDuawWAwGIxYp82jo8vK6lr0eikpdlRVOVv0mu0F60t0wvoSnbC+RB8d\npR9Ay/clPT1B83jMW8JGo6G9m9BisL5EJ6wv0QnrS/TRUfoBtF1fYl6EGQxG28FCSBiMloWJMIPR\nCanhq1HvaVya1xXfP4drPxwHr9/bSq2KjL2XvkOFq6Jd29AalLvK23ySU1CXj0Ml3wMAqrkqnKg4\n3qbfz2AizGB0SmZ8chPmfXFnoz5zsOQATlX9hFp3TSu1qmHOV5/F7Z/ejGkfT263NkTCT5Un8csv\nZqHYURTR+eerzmPYW/2w+tgbrdwyOdM33oibN1yPEkcxlu15ElPXT2r05IzRPJgIMxidiJ+v+zn+\nsmcpCusLcbG+sFGfdfvcsn9bG7/gx9oT76DEUSwdK3OJmYvy6/LapA1N5ev87fgybysOFO0Le15B\nXT78gh/5NfkQICC/Lr+NWihCJglbczejzFkKt9+NenfLBs8ywsNEmMHoRGw+sxk7C3bA7eMbLaa8\nj5f929ocKzuKP+5cjDU5q6RjVoOlTb67ufA+LvBv6Ht1rOwoLn9vON4/+S54r3ieu43uLaGLTUz1\nu+nCf8D7xd9DW40vQ4SJMIPRSRAEAbyPB+d1gffxklBESltbwjUBt3e9O+ge9Qrtux4dKZFMWC45\nLgEAiuovSee1xb2t5qpwsU70gmTYxVKEuwt3wRGwgNtqfBkiTIQZjE6CO2DpODwOAADfyIetu40t\nYZfXBQDgqO8jRU/+7QAAIABJREFUFmO0Q4Qs3L3ivUFrmfSrLe7tg18twE0bpgAIjqnH70EVX9Vm\nbWAEYSLMYHQSyEO/TrJ4GvewDVprbSTCHqfq+2JFIIiXIZxVSd/PtrSES5wlKHEWQxAE2ffVuWul\n9jDaDibCDEYngVi+Tq9oCbv97kZtiWlrdzSxhGm3ObHmAcDn96k+Ey3w0r0KYwkH3uNklnDjlgia\n1LbAZMztd8smNbU8EWHmjm5LmAgzGJ0ErQc8LWoNf76N3dE+IsLBNtKiVsO331aphogkMIu2hDlv\nw+e3XNsC4+jlZPfTzQKz2gUmwgxGJ0FLhIlVFAnkId127mi1JUwLRJWrqk3a0RQiWT8PTmq4NnVH\nc4H7yVFucBrmjm5bmAgzGJ0ErUCsxgRnBYWlrdzRZE2YtoSDr6u56jZpR1PgIthyRCZAnLdtA7O0\nxJ+GYyLcpjARZjA6CVpWb2OsHsla87dxdLQ3hCXMxbgl7NcIzGrE8kBTIb8Dp8cJn6BeV2eWcNvC\nRJjB6CTwGg94PkJB9fq98At+AG0ZmBWwhP3aa8LR7I6OxL1MW79tlaxDEATJHR0q/SgLzGpbmAgz\nGJ0ELUs40n23tEXX1vuEeZklHBvu6EiC2Ghrua2C3ugJDdmSpIT38ShzlmFf0d5WbQtDhIkwg9FJ\n0LKyIrW8ZFG0bS3CIb471t3RnE/LEm5dK5Se0JAtSUrcPh43b7weMz6ZhjNVp1u1PQwmwgxGp0Er\n4CbSICtaHNouMEstwvTrWLCEw01Y3D71mnBr7xOmfwO1oSxhvxv5tbkAgLzaC63aHgYTYQaj06Bp\nCUe4JhzKGm1NgtHR2iIcC2vC4bcoka1CHLVPuJUtYUrkiQjbjXGyc+j77WrEFjZG02AizGB0Epqz\nJ9QdImFGa6KVOzp2knU0HO3MUxnI2iolKB0DUBu4f4mWRNk5dBucgTzjjNaDiTCD0UnQ3BMaYWAW\nLSZt7Y6Wr0fTgUXRW/c2ElENZtXiZJHSjUkl2lg4mSUcEGGzXITp8a3iK1utLQwRJsIMRidBM21l\nNAdmBQo4ePweaXsUPZGo46NfhMNNcsiEgvPKM1d5/J5WbJfaHZ1gDm0JV7gqWq0tDBEmwgxGJ0Er\n8jbSLTF8OwZmid+pjh6m6wxHG+4ILGGyDuymoqMb+kxzob+HbFFSW8LBcyo5JsKtDRNhBqOTwGll\nzIowQ5M80X/bWMKcjxJhErgU+G6LwRK17mhBEIKBWWHur5SL2+9WZAVrvUkOp2EJJ5qTZOfwzBJu\nU5gIMxidBC2rN9ICDu3hjnZ6KBFWFI9IsaZGrTs6VIYvJaH27LbmNiWt0oVagVkGnQEAs4TbAibC\nDEYnQUsQIrW62todLQiCtEUJoGrgBr471ZoWte7oSCcstFVKR3q3ZtYsWvjrQqwJOzwOKac0E+HW\nh4kwg9FJ0ErWEa2BWbyPh4BglDARX97Hw6g3ItGciHp3fatGEjcVOhgrksAsAKjhajSPtzQy4Q8R\nHV3NB5OgMBFufZgIMxidBE1LuAnJOtrCEqatYCAoHryPh1lvQbwpHgIEOLzRt4810vVz2u3soPbj\ntmpglswdHUKEqXSglVylFJkebVRxlSHzX8cSTIQZjE6C9halCAOzqHVOTxuU26MjowF5tLHFYEac\nKR6AXLyiBfo+09Wn1Odp38e2ckcTT4PSHV3FB0XYL/hRzUdnZrLpG2/Eb7f9pr2b0WyYCDMYnQSt\nh360BmZxChGm00CaDRbEmwMiHIUR0sr7HEpUQwVgta47Wt2WRIs8OlopuuXO8lZrT1PhfTzOVp/B\nyYoT7d2UZsNEmMHoJGiWMozSwCxnCBF2+9ywGER3NADUe6IvOEs5SdGatPj8Pnj9Xs3Pt6olrCH8\nNqMNRr1R+lvZrjJXaau1p6mUO8vEf11lURkX0BiYCDMYnQStPauR7vlta0vYGciWRcRBbgmbEWcS\niw5EoztaaW1qV68KE7DViu5+rfrRFoMFFoNVdbxrXDcAQKmzpNXa0xgOFO1Hbo1Y1ancJYqw2++W\n0m/GKkyEGYxOgpYlHKmghion2FqUOIsBAD3iewKg14TdMBssiDMnAADqm+COLnWWosRR3EItVROJ\nJRzp/uGWRssSNhvMsBosquN9ErMBRIcIu7wu3PH5bXh01x8AyK3zsoBVHKswEWYwOglaD/6ICzjI\nqii1vju6oC4fANA/eQAAeYpHazPd0b/8Yhbu+HxGC7VUjVLotPdnh4uabr1JjpZVbjZYYNYQ4eyk\nvgDESUs4ztecwwNf3otyV+i14zp3bbPcxgW1+eB8HM5WnwEgF15iFccqTIQZjE5C80oZtq07ulAh\nwm6fW0oHaTZYmuyO5n08csp/xKmqn5pkRUf2HcrArMbl7G7NSY6WJWzRW2BpgiWcV5uLp757An/Y\n8TtsPLMef/52ieZ5h0sOYsDqXvj83CeNamstXyOtT+fVim7oS/UXwft4lFHCG41r1o2BiTCD0Ung\nfBysRnHtz2a0AQif25iGiIbFYGmTwKzCugIAQD9iCfs4eP1eCBDE6GhTwB3taZyQ5tZckLJBnas+\n24ItDkKEzm4UJwrhLGG9LvgIlta/WzE3t5ar22K0SL8LWoz7JIkiTJYGlDy99y94/egr2Fe0BwBw\nuPSg5nlbLmyCX/BjV8HXEbezlq/B5WtHYMHWXwEA8uvyAIjbqgrr8uXuaGYJMxiMWMDtcyMpsB3F\nbrRDB10jLGFReONN8W1iCRfUFcBujENmXFfp+4PFG8zSFqXGpq4k7kzl66bg8Xnw52+XYPwHY3Cx\nrlA6Tu4Vycms5QImyUfoPbokaUZr3l/SFvp76cCshMBaOyCmBk0wJ2q6o0ucJfjiwueyY3m1uZrb\nmb67tBsAkFP+Y8Tt/L54P2r4amy68B/svfQdcmtzqe/Jk6KjAaCsAXe5qj0Xd+PVIyujJqq6RUT4\n2WefxZ133ok5c+bgxx8jv9EMBqPt4H2cJAxmg2j9NDYwK96cALff3eoPsML6AmQlZEmWGe/jpLYq\n3dEbz6zH8fKciK57tuq09PpM9ekwZwKnK09h/akPQybbeOH75Xjjx1dxrvosfrlpNsZ/MAZHSg9L\n69fhRJUcS6IqGMVL57e+O5r+XrPBLN1nWpztJjsy7Bma7ugPTryr2srkF/zYeHKj7JjD48CR0sMA\ngJOVJ0Juy1LyffF+6fWK759Dfm2e9Hdeba7M+g23Fq1EEAQ8sush/GXPk5qTgiOlh/H03r+0SfAh\nodkifODAAeTl5WHdunV45pln8Mwzz7REuxgMRgvD+9yIM8fBoDPAEgjGIYFZfsGPJ3c/hsXbH9AU\nAbJthjykW3MbTS1fgxq+Gj0TsmANWGg8VXPXYjBL7uhPznyMB768F/M3z8FXeVtxvuYcADEQ6I7P\nb8dDOxbC5/dJ16at33NVojs6t+YC9l3aA4/PIx6vPoOtuZsx+z8/w++2/xYLtv4K56rPQBAESZA5\nL4d3T6yRxOtERQ7OVZ/Fgq2/wq5C0e2aQIlwmbMMrx5ZiZKAoJG+aFnCRAA8Po/0nYIg4HzNOVRz\nVRAEAetPfYjDJWr3r1/wY1vuZhwo2q96T/69QYvXbLDAYiSWMCXCxjhk2DNR4SpHbs0FrD/1ITgv\nB5/fh/dOvA27MQ59k/oBAG7Kng69To9Vh1bJvm9b7mZ4/B6pXz9VnsRXeVtxuOQg1uS8KRNXQk75\nMXyV/yUAYEjqMOy+uAu7C3dJ7+fV5qLMWSq58sucpThWdhQHiw80mGIzp/xHaRliQ2Dyti13M7x+\nL9w+Nx748l68/MM/8NqRlWGv05IYGz4lPHv37sUNN9wAAOjXrx9qampQX1+P+Pj4ZjeOwWC0HJzX\nBavRCovBCovBgjhjHM5Un8L0jTeizl2LnypPAgD2Fe1BiiUFXeO6SakND5ccAhB8eM/bdCeMOiN0\nOh100EGn0wEAdNABgdfQsJYdHgcu1JxH3+T+8As+HC8/hkGpQ5BoToQAUXCcgbzRPRN6wWIURe7f\nJ9diZ8F2AKJokHZcclwEIEZT3/3FLJj1ZkzoeS3yanOlh+3RsiNIs3WBSW/EkdLDMOlNMOlN2FW4\nA7P/8zN8e/EbeP1emPQm9EzIQmFdgSQcAPDf85/hv+c/Q/e4HihxFqNvUj/UumtRyVVi0eg/YM/F\n3Thcegg947OQX5eH/Lo8dI3rhkk9J+NQyfd44fvlKHGU4JLjIl47shKjM8ZI1htdRpD0ad2pf2Nn\nwQ78UHoIPeJ7osRRjARzIspcpYgzxaNvUj8cKz8Ko96I67Kul8oO+gU/TlaeQEFdPnTQYXLWFJgN\nZhwr+xE+wYdRGaNxvOIYzHqzFBMAiIFZtsBkJ1FpCdsyIUDA2PdHAgD+smcpusZ1Q2F9AeYPvQd+\nwYfzNedwXdb1gCBgS+4mZLyaiFHpo1HmKkMVVwWLwYLZg+7GeyfewpSPrpH9HpIsybiq23jp7yqu\nCgeK9wEQA8MeHLUIv9/xIOo9dehiS0e5qwyfntmASq4CWQm9kFebi00X/oNNF/4DQFxj75nQC0NS\nh4i/RQV5lOi/euRlvHrkZQBAVkIvpFnTpEnc/x56AY9N/iPaYsW22SJcXl6OYcOGSX+npqairKws\npAinpNhhNBqa+7Uy0tMTGj4pRmB9iU5ivS+8l4fH70GiJRE3DZiGrMQsTO03FQu/WIhDJd9DBx3G\n9hiLFGsKdlzYgWJHEY6U/SC7xoDUAbix//XYe+k77CzY0eS2ZMRl4JuAtdgrqZcU2ENj0Blwy5Cp\nGNt3FHom9sSluku45LgIvU6PSf0m4LI+g/DQuIew5ewWzBo6C5vPbkaqLRUny09iR/5X0EGHu4bf\nhYLaAnyb/63s2tP6TYPNZMOnP32KnQU7kJ2cjan9puJI8RGcrzqPPsl90D+1P8qd5dgydwu+PPcl\nXj7wMk6UncCYbmNwuuI0avgaJJgT8KdrH8LvvPdjzQ9rsGzSMpwoO4Gc0hzMHDITh4oO4eUf/hc/\nlB6GUW/E7YNux6Yzm7AldxMAUTDmjrobp6t+QqWrEneOmIUTFTnIr81Ffm0uhmcMx5mKM+iZ2BPV\nXDUm9pqIc1XncKz8KK7tfS3OVJzBl3lbZX1LtiZj3mXzsLdwL74OTFpSrCkw6A3YmrsZADCuxzhM\nyZ6C09WnMCV7CrplpuDhCQ/h8qzRsBlt+PbiN+iR0AMjeg/ElIpJ+OzcRiRaEnH7oNux7dw2HK84\nBpvRhscm/REljhLsvrQTvxg5AxP7X4XTn/wEi8GCo2VHkBGXAd7H4V8z/oUru1+Jj059AN7H485h\nd8JmsqGLrQteO/ia1C7C2B5jca7yHO4Z8xvcM24e/n7wGRTWFuKuEXOw/cJ2nCgTU1Ve13cycqtz\nsadgD6ZkT0H3+O44VXEKOaU5qmvS9E7qjVlDZ2HV4VUY22Mseib2xIYTG1BQl4+xPcbioXEP4ZOf\nPoHJYEJSuj3i33VT0QnNXNz585//jEmTJknW8F133YVnn30W2dnZmueXlbXstoD09IQWv2Z7wfoS\nnXSEvpS7yjH0rb64Y+gdeHXyGum4IAjw+r3Q6/TQ6/TQ6XSS+7PeUydZuTroYDPaYdAb4PQ44Yef\nXAACBGmNmC4/CEBljRj1JthNdml/b7wpHg6PA37BF/gusR0GnQFmg1n2WSHwXcQNqTUufsEPl9cF\ni8EiRRuTPnoFL7x+jyyy2qAzwmq0yqKUG4LcG7NBe2sPDefl4PG7YdAZYTfZ4fK64Am4+w16I+JM\ncRAEAUmpFtRWueHxeeATfDDpTTDoDdJ9JZ4Gck2r0Qqv3wunYotWvDkBep0efsEvbcGym+Kgg04a\nzzhTPAz60IaQw+OA1WCVznF6nLAYLNLffsEPr9+rGh8gOCZevxdGvRF+wS/dW87LwSf4pPV8gCwz\ncFIfdTq9tAec4PF54PI6kWBODHhKHFI/SHvo/vj8PjjC7B+3m+JkaToBcUzdfrdsPFv6/32oiXyz\nLeGMjAyUlwcXxktLS5Gent7cyzKikDp3LfyCH0mW5PZuCqORkJJvyrJ1Op0OJoNJdkyv0wM6hBxn\nu6n51gH9oKUfyuEgk4Fw6HV61fVIH00wAQi6YZXVgyJFp9NF/Fmr0QorgikhbUabzBVMrie63d1U\nO4PvaV0TELc0KYsvEPQ6veq9SP/fKu+fcrz1Or2mANMQkaMnN6TdNJYIJjImgwkmg9gXg86guvfE\nHS/9rTeEvC+h0Ol0DbajtWi2w/uaa67B1q2iS+T48ePIyMhg68GtyLHyHzHpw/H4seyI5vs1VEHu\nlsQv+HHbJzdh6seTI45wDIXb5444mjUW+Tp/Ox748t6oqnVKrCJ6DZLBYLQ/zRbhMWPGYNiwYZgz\nZw6efvppLFu2rCXaFZXcu3U+lnzzp3Ztw/P7n8bJyuN4O2e16r3NF77AkLf64sndj7XId7l9bina\ncFfB1zhRkYMLNefxVd62Zl133qY7cd1HV+NExfGWaGbU8ciuh7DxzHosDZFBqD2oYyLMYEQlzXZH\nA8AjjzzSEpdpNLk1F3DrZ/chtyoPb9/0Pq7oOhaAaA3+4etFMOtNeGDkInxTuBNHy46gyHERT4xb\nhiu6jsXMz27FfZc9gJkDZknXEwQBv9/xIMZ1G4+5Q8VMLe8cX4OshCxM6XUjtud9ie7x3QEALx/+\nX3xfvA9ZCb1Qw9eg1l2Dar4aZr0ZVqMV2Ul98fSE51FYV4D/PbQCZ6pOIdmagjq+FvWeehh0egxN\nG44XJr0Ev+DHhjMfoejHfIxNm4Cn9y1Dv+QBmDngDjg8Tkzvexv0Oj1OVf6EbXlbAABrT76DCzXn\n8bcJz6HUWYJBKYPx0I4H4fV78eax13Fdr+txQ+9pmvft/354GeO7X43RGZfjsW/+iKu6jUdBXT72\nFe3BrIFz8IuBs1HNVeGqD0bjisyxWDv9I6zJCW49ePf4GhTU5SG/Lh8j00fhbPUZLBm7FACw5+K3\nOFhyAH+bJk7GNp5Zj/+c+wz3DL8P609/iBcnvSwFjOwq+BqvHnkZl2deiY1n1uPZiS/gkzMf44+X\nP4p4agsF5+Xw2pGV+PmAO/DXvU9h7tD5eOWHf8LldeJ3o/6AD39aK7nMpvedga/zt2P2oLtQ7irD\nZemj0CcpG68eWYlR6aPxZd5WnK0+DZPejDmD78bIdDEYRem+2p63DW6/BzdnT5cdf//Eu8ip+BHL\nJ67QvLc+v09KHvDvn9ZiRr+f4ZvCXVh61V9Ubt8SZwnezvkXfjfq94g3J+BY+Y/4y56lMOmNeG7i\ni1LGIkBMYP/Ud09g/rDf4IOT76LMWYbfj3kYl6WPks6pd9fBqihLR6jzMBFmMKKRZgdmNZaWXOg+\nVnYU16+fCAC4PPMKJJgT8bdrnkN+bS5+uWm25mfuG/EA5g+7BxM/HIs5g3+Jl6e8Jr1X4ijGiHcG\nAgAK7y+H2WBGz9e7YET6SGya+RW6vpaMnglZODQvB0Pf6qvaJK6DThaYcvI3FzB/8xzZxnNAXBdy\nBeql7rpzHzZf+C+eO/A0AKBnfBYK6wtk538wfT1u6D0N7514G3/a+XvEmxKkdH1xpng4PPXok5iN\n3NoLuKrb1dhXtAcLR/0ef7n6aVX/y5xlGPZ2P9zebyYeH/skrv735bL3r8gci02/+AoPfHkvNp5Z\nDwA4fU8ehr7dD0PThsPhqUe5q1zl9s69r1jc0vCq+JAv+lMR8otLMO79UbLznpnwPJ789nEAwPAu\nl8k2zKdYUlDFV2HmgFl4/cbVOF99Fn/a+RC62NLx2Tl5EoCGGJI6FCcrxSjKM/fmY8DqXqpzxnUb\nj8K6AgxMGYR1t8nz2o7/YAxcHheO/OqkLEBj+sYb8X3xfhQ/WK0K5ll74h08/s0fZdtbCG9OfRu3\n958pO7b62Bv4f7sfxVs3vY+R6aMwfeONKHJcAgAsn7gC9474rXTua0dewbI9T8g+f9+IB/DMxL8D\nCAZeTe87A2/dtFb1/R+fXoeFX92HVbeuws96zdG+aTFGRwiYI3SUvnSUfgBtF5gV02krR6SPhP8p\nP3ol9MahkoPYWbBD3FAe2Ow+KGUwdNBhet8Z2DBD3EfG+9xUWTR5VhQ6R+rMz27FvqK9cPvd4Lwc\nXF4XBAhSNhxBEBBvSsD22d/i0LwcnL23AEUPVuH8fZdw9+B5AIAtF77A98X7MbHHJBTcX4ZT9+Ti\n0gOVyPttCf4wRvQe1PDVUp5cQMwUZNAZ8N4t69AtTrS6z1SJCQZcgRqrvxp2j3Q+iQLMDSQ4H5Q6\nRNY3v+DHsu+exA+BfZ6uwB5Ml9eJczXq3LkkUQDZ+tA1rhu25W2B1+/FrX1nIM3aRXOts9hZJPvb\nL/jxyg//VJ238czH0muPIimEPzCBIYnel+15Et9d2q0pwP2TB+DXw+4FAPRL7o99v/wB62/7TArS\nMOqDVienyJe75Rc7YDPawHs5FDuKUKxR1s7hccDpDUae/t8PL+OxXQ9LiSy0Muq8dPhFSYBJ8nuC\nVgIMR2A8z1adxrSPr0OR4xKu7DpO83yt/L10OsQzVacAAF+c/1x1HsDc0QxGtBLTIgyIUW039J4q\n/Z1oSZIEaMFlD+D4b85hzbT3kJUgWkK8j5MeoCRb0Ns5q3G8PEdWY/RA8T78z56l0mdIAoFgcXE3\n+iRlY0SXy5CV0AuJliToA+H14wKbz5/Z/z8AgLuGzIXFYEGKNVVyFZJIxWq+GjWKotQDUwZjWp+b\nsfaWdQCA/LpcAJCs54k9J6H4wWoka0Q7drF1kbXz24vf4LWjKzFtw3UAIBORU4HkDDTk3pFtA16/\nF1+cFycw0/vOQLw5XjMrTXG9XIQ9Pg9KHEWq8w6VfC+9JsLw4MjFAABT4N54/V7Ue+qhC7FtJMmS\njKcnPI8nxj2FWQPn4JXr30DfpH6YlHUdjv06MGEJjBd9LwDgjoF3YkzmFTAbLHB6nfAJPs3C9m4f\nL/vc/+xdirePr1bdH5qhqUOl19P63Cx7TysylFxr84X/osxVisWjH8afrnhM9h5BuRVF7FewDcqJ\nhhImwgxGdBLzIgwAD1/+qGQ1un28JDQWgwVdbF1k4ef0+ySd3GPfPIyXD78opZQbmT4aQDAxuNvn\nlh6C5MHn9vGwhAjTH5AiurTLXWWwG+NwS/ZtqnOIgNbw1ajhRREmWwOGdRkOAOid2AcAkFeTCwCS\nZWY32qHX6SWrlybDnhlop7a1Lx33u3Gy4oTq87yPl/bMkb4fLf0B3eK6Y0DKQGmPpRLiRqWvU9tA\ndDBZp0yxpgAAKlwV0nv7Ln0Hu2IrByC68k/dk4spvW5AsjUF/3fDKlyeeaX0PhmTOqpMHenz7EF3\nYeWU1wPnWaRzeI2aurxP9IAoV2ukyZjfjR35X+H5A8E0rcQK/ui2T2VrtQBg0qt/K+R3SCZhZHJA\nt1n5vfLPB89pqK4ui45mMKKTDiHCmXFdsWrq2wAC1VakRO/BB1/w4eamrFlecufWuetQHLDcnhj3\nFOJNCVKlE97Hyyxhn98X2Nittm4AYGDKIOn1Db2nau6rJIFANXw1avlq2Iw2jO0hBpYNSxshnZNs\nScZX+dswed3VkmiSfYaDUtQinG7LENsZEBaDTh6kQ1tyJE0hvbZJ3z9yPudzSftL6ZyzNEUKq5fz\ncjIh1IIIQ7JFFGF6Pf1CzXnYjOr71iexb9jECmSc6e8mrtwEc4K0qZ8WYY6yKKu5KtTyNXD7eAgQ\n4PF7pJzCdJvdPh5v/vgaXjz4vOSeJ6I6oce1qkAvj0auZXKfa3nx81aDBWY9mSy6UckFJyXECyL/\nfPCaVVxlqFsCAKjziN+RYIntzF8MRkejQ4gwELSAOB8nWau0SJIctG4fL1l5POVydHldkiXcNa4b\nrEaL9HDlfZwsAwsJigq1YZ1+AE/vq7aCgaAlTNzRieYkXNH9CgDAZekjpfN6BazhExU5Uro7e8Bi\nHpw6WHXdLvZ0qc0AVIJF6se6vC5pHZF2L9PVasS/eXBeTkrwrsxmQyhWWsJevsF9skR0tdzqBXUF\nqqQGgLj+Gw5zwOKk13OJJ4H+PZgNZmkc6UnHwDW90X91FpV0npOVZ6uVBJeXhNEVcAVzPg4GnUFM\noqBIKKC1hkzGKPh7ski/4/3FezF4TTY+PbMBuwt3oZqrUn2eHqcGRZhZwgxGVNIiW5SiAYtUbYWT\nLATaXWwJWBi8Xx6YRR6ETq9Dspgy4zJh1ltQ7i0PnOeG0xN0B5IHsTWEJQwAYzIux+HSQ7L1ahoi\nPLXuGtTyNUizdcHj1zyOPrYBmNDjWum8nvFZqsQcRJym9LpBFU2dYSMiHMIdHRCMMleZZiUc3ueW\nBfwIEOD0OiVxizOHEmF54JDojq7RPFdJcsAdTXOxvhC9EnqrjpOqLaHQ6XQw682yvpE1dfr3QCxO\nQHt9l8B5edQ5glY1EWfOy4MLiHBwicKtWRKOvKeEHCNibjFYJUueTJBeO7oSPwRKwYX6PABUNkKE\nfergbQaD0U50HEs4YOnyXl5Wd5Rg1BulIua0O5oEZzk9TpQ6imHWm5FiSZWuR86j1+TIGq45TJqz\ndbd9gh/mnQiZ3o5Yy7QlnGZPw6xBc2Sp6sqpupkE4t7um9wfh+cfl6xlAOiiEGFlQXFyb0JZqeKa\nudpqI4FFCaZgf6b2vgnb7tgJg86AIsclmUUdzh2ttGZTLHIRNuqNKKzLh1ex1ad/8gDclH2L5jVp\nLIogqLxAQXB6vGhBJvVxtXbr8T4OpQ510XDREg4sV3h56VwiwkpLmHZ5B68tv89WY9ASJhO9nPJj\nGj1Uf552XWtB3OihlhMYDEb70GFEmK47SiwE+qFLgrPcVF1S3sdLkbHEHZ1hz1TlEfUJPplokdfh\n8qcmWZLRI6FnyPeJJVxUfwlevxdJIXKd/mb4AtUx5VopKdCt1+kRb06AWW+WrDNOsZbIh9liA0Da\nkqWE3I+LMT6oAAAbzUlEQVR4yhIemjYcozLGINPeFcWOItm6ZZWrCj7Bp7oOIIqprP2UO9pqsCIr\noRcK6wplbewe1wN77j4kJWQJhzJgTlOEFULNU+5l+XEOJQ51UXPe7wbnE8+nYwfIdyjHU7uwu9w6\nNgdq/AKQUoOGcv8DonX7i89nYNP5/0bgjq6FzWhTJQxhMBjtS4cRYTqqlDy8LYqIVLPBIgZm+YMi\nTFyRDk89SpzFyIwTo4uVQVf0mhyxhMO5oxsiwZwIHXTIrxPrW4YS4ZkDZmH9bZ9Jf+ugU31vMGgq\nEXqdHhajVbLwlWKrtR1HCVmjpCH3gxYFIsjd4ruh2FEEB7WNpswpWvDK5OoA0D95oPRamZDdbrKj\nZ3wWylylMnd2qPujBe1qBoIiTP8elF4M3sdJ0do0nJfXtIR5LydNVshEh3ZHK6PItdzRvGIsxGT2\n8rHVmhgQfqo8gd2FO7Etd7PMHa2V27vOUxcysp3BYLQfHUaErZIIc5LQKB+0ZoNZ5m7lfbzkrq3g\nKuD1e5FuJyIs/yz9kCPi0FAlkXCQKif5gSLTiWZtkdHpdOiVGFwbtRntqsoqxLVNxJhY/IB8L6nP\n79MUAyVaW4usRmIJBx/kpJRYojkJHr9HNlEpqRetx3R7huw6FoMFozJGy/6mo8ftxjj0TMgCIEZI\nK/sYCcpxIZnNZJawYoLG+Xg4NNznbp+2CNPxBLxP7Y426A0y0dPyLiitYwsVmBVsV+j1ahLYxvlc\nqOKDv0+tPcV17jrmimYwopAOI8LBwCy3JDRWo0VxjgVu6n1xO478IUdcu0oRruaDAkPc0aG2KEVK\nkiVZepCGKzNGP8ztJnXEMG0JA6KFrkxIAojWfig3NI3WWi4RsASqLeShTqK1KziqpGVAuMgaNSCm\nkjw07ziyk/pS1zXDarBKJepsRht6xItu/HPV56TztCKoQxGqJBmdMEM5QXP7eM29tnwIESb7iMXX\nnHSMvi69LqxpCXuVImwNG2cQCqfXhUpX+O1M9e66JpfuYzAYrUeHEWESeMX7gm5CLUuYdlfzPk71\nIKStSZoqDXd0c+tP0sISztKj12HtRnXtVeKqJf+aDWZqnTI4yaj31GuuTSrRCtqS3NFUW8jkwB5Y\no6aDyEoDiU7SKRGOM8Ujw54hS1xhNlig0+mkdW67KQ5d47oBgMwdHcpToEUoIaMtZKXFKW6p0nBH\nhwjM4n2cJHZkoqNM4EJvB1K6nsVrKEXY3CTvisPjQDWVy9vhlVvCTo8TTq+zURMZBoPRNnQYEdbp\ndLAareC9nGZgFhB009KpG10+udWQEHhwKj9Lu/uC0dFNd0cDQatb+VqJ1WCV1la19s4SgQpOIKyS\n2NJuUIfHIUvwoPU9gLYIW6W1TvWaMBHQMkqEyxzia9odTSxR2daxwHWJS9pusmsWeW8JS5heK1YG\nZnE+rlGWcL2nXvJi8D4xsxbv42XXpS1PrW1Qyi1iFoMVep0eJn3jgqdKHEWyRCf0djogmNe7W6AC\nGIPBiB46jAgD4sOXDrzSDsyS5wSud8sfvETQlK5sOvpUckdr5ANuDLQLOlzgkU6nk9ZitbNvKdzR\nRgu1RYnKBsVXqdzvNOTzZE2YdoMHLeGgsBBBJm2qcKnd0SSDl3gN8Z7SExwykSEubbvRLr2W9zFy\nSziUCIfaJwyIQlqvYQnzXk6adNHQxzgvJwmqmfrNNeSOpr0SOuikvOKRuKRpzwBJMkNwKVJckrze\n3QIeBgaDET10KBEWRTaY8UnljtabA1uYgg8/pdVH1jlVljDtjg64SZUi31hk7ugG3K1E8LRSOSaZ\nkwPXCFrxJO8xLbrTN94oy3UsXi9oWZO+kzSKtIiQfdMyS9gknxhoirCdFmGr1D7lsTjKHW3X6GNj\nLOFQHopQ+4SB8O7oOl59vJYWYR8nWbr0ujM9sdLOmBU8ZjVapYA7rZzki0c/LOVHB+RjoywrGcoS\nzmQizGBEHR1KhElAEl3AgcZisMAn+GSBK8qsTrRLl6aKCswiD+DmWsI/H3BH8HsbSCcYFGG1O5pY\nsOShbzFYIUCA1+/VLE5Ao2WNk4kJ3SZyL21Gm5QKUwrMCqxT0/WVyaSFVHUCgt4Fi8baLOmXzWhT\nWfsDkgdiQo9JYftBE9oSpi1wpSUcOjBLS5zpNVg6S5s8MCu8CNPWsTlM2wBgwYj70TWuq/S3VqQz\n6Z+y2EORZAkzdzSDEW10KBG2UO5mo94oJesnEAuJftgqXY3BCGP5g5C2NohwNzcwa2LPSfjX1Hdw\nU/Z0DE0bHvZcsk6q5aodlTEa3eN64Kpu18jazvu4sFtcAPladIKZiDDJrqQWYZ1OJx0na8Kk2pFW\ndi+5O1ptCZulNWHKHU0Fn2XYM/Hd3QelylKRILd4Q71WWMI+XnN/tMvjVC1ZAECtmxJhOksb5R35\n5ZD5mD3oLgDayTpoL0WodhKsRnnkdLyGCJNIdOUWJWIJd7V3VX2GwWC0Lx1LhI1WSYSVa37kfQCa\n2a8ItEs3FLXSFqXmiTAAzOj/c7x78781LVyauMBDV+u8nglZOPKrk7iu1/ViuwL95ALFF8JBr7US\n60qquGNWrwkDQas8TloTJpawhgjbNdaENZJm2Gl3NGUJN+Ue0+5o2tLXcoMTQq0Jh0oHSU/eXD6X\nJKi0O3pkxmi8OPnlwPW1yyUG29OQCNtk7deyhIkIF9Tly7w90powC8xiMKKOjiXCBnMgOlq71i8p\n4kC7F5WJKRJD7BOmIWumTdnT2VSkICiN9VIlROTohBKhoC1hMgEh/aPzRNPikmhORLwpQXJLkzbR\na8IEmQgHrmHQG6Rob7KuLm1RUgRmNUWE6Yxi9FpyOHc05+U0Ld7ywP7bNGua7Di9jMF7ecodrQgG\nDPRP2x0dPBaubYDYJzoGQSv7FdkO9uz+v+LXm++Wjhc7i6DX6WV7thkMRnTQYaooAYGtOYHcx1oP\nMvKApK1fIjgEsg4aVoQld3TzArMaQ7jALCVWyRLmGkzOQVvCRITDrQkDwJJxf5Ylh5ACszSsxlRL\nKvQ6PfyCXyaOFoNFrM6k2qIUJwVpAU2b6IS2hEPvE3b73ZprwiQBSao1TdY/5ZpwqGBAOmc5DdnS\nFGxbaFe5zWgTq0MFzjHqjbJJEYGUsQSArwu2S6+LHEXIsGdK0dcMBiN66FD/K4lQ1HvqNJNakPdp\nS1gdHR0QYWPoh7+Um7qZGbMag7T+qrFFSQnpJ+9t2B1NR/CSdUatLUq0SNycPV12jVATA1IwwGqw\nwul1Kqw9M5xepxSsRfplM9pk11OuzUcC3dZILWHey2muCRN3dJqtC85Un5aO0+5oOv2pVj5xkrOc\nxqOoEGUN0zayBEHE2ay3aE4SlZbu49/8EVd2HYcSRxGGpA5Vnc9gMNqfDinCtXwtUiypqveDlnDw\nYVujiI4mrlUtgTXpTbKHZ9u6o8macCQiHKyt3HBglnqblFYB+HBiGGpikEBlH3N6nbJocnLvyL+k\nX3GmOBj0BinIrin3mBYoOkKZtoSVbmMuRBQ0cbGnKtzR9OSN89KWsMYySGDrHI3SMpYFqym2vlkN\nARGmkp1ofY9ShN/K+Re+Lz4A3scjI5ATncFgRBcdbE1YfEi5/e4Q7uigpUxQWsLBvZrqz3dV7LNs\nipXWVIJrwuEDuADKEva5wXs5dLF1wcopr6NnfJbqXC13NLk/dJ7ocNuxtLwO9PXIZ60ylysJ0lIE\nZgX+JaktmxOYJVZo0g4uU1qsYmCWhjs6IMJp1FYr8fygiIpuf071HcHvtaiSdSjrPIcLzLIF8oWT\ne2UxWjW/p4uijQBwtkq03lNtaar3GAxG+9OxRNhIP8i0LZKIr6VxrnKfZZtawmZ5JHI4yH3gA2vC\nFoMVdw6+G0PThqnOleevlu9VpgU63L0LZQkr83DTwkGEkowTKerQO7EPAEjby5oiwsHvs8g8B+Hd\n0TwcmmvCoju6SxgR473BfcJavzuSs5xGaQmHKy4hWcLEHa1RbQkAUq1q7w/xhKRZ1QLNYDDan44l\nwg1EmDYm17PW55Ui3JaBWcPSRiDOFI9BqYMbPFdyR3tFdzR5wGvlZKbXhOMUBeTpNeFwtZNpSzjR\nnCRVRIqnqjqJ7VK7XMl9njlgFk7+5gJGBsocGgPR081xR5sNZsmKNOgMsn3jWvuE6YQsSsKJGEdl\nYQsV2ax0RytFWSuVJ4GsCZNzLHqz5vf0Tx6Im7Nv1W6/hpXMYDDan04lwo2xqrRczcp9lm0ZmHV1\njwk4t6AQl2de2eC5RGCeO/AMSp0lVN5n9bYWKVe2waq6P7QrN5wY2qjyit3iuknXUbmjNaw90lad\nToc0ytrU65puCdPrzTbJirRonkOo4atR567VtCaB8CLGU1HooQKzlO5o5d90+5TXUAVmGSya45Fo\nScQ7N3+An/f/hbr9VuaOZjCikQ4mwvQWGG23YMTX0lgDbU93NABpX25DkPtwrPwogOCEQunKNugM\nknUsrjPK+5OokTFLC3rvcrf47tJ9icQdHeoeBosZNN7bQL7ParBSVqS6mAdNQX0BACArobfmNZWB\nWTScNyjCWu2lS0sSlO5oZeQ4DZm80BMXrbzlxCORqJFnO42tCTMYUUnHEmHZmrC2RaJF97ge+N2o\nh/DRbZ+GPZfO3QuoKy1FC6qc2YGHeLzC3Ww12mRZrNSWsHayDiX05KBbXHdJREhZSC13tJYw0xAR\n9gv+kN8biqDAm2ELrFer11kVIlybBwDolagtwuFELNw+YfG7rPALfnj9XumYUpTDBmYZ5X3QsoQN\nOoP0Oa2ymMwdzWBEJx1ri5I+tDWhfF923GjBsqv/Jjum5Y5OtaZJW2fE74hOEVYKJnk4K9d8rQaL\nJILK3MRAMBiMvkZDdIvvrnZHE8vUGDowSwkRdp/gi+h7aeiSicQSVrp4VZZwXT4AICuhl+Y1480J\nMOvNqhrAgGgJB/cJh45FIDnNAbU7OlwBB2UdZjEwS36O3RQnRfZrlX0MZ8kzGIz2o4NZwvKMTOr3\ntYUk1DqeklRbmtyl2sxShq2Fsu3kga8MzLIabdI9sRgsioxS8r8jnXDILOHAmnJwf6taaBpyR/so\n6zFSaLdt0IqUj5W0Fh0IIiNiT1vCdHvjTQmaSxR6nV5WHjPc1jg6OEsZmGXVcNUTlJaw1j5hemzp\nZQSC1vYlBoPR/nQsEW5EYJYyhaISYtHQqf7SrGlSNLFZb5Ysj2hD2Z/COnG9U+mOtlAWldK6shjk\nlnGklnD3ONoSlufh1prAhFrzJbmlfU1wR8stYXXlJvrvBIVg9abWhOn34k3xknDTv4kkc5IYmBUo\nGakl1OS3RFu/aktYPgECgvfAqpjEKMcGkK/LJyksYbPerJlrmsFgtD8dVoS1A7OC78vK9Gk8OJXB\nRQCQYk3FlV3HAYCmWzJaINYdoTAQdKRyR1NrwrRrGhBFgbjvjXpjxHmHu1KBWeQeB/+lo63DJ+Mw\n6MTv8zbBEqbFyiZlQNMOzIo3xcvuV8+AO5oOWgPECGVyf+jfRJIlWRaYpRUwFbSEg9YvsZzJmGhl\nE0uxpgAIJmiht14p3d702CpFONWWFrUTRgajs9NsET5w4ADGjx+Pr7/+uiXa0yyUlpwS2n0cKpOS\n8hgt1jajDdf2nNwSTW1V6DJ2QDC4SblWbKUCfJQJIKwGK4x6I3TQNWorVle7eovS4tF/wCvXv6Hp\n6g3ljiZ7ev1NWBOm15uVe2wJVkrQ6N9Npj1T2q5FEoh0je8qFWIAgvufTXoTUq2psoxZYd3R3qAI\nE0GW1s31tCUsvibFJ0iyjqA7OjhuwRKQQUuYeCBMehMAlqiDwYhmmhWYlZ+fj7feegtjxoxpqfY0\nCyuV0jFUDl+CvGC9+lwS+ay0Hif0uLbZ7Wxtpva5CQtG3I9fDJyNfx56Eb8evgBA8KFMsBptsBlt\n6BmfhQEpA1UJI4jwRJKe85/XvYrvi/eji62LSoR7JfZWRR03FJhFknU0xRKW7RM2akdHk7+tRiv6\nJvfHiYocAKLwWYxW6AC8c/O/8XX+dgzqkR1oq/iZ/NpcAMBN2dNRzVfDL/jh8DgC1wu9tHG+5hy2\n5W3Bb4YvkEQ4wZyAIocynkF8PTrjcnBeDmMyrwgcVwdmpVhT4ax3KtaERRHOTuqLEmcJ+iX3b8Td\nYzAYbUmzRDg9PR2vvPIKnnzyyZZqT7MY12289Jo8FGloYe6TmI2jZT8ACEbGys+VJ5MgEDGJ5geb\nUW/EsxNfAAC8e8uH0nGTKjjJAr1Ojz13HxJFl3LL0pZqJEFZdw2Zi7uGzA18hgRmqQOECMH7q21l\nG0hgVlOio/XBsQtGRytFOChoD435E+7dOg+AmDSExAvYjDbc0vdWpKcnoKysTuU6/+WQeVh9bBUA\nYN2pD2T9oiETuUXb70etuwZ5tblSulApeE1jn/Dg1CF49YY3qePqwKxkSwou1hfKspYRd3S6LQPv\n3bJO5Z5mMBjRQ7NE2GZruJhAW5Jhz8D9ly3EGz++KuUgpqHzCKfZ0vDylNfw+x0PYljaCNW5Zr0Z\ndqMdSZZkrJ72nqw4/YX7imKyNqsyapaIJO2mzrBnotRZgt5JovVnC1jLjYG4T7W2yhCI5RYq7/QL\nk17C4u0P4K/XLG/UdwPiGqhep0e6LSOYc1tRZEKv0yPVmopUaypu7TsDswbOQVaCWOBiQMpACIKg\nuu6QtGHgfBx+PXwB9l78DpOzrkdRfRF2FuyAx+9Bpr2rqpIRANw9ZB7ePbEGlVwl9Do93jm+Wnov\nPVDdiPa4kPutvO/B43bpt5xuTwcq5NvJ0mxdMCp9NK7tOVlyqTMYjOhEJ2g9bTRYv3491q9fLzu2\nePFiTJw4EUuWLMG0adNw3XXXNXgdr9cHo9HQ4HlNRRAE7M7fjbE9xqrWQP2CH0t3LEUtX4vFYxdj\nUJdB2JW7C4O7DEZmvLrU23f53yEzPhP9U6PX6m0MgiDg2d3P4sZ+N+J0xWmM7joawzLkRR3OVp5F\nSX0Jruh+BSxGC97/8X1YjVb8Yqg6FWIovsn7Bjtzd+KpSU+FPKegpgAbTm7A4rGLZTmdW4pjJceQ\nnZKNeHM81vywBld2vxIjMuWTrZzSHKRYU9AjsYfsuMcnlqs0GeTue0EQ4PV7VccLawtxpuIMrup5\nlSyFJ83hosP497F/Y9awWXjlwCvw+D0YlDYI919+Pzac3IB7Rt8jTUiqXFVYtnMZHr36UWQlBStf\neXwe/HXXXzF/5Hz0S+2HP+/4M2YPm42Pjn+Enw3+Ga7s0XBKUwaDEV1ELMLhaIwIl5Wpa7Y2B+Iq\n7AiwvkQnrC/RCetL9NFR+gG0fF/S07W3CXaoLUoMBoPBYMQSzRLhnTt3Yt68edi9ezf+8Y9/4J57\n7mmpdjEYDAaD0eFpEXc0g8FgMBiMxsPc0QwGg8FgtBNMhBkMBoPBaCeYCDMYDAaD0U4wEWYwGAwG\no51gIsxgMBgMRjvBRJjBYDAYjHYi9hIgUzz77LM4evQodDodnnjiCVx22WXt3aSI2b9/Px566CEM\nGDAAADBw4EAsWLAAjz32GHw+H9LT0/HCCy/AbNauMhQNnD59GgsXLsSvf/1rzJ07F0VFRZrt//zz\nz/HOO+9Ar9dj9uzZmDVrVns3XYWyL0uWLMHx48eRnCwWWrj33nsxefLkmOjL3//+dxw6dAherxf3\n338/RowYEbPjouzLjh07YnJcXC4XlixZgoqKCvA8j4ULF2Lw4MExNy5a/di6dWtMjgmB4zjceuut\nWLhwIcaPH9/2YyLEKPv37xd++9vfCoIgCGfPnhVmz57dzi1qHPv27RMWL14sO7ZkyRJh06ZNgiAI\nwosvvii8//777dG0iHA4HMLcuXOFpUuXCu+9954gCNrtdzgcwtSpU4Xa2lrB5XIJ06dPF6qqqtqz\n6Sq0+vL4448LO3bsUJ0X7X3Zu3evsGDBAkEQBKGyslKYNGlSzI6LVl9idVy++OILYdWqVYIgCEJh\nYaEwderUmBwXrX7E6pgQ/vGPfwgzZ84UNmzY0C5jErPu6L179+KGG24AAPTr1w81NTWor69v51Y1\nj/379+P6668HAFx33XXYu3dvO7coNGazGW+++SYyMoLVpbTaf/ToUYwYMQIJCQmwWq0YM2YMDh8+\n3F7N1kSrL1rEQl+uvPJK/POf/wQAJCYmwuVyxey4aPXF51OXtoyFvtxyyy247777AABFRUXIzMyM\nyXHR6ocW0d4Pwrlz53D27FlMnjwZQPs8w2JWhMvLy5GSkiL9nZqairKysnZsUeM5e/YsHnjgAdx1\n11347rvv4HK5JPdzWlpaVPfHaDTCapVXqdJqf3l5OVJTU6VzonGctPoCAGvXrsX8+fPx8MMPo7Ky\nMib6YjAYYLeL1Zg+/vhjXHvttTE7Llp9MRgMMTkuhDlz5uCRRx7BE088EbPjAsj7AcTm/xUAeP75\n57FkyRLp7/YYk5heE6YRYiz7Zp8+fbBo0SLcfPPNKCgowPz582Wz/Fjrj5JQ7Y+Vft1+++1ITk7G\nkCFDsGrVKrzyyisYPXq07Jxo7stXX32Fjz/+GGvWrMHUqVOl47E4LnRfcnJyYnpcPvzwQ5w8eRKP\nPvqorJ2xNi50P5544omYHJNPP/0Uo0aNQlZWlub7bTUmMWsJZ2RkoLy8XPq7tLQU6enqgurRSmZm\nJm655RbodDr06tULXbp0QU1NDTiOAwCUlJQ06B6NNux2u6r9WuMUC/0aP348hgwZAgCYMmUKTp8+\nHTN92b17N15//XW8+eabSEhIiOlxUfYlVsclJycHRUVFAIAhQ4bA5/MhLi4u5sZFqx8DBw6MyTHZ\nuXMntm/fjtmzZ2P9+vV49dVX2+X/SsyK8DXXXIOtW7cCAI4fP46MjAzEx8e3c6si5/PPP8fq1asB\nAGVlZaioqMDMmTOlPm3btg0TJ05szyY2mquvvlrV/pEjR+LYsWOora2Fw+HA4cOHccUVV7RzSxtm\n8eLFKCgoACCuEw0YMCAm+lJXV4e///3veOONN6Ro1VgdF62+xOq4HDx4EGvWrAEgLqU5nc6YHBet\nfjz11FMxOSYvvfQSNmzYgI8++gizZs3CwoUL22VMYrqK0ooVK3Dw4EHodDosW7YMgwcPbu8mRUx9\nfT0eeeQR1NbWwuPxYNGiRRgyZAgef/xx8DyP7t27Y/ny5TCZTO3dVE1ycnLw/PPP4+LFizAajcjM\nzMSKFSuwZMkSVfu3bNmC1atXQ6fTYe7cuZgxY0Z7N1+GVl/mzp2LVatWwWazwW63Y/ny5UhLS4v6\nvqxbtw4rV65Edna2dOy5557D0qVLY25ctPoyc+ZMrF27NubGheM4PPnkkygqKgLHcVi0aBGGDx+u\n+f89mvui1Q+73Y4XXngh5saEZuXKlejRowcmTJjQ5mMS0yLMYDAYDEYsE7PuaAaDwWAwYh0mwgwG\ng8FgtBNMhBkMBoPBaCeYCDMYDAaD0U4wEWYwGAwGo51gIsxgMBgMRjvBRJjBYDAYjHaCiTCDwWAw\nGO3E/weAGtjEmMl4lQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f9870604ba8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "IPTFOJh3DTgq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "8977c9f6-b8ad-4bee-f1db-6c02c3e0a445"
      },
      "cell_type": "code",
      "source": [
        "now = datetime.datetime.now()\n",
        "\n",
        "# modelSaved = '{}-{}_{}_{}.h5'.format(folderNormal, folderFault, pretrainedModel, now.strftime('%m-%d-%H:%M:%S'))\n",
        "\n",
        "modelSaved = '{}-{}_{}_{}.h5'.format('A1', 'A5', pretrainedModel, now.strftime('%m-%d-%H:%M:%S'))\n",
        "meanSaved = 'mean_{}.npy'.format(now.strftime('%m-%d-%H:%M:%S'))\n",
        "stdSaved = 'std_{}.npy'.format(now.strftime('%m-%d-%H:%M:%S'))\n",
        "\n",
        "inputStr = input('''Save Model as '{}'? (y/n)\\n'''.format(modelSaved))\n",
        "\n",
        "if (inputStr == 'y' or inputStr == 'Y'):  \n",
        "    model.save('gdrive/My Drive/Colab/Model/{}'.format(modelSaved))\n",
        "    np.save('gdrive/My Drive/Colab/Model/{}'.format(meanSaved), trainMean)\n",
        "    np.save('gdrive/My Drive/Colab/Model/{}'.format(stdSaved), trainStd)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Save Model as 'A1-A5_InceptionV3_11-19-12:19:05.h5'? (y/n)\n",
            "n\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}