{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning Clean Up.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joovvhan/Master-Thesis/blob/master/log/(PN)N1-N5_Xception.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "c3821KWLNey6",
        "colab_type": "code",
        "outputId": "a66dd8e3-ecb3-407f-d208-785eb5296def",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Import necessary modules\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy.io.wavfile as wf\n",
        "import time\n",
        "import glob\n",
        "import datetime\n",
        "\n",
        "from tqdm import trange\n",
        "\n",
        "# Import Keras modules\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.layers import Input, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
        "from keras.models import Sequential\n",
        "from keras import backend as K\n",
        "from keras.models import load_model\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "nxSASpgF7unA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Mount google drive\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "# os.listdir('gdrive/My Drive/Colab')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rw9NU8Xjwcz2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set data directories\n",
        "\n",
        "dataPath = '''D:\\\\0_Joowhan's Paper\\\\Synthesized\\\\Total\\\\Impulse'''\n",
        "modelPath = '''D:\\\\0_Joowhan's Paper\\\\Synthesized\\\\Total\\\\Model'''\n",
        "\n",
        "\n",
        "# Changed variable names to normal and fault\n",
        "# Changed variable names from folder to path\n",
        "# Need to consider multiple folders\n",
        "# Need to add files to be tested\n",
        "\n",
        "folderNormal = ['P1N1', 'P2N1', 'P3N1', 'P4N1', 'P5N1']\n",
        "# folderNormal = list()\n",
        "\n",
        "# for x in range(1, 6):\n",
        "#     for y in range(1, 6):\n",
        "#         for z in range(1, 6):\n",
        "#             if (x <= 2 and y <= 2 and z <= 2):\n",
        "#                 folderNormal.append('A{}F{}P{}'.format(x, y, z))\n",
        "\n",
        "# folderFault = list()\n",
        "\n",
        "folderFault = ['P1N5', 'P2N5', 'P3N5', 'P4N5', 'P5N5']\n",
        "\n",
        "# for x in range(1, 6):\n",
        "#     for y in range(1, 6):\n",
        "#         for z in range(1, 6):\n",
        "#             if (x == 5 or y == 5 or z == 5):\n",
        "#                 folderFault.append('A{}F{}P{}'.format(x, y, z))\n",
        "\n",
        "\n",
        "pathNormal = list()\n",
        "pathFault = list()\n",
        "\n",
        "for i in range(len(folderNormal)):\n",
        "    pathNormal.append(dataPath + '/' + folderNormal[i])\n",
        "    \n",
        "for i in range(len(folderFault)):\n",
        "    pathFault.append(dataPath + '/' + folderFault[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xgGP7PZO-rTA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Specgram settings\n",
        "\n",
        "nsc = 1470\n",
        "nov = nsc/2\n",
        "nff = nsc \n",
        "imgSize = 224\n",
        "\n",
        "# pretrainedModel = 'VGG19'\n",
        "pretrainedModel = 'Xception'\n",
        "# pretrainedModel = 'ResNet50'\n",
        "\n",
        "# pretrainedModel = 'DenseNet169'\n",
        "# pretrainedModel = 'InceptionV3'\n",
        "\n",
        "\n",
        "lastActivation = 'softmax'\n",
        "sizeBatch = 4\n",
        "numEpochs = 12\n",
        "verb = 1\n",
        "\n",
        "\n",
        "# Learning parameters\n",
        "\n",
        "trainingRatio = 0.8\n",
        "\n",
        "totalDataNum = 1000\n",
        "repeat = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5AskF2qFT2xr",
        "colab_type": "code",
        "outputId": "38b7e6df-dc39-42cf-9d57-8b9a30ada039",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "cell_type": "code",
      "source": [
        "startNum = 0\n",
        "\n",
        "pickNum = int(np.ceil(totalDataNum / len(pathNormal)))\n",
        "\n",
        "for i in range(startNum, len(pathNormal)):\n",
        "\n",
        "    npyTestPath = glob.glob(pathNormal[i] + '/' + '*Image_With_Label.npy')\n",
        "    data = np.load(npyTestPath[0])\n",
        "    \n",
        "    pickIdx = np.random.choice(1000, pickNum, replace=False)\n",
        "    pickIdx.sort()\n",
        "    \n",
        "#     imgs = np.moveaxis(np.dstack(data[:, 0]), 2, 0)\n",
        "#     label = data[:, 1:5]\n",
        "\n",
        "    imgs = np.moveaxis(np.dstack(data[pickIdx, 0]), 2, 0)\n",
        "    label = data[pickIdx, 1:5]\n",
        "    \n",
        "    if i == startNum:\n",
        "        labelListNormal = label\n",
        "        imgsNormal = imgs\n",
        "    else:\n",
        "        labelListNormal = np.vstack([labelListNormal, label])\n",
        "        imgsNormal = np.vstack([imgsNormal, imgs])\n",
        "\n",
        "    print('Normal Image Shape From {}: {}:'.format(pathNormal[i], totalDataNum))    \n",
        "    print('Selected {}/{}:'.format(pickNum * (i + 1), len(data)))    \n",
        "    \n",
        "    \n",
        "print('Normal Image Shape: {}'.format(imgsNormal.shape))\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P1N1: 1000:\n",
            "Selected 200/1000:\n",
            "Normal Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P2N1: 1000:\n",
            "Selected 400/1000:\n",
            "Normal Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P3N1: 1000:\n",
            "Selected 600/1000:\n",
            "Normal Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P4N1: 1000:\n",
            "Selected 800/1000:\n",
            "Normal Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P5N1: 1000:\n",
            "Selected 1000/1000:\n",
            "Normal Image Shape: (1000, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P_MZtpk3Br_i",
        "colab_type": "code",
        "outputId": "78586349-a749-4253-d6ce-d58d42532662",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "cell_type": "code",
      "source": [
        "startNum = 0\n",
        "\n",
        "pickNum = int(np.ceil(totalDataNum / len(pathFault)))\n",
        "\n",
        "for i in range(startNum, len(pathFault)):\n",
        "\n",
        "    npyTestPath = glob.glob(pathFault[i] + '/' + '*Image_With_Label.npy')\n",
        "    data = np.load(npyTestPath[0])\n",
        "    \n",
        "    pickIdx = np.random.choice(1000, pickNum, replace=False)\n",
        "    pickIdx.sort()\n",
        "    \n",
        "#     imgs = np.moveaxis(np.dstack(data[:, 0]), 2, 0)\n",
        "#     label = data[:, 1:5]\n",
        "    \n",
        "    imgs = np.moveaxis(np.dstack(data[pickIdx, 0]), 2, 0)\n",
        "    label = data[pickIdx, 1:5]\n",
        "    \n",
        "    if i == startNum:\n",
        "        labelListFault = label\n",
        "        imgsFault = imgs\n",
        "    else:\n",
        "        labelListFault = np.vstack([labelListFault, label])\n",
        "        imgsFault = np.vstack([imgsFault, imgs])\n",
        "\n",
        "    print('Fault Image Shape From {}: {}:'.format(pathFault[i], totalDataNum))    \n",
        "    print('Selected {}/{}:'.format(pickNum * (i + 1), len(data)))     \n",
        "    \n",
        "print('Fault Image Shape: {}'.format(imgsFault.shape))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P1N5: 1000:\n",
            "Selected 200/1000:\n",
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P2N5: 1000:\n",
            "Selected 400/1000:\n",
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P3N5: 1000:\n",
            "Selected 600/1000:\n",
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P4N5: 1000:\n",
            "Selected 800/1000:\n",
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P5N5: 1000:\n",
            "Selected 1000/1000:\n",
            "Fault Image Shape: (1000, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e91QsAurSkIP",
        "colab_type": "code",
        "outputId": "5934115e-4295-42d6-8b81-e9efc640ca27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "cell_type": "code",
      "source": [
        "# Change name from imgsF1 or imgsF5 to imgsNormal and imgsFault\n",
        "\n",
        "dataNumNormal = len(imgsNormal)\n",
        "dataNumFault = len(imgsFault)\n",
        "dataNumNormalTrain = int(dataNumNormal * trainingRatio)\n",
        "dataNumFaultTrain = int(dataNumFault * trainingRatio)\n",
        "dataNumNormalTest = dataNumNormal - dataNumNormalTrain\n",
        "dataNumFaultTest = dataNumFault - dataNumFaultTrain\n",
        "\n",
        "print('Normal Train:Test = {:d}:{:d}'.format(dataNumNormalTrain, dataNumNormalTest))\n",
        "print('Fault  Train:Test = {:d}:{:d}\\n'.format(dataNumFaultTrain, dataNumFaultTest))\n",
        "\n",
        "trainIdxNormal = np.random.choice(dataNumNormal - 1, dataNumNormalTrain, replace=False)\n",
        "testIdxNormal = list(set(range(0, dataNumNormal)) - set(trainIdxNormal))\n",
        "\n",
        "trainImgsNormal = imgsNormal[trainIdxNormal, :, :]\n",
        "testImgsNormal = imgsNormal[testIdxNormal, :, :]\n",
        "\n",
        "print('Normal Training Image Shape {}'.format(trainImgsNormal.shape))\n",
        "print('Normal Test Image Shape {}\\n'.format(testImgsNormal.shape))\n",
        "\n",
        "trainIdxFault  = np.random.choice(dataNumFault - 1, dataNumFaultTrain, replace=False)\n",
        "testIdxFault = list(set(range(0, dataNumFault)) - set(trainIdxFault))\n",
        "\n",
        "trainImgsFault = imgsFault[trainIdxFault, :, :]\n",
        "testImgsFault = imgsFault[testIdxFault, :, :]\n",
        "\n",
        "print('Fault Training Image Shape {}'.format(trainImgsFault.shape))\n",
        "print('Fault Test Image Shape {}\\n'.format(testImgsFault.shape))\n",
        "\n",
        "trainImgs = np.vstack([trainImgsNormal, trainImgsFault])\n",
        "testImgs = np.vstack([testImgsNormal, testImgsFault])\n",
        "\n",
        "print('Training Image Shape {}'.format(trainImgs.shape))\n",
        "print('Test Image Shape {}'.format(testImgs.shape))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal Train:Test = 800:200\n",
            "Fault  Train:Test = 800:200\n",
            "\n",
            "Normal Training Image Shape (800, 224, 224)\n",
            "Normal Test Image Shape (200, 224, 224)\n",
            "\n",
            "Fault Training Image Shape (800, 224, 224)\n",
            "Fault Test Image Shape (200, 224, 224)\n",
            "\n",
            "Training Image Shape (1600, 224, 224)\n",
            "Test Image Shape (400, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MoE7f_hzs0av",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "feQ_AHAcUgHD",
        "colab_type": "code",
        "outputId": "458496ff-328d-4a67-e710-73c59edff219",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "trainMean = np.mean(trainImgs)\n",
        "trainStd = np.std(trainImgs)\n",
        "\n",
        "print('Mean of Training Image: {}'.format(trainMean))\n",
        "print('Standard Deviation of Training Image: {}'.format(trainStd))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean of Training Image: -79.07930945278375\n",
            "Standard Deviation of Training Image: 8.20717802263214\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wUi9IuXNUpir",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Should Change Norm to Normalized\n",
        "\n",
        "trainImgsNorm = (trainImgs - trainMean) / trainStd\n",
        "testImgsNorm = (testImgs - trainMean) / trainStd\n",
        "\n",
        "trainImgsNorm = trainImgsNorm.reshape(list(trainImgsNorm.shape) + [1])\n",
        "testImgsNorm = testImgsNorm.reshape(list(testImgsNorm.shape) + [1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aklxiPz1Ve4n",
        "colab_type": "code",
        "outputId": "aa7d03bb-4761-4db2-ce5e-e68637ae9da2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = np.stack([trainImgsNorm[:, :, :, 0], trainImgsNorm[:, :, :, 0], trainImgsNorm[:, :, :, 0]], axis = -1)\n",
        "X_test = np.stack([testImgsNorm[:, :, :, 0], testImgsNorm[:, :, :, 0], testImgsNorm[:, :, :, 0]], axis = -1)\n",
        "\n",
        "print('X_train Shape: {}'.format(X_train.shape))\n",
        "print('X_test  Shape: {}'.format(X_test.shape))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train Shape: (1600, 224, 224, 3)\n",
            "X_test  Shape: (400, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sRgIPzT7K_YP",
        "colab_type": "code",
        "outputId": "bcfe7e05-e3d9-4634-cc8b-224ac54144e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "trainLabelNormal = np.stack((np.ones(dataNumNormalTrain), np.zeros(dataNumNormalTrain)), axis = -1)\n",
        "testLabelNormal = np.stack((np.ones(dataNumNormalTest), np.zeros(dataNumNormalTest)), axis = -1)\n",
        "\n",
        "trainLabelFault = np.stack((np.zeros(dataNumFaultTrain), np.ones(dataNumFaultTrain)), axis = -1)\n",
        "testLabelFault = np.stack((np.zeros(dataNumFaultTest), np.ones(dataNumFaultTest)), axis = -1)\n",
        "\n",
        "Y_train = np.vstack((trainLabelNormal, trainLabelFault))\n",
        "Y_test = np.vstack((testLabelNormal, testLabelFault))\n",
        "\n",
        "print('Y_train Normal:Fault = {:d}:{:d}'.format(len(trainLabelNormal), len(trainLabelFault)))\n",
        "print('Y_test  Normal:Fault = {:d}:{:d}'.format(len(testLabelNormal), len(testLabelFault)))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Y_train Normal:Fault = 800:800\n",
            "Y_test  Normal:Fault = 200:200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kczwZk7Tbp5C",
        "colab_type": "code",
        "outputId": "213fbad7-49ed-491f-acc6-a575d656c562",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2647
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG19\n",
        "from keras.applications import VGG16\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications.densenet import DenseNet169\n",
        "from keras.applications.densenet import DenseNet201\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# pretrainedModel = 'ResNet50'\n",
        "# lastActivation = 'softmax'\n",
        "# lossFunction = 'binary_crossentropy'\n",
        "# sizeBatch = 2\n",
        "# numEpochs = 2\n",
        "# verb = 1\n",
        "\n",
        "for rp in range(repeat):\n",
        "\n",
        "    # Refresh all background variables\n",
        "    K.clear_session()\n",
        "\n",
        "    input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "    # Building sequential model with name 'model'\n",
        "    model = Sequential()\n",
        "\n",
        "    # Model selection\n",
        "\n",
        "    if (pretrainedModel == 'VGG16'):\n",
        "\n",
        "        modelWoTop = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'VGG19'):\n",
        "\n",
        "        modelWoTop = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif pretrainedModel == 'ResNet50':\n",
        "\n",
        "        modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'InceptionV3'):\n",
        "        modelWoTop = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'Xception'):\n",
        "        modelWoTop = Xception(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet169'):\n",
        "\n",
        "        modelWoTop = DenseNet169(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet201'):\n",
        "        modelWoTop = DenseNet201(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    else:\n",
        "        print('Invalid Pretrained Model Selection')\n",
        "\n",
        "\n",
        "\n",
        "    # Model compiling\n",
        "\n",
        "    print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "    print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "    model.fit(X_train, Y_train,\n",
        "              batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "              validation_data=(X_test, Y_test))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compiling Pretrained xception Model\n",
            "Training Pretrained xception Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/12\n",
            "1600/1600 [==============================] - 81s 51ms/step - loss: 0.2302 - acc: 0.9256 - val_loss: 0.1676 - val_acc: 0.9775\n",
            "Epoch 2/12\n",
            "1600/1600 [==============================] - 71s 44ms/step - loss: 0.1151 - acc: 0.9606 - val_loss: 0.0444 - val_acc: 0.9725\n",
            "Epoch 3/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.1082 - acc: 0.9594 - val_loss: 0.1161 - val_acc: 0.9575\n",
            "Epoch 4/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0410 - acc: 0.9831 - val_loss: 0.0410 - val_acc: 0.9700\n",
            "Epoch 5/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0447 - acc: 0.9812 - val_loss: 0.0473 - val_acc: 0.9725\n",
            "Epoch 6/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0519 - acc: 0.9781 - val_loss: 0.0454 - val_acc: 0.9750\n",
            "Epoch 7/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0356 - acc: 0.9831 - val_loss: 0.0558 - val_acc: 0.9725\n",
            "Epoch 8/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0619 - acc: 0.9769 - val_loss: 0.0461 - val_acc: 0.9700\n",
            "Epoch 9/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0305 - acc: 0.9838 - val_loss: 0.0396 - val_acc: 0.9775\n",
            "Epoch 10/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0289 - acc: 0.9894 - val_loss: 0.0427 - val_acc: 0.9800\n",
            "Epoch 11/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0224 - acc: 0.9875 - val_loss: 0.0431 - val_acc: 0.9750\n",
            "Epoch 12/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0199 - acc: 0.9894 - val_loss: 0.0363 - val_acc: 0.9775\n",
            "Compiling Pretrained xception Model\n",
            "Training Pretrained xception Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/12\n",
            "1600/1600 [==============================] - 78s 49ms/step - loss: 0.3123 - acc: 0.8912 - val_loss: 0.2311 - val_acc: 0.9275\n",
            "Epoch 2/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.1616 - acc: 0.9494 - val_loss: 0.6031 - val_acc: 0.8750\n",
            "Epoch 3/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0563 - acc: 0.9731 - val_loss: 0.0714 - val_acc: 0.9800\n",
            "Epoch 4/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0386 - acc: 0.9812 - val_loss: 0.0395 - val_acc: 0.9775\n",
            "Epoch 5/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0714 - acc: 0.9706 - val_loss: 6.1079 - val_acc: 0.4025\n",
            "Epoch 6/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0907 - acc: 0.9637 - val_loss: 0.0442 - val_acc: 0.9775\n",
            "Epoch 7/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0335 - acc: 0.9862 - val_loss: 0.0691 - val_acc: 0.9775\n",
            "Epoch 8/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0434 - acc: 0.9800 - val_loss: 0.0490 - val_acc: 0.9675\n",
            "Epoch 9/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0426 - acc: 0.9756 - val_loss: 0.0586 - val_acc: 0.9650\n",
            "Epoch 10/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0625 - acc: 0.9788 - val_loss: 11.8014 - val_acc: 0.1400\n",
            "Epoch 11/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0379 - acc: 0.9812 - val_loss: 0.0520 - val_acc: 0.9700\n",
            "Epoch 12/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0367 - acc: 0.9838 - val_loss: 0.0425 - val_acc: 0.9775\n",
            "Compiling Pretrained xception Model\n",
            "Training Pretrained xception Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/12\n",
            "1600/1600 [==============================] - 80s 50ms/step - loss: 0.2573 - acc: 0.9100 - val_loss: 5.3064 - val_acc: 0.5150\n",
            "Epoch 2/12\n",
            "1600/1600 [==============================] - 71s 44ms/step - loss: 0.1039 - acc: 0.9669 - val_loss: 0.0635 - val_acc: 0.9650\n",
            "Epoch 3/12\n",
            "1600/1600 [==============================] - 71s 44ms/step - loss: 0.1563 - acc: 0.9544 - val_loss: 0.6584 - val_acc: 0.8950\n",
            "Epoch 4/12\n",
            "1600/1600 [==============================] - 71s 44ms/step - loss: 0.0752 - acc: 0.9663 - val_loss: 0.0457 - val_acc: 0.9725\n",
            "Epoch 5/12\n",
            "1600/1600 [==============================] - 71s 44ms/step - loss: 0.0648 - acc: 0.9712 - val_loss: 0.1637 - val_acc: 0.9675\n",
            "Epoch 6/12\n",
            "1600/1600 [==============================] - 71s 44ms/step - loss: 0.0461 - acc: 0.9756 - val_loss: 0.0521 - val_acc: 0.9675\n",
            "Epoch 7/12\n",
            "1600/1600 [==============================] - 71s 44ms/step - loss: 0.0318 - acc: 0.9812 - val_loss: 0.0506 - val_acc: 0.9700\n",
            "Epoch 8/12\n",
            "1600/1600 [==============================] - 71s 44ms/step - loss: 0.0579 - acc: 0.9775 - val_loss: 0.0845 - val_acc: 0.9725\n",
            "Epoch 9/12\n",
            "1600/1600 [==============================] - 71s 44ms/step - loss: 0.0367 - acc: 0.9806 - val_loss: 0.0537 - val_acc: 0.9750\n",
            "Epoch 10/12\n",
            "1600/1600 [==============================] - 71s 44ms/step - loss: 0.0326 - acc: 0.9800 - val_loss: 0.0498 - val_acc: 0.9700\n",
            "Epoch 11/12\n",
            "1600/1600 [==============================] - 71s 44ms/step - loss: 0.0712 - acc: 0.9738 - val_loss: 0.2294 - val_acc: 0.9150\n",
            "Epoch 12/12\n",
            "1600/1600 [==============================] - 71s 44ms/step - loss: 0.0433 - acc: 0.9794 - val_loss: 0.0387 - val_acc: 0.9775\n",
            "Compiling Pretrained xception Model\n",
            "Training Pretrained xception Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/12\n",
            "1600/1600 [==============================] - 78s 49ms/step - loss: 0.2192 - acc: 0.9225 - val_loss: 0.0602 - val_acc: 0.9675\n",
            "Epoch 2/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.1069 - acc: 0.9575 - val_loss: 0.0778 - val_acc: 0.9675\n",
            "Epoch 3/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.1289 - acc: 0.9519 - val_loss: 0.0470 - val_acc: 0.9800\n",
            "Epoch 4/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0352 - acc: 0.9831 - val_loss: 0.0431 - val_acc: 0.9675\n",
            "Epoch 5/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0642 - acc: 0.9750 - val_loss: 0.0584 - val_acc: 0.9675\n",
            "Epoch 6/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0543 - acc: 0.9775 - val_loss: 0.0511 - val_acc: 0.9750\n",
            "Epoch 7/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0450 - acc: 0.9781 - val_loss: 0.3193 - val_acc: 0.8525\n",
            "Epoch 8/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.2219 - acc: 0.9438 - val_loss: 0.6218 - val_acc: 0.8375\n",
            "Epoch 9/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0539 - acc: 0.9725 - val_loss: 0.0944 - val_acc: 0.9700\n",
            "Epoch 10/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0350 - acc: 0.9788 - val_loss: 0.0472 - val_acc: 0.9700\n",
            "Epoch 11/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0463 - acc: 0.9775 - val_loss: 0.0516 - val_acc: 0.9775\n",
            "Epoch 12/12\n",
            "1600/1600 [==============================] - 73s 46ms/step - loss: 0.0294 - acc: 0.9844 - val_loss: 0.0400 - val_acc: 0.9750\n",
            "Compiling Pretrained xception Model\n",
            "Training Pretrained xception Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/12\n",
            "1600/1600 [==============================] - 78s 49ms/step - loss: 0.3037 - acc: 0.8981 - val_loss: 0.6330 - val_acc: 0.6950\n",
            "Epoch 2/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.1812 - acc: 0.9362 - val_loss: 0.0781 - val_acc: 0.9725\n",
            "Epoch 3/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0570 - acc: 0.9731 - val_loss: 0.0462 - val_acc: 0.9775\n",
            "Epoch 4/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0388 - acc: 0.9819 - val_loss: 0.0705 - val_acc: 0.9675\n",
            "Epoch 5/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0518 - acc: 0.9756 - val_loss: 0.0394 - val_acc: 0.9775\n",
            "Epoch 6/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0471 - acc: 0.9775 - val_loss: 0.0477 - val_acc: 0.9700\n",
            "Epoch 7/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0837 - acc: 0.9681 - val_loss: 0.0605 - val_acc: 0.9775\n",
            "Epoch 8/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0281 - acc: 0.9887 - val_loss: 0.0486 - val_acc: 0.9675\n",
            "Epoch 9/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0272 - acc: 0.9838 - val_loss: 0.0374 - val_acc: 0.9775\n",
            "Epoch 10/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0197 - acc: 0.9887 - val_loss: 0.0386 - val_acc: 0.9750\n",
            "Epoch 11/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0793 - acc: 0.9731 - val_loss: 0.0386 - val_acc: 0.9775\n",
            "Epoch 12/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0475 - acc: 0.9775 - val_loss: 0.0394 - val_acc: 0.9750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jKgFIa4gkgkk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "# print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "# model.fit(X_train, Y_train,\n",
        "#           batch_size=sizeBatch, epochs=1, verbose=1,\n",
        "#           validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "agqqH8sf3CiV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# K.clear_session()\n",
        "\n",
        "# input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "# # Building sequential model with name 'model'\n",
        "# model = Sequential()\n",
        "\n",
        "# modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "# model.add(modelWoTop)\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "# # Model compiling\n",
        "\n",
        "# print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "# model.compile(loss='binary_crossentropy',\n",
        "#               optimizer='adam',\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "# numEpochs = 1\n",
        "\n",
        "# print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "# print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "# model.fit(X_train, Y_train,\n",
        "#           batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "#           validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qexmaPZVz04q",
        "colab_type": "code",
        "outputId": "75464091-4a91-4bee-bbfd-740622ba1764",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.plot(Y_test[:, 1], 'r')\n",
        "\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.plot(Y_pred[:, 1], 'b')\n",
        "\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.plot(Y_test[:, 1] - Y_pred[:, 1], 'g')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "IPTFOJh3DTgq",
        "colab_type": "code",
        "outputId": "7e699d7d-251c-4753-aa08-bec6fcebf07a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "cell_type": "code",
      "source": [
        "now = datetime.datetime.now()\n",
        "\n",
        "# modelSaved = '{}-{}_{}_{}.h5'.format(folderNormal, folderFault, pretrainedModel, now.strftime('%m-%d-%H:%M:%S'))\n",
        "\n",
        "modelSaved = '{}-{}_{}_{}.h5'.format(folderNormal, folderFault, pretrainedModel, now.strftime('%m-%d-%H-%M-%S'))\n",
        "meanSaved = 'mean_{}.npy'.format(now.strftime('%m-%d-%H-%M-%S'))\n",
        "stdSaved = 'std_{}.npy'.format(now.strftime('%m-%d-%H-%M-%S'))\n",
        "\n",
        "inputStr = input('''Save Model as '{}'? (y/n)\\n'''.format(modelSaved))\n",
        "\n",
        "if (inputStr == 'y' or inputStr == 'Y'):  \n",
        "    model.save(modelPath + '/{}'.format(modelSaved))\n",
        "    np.save(modelPath + '/{}'.format(meanSaved), trainMean)\n",
        "    np.save(modelPath + '/{}'.format(stdSaved), trainStd)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Save Model as '['P1N1', 'P2N1', 'P3N1', 'P4N1', 'P5N1']-['P1N5', 'P2N5', 'P3N5', 'P4N5', 'P5N5']_Xception_11-18-04-30-17.h5'? (y/n)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}