{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning Clean Up.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joovvhan/Master-Thesis/blob/master/log/['A3F3P1']-['A3F3P5']_DenseNet201.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "c3821KWLNey6",
        "colab_type": "code",
        "outputId": "775a80dc-6c1f-404f-f0f6-4de30472deb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Import necessary modules\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy.io.wavfile as wf\n",
        "import time\n",
        "import glob\n",
        "import datetime\n",
        "\n",
        "from tqdm import trange\n",
        "\n",
        "# Import Keras modules\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.layers import Input, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
        "from keras.models import Sequential\n",
        "from keras import backend as K\n",
        "from keras.models import load_model\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "nxSASpgF7unA",
        "colab_type": "code",
        "outputId": "7d7a11e7-0094-4d69-bef2-8610c9093fcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "cell_type": "code",
      "source": [
        "# Mount google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "os.listdir('gdrive/My Drive/Colab')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Data', 'Model', 'Data_']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "rw9NU8Xjwcz2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set data directories\n",
        "\n",
        "dataPath = 'gdrive/My Drive/Colab/Data'\n",
        "\n",
        "# Changed variable names to normal and fault\n",
        "# Changed variable names from folder to path\n",
        "# Need to consider multiple folders\n",
        "# Need to add files to be tested\n",
        "\n",
        "#folderNormal = ['A1F3P3']\n",
        "folderNormal = list()\n",
        "\n",
        "for x in range(3, 4):\n",
        "    for y in range(3, 4):\n",
        "        for z in range(1, 2):\n",
        "            #if (x <= 2 and y <= 2 and z <= 2):\n",
        "            folderNormal.append('A{}F{}P{}'.format(x, y, z))\n",
        "\n",
        "folderFault = list()\n",
        "\n",
        "# folderFault = ['A5F3P3']\n",
        "\n",
        "for x in range(3, 4):\n",
        "    for y in range(3, 4):\n",
        "        for z in range(5, 6):\n",
        "            #if (x == 5 or y == 5 or z == 5):\n",
        "            folderFault.append('A{}F{}P{}'.format(x, y, z))\n",
        "\n",
        "\n",
        "pathNormal = list()\n",
        "pathFault = list()\n",
        "\n",
        "for i in range(len(folderNormal)):\n",
        "    pathNormal.append(dataPath + '/' + folderNormal[i])\n",
        "    \n",
        "for i in range(len(folderFault)):\n",
        "    pathFault.append(dataPath + '/' + folderFault[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xgGP7PZO-rTA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Specgram settings\n",
        "\n",
        "nsc = 1470\n",
        "nov = nsc/2\n",
        "nff = nsc \n",
        "imgSize = 224\n",
        "\n",
        "# pretrainedModel = 'VGG19'\n",
        "# pretrainedModel = 'Xception'\n",
        "# pretrainedModel = 'ResNet50'\n",
        "\n",
        "# pretrainedModel = 'VGG19'\n",
        "# pretrainedModel = 'InceptionV3'\n",
        "# pretrainedModel = 'DenseNet169'\n",
        "pretrainedModel = 'DenseNet201'\n",
        "\n",
        "\n",
        "lastActivation = 'softmax'\n",
        "sizeBatch = 4\n",
        "numEpochs = 6\n",
        "verb = 1\n",
        "\n",
        "\n",
        "# Learning parameters\n",
        "\n",
        "trainingRatio = 0.8\n",
        "\n",
        "totalDataNum = 1000\n",
        "repeat = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5AskF2qFT2xr",
        "colab_type": "code",
        "outputId": "7176c9af-48eb-46b4-bffe-6869d1c2205b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "startNum = 0\n",
        "\n",
        "pickNum = int(np.ceil(totalDataNum / len(pathNormal)))\n",
        "\n",
        "for i in range(startNum, len(pathNormal)):\n",
        "\n",
        "    npyTestPath = glob.glob(pathNormal[i] + '/' + '*Image_With_Label.npy')\n",
        "    data = np.load(npyTestPath[0])\n",
        "    \n",
        "    pickIdx = np.random.choice(1000, pickNum, replace=False)\n",
        "    pickIdx.sort()\n",
        "    \n",
        "#     imgs = np.moveaxis(np.dstack(data[:, 0]), 2, 0)\n",
        "#     label = data[:, 1:5]\n",
        "\n",
        "    imgs = np.moveaxis(np.dstack(data[pickIdx, 0]), 2, 0)\n",
        "    label = data[pickIdx, 1:5]\n",
        "    \n",
        "    if i == startNum:\n",
        "        labelListNormal = label\n",
        "        imgsNormal = imgs\n",
        "    else:\n",
        "        labelListNormal = np.vstack([labelListNormal, label])\n",
        "        imgsNormal = np.vstack([imgsNormal, imgs])\n",
        "\n",
        "    print('Normal Image Shape From {}: {}:'.format(pathNormal[i], totalDataNum))    \n",
        "    print('Selected {}/{}:'.format(pickNum * (i + 1), len(data)))    \n",
        "    \n",
        "    \n",
        "print('Normal Image Shape: {}'.format(imgsNormal.shape))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A3F3P1: 1000:\n",
            "Selected 1000/1000:\n",
            "Normal Image Shape: (1000, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P_MZtpk3Br_i",
        "colab_type": "code",
        "outputId": "d8ba08c2-ddc5-4fcd-9d60-80d49adc81ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "startNum = 0\n",
        "\n",
        "pickNum = int(np.ceil(totalDataNum / len(pathFault)))\n",
        "\n",
        "for i in range(startNum, len(pathFault)):\n",
        "\n",
        "    npyTestPath = glob.glob(pathFault[i] + '/' + '*Image_With_Label.npy')\n",
        "    data = np.load(npyTestPath[0])\n",
        "    \n",
        "    pickIdx = np.random.choice(1000, pickNum, replace=False)\n",
        "    pickIdx.sort()\n",
        "    \n",
        "#     imgs = np.moveaxis(np.dstack(data[:, 0]), 2, 0)\n",
        "#     label = data[:, 1:5]\n",
        "    \n",
        "    imgs = np.moveaxis(np.dstack(data[pickIdx, 0]), 2, 0)\n",
        "    label = data[pickIdx, 1:5]\n",
        "    \n",
        "    if i == startNum:\n",
        "        labelListFault = label\n",
        "        imgsFault = imgs\n",
        "    else:\n",
        "        labelListFault = np.vstack([labelListFault, label])\n",
        "        imgsFault = np.vstack([imgsFault, imgs])\n",
        "\n",
        "    print('Fault Image Shape From {}: {}:'.format(pathFault[i], totalDataNum))    \n",
        "    print('Selected {}/{}:'.format(pickNum * (i + 1), len(data)))     \n",
        "    \n",
        "print('Fault Image Shape: {}'.format(imgsFault.shape))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A3F3P5: 1000:\n",
            "Selected 1000/1000:\n",
            "Fault Image Shape: (1000, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e91QsAurSkIP",
        "colab_type": "code",
        "outputId": "6df2cdc5-93c2-4e30-f547-3305e52f61a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "cell_type": "code",
      "source": [
        "# Change name from imgsF1 or imgsF5 to imgsNormal and imgsFault\n",
        "\n",
        "dataNumNormal = len(imgsNormal)\n",
        "dataNumFault = len(imgsFault)\n",
        "dataNumNormalTrain = int(dataNumNormal * trainingRatio)\n",
        "dataNumFaultTrain = int(dataNumFault * trainingRatio)\n",
        "dataNumNormalTest = dataNumNormal - dataNumNormalTrain\n",
        "dataNumFaultTest = dataNumFault - dataNumFaultTrain\n",
        "\n",
        "print('Normal Train:Test = {:d}:{:d}'.format(dataNumNormalTrain, dataNumNormalTest))\n",
        "print('Fault  Train:Test = {:d}:{:d}\\n'.format(dataNumFaultTrain, dataNumFaultTest))\n",
        "\n",
        "trainIdxNormal = np.random.choice(dataNumNormal - 1, dataNumNormalTrain, replace=False)\n",
        "testIdxNormal = list(set(range(0, dataNumNormal)) - set(trainIdxNormal))\n",
        "\n",
        "trainImgsNormal = imgsNormal[trainIdxNormal, :, :]\n",
        "testImgsNormal = imgsNormal[testIdxNormal, :, :]\n",
        "\n",
        "print('Normal Training Image Shape {}'.format(trainImgsNormal.shape))\n",
        "print('Normal Test Image Shape {}\\n'.format(testImgsNormal.shape))\n",
        "\n",
        "trainIdxFault  = np.random.choice(dataNumFault - 1, dataNumFaultTrain, replace=False)\n",
        "testIdxFault = list(set(range(0, dataNumFault)) - set(trainIdxFault))\n",
        "\n",
        "trainImgsFault = imgsFault[trainIdxFault, :, :]\n",
        "testImgsFault = imgsFault[testIdxFault, :, :]\n",
        "\n",
        "print('Fault Training Image Shape {}'.format(trainImgsFault.shape))\n",
        "print('Fault Test Image Shape {}\\n'.format(testImgsFault.shape))\n",
        "\n",
        "trainImgs = np.vstack([trainImgsNormal, trainImgsFault])\n",
        "testImgs = np.vstack([testImgsNormal, testImgsFault])\n",
        "\n",
        "print('Training Image Shape {}'.format(trainImgs.shape))\n",
        "print('Test Image Shape {}'.format(testImgs.shape))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal Train:Test = 800:200\n",
            "Fault  Train:Test = 800:200\n",
            "\n",
            "Normal Training Image Shape (800, 224, 224)\n",
            "Normal Test Image Shape (200, 224, 224)\n",
            "\n",
            "Fault Training Image Shape (800, 224, 224)\n",
            "Fault Test Image Shape (200, 224, 224)\n",
            "\n",
            "Training Image Shape (1600, 224, 224)\n",
            "Test Image Shape (400, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MoE7f_hzs0av",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "feQ_AHAcUgHD",
        "colab_type": "code",
        "outputId": "df3cf9e5-8596-4874-de91-ee524af2a24c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "trainMean = np.mean(trainImgs)\n",
        "trainStd = np.std(trainImgs)\n",
        "\n",
        "print('Mean of Training Image: {}'.format(trainMean))\n",
        "print('Standard Deviation of Training Image: {}'.format(trainStd))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean of Training Image: -78.18166005231248\n",
            "Standard Deviation of Training Image: 9.399858577679174\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wUi9IuXNUpir",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Should Change Norm to Normalized\n",
        "\n",
        "trainImgsNorm = (trainImgs - trainMean) / trainStd\n",
        "testImgsNorm = (testImgs - trainMean) / trainStd\n",
        "\n",
        "trainImgsNorm = trainImgsNorm.reshape(list(trainImgsNorm.shape) + [1])\n",
        "testImgsNorm = testImgsNorm.reshape(list(testImgsNorm.shape) + [1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aklxiPz1Ve4n",
        "colab_type": "code",
        "outputId": "02a54b01-d49c-47bd-b077-f9e894151a46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = np.stack([trainImgsNorm[:, :, :, 0], trainImgsNorm[:, :, :, 0], trainImgsNorm[:, :, :, 0]], axis = -1)\n",
        "X_test = np.stack([testImgsNorm[:, :, :, 0], testImgsNorm[:, :, :, 0], testImgsNorm[:, :, :, 0]], axis = -1)\n",
        "\n",
        "print('X_train Shape: {}'.format(X_train.shape))\n",
        "print('X_test  Shape: {}'.format(X_test.shape))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train Shape: (1600, 224, 224, 3)\n",
            "X_test  Shape: (400, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sRgIPzT7K_YP",
        "colab_type": "code",
        "outputId": "6c6f5667-fe3c-4c31-9330-b5808e80140d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "trainLabelNormal = np.stack((np.ones(dataNumNormalTrain), np.zeros(dataNumNormalTrain)), axis = -1)\n",
        "testLabelNormal = np.stack((np.ones(dataNumNormalTest), np.zeros(dataNumNormalTest)), axis = -1)\n",
        "\n",
        "trainLabelFault = np.stack((np.zeros(dataNumFaultTrain), np.ones(dataNumFaultTrain)), axis = -1)\n",
        "testLabelFault = np.stack((np.zeros(dataNumFaultTest), np.ones(dataNumFaultTest)), axis = -1)\n",
        "\n",
        "Y_train = np.vstack((trainLabelNormal, trainLabelFault))\n",
        "Y_test = np.vstack((testLabelNormal, testLabelFault))\n",
        "\n",
        "print('Y_train Normal:Fault = {:d}:{:d}'.format(len(trainLabelNormal), len(trainLabelFault)))\n",
        "print('Y_test  Normal:Fault = {:d}:{:d}'.format(len(testLabelNormal), len(testLabelFault)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Y_train Normal:Fault = 800:800\n",
            "Y_test  Normal:Fault = 200:200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kczwZk7Tbp5C",
        "colab_type": "code",
        "outputId": "67494376-72a9-49d5-9644-995c13051f1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG19\n",
        "from keras.applications import VGG16\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications.densenet import DenseNet169\n",
        "from keras.applications.densenet import DenseNet201\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# pretrainedModel = 'ResNet50'\n",
        "# lastActivation = 'softmax'\n",
        "# lossFunction = 'binary_crossentropy'\n",
        "# sizeBatch = 2\n",
        "# numEpochs = 2\n",
        "# verb = 1\n",
        "\n",
        "for rp in range(repeat):\n",
        "\n",
        "    # Refresh all background variables\n",
        "    K.clear_session()\n",
        "\n",
        "    input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "    # Building sequential model with name 'model'\n",
        "    model = Sequential()\n",
        "\n",
        "    # Model selection\n",
        "\n",
        "    if (pretrainedModel == 'VGG16'):\n",
        "\n",
        "        modelWoTop = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'VGG19'):\n",
        "\n",
        "        modelWoTop = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif pretrainedModel == 'ResNet50':\n",
        "\n",
        "        modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'InceptionV3'):\n",
        "        modelWoTop = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'Xception'):\n",
        "        modelWoTop = Xception(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet169'):\n",
        "\n",
        "        modelWoTop = DenseNet169(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet201'):\n",
        "        modelWoTop = DenseNet201(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    else:\n",
        "        print('Invalid Pretrained Model Selection')\n",
        "\n",
        "\n",
        "\n",
        "    # Model compiling\n",
        "\n",
        "    print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "    print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "    model.fit(X_train, Y_train,\n",
        "              batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "              validation_data=(X_test, Y_test))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/keras-team/keras-applications/releases/download/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "74842112/74836368 [==============================] - 3s 0us/step\n",
            "Compiling Pretrained densenet201 Model\n",
            "Training Pretrained densenet201 Model\n",
            "Batch Size: 4\t Epochs: 6\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 251s 157ms/step - loss: 0.1850 - acc: 0.9494 - val_loss: 0.0052 - val_acc: 1.0000\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 194s 121ms/step - loss: 0.0435 - acc: 0.9875 - val_loss: 3.4365e-05 - val_acc: 1.0000\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 194s 121ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 6.3623e-05 - val_acc: 1.0000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 192s 120ms/step - loss: 0.1714 - acc: 0.9537 - val_loss: 2.0382 - val_acc: 0.7550\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 193s 121ms/step - loss: 0.0303 - acc: 0.9887 - val_loss: 0.4963 - val_acc: 0.9250\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 193s 120ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 0.9975\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-aE0MIEjuC_k",
        "colab_type": "code",
        "outputId": "d7213180-3d81-4ef9-fd77-593b3641287c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "for rp in range(repeat):\n",
        "\n",
        "    # Refresh all background variables\n",
        "    K.clear_session()\n",
        "\n",
        "    input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "    # Building sequential model with name 'model'\n",
        "    model = Sequential()\n",
        "\n",
        "    # Model selection\n",
        "\n",
        "    if (pretrainedModel == 'VGG16'):\n",
        "\n",
        "        modelWoTop = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'VGG19'):\n",
        "\n",
        "        modelWoTop = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif pretrainedModel == 'ResNet50':\n",
        "\n",
        "        modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'InceptionV3'):\n",
        "        modelWoTop = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'Xception'):\n",
        "        modelWoTop = Xception(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet169'):\n",
        "\n",
        "        modelWoTop = DenseNet169(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet201'):\n",
        "        modelWoTop = DenseNet201(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    else:\n",
        "        print('Invalid Pretrained Model Selection')\n",
        "\n",
        "\n",
        "\n",
        "    # Model compiling\n",
        "\n",
        "    print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "    print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "    model.fit(X_train, Y_train,\n",
        "              batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "              validation_data=(X_test, Y_test))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compiling Pretrained densenet201 Model\n",
            "Training Pretrained densenet201 Model\n",
            "Batch Size: 4\t Epochs: 6\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 251s 157ms/step - loss: 0.1412 - acc: 0.9519 - val_loss: 0.0012 - val_acc: 1.0000\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 195s 122ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 1.0330e-04 - val_acc: 1.0000\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 194s 122ms/step - loss: 2.9975e-04 - acc: 1.0000 - val_loss: 3.5633e-05 - val_acc: 1.0000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 195s 122ms/step - loss: 1.9867e-04 - acc: 1.0000 - val_loss: 2.7404e-05 - val_acc: 1.0000\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 194s 121ms/step - loss: 1.4796e-04 - acc: 1.0000 - val_loss: 2.6568e-05 - val_acc: 1.0000\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 195s 122ms/step - loss: 8.4203e-05 - acc: 1.0000 - val_loss: 2.0887e-05 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "15t3_glRqbHT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "6fad8d15-8ece-46c0-8a49-babcec35e3f2"
      },
      "cell_type": "code",
      "source": [
        "# Refresh all background variables\n",
        "K.clear_session()\n",
        "\n",
        "input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "# Building sequential model with name 'model'\n",
        "model = Sequential()\n",
        "\n",
        "# Model selection\n",
        "\n",
        "if (pretrainedModel == 'VGG16'):\n",
        "\n",
        "    modelWoTop = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'VGG19'):\n",
        "\n",
        "    modelWoTop = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif pretrainedModel == 'ResNet50':\n",
        "\n",
        "    modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'InceptionV3'):\n",
        "    modelWoTop = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'Xception'):\n",
        "    modelWoTop = Xception(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'DenseNet169'):\n",
        "\n",
        "    modelWoTop = DenseNet169(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'DenseNet201'):\n",
        "    modelWoTop = DenseNet201(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "else:\n",
        "    print('Invalid Pretrained Model Selection')\n",
        "\n",
        "\n",
        "\n",
        "# Model compiling\n",
        "\n",
        "print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compiling Pretrained densenet201 Model\n",
            "Training Pretrained densenet201 Model\n",
            "Batch Size: 4\t Epochs: 6\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 252s 157ms/step - loss: 0.1890 - acc: 0.9494 - val_loss: 0.0672 - val_acc: 0.9875\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 195s 122ms/step - loss: 0.0041 - acc: 0.9987 - val_loss: 3.2492e-04 - val_acc: 1.0000\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 195s 122ms/step - loss: 5.7803e-04 - acc: 1.0000 - val_loss: 3.7757e-05 - val_acc: 1.0000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 195s 122ms/step - loss: 2.4185e-04 - acc: 1.0000 - val_loss: 2.2254e-05 - val_acc: 1.0000\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 194s 121ms/step - loss: 1.9333e-04 - acc: 1.0000 - val_loss: 6.9735e-04 - val_acc: 1.0000\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 195s 122ms/step - loss: 1.4328e-04 - acc: 1.0000 - val_loss: 1.5474e-05 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1ab0ba9710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "JJoK167dqbdS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "7fec9c79-0073-4c9c-e0e5-9ab4595acc73"
      },
      "cell_type": "code",
      "source": [
        "K.clear_session()\n",
        "\n",
        "input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "# Building sequential model with name 'model'\n",
        "model = Sequential()\n",
        "\n",
        "# Model selection\n",
        "\n",
        "if (pretrainedModel == 'VGG16'):\n",
        "\n",
        "    modelWoTop = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'VGG19'):\n",
        "\n",
        "    modelWoTop = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif pretrainedModel == 'ResNet50':\n",
        "\n",
        "    modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'InceptionV3'):\n",
        "    modelWoTop = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'Xception'):\n",
        "    modelWoTop = Xception(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'DenseNet169'):\n",
        "\n",
        "    modelWoTop = DenseNet169(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'DenseNet201'):\n",
        "    modelWoTop = DenseNet201(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "else:\n",
        "    print('Invalid Pretrained Model Selection')\n",
        "\n",
        "\n",
        "\n",
        "# Model compiling\n",
        "\n",
        "print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compiling Pretrained densenet201 Model\n",
            "Training Pretrained densenet201 Model\n",
            "Batch Size: 4\t Epochs: 6\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/6\n",
            "1600/1600 [==============================] - 250s 156ms/step - loss: 0.1642 - acc: 0.9525 - val_loss: 0.0016 - val_acc: 1.0000\n",
            "Epoch 2/6\n",
            "1600/1600 [==============================] - 195s 122ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 4.7034e-04 - val_acc: 1.0000\n",
            "Epoch 3/6\n",
            "1600/1600 [==============================] - 195s 122ms/step - loss: 4.8314e-04 - acc: 1.0000 - val_loss: 4.4036e-05 - val_acc: 1.0000\n",
            "Epoch 4/6\n",
            "1600/1600 [==============================] - 196s 122ms/step - loss: 2.7028e-04 - acc: 1.0000 - val_loss: 1.9342e-05 - val_acc: 1.0000\n",
            "Epoch 5/6\n",
            "1600/1600 [==============================] - 195s 122ms/step - loss: 1.2734e-04 - acc: 1.0000 - val_loss: 1.3832e-05 - val_acc: 1.0000\n",
            "Epoch 6/6\n",
            "1600/1600 [==============================] - 196s 122ms/step - loss: 1.1147e-04 - acc: 1.0000 - val_loss: 1.1680e-05 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1a677317b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "eA9GZhLGe5X9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "# print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "# model.fit(X_train, Y_train,\n",
        "#           batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "#           validation_data=(X_test, Y_test))\n",
        "\n",
        "# Y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qexmaPZVz04q",
        "colab_type": "code",
        "outputId": "e2b16253-8606-4ba3-dc70-cf1c591a9425",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "cell_type": "code",
      "source": [
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.plot(Y_test[:, 1], 'r')\n",
        "\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.plot(Y_pred[:, 1], 'b')\n",
        "\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.plot(Y_test[:, 1] - Y_pred[:, 1], 'g')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfgAAAFKCAYAAADxKk0BAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f1a82dbaf98>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "IPTFOJh3DTgq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "0f373d90-03c9-4415-8d68-e1a1d498494c"
      },
      "cell_type": "code",
      "source": [
        "now = datetime.datetime.now()\n",
        "\n",
        "modelSaved = '{}-{}_{}_{}.h5'.format(folderNormal, folderFault, pretrainedModel, now.strftime('%m-%d-%H:%M:%S'))\n",
        "\n",
        "# modelSaved = '{}-{}_{}_{}.h5'.format('P1', 'P5', pretrainedModel, now.strftime('%m-%d-%H:%M:%S'))\n",
        "meanSaved = 'mean_{}.npy'.format(now.strftime('%m-%d-%H:%M:%S'))\n",
        "stdSaved = 'std_{}.npy'.format(now.strftime('%m-%d-%H:%M:%S'))\n",
        "\n",
        "inputStr = input('''Save Model as '{}'? (y/n)\\n'''.format(modelSaved))\n",
        "\n",
        "if (inputStr == 'y' or inputStr == 'Y'):  \n",
        "    model.save('gdrive/My Drive/Colab/Model/{}'.format(modelSaved))\n",
        "    np.save('gdrive/My Drive/Colab/Model/{}'.format(meanSaved), trainMean)\n",
        "    np.save('gdrive/My Drive/Colab/Model/{}'.format(stdSaved), trainStd)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Save Model as '['A3F3P1']-['A3F3P5']_DenseNet201_11-20-09:16:37.h5'? (y/n)\n",
            "y\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}