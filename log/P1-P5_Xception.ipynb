{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning Clean Up.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joovvhan/Master-Thesis/blob/master/log/P1-P5_Xception.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "c3821KWLNey6",
        "colab_type": "code",
        "outputId": "3dffd4de-0f22-4acd-8677-0773c13c9b17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Import necessary modules\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy.io.wavfile as wf\n",
        "import time\n",
        "import glob\n",
        "import datetime\n",
        "\n",
        "from tqdm import trange\n",
        "\n",
        "# Import Keras modules\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.layers import Input, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
        "from keras.models import Sequential\n",
        "from keras import backend as K\n",
        "from keras.models import load_model\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "nxSASpgF7unA",
        "colab_type": "code",
        "outputId": "80c4a0f7-80c5-41fd-80c7-dc5885cbd868",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "cell_type": "code",
      "source": [
        "# Mount google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "os.listdir('gdrive/My Drive/Colab')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Data', 'Model', 'Data_']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "rw9NU8Xjwcz2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set data directories\n",
        "\n",
        "dataPath = 'gdrive/My Drive/Colab/Data'\n",
        "\n",
        "# Changed variable names to normal and fault\n",
        "# Changed variable names from folder to path\n",
        "# Need to consider multiple folders\n",
        "# Need to add files to be tested\n",
        "\n",
        "#folderNormal = ['A1F3P3']\n",
        "folderNormal = list()\n",
        "\n",
        "for x in range(1, 6):\n",
        "    for y in range(1, 6):\n",
        "        for z in range(1, 2):\n",
        "            #if (x <= 2 and y <= 2 and z <= 2):\n",
        "            folderNormal.append('A{}F{}P{}'.format(x, y, z))\n",
        "\n",
        "folderFault = list()\n",
        "\n",
        "# folderFault = ['A5F3P3']\n",
        "\n",
        "for x in range(1, 6):\n",
        "    for y in range(1, 6):\n",
        "        for z in range(5, 6):\n",
        "            #if (x == 5 or y == 5 or z == 5):\n",
        "            folderFault.append('A{}F{}P{}'.format(x, y, z))\n",
        "\n",
        "\n",
        "pathNormal = list()\n",
        "pathFault = list()\n",
        "\n",
        "for i in range(len(folderNormal)):\n",
        "    pathNormal.append(dataPath + '/' + folderNormal[i])\n",
        "    \n",
        "for i in range(len(folderFault)):\n",
        "    pathFault.append(dataPath + '/' + folderFault[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xgGP7PZO-rTA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Specgram settings\n",
        "\n",
        "nsc = 1470\n",
        "nov = nsc/2\n",
        "nff = nsc \n",
        "imgSize = 224\n",
        "\n",
        "# pretrainedModel = 'VGG19'\n",
        "pretrainedModel = 'Xception'\n",
        "# pretrainedModel = 'ResNet50'\n",
        "\n",
        "# pretrainedModel = 'VGG19'\n",
        "# pretrainedModel = 'InceptionV3'\n",
        "# pretrainedModel = 'DenseNet169'\n",
        "# pretrainedModel = 'DenseNet201'\n",
        "\n",
        "\n",
        "lastActivation = 'softmax'\n",
        "sizeBatch = 4\n",
        "numEpochs = 8\n",
        "verb = 1\n",
        "\n",
        "\n",
        "# Learning parameters\n",
        "\n",
        "trainingRatio = 0.8\n",
        "\n",
        "totalDataNum = 1000\n",
        "repeat = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5AskF2qFT2xr",
        "colab_type": "code",
        "outputId": "c7bbe97e-c055-45d7-8ed3-6d39614dddf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "cell_type": "code",
      "source": [
        "startNum = 0\n",
        "\n",
        "pickNum = int(np.ceil(totalDataNum / len(pathNormal)))\n",
        "\n",
        "for i in range(startNum, len(pathNormal)):\n",
        "\n",
        "    npyTestPath = glob.glob(pathNormal[i] + '/' + '*Image_With_Label.npy')\n",
        "    data = np.load(npyTestPath[0])\n",
        "    \n",
        "    pickIdx = np.random.choice(1000, pickNum, replace=False)\n",
        "    pickIdx.sort()\n",
        "    \n",
        "#     imgs = np.moveaxis(np.dstack(data[:, 0]), 2, 0)\n",
        "#     label = data[:, 1:5]\n",
        "\n",
        "    imgs = np.moveaxis(np.dstack(data[pickIdx, 0]), 2, 0)\n",
        "    label = data[pickIdx, 1:5]\n",
        "    \n",
        "    if i == startNum:\n",
        "        labelListNormal = label\n",
        "        imgsNormal = imgs\n",
        "    else:\n",
        "        labelListNormal = np.vstack([labelListNormal, label])\n",
        "        imgsNormal = np.vstack([imgsNormal, imgs])\n",
        "\n",
        "    print('Normal Image Shape From {}: {}:'.format(pathNormal[i], totalDataNum))    \n",
        "    print('Selected {}/{}:'.format(pickNum * (i + 1), len(data)))    \n",
        "    \n",
        "    \n",
        "print('Normal Image Shape: {}'.format(imgsNormal.shape))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A1F1P1: 1000:\n",
            "Selected 40/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A1F2P1: 1000:\n",
            "Selected 80/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A1F3P1: 1000:\n",
            "Selected 120/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A1F4P1: 1000:\n",
            "Selected 160/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A1F5P1: 1000:\n",
            "Selected 200/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A2F1P1: 1000:\n",
            "Selected 240/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A2F2P1: 1000:\n",
            "Selected 280/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A2F3P1: 1000:\n",
            "Selected 320/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A2F4P1: 1000:\n",
            "Selected 360/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A2F5P1: 1000:\n",
            "Selected 400/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A3F1P1: 1000:\n",
            "Selected 440/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A3F2P1: 1000:\n",
            "Selected 480/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A3F3P1: 1000:\n",
            "Selected 520/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A3F4P1: 1000:\n",
            "Selected 560/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A3F5P1: 1000:\n",
            "Selected 600/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A4F1P1: 1000:\n",
            "Selected 640/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A4F2P1: 1000:\n",
            "Selected 680/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A4F3P1: 1000:\n",
            "Selected 720/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A4F4P1: 1000:\n",
            "Selected 760/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A4F5P1: 1000:\n",
            "Selected 800/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A5F1P1: 1000:\n",
            "Selected 840/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A5F2P1: 1000:\n",
            "Selected 880/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A5F3P1: 1000:\n",
            "Selected 920/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A5F4P1: 1000:\n",
            "Selected 960/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A5F5P1: 1000:\n",
            "Selected 1000/1000:\n",
            "Normal Image Shape: (1000, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P_MZtpk3Br_i",
        "colab_type": "code",
        "outputId": "8be60609-202e-4406-e1cd-02d76ed0aba1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "cell_type": "code",
      "source": [
        "startNum = 0\n",
        "\n",
        "pickNum = int(np.ceil(totalDataNum / len(pathFault)))\n",
        "\n",
        "for i in range(startNum, len(pathFault)):\n",
        "\n",
        "    npyTestPath = glob.glob(pathFault[i] + '/' + '*Image_With_Label.npy')\n",
        "    data = np.load(npyTestPath[0])\n",
        "    \n",
        "    pickIdx = np.random.choice(1000, pickNum, replace=False)\n",
        "    pickIdx.sort()\n",
        "    \n",
        "#     imgs = np.moveaxis(np.dstack(data[:, 0]), 2, 0)\n",
        "#     label = data[:, 1:5]\n",
        "    \n",
        "    imgs = np.moveaxis(np.dstack(data[pickIdx, 0]), 2, 0)\n",
        "    label = data[pickIdx, 1:5]\n",
        "    \n",
        "    if i == startNum:\n",
        "        labelListFault = label\n",
        "        imgsFault = imgs\n",
        "    else:\n",
        "        labelListFault = np.vstack([labelListFault, label])\n",
        "        imgsFault = np.vstack([imgsFault, imgs])\n",
        "\n",
        "    print('Fault Image Shape From {}: {}:'.format(pathFault[i], totalDataNum))    \n",
        "    print('Selected {}/{}:'.format(pickNum * (i + 1), len(data)))     \n",
        "    \n",
        "print('Fault Image Shape: {}'.format(imgsFault.shape))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A1F1P5: 1000:\n",
            "Selected 40/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A1F2P5: 1000:\n",
            "Selected 80/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A1F3P5: 1000:\n",
            "Selected 120/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A1F4P5: 1000:\n",
            "Selected 160/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A1F5P5: 1000:\n",
            "Selected 200/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A2F1P5: 1000:\n",
            "Selected 240/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A2F2P5: 1000:\n",
            "Selected 280/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A2F3P5: 1000:\n",
            "Selected 320/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A2F4P5: 1000:\n",
            "Selected 360/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A2F5P5: 1000:\n",
            "Selected 400/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A3F1P5: 1000:\n",
            "Selected 440/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A3F2P5: 1000:\n",
            "Selected 480/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A3F3P5: 1000:\n",
            "Selected 520/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A3F4P5: 1000:\n",
            "Selected 560/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A3F5P5: 1000:\n",
            "Selected 600/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A4F1P5: 1000:\n",
            "Selected 640/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A4F2P5: 1000:\n",
            "Selected 680/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A4F3P5: 1000:\n",
            "Selected 720/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A4F4P5: 1000:\n",
            "Selected 760/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A4F5P5: 1000:\n",
            "Selected 800/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A5F1P5: 1000:\n",
            "Selected 840/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A5F2P5: 1000:\n",
            "Selected 880/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A5F3P5: 1000:\n",
            "Selected 920/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A5F4P5: 1000:\n",
            "Selected 960/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A5F5P5: 1000:\n",
            "Selected 1000/1000:\n",
            "Fault Image Shape: (1000, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e91QsAurSkIP",
        "colab_type": "code",
        "outputId": "56e5ee35-ee1e-4b63-d2e2-a184f1b0ecca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "cell_type": "code",
      "source": [
        "# Change name from imgsF1 or imgsF5 to imgsNormal and imgsFault\n",
        "\n",
        "dataNumNormal = len(imgsNormal)\n",
        "dataNumFault = len(imgsFault)\n",
        "dataNumNormalTrain = int(dataNumNormal * trainingRatio)\n",
        "dataNumFaultTrain = int(dataNumFault * trainingRatio)\n",
        "dataNumNormalTest = dataNumNormal - dataNumNormalTrain\n",
        "dataNumFaultTest = dataNumFault - dataNumFaultTrain\n",
        "\n",
        "print('Normal Train:Test = {:d}:{:d}'.format(dataNumNormalTrain, dataNumNormalTest))\n",
        "print('Fault  Train:Test = {:d}:{:d}\\n'.format(dataNumFaultTrain, dataNumFaultTest))\n",
        "\n",
        "trainIdxNormal = np.random.choice(dataNumNormal - 1, dataNumNormalTrain, replace=False)\n",
        "testIdxNormal = list(set(range(0, dataNumNormal)) - set(trainIdxNormal))\n",
        "\n",
        "trainImgsNormal = imgsNormal[trainIdxNormal, :, :]\n",
        "testImgsNormal = imgsNormal[testIdxNormal, :, :]\n",
        "\n",
        "print('Normal Training Image Shape {}'.format(trainImgsNormal.shape))\n",
        "print('Normal Test Image Shape {}\\n'.format(testImgsNormal.shape))\n",
        "\n",
        "trainIdxFault  = np.random.choice(dataNumFault - 1, dataNumFaultTrain, replace=False)\n",
        "testIdxFault = list(set(range(0, dataNumFault)) - set(trainIdxFault))\n",
        "\n",
        "trainImgsFault = imgsFault[trainIdxFault, :, :]\n",
        "testImgsFault = imgsFault[testIdxFault, :, :]\n",
        "\n",
        "print('Fault Training Image Shape {}'.format(trainImgsFault.shape))\n",
        "print('Fault Test Image Shape {}\\n'.format(testImgsFault.shape))\n",
        "\n",
        "trainImgs = np.vstack([trainImgsNormal, trainImgsFault])\n",
        "testImgs = np.vstack([testImgsNormal, testImgsFault])\n",
        "\n",
        "print('Training Image Shape {}'.format(trainImgs.shape))\n",
        "print('Test Image Shape {}'.format(testImgs.shape))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal Train:Test = 800:200\n",
            "Fault  Train:Test = 800:200\n",
            "\n",
            "Normal Training Image Shape (800, 224, 224)\n",
            "Normal Test Image Shape (200, 224, 224)\n",
            "\n",
            "Fault Training Image Shape (800, 224, 224)\n",
            "Fault Test Image Shape (200, 224, 224)\n",
            "\n",
            "Training Image Shape (1600, 224, 224)\n",
            "Test Image Shape (400, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MoE7f_hzs0av",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "feQ_AHAcUgHD",
        "colab_type": "code",
        "outputId": "d27fbd38-c5de-4ba1-903f-f24d72ae7814",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "trainMean = np.mean(trainImgs)\n",
        "trainStd = np.std(trainImgs)\n",
        "\n",
        "print('Mean of Training Image: {}'.format(trainMean))\n",
        "print('Standard Deviation of Training Image: {}'.format(trainStd))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean of Training Image: -78.32583509522203\n",
            "Standard Deviation of Training Image: 9.329978868568999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wUi9IuXNUpir",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Should Change Norm to Normalized\n",
        "\n",
        "trainImgsNorm = (trainImgs - trainMean) / trainStd\n",
        "testImgsNorm = (testImgs - trainMean) / trainStd\n",
        "\n",
        "trainImgsNorm = trainImgsNorm.reshape(list(trainImgsNorm.shape) + [1])\n",
        "testImgsNorm = testImgsNorm.reshape(list(testImgsNorm.shape) + [1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aklxiPz1Ve4n",
        "colab_type": "code",
        "outputId": "7d3c0a3f-3553-4216-97c8-6fa3f762f46a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = np.stack([trainImgsNorm[:, :, :, 0], trainImgsNorm[:, :, :, 0], trainImgsNorm[:, :, :, 0]], axis = -1)\n",
        "X_test = np.stack([testImgsNorm[:, :, :, 0], testImgsNorm[:, :, :, 0], testImgsNorm[:, :, :, 0]], axis = -1)\n",
        "\n",
        "print('X_train Shape: {}'.format(X_train.shape))\n",
        "print('X_test  Shape: {}'.format(X_test.shape))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train Shape: (1600, 224, 224, 3)\n",
            "X_test  Shape: (400, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sRgIPzT7K_YP",
        "colab_type": "code",
        "outputId": "f381e5ff-da59-4df1-bb76-7fb2d8b02eea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "trainLabelNormal = np.stack((np.ones(dataNumNormalTrain), np.zeros(dataNumNormalTrain)), axis = -1)\n",
        "testLabelNormal = np.stack((np.ones(dataNumNormalTest), np.zeros(dataNumNormalTest)), axis = -1)\n",
        "\n",
        "trainLabelFault = np.stack((np.zeros(dataNumFaultTrain), np.ones(dataNumFaultTrain)), axis = -1)\n",
        "testLabelFault = np.stack((np.zeros(dataNumFaultTest), np.ones(dataNumFaultTest)), axis = -1)\n",
        "\n",
        "Y_train = np.vstack((trainLabelNormal, trainLabelFault))\n",
        "Y_test = np.vstack((testLabelNormal, testLabelFault))\n",
        "\n",
        "print('Y_train Normal:Fault = {:d}:{:d}'.format(len(trainLabelNormal), len(trainLabelFault)))\n",
        "print('Y_test  Normal:Fault = {:d}:{:d}'.format(len(testLabelNormal), len(testLabelFault)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Y_train Normal:Fault = 800:800\n",
            "Y_test  Normal:Fault = 200:200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kczwZk7Tbp5C",
        "colab_type": "code",
        "outputId": "7950918b-5e2e-4200-b060-1430618a8977",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG19\n",
        "from keras.applications import VGG16\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications.densenet import DenseNet169\n",
        "from keras.applications.densenet import DenseNet201\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# pretrainedModel = 'ResNet50'\n",
        "# lastActivation = 'softmax'\n",
        "# lossFunction = 'binary_crossentropy'\n",
        "# sizeBatch = 2\n",
        "# numEpochs = 2\n",
        "# verb = 1\n",
        "\n",
        "for rp in range(repeat):\n",
        "\n",
        "    # Refresh all background variables\n",
        "    K.clear_session()\n",
        "\n",
        "    input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "    # Building sequential model with name 'model'\n",
        "    model = Sequential()\n",
        "\n",
        "    # Model selection\n",
        "\n",
        "    if (pretrainedModel == 'VGG16'):\n",
        "\n",
        "        modelWoTop = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'VGG19'):\n",
        "\n",
        "        modelWoTop = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif pretrainedModel == 'ResNet50':\n",
        "\n",
        "        modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'InceptionV3'):\n",
        "        modelWoTop = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'Xception'):\n",
        "        modelWoTop = Xception(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet169'):\n",
        "\n",
        "        modelWoTop = DenseNet169(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet201'):\n",
        "        modelWoTop = DenseNet201(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    else:\n",
        "        print('Invalid Pretrained Model Selection')\n",
        "\n",
        "\n",
        "\n",
        "    # Model compiling\n",
        "\n",
        "    print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "    print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "    model.fit(X_train, Y_train,\n",
        "              batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "              validation_data=(X_test, Y_test))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 10s 0us/step\n",
            "Compiling Pretrained xception Model\n",
            "Training Pretrained xception Model\n",
            "Batch Size: 4\t Epochs: 8\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/8\n",
            "1600/1600 [==============================] - 121s 76ms/step - loss: 0.5927 - acc: 0.6806 - val_loss: 0.6437 - val_acc: 0.8425\n",
            "Epoch 2/8\n",
            "1600/1600 [==============================] - 108s 67ms/step - loss: 0.4364 - acc: 0.8131 - val_loss: 0.9821 - val_acc: 0.7375\n",
            "Epoch 3/8\n",
            "1600/1600 [==============================] - 109s 68ms/step - loss: 0.3298 - acc: 0.8737 - val_loss: 3.8458 - val_acc: 0.6175\n",
            "Epoch 4/8\n",
            "1600/1600 [==============================] - 107s 67ms/step - loss: 0.2840 - acc: 0.8869 - val_loss: 0.3575 - val_acc: 0.8500\n",
            "Epoch 5/8\n",
            "1600/1600 [==============================] - 108s 67ms/step - loss: 0.2268 - acc: 0.9169 - val_loss: 0.4300 - val_acc: 0.8475\n",
            "Epoch 6/8\n",
            "1600/1600 [==============================] - 108s 68ms/step - loss: 0.2128 - acc: 0.9194 - val_loss: 0.2282 - val_acc: 0.9075\n",
            "Epoch 7/8\n",
            "1600/1600 [==============================] - 108s 68ms/step - loss: 0.1825 - acc: 0.9362 - val_loss: 0.1515 - val_acc: 0.9450\n",
            "Epoch 8/8\n",
            "1600/1600 [==============================] - 108s 67ms/step - loss: 0.1662 - acc: 0.9444 - val_loss: 0.1864 - val_acc: 0.9375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-aE0MIEjuC_k",
        "colab_type": "code",
        "outputId": "fe3a6a0c-f7c4-4261-cd2c-599ae2589972",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "for rp in range(repeat):\n",
        "\n",
        "    # Refresh all background variables\n",
        "    K.clear_session()\n",
        "\n",
        "    input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "    # Building sequential model with name 'model'\n",
        "    model = Sequential()\n",
        "\n",
        "    # Model selection\n",
        "\n",
        "    if (pretrainedModel == 'VGG16'):\n",
        "\n",
        "        modelWoTop = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'VGG19'):\n",
        "\n",
        "        modelWoTop = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif pretrainedModel == 'ResNet50':\n",
        "\n",
        "        modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'InceptionV3'):\n",
        "        modelWoTop = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'Xception'):\n",
        "        modelWoTop = Xception(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet169'):\n",
        "\n",
        "        modelWoTop = DenseNet169(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet201'):\n",
        "        modelWoTop = DenseNet201(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    else:\n",
        "        print('Invalid Pretrained Model Selection')\n",
        "\n",
        "\n",
        "\n",
        "    # Model compiling\n",
        "\n",
        "    print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "    print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "    model.fit(X_train, Y_train,\n",
        "              batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "              validation_data=(X_test, Y_test))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compiling Pretrained xception Model\n",
            "Training Pretrained xception Model\n",
            "Batch Size: 4\t Epochs: 8\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/8\n",
            "1600/1600 [==============================] - 119s 74ms/step - loss: 0.5365 - acc: 0.7475 - val_loss: 0.3000 - val_acc: 0.9100\n",
            "Epoch 2/8\n",
            "1600/1600 [==============================] - 110s 69ms/step - loss: 0.3458 - acc: 0.8750 - val_loss: 0.3094 - val_acc: 0.8925\n",
            "Epoch 3/8\n",
            "1600/1600 [==============================] - 110s 69ms/step - loss: 0.3227 - acc: 0.8750 - val_loss: 0.2438 - val_acc: 0.9100\n",
            "Epoch 4/8\n",
            "1600/1600 [==============================] - 109s 68ms/step - loss: 0.2411 - acc: 0.9169 - val_loss: 0.1729 - val_acc: 0.9275\n",
            "Epoch 5/8\n",
            "1600/1600 [==============================] - 109s 68ms/step - loss: 0.1980 - acc: 0.9325 - val_loss: 0.3234 - val_acc: 0.8100\n",
            "Epoch 6/8\n",
            "1600/1600 [==============================] - 109s 68ms/step - loss: 0.1812 - acc: 0.9337 - val_loss: 0.1736 - val_acc: 0.9100\n",
            "Epoch 7/8\n",
            "1600/1600 [==============================] - 109s 68ms/step - loss: 0.1698 - acc: 0.9350 - val_loss: 0.1749 - val_acc: 0.9025\n",
            "Epoch 8/8\n",
            "1600/1600 [==============================] - 109s 68ms/step - loss: 0.1631 - acc: 0.9406 - val_loss: 0.1883 - val_acc: 0.9275\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "15t3_glRqbHT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "3154be46-ba2a-40c3-fa1f-9733a1fbfbf1"
      },
      "cell_type": "code",
      "source": [
        "# Refresh all background variables\n",
        "K.clear_session()\n",
        "\n",
        "input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "# Building sequential model with name 'model'\n",
        "model = Sequential()\n",
        "\n",
        "# Model selection\n",
        "\n",
        "if (pretrainedModel == 'VGG16'):\n",
        "\n",
        "    modelWoTop = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'VGG19'):\n",
        "\n",
        "    modelWoTop = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif pretrainedModel == 'ResNet50':\n",
        "\n",
        "    modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'InceptionV3'):\n",
        "    modelWoTop = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'Xception'):\n",
        "    modelWoTop = Xception(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'DenseNet169'):\n",
        "\n",
        "    modelWoTop = DenseNet169(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'DenseNet201'):\n",
        "    modelWoTop = DenseNet201(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "else:\n",
        "    print('Invalid Pretrained Model Selection')\n",
        "\n",
        "\n",
        "\n",
        "# Model compiling\n",
        "\n",
        "print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compiling Pretrained xception Model\n",
            "Training Pretrained xception Model\n",
            "Batch Size: 4\t Epochs: 8\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/8\n",
            "1600/1600 [==============================] - 119s 74ms/step - loss: 0.4691 - acc: 0.8188 - val_loss: 0.5923 - val_acc: 0.6025\n",
            "Epoch 2/8\n",
            "1600/1600 [==============================] - 110s 69ms/step - loss: 0.4131 - acc: 0.8225 - val_loss: 0.7244 - val_acc: 0.7375\n",
            "Epoch 3/8\n",
            "1600/1600 [==============================] - 111s 69ms/step - loss: 0.2919 - acc: 0.8906 - val_loss: 1.2571 - val_acc: 0.5550\n",
            "Epoch 4/8\n",
            "1600/1600 [==============================] - 110s 69ms/step - loss: 0.3353 - acc: 0.8500 - val_loss: 0.2415 - val_acc: 0.9050\n",
            "Epoch 5/8\n",
            "1600/1600 [==============================] - 110s 69ms/step - loss: 0.2410 - acc: 0.9075 - val_loss: 0.4366 - val_acc: 0.8750\n",
            "Epoch 6/8\n",
            "1600/1600 [==============================] - 111s 69ms/step - loss: 0.2437 - acc: 0.9075 - val_loss: 0.4704 - val_acc: 0.8325\n",
            "Epoch 7/8\n",
            "1600/1600 [==============================] - 109s 68ms/step - loss: 0.2335 - acc: 0.9050 - val_loss: 0.3032 - val_acc: 0.8875\n",
            "Epoch 8/8\n",
            "1600/1600 [==============================] - 110s 69ms/step - loss: 0.2000 - acc: 0.9244 - val_loss: 0.1864 - val_acc: 0.9300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe9841947f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "JJoK167dqbdS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "72b003e2-2502-4507-dc67-aed7e5d7756b"
      },
      "cell_type": "code",
      "source": [
        "K.clear_session()\n",
        "\n",
        "input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "# Building sequential model with name 'model'\n",
        "model = Sequential()\n",
        "\n",
        "# Model selection\n",
        "\n",
        "if (pretrainedModel == 'VGG16'):\n",
        "\n",
        "    modelWoTop = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'VGG19'):\n",
        "\n",
        "    modelWoTop = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif pretrainedModel == 'ResNet50':\n",
        "\n",
        "    modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'InceptionV3'):\n",
        "    modelWoTop = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'Xception'):\n",
        "    modelWoTop = Xception(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'DenseNet169'):\n",
        "\n",
        "    modelWoTop = DenseNet169(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'DenseNet201'):\n",
        "    modelWoTop = DenseNet201(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "else:\n",
        "    print('Invalid Pretrained Model Selection')\n",
        "\n",
        "\n",
        "\n",
        "# Model compiling\n",
        "\n",
        "print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compiling Pretrained xception Model\n",
            "Training Pretrained xception Model\n",
            "Batch Size: 4\t Epochs: 8\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/8\n",
            "1600/1600 [==============================] - 118s 73ms/step - loss: 0.4936 - acc: 0.7875 - val_loss: 0.3263 - val_acc: 0.8375\n",
            "Epoch 2/8\n",
            "1600/1600 [==============================] - 109s 68ms/step - loss: 0.3263 - acc: 0.8775 - val_loss: 0.4775 - val_acc: 0.6800\n",
            "Epoch 3/8\n",
            "1600/1600 [==============================] - 109s 68ms/step - loss: 0.2655 - acc: 0.9025 - val_loss: 1.9828 - val_acc: 0.7275\n",
            "Epoch 4/8\n",
            "1600/1600 [==============================] - 109s 68ms/step - loss: 0.2711 - acc: 0.9000 - val_loss: 0.3180 - val_acc: 0.8725\n",
            "Epoch 5/8\n",
            "1600/1600 [==============================] - 109s 68ms/step - loss: 0.2179 - acc: 0.9137 - val_loss: 0.1787 - val_acc: 0.9325\n",
            "Epoch 6/8\n",
            "1600/1600 [==============================] - 109s 68ms/step - loss: 0.1835 - acc: 0.9281 - val_loss: 0.1912 - val_acc: 0.9125\n",
            "Epoch 7/8\n",
            "1600/1600 [==============================] - 109s 68ms/step - loss: 0.1745 - acc: 0.9337 - val_loss: 0.1633 - val_acc: 0.9250\n",
            "Epoch 8/8\n",
            "1600/1600 [==============================] - 109s 68ms/step - loss: 0.1660 - acc: 0.9362 - val_loss: 0.1466 - val_acc: 0.9375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe9891da4a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "1MHaHPv8wK-n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "outputId": "b1da3c4b-5cbb-49af-a2f7-ed50befe0999"
      },
      "cell_type": "code",
      "source": [
        "numEpochs = 12\n",
        "\n",
        "print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Pretrained xception Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/12\n",
            "1600/1600 [==============================] - 109s 68ms/step - loss: 0.1739 - acc: 0.9375 - val_loss: 0.1778 - val_acc: 0.9175\n",
            "Epoch 2/12\n",
            "1600/1600 [==============================] - 109s 68ms/step - loss: 0.1501 - acc: 0.9450 - val_loss: 0.1563 - val_acc: 0.9325\n",
            "Epoch 3/12\n",
            "1600/1600 [==============================] - 109s 68ms/step - loss: 0.1460 - acc: 0.9463 - val_loss: 0.1631 - val_acc: 0.9325\n",
            "Epoch 4/12\n",
            "1600/1600 [==============================] - 108s 68ms/step - loss: 0.1404 - acc: 0.9431 - val_loss: 0.1540 - val_acc: 0.9350\n",
            "Epoch 5/12\n",
            "1600/1600 [==============================] - 109s 68ms/step - loss: 0.1342 - acc: 0.9444 - val_loss: 0.1429 - val_acc: 0.9300\n",
            "Epoch 6/12\n",
            "1600/1600 [==============================] - 109s 68ms/step - loss: 0.1290 - acc: 0.9500 - val_loss: 0.1905 - val_acc: 0.9300\n",
            "Epoch 7/12\n",
            "1600/1600 [==============================] - 109s 68ms/step - loss: 0.1119 - acc: 0.9556 - val_loss: 0.1726 - val_acc: 0.9300\n",
            "Epoch 8/12\n",
            "1600/1600 [==============================] - 109s 68ms/step - loss: 0.1111 - acc: 0.9537 - val_loss: 0.1184 - val_acc: 0.9525\n",
            "Epoch 9/12\n",
            "1600/1600 [==============================] - 108s 68ms/step - loss: 0.0935 - acc: 0.9619 - val_loss: 0.1429 - val_acc: 0.9300\n",
            "Epoch 10/12\n",
            "1600/1600 [==============================] - 109s 68ms/step - loss: 0.0927 - acc: 0.9688 - val_loss: 0.1469 - val_acc: 0.9375\n",
            "Epoch 11/12\n",
            "1600/1600 [==============================] - 109s 68ms/step - loss: 0.0563 - acc: 0.9781 - val_loss: 0.1622 - val_acc: 0.9350\n",
            "Epoch 12/12\n",
            "1600/1600 [==============================] - 109s 68ms/step - loss: 0.0738 - acc: 0.9756 - val_loss: 0.2091 - val_acc: 0.9050\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe983d76e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "pW8YrVQ-1Y2K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "outputId": "0bc3ec03-69f6-4c4e-ab7c-a5e05e1fd6c7"
      },
      "cell_type": "code",
      "source": [
        "numEpochs = 12\n",
        "\n",
        "print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Pretrained xception Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/12\n",
            "1600/1600 [==============================] - 109s 68ms/step - loss: 0.0740 - acc: 0.9694 - val_loss: 0.1912 - val_acc: 0.9250\n",
            "Epoch 2/12\n",
            "1600/1600 [==============================] - 109s 68ms/step - loss: 0.0372 - acc: 0.9869 - val_loss: 0.2469 - val_acc: 0.8925\n",
            "Epoch 3/12\n",
            "1600/1600 [==============================] - 109s 68ms/step - loss: 0.0590 - acc: 0.9769 - val_loss: 0.1845 - val_acc: 0.9375\n",
            "Epoch 4/12\n",
            "1600/1600 [==============================] - 109s 68ms/step - loss: 0.0295 - acc: 0.9887 - val_loss: 0.2235 - val_acc: 0.9325\n",
            "Epoch 5/12\n",
            "1600/1600 [==============================] - 109s 68ms/step - loss: 0.0453 - acc: 0.9825 - val_loss: 0.2494 - val_acc: 0.9375\n",
            "Epoch 6/12\n",
            "1600/1600 [==============================] - 110s 69ms/step - loss: 0.0522 - acc: 0.9856 - val_loss: 0.2197 - val_acc: 0.9275\n",
            "Epoch 7/12\n",
            "1600/1600 [==============================] - 109s 68ms/step - loss: 0.0177 - acc: 0.9950 - val_loss: 0.2738 - val_acc: 0.9250\n",
            "Epoch 8/12\n",
            "1600/1600 [==============================] - 109s 68ms/step - loss: 0.0458 - acc: 0.9887 - val_loss: 0.2735 - val_acc: 0.9025\n",
            "Epoch 9/12\n",
            "1600/1600 [==============================] - 110s 69ms/step - loss: 0.0255 - acc: 0.9925 - val_loss: 0.2610 - val_acc: 0.9325\n",
            "Epoch 10/12\n",
            "1600/1600 [==============================] - 109s 68ms/step - loss: 0.0314 - acc: 0.9881 - val_loss: 0.3199 - val_acc: 0.9375\n",
            "Epoch 11/12\n",
            "1600/1600 [==============================] - 109s 68ms/step - loss: 0.0298 - acc: 0.9912 - val_loss: 0.2840 - val_acc: 0.9325\n",
            "Epoch 12/12\n",
            "1600/1600 [==============================] - 108s 68ms/step - loss: 0.0295 - acc: 0.9912 - val_loss: 0.1878 - val_acc: 0.9225\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe984177e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "4RT-kNo1btaN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "outputId": "a188b69e-a2be-4c80-996f-e5b47f47a7e4"
      },
      "cell_type": "code",
      "source": [
        "numEpochs = 12\n",
        "\n",
        "print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Pretrained xception Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/12\n",
            "1600/1600 [==============================] - 108s 68ms/step - loss: 0.0194 - acc: 0.9919 - val_loss: 0.2050 - val_acc: 0.9200\n",
            "Epoch 2/12\n",
            "1600/1600 [==============================] - 108s 68ms/step - loss: 0.0062 - acc: 0.9975 - val_loss: 0.3423 - val_acc: 0.9400\n",
            "Epoch 3/12\n",
            "1600/1600 [==============================] - 108s 68ms/step - loss: 8.7511e-04 - acc: 1.0000 - val_loss: 0.2838 - val_acc: 0.9325\n",
            "Epoch 4/12\n",
            "1600/1600 [==============================] - 108s 68ms/step - loss: 2.7938e-04 - acc: 1.0000 - val_loss: 0.3670 - val_acc: 0.9400\n",
            "Epoch 5/12\n",
            "1600/1600 [==============================] - 108s 68ms/step - loss: 1.7324e-04 - acc: 1.0000 - val_loss: 0.3553 - val_acc: 0.9300\n",
            "Epoch 6/12\n",
            "1600/1600 [==============================] - 108s 68ms/step - loss: 7.4087e-05 - acc: 1.0000 - val_loss: 0.3891 - val_acc: 0.9275\n",
            "Epoch 7/12\n",
            "1600/1600 [==============================] - 108s 67ms/step - loss: 1.3327e-04 - acc: 1.0000 - val_loss: 0.3846 - val_acc: 0.9325\n",
            "Epoch 8/12\n",
            "1600/1600 [==============================] - 108s 68ms/step - loss: 1.7706e-04 - acc: 1.0000 - val_loss: 0.4446 - val_acc: 0.9375\n",
            "Epoch 9/12\n",
            "1600/1600 [==============================] - 108s 68ms/step - loss: 7.7803e-05 - acc: 1.0000 - val_loss: 0.4282 - val_acc: 0.9350\n",
            "Epoch 10/12\n",
            "1600/1600 [==============================] - 108s 68ms/step - loss: 0.1375 - acc: 0.9500 - val_loss: 0.1713 - val_acc: 0.9350\n",
            "Epoch 11/12\n",
            "1600/1600 [==============================] - 108s 68ms/step - loss: 0.0414 - acc: 0.9850 - val_loss: 0.2204 - val_acc: 0.9275\n",
            "Epoch 12/12\n",
            "1600/1600 [==============================] - 108s 68ms/step - loss: 0.0184 - acc: 0.9950 - val_loss: 0.3289 - val_acc: 0.9400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe9a36b9240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "eA9GZhLGe5X9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "# print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "# model.fit(X_train, Y_train,\n",
        "#           batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "#           validation_data=(X_test, Y_test))\n",
        "\n",
        "# Y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qexmaPZVz04q",
        "colab_type": "code",
        "outputId": "77621913-f204-4c59-ccc3-ed88419c3a2b",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "cell_type": "code",
      "source": [
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.plot(Y_test[:, 1], 'r')\n",
        "\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.plot(Y_pred[:, 1], 'b')\n",
        "\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.plot(Y_test[:, 1] - Y_pred[:, 1], 'g')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFKCAYAAAAqkecjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fe9a3e98eb8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "IPTFOJh3DTgq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "70043fa8-0a2b-4785-8c54-4c1c619dce8c"
      },
      "cell_type": "code",
      "source": [
        "now = datetime.datetime.now()\n",
        "\n",
        "modelSaved = '{}-{}_{}_{}.h5'.format(folderNormal, folderFault, pretrainedModel, now.strftime('%m-%d-%H:%M:%S'))\n",
        "\n",
        "modelSaved = '{}-{}_{}_{}.h5'.format('P1', 'P5', pretrainedModel, now.strftime('%m-%d-%H:%M:%S'))\n",
        "meanSaved = 'mean_{}.npy'.format(now.strftime('%m-%d-%H:%M:%S'))\n",
        "stdSaved = 'std_{}.npy'.format(now.strftime('%m-%d-%H:%M:%S'))\n",
        "\n",
        "inputStr = input('''Save Model as '{}'? (y/n)\\n'''.format(modelSaved))\n",
        "\n",
        "if (inputStr == 'y' or inputStr == 'Y'):  \n",
        "    model.save('gdrive/My Drive/Colab/Model/{}'.format(modelSaved))\n",
        "    np.save('gdrive/My Drive/Colab/Model/{}'.format(meanSaved), trainMean)\n",
        "    np.save('gdrive/My Drive/Colab/Model/{}'.format(stdSaved), trainStd)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Save Model as 'P1-P5_Xception_11-21-00:24:56.h5'? (y/n)\n",
            "y\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}