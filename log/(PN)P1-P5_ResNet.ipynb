{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning Clean Up.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joovvhan/Master-Thesis/blob/master/log/(PN)P1-P5_ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "c3821KWLNey6",
        "colab_type": "code",
        "outputId": "ebe1b00e-13ea-4c83-f78d-32ade6963823",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Import necessary modules\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy.io.wavfile as wf\n",
        "import time\n",
        "import glob\n",
        "import datetime\n",
        "\n",
        "from tqdm import trange\n",
        "\n",
        "# Import Keras modules\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.layers import Input, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
        "from keras.models import Sequential\n",
        "from keras import backend as K\n",
        "from keras.models import load_model\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "nxSASpgF7unA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Mount google drive\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "# os.listdir('gdrive/My Drive/Colab')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rw9NU8Xjwcz2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set data directories\n",
        "\n",
        "dataPath = '''D:\\\\0_Joowhan's Paper\\\\Synthesized\\\\Total\\\\Impulse'''\n",
        "modelPath = '''D:\\\\0_Joowhan's Paper\\\\Synthesized\\\\Total\\\\Model'''\n",
        "\n",
        "\n",
        "# Changed variable names to normal and fault\n",
        "# Changed variable names from folder to path\n",
        "# Need to consider multiple folders\n",
        "# Need to add files to be tested\n",
        "\n",
        "# folderNormal = ['P1N1', 'P2N1', 'P3N1', 'P4N1', 'P5N1']\n",
        "folderNormal = ['P1N1', 'P1N2', 'P1N3', 'P1N4', 'P1N5']\n",
        "\n",
        "# folderNormal = list()\n",
        "\n",
        "# for x in range(1, 6):\n",
        "#     for y in range(1, 6):\n",
        "#         for z in range(1, 6):\n",
        "#             if (x <= 2 and y <= 2 and z <= 2):\n",
        "#                 folderNormal.append('A{}F{}P{}'.format(x, y, z))\n",
        "\n",
        "# folderFault = list()\n",
        "\n",
        "folderFault = ['P5N1', 'P5N2', 'P5N3', 'P5N4', 'P5N5']\n",
        "\n",
        "# for x in range(1, 6):\n",
        "#     for y in range(1, 6):\n",
        "#         for z in range(1, 6):\n",
        "#             if (x == 5 or y == 5 or z == 5):\n",
        "#                 folderFault.append('A{}F{}P{}'.format(x, y, z))\n",
        "\n",
        "\n",
        "pathNormal = list()\n",
        "pathFault = list()\n",
        "\n",
        "for i in range(len(folderNormal)):\n",
        "    pathNormal.append(dataPath + '/' + folderNormal[i])\n",
        "    \n",
        "for i in range(len(folderFault)):\n",
        "    pathFault.append(dataPath + '/' + folderFault[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xgGP7PZO-rTA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Specgram settings\n",
        "\n",
        "nsc = 1470\n",
        "nov = nsc/2\n",
        "nff = nsc \n",
        "imgSize = 224\n",
        "\n",
        "# pretrainedModel = 'VGG19'\n",
        "# pretrainedModel = 'Xception'\n",
        "pretrainedModel = 'ResNet50'\n",
        "\n",
        "# pretrainedModel = 'DenseNet169'\n",
        "# pretrainedModel = 'InceptionV3'\n",
        "\n",
        "\n",
        "lastActivation = 'softmax'\n",
        "sizeBatch = 4\n",
        "numEpochs = 12\n",
        "verb = 1\n",
        "\n",
        "\n",
        "# Learning parameters\n",
        "\n",
        "trainingRatio = 0.8\n",
        "\n",
        "totalDataNum = 1000\n",
        "repeat = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5AskF2qFT2xr",
        "colab_type": "code",
        "outputId": "aa16af79-b539-44e0-9966-29af4e244047",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "cell_type": "code",
      "source": [
        "startNum = 0\n",
        "\n",
        "pickNum = int(np.ceil(totalDataNum / len(pathNormal)))\n",
        "\n",
        "for i in range(startNum, len(pathNormal)):\n",
        "\n",
        "    npyTestPath = glob.glob(pathNormal[i] + '/' + '*Image_With_Label.npy')\n",
        "    data = np.load(npyTestPath[0])\n",
        "    \n",
        "    pickIdx = np.random.choice(1000, pickNum, replace=False)\n",
        "    pickIdx.sort()\n",
        "    \n",
        "#     imgs = np.moveaxis(np.dstack(data[:, 0]), 2, 0)\n",
        "#     label = data[:, 1:5]\n",
        "\n",
        "    imgs = np.moveaxis(np.dstack(data[pickIdx, 0]), 2, 0)\n",
        "    label = data[pickIdx, 1:5]\n",
        "    \n",
        "    if i == startNum:\n",
        "        labelListNormal = label\n",
        "        imgsNormal = imgs\n",
        "    else:\n",
        "        labelListNormal = np.vstack([labelListNormal, label])\n",
        "        imgsNormal = np.vstack([imgsNormal, imgs])\n",
        "\n",
        "    print('Normal Image Shape From {}: {}:'.format(pathNormal[i], totalDataNum))    \n",
        "    print('Selected {}/{}:'.format(pickNum * (i + 1), len(data)))    \n",
        "    \n",
        "    \n",
        "print('Normal Image Shape: {}'.format(imgsNormal.shape))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P1N1: 1000:\n",
            "Selected 200/1000:\n",
            "Normal Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P1N2: 1000:\n",
            "Selected 400/1000:\n",
            "Normal Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P1N3: 1000:\n",
            "Selected 600/1000:\n",
            "Normal Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P1N4: 1000:\n",
            "Selected 800/1000:\n",
            "Normal Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P1N5: 1000:\n",
            "Selected 1000/1000:\n",
            "Normal Image Shape: (1000, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P_MZtpk3Br_i",
        "colab_type": "code",
        "outputId": "c0f01594-0fbd-435c-a887-9cf1fe54b060",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "cell_type": "code",
      "source": [
        "startNum = 0\n",
        "\n",
        "pickNum = int(np.ceil(totalDataNum / len(pathFault)))\n",
        "\n",
        "for i in range(startNum, len(pathFault)):\n",
        "\n",
        "    npyTestPath = glob.glob(pathFault[i] + '/' + '*Image_With_Label.npy')\n",
        "    data = np.load(npyTestPath[0])\n",
        "    \n",
        "    pickIdx = np.random.choice(1000, pickNum, replace=False)\n",
        "    pickIdx.sort()\n",
        "    \n",
        "#     imgs = np.moveaxis(np.dstack(data[:, 0]), 2, 0)\n",
        "#     label = data[:, 1:5]\n",
        "    \n",
        "    imgs = np.moveaxis(np.dstack(data[pickIdx, 0]), 2, 0)\n",
        "    label = data[pickIdx, 1:5]\n",
        "    \n",
        "    if i == startNum:\n",
        "        labelListFault = label\n",
        "        imgsFault = imgs\n",
        "    else:\n",
        "        labelListFault = np.vstack([labelListFault, label])\n",
        "        imgsFault = np.vstack([imgsFault, imgs])\n",
        "\n",
        "    print('Fault Image Shape From {}: {}:'.format(pathFault[i], totalDataNum))    \n",
        "    print('Selected {}/{}:'.format(pickNum * (i + 1), len(data)))     \n",
        "    \n",
        "print('Fault Image Shape: {}'.format(imgsFault.shape))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P5N1: 1000:\n",
            "Selected 200/1000:\n",
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P5N2: 1000:\n",
            "Selected 400/1000:\n",
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P5N3: 1000:\n",
            "Selected 600/1000:\n",
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P5N4: 1000:\n",
            "Selected 800/1000:\n",
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P5N5: 1000:\n",
            "Selected 1000/1000:\n",
            "Fault Image Shape: (1000, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e91QsAurSkIP",
        "colab_type": "code",
        "outputId": "4606a13f-aac5-44f9-8c54-7516ddc165d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "cell_type": "code",
      "source": [
        "# Change name from imgsF1 or imgsF5 to imgsNormal and imgsFault\n",
        "\n",
        "dataNumNormal = len(imgsNormal)\n",
        "dataNumFault = len(imgsFault)\n",
        "dataNumNormalTrain = int(dataNumNormal * trainingRatio)\n",
        "dataNumFaultTrain = int(dataNumFault * trainingRatio)\n",
        "dataNumNormalTest = dataNumNormal - dataNumNormalTrain\n",
        "dataNumFaultTest = dataNumFault - dataNumFaultTrain\n",
        "\n",
        "print('Normal Train:Test = {:d}:{:d}'.format(dataNumNormalTrain, dataNumNormalTest))\n",
        "print('Fault  Train:Test = {:d}:{:d}\\n'.format(dataNumFaultTrain, dataNumFaultTest))\n",
        "\n",
        "trainIdxNormal = np.random.choice(dataNumNormal - 1, dataNumNormalTrain, replace=False)\n",
        "testIdxNormal = list(set(range(0, dataNumNormal)) - set(trainIdxNormal))\n",
        "\n",
        "trainImgsNormal = imgsNormal[trainIdxNormal, :, :]\n",
        "testImgsNormal = imgsNormal[testIdxNormal, :, :]\n",
        "\n",
        "print('Normal Training Image Shape {}'.format(trainImgsNormal.shape))\n",
        "print('Normal Test Image Shape {}\\n'.format(testImgsNormal.shape))\n",
        "\n",
        "trainIdxFault  = np.random.choice(dataNumFault - 1, dataNumFaultTrain, replace=False)\n",
        "testIdxFault = list(set(range(0, dataNumFault)) - set(trainIdxFault))\n",
        "\n",
        "trainImgsFault = imgsFault[trainIdxFault, :, :]\n",
        "testImgsFault = imgsFault[testIdxFault, :, :]\n",
        "\n",
        "print('Fault Training Image Shape {}'.format(trainImgsFault.shape))\n",
        "print('Fault Test Image Shape {}\\n'.format(testImgsFault.shape))\n",
        "\n",
        "trainImgs = np.vstack([trainImgsNormal, trainImgsFault])\n",
        "testImgs = np.vstack([testImgsNormal, testImgsFault])\n",
        "\n",
        "print('Training Image Shape {}'.format(trainImgs.shape))\n",
        "print('Test Image Shape {}'.format(testImgs.shape))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal Train:Test = 800:200\n",
            "Fault  Train:Test = 800:200\n",
            "\n",
            "Normal Training Image Shape (800, 224, 224)\n",
            "Normal Test Image Shape (200, 224, 224)\n",
            "\n",
            "Fault Training Image Shape (800, 224, 224)\n",
            "Fault Test Image Shape (200, 224, 224)\n",
            "\n",
            "Training Image Shape (1600, 224, 224)\n",
            "Test Image Shape (400, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MoE7f_hzs0av",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "feQ_AHAcUgHD",
        "colab_type": "code",
        "outputId": "691bd8cb-34f7-491c-9a46-2abd31ca5494",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "trainMean = np.mean(trainImgs)\n",
        "trainStd = np.std(trainImgs)\n",
        "\n",
        "print('Mean of Training Image: {}'.format(trainMean))\n",
        "print('Standard Deviation of Training Image: {}'.format(trainStd))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean of Training Image: -79.14705638131328\n",
            "Standard Deviation of Training Image: 8.219381855826235\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wUi9IuXNUpir",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Should Change Norm to Normalized\n",
        "\n",
        "trainImgsNorm = (trainImgs - trainMean) / trainStd\n",
        "testImgsNorm = (testImgs - trainMean) / trainStd\n",
        "\n",
        "trainImgsNorm = trainImgsNorm.reshape(list(trainImgsNorm.shape) + [1])\n",
        "testImgsNorm = testImgsNorm.reshape(list(testImgsNorm.shape) + [1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aklxiPz1Ve4n",
        "colab_type": "code",
        "outputId": "cdafb5dc-8570-4076-d50d-08ab346e9bbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = np.stack([trainImgsNorm[:, :, :, 0], trainImgsNorm[:, :, :, 0], trainImgsNorm[:, :, :, 0]], axis = -1)\n",
        "X_test = np.stack([testImgsNorm[:, :, :, 0], testImgsNorm[:, :, :, 0], testImgsNorm[:, :, :, 0]], axis = -1)\n",
        "\n",
        "print('X_train Shape: {}'.format(X_train.shape))\n",
        "print('X_test  Shape: {}'.format(X_test.shape))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train Shape: (1600, 224, 224, 3)\n",
            "X_test  Shape: (400, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sRgIPzT7K_YP",
        "colab_type": "code",
        "outputId": "04779b26-71af-46f9-937a-f97b8736135d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "trainLabelNormal = np.stack((np.ones(dataNumNormalTrain), np.zeros(dataNumNormalTrain)), axis = -1)\n",
        "testLabelNormal = np.stack((np.ones(dataNumNormalTest), np.zeros(dataNumNormalTest)), axis = -1)\n",
        "\n",
        "trainLabelFault = np.stack((np.zeros(dataNumFaultTrain), np.ones(dataNumFaultTrain)), axis = -1)\n",
        "testLabelFault = np.stack((np.zeros(dataNumFaultTest), np.ones(dataNumFaultTest)), axis = -1)\n",
        "\n",
        "Y_train = np.vstack((trainLabelNormal, trainLabelFault))\n",
        "Y_test = np.vstack((testLabelNormal, testLabelFault))\n",
        "\n",
        "print('Y_train Normal:Fault = {:d}:{:d}'.format(len(trainLabelNormal), len(trainLabelFault)))\n",
        "print('Y_test  Normal:Fault = {:d}:{:d}'.format(len(testLabelNormal), len(testLabelFault)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Y_train Normal:Fault = 800:800\n",
            "Y_test  Normal:Fault = 200:200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kczwZk7Tbp5C",
        "colab_type": "code",
        "outputId": "c499d301-2b8a-4b27-de29-bde454a8fc94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2683
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG19\n",
        "from keras.applications import VGG16\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications.densenet import DenseNet169\n",
        "from keras.applications.densenet import DenseNet201\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# pretrainedModel = 'ResNet50'\n",
        "# lastActivation = 'softmax'\n",
        "# lossFunction = 'binary_crossentropy'\n",
        "# sizeBatch = 2\n",
        "# numEpochs = 2\n",
        "# verb = 1\n",
        "\n",
        "for rp in range(repeat):\n",
        "\n",
        "    # Refresh all background variables\n",
        "    K.clear_session()\n",
        "\n",
        "    input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "    # Building sequential model with name 'model'\n",
        "    model = Sequential()\n",
        "\n",
        "    # Model selection\n",
        "\n",
        "    if (pretrainedModel == 'VGG16'):\n",
        "\n",
        "        modelWoTop = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'VGG19'):\n",
        "\n",
        "        modelWoTop = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif pretrainedModel == 'ResNet50':\n",
        "\n",
        "        modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'InceptionV3'):\n",
        "        modelWoTop = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'Xception'):\n",
        "        modelWoTop = Xception(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet169'):\n",
        "\n",
        "        modelWoTop = DenseNet169(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet201'):\n",
        "        modelWoTop = DenseNet201(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    else:\n",
        "        print('Invalid Pretrained Model Selection')\n",
        "\n",
        "\n",
        "\n",
        "    # Model compiling\n",
        "\n",
        "    print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "    print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "    model.fit(X_train, Y_train,\n",
        "              batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "              validation_data=(X_test, Y_test))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "c:\\users\\주환\\appdata\\local\\conda\\conda\\envs\\paper\\lib\\site-packages\\keras_applications\\resnet50.py:263: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Compiling Pretrained resnet50 Model\n",
            "Training Pretrained resnet50 Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/12\n",
            "1600/1600 [==============================] - 79s 49ms/step - loss: 3.3006 - acc: 0.7269 - val_loss: 6.5424 - val_acc: 0.5825\n",
            "Epoch 2/12\n",
            "1600/1600 [==============================] - 67s 42ms/step - loss: 2.5226 - acc: 0.8131 - val_loss: 6.0481 - val_acc: 0.5850\n",
            "Epoch 3/12\n",
            "1600/1600 [==============================] - 67s 42ms/step - loss: 1.5855 - acc: 0.8494 - val_loss: 0.1233 - val_acc: 0.9875\n",
            "Epoch 4/12\n",
            "1600/1600 [==============================] - 67s 42ms/step - loss: 0.4474 - acc: 0.9312 - val_loss: 0.0762 - val_acc: 0.9925\n",
            "Epoch 5/12\n",
            "1600/1600 [==============================] - 67s 42ms/step - loss: 0.2589 - acc: 0.9669 - val_loss: 0.1537 - val_acc: 0.9900\n",
            "Epoch 6/12\n",
            "1600/1600 [==============================] - 68s 42ms/step - loss: 0.6063 - acc: 0.9444 - val_loss: 7.9751 - val_acc: 0.5025\n",
            "Epoch 7/12\n",
            "1600/1600 [==============================] - 67s 42ms/step - loss: 0.3579 - acc: 0.9681 - val_loss: 0.0072 - val_acc: 1.0000\n",
            "Epoch 8/12\n",
            "1600/1600 [==============================] - 67s 42ms/step - loss: 0.3339 - acc: 0.9706 - val_loss: 0.0067 - val_acc: 1.0000\n",
            "Epoch 9/12\n",
            "1600/1600 [==============================] - 67s 42ms/step - loss: 0.5219 - acc: 0.9550 - val_loss: 0.0185 - val_acc: 1.0000\n",
            "Epoch 10/12\n",
            "1600/1600 [==============================] - 67s 42ms/step - loss: 0.4446 - acc: 0.9569 - val_loss: 0.0473 - val_acc: 0.9975\n",
            "Epoch 11/12\n",
            "1600/1600 [==============================] - 67s 42ms/step - loss: 0.6179 - acc: 0.9438 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 12/12\n",
            "1600/1600 [==============================] - 68s 42ms/step - loss: 1.1984 - acc: 0.9131 - val_loss: 3.8601 - val_acc: 0.7500\n",
            "Compiling Pretrained resnet50 Model\n",
            "Training Pretrained resnet50 Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/12\n",
            "1600/1600 [==============================] - 78s 49ms/step - loss: 0.9718 - acc: 0.8881 - val_loss: 0.0148 - val_acc: 1.0000\n",
            "Epoch 2/12\n",
            "1600/1600 [==============================] - 68s 42ms/step - loss: 0.6041 - acc: 0.9406 - val_loss: 0.5186 - val_acc: 0.7500\n",
            "Epoch 3/12\n",
            "1600/1600 [==============================] - 68s 42ms/step - loss: 0.4526 - acc: 0.9438 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 4/12\n",
            "1600/1600 [==============================] - 67s 42ms/step - loss: 0.3855 - acc: 0.9669 - val_loss: 2.0150 - val_acc: 0.8500\n",
            "Epoch 5/12\n",
            "1600/1600 [==============================] - 67s 42ms/step - loss: 0.4514 - acc: 0.9594 - val_loss: 0.0081 - val_acc: 1.0000\n",
            "Epoch 6/12\n",
            "1600/1600 [==============================] - 67s 42ms/step - loss: 0.2957 - acc: 0.9794 - val_loss: 0.0061 - val_acc: 1.0000\n",
            "Epoch 7/12\n",
            "1600/1600 [==============================] - 68s 42ms/step - loss: 0.3453 - acc: 0.9781 - val_loss: 0.0060 - val_acc: 0.9975\n",
            "Epoch 8/12\n",
            "1600/1600 [==============================] - 67s 42ms/step - loss: 0.3902 - acc: 0.9619 - val_loss: 0.0188 - val_acc: 0.9975\n",
            "Epoch 9/12\n",
            "1600/1600 [==============================] - 67s 42ms/step - loss: 0.6661 - acc: 0.9506 - val_loss: 0.0037 - val_acc: 1.0000\n",
            "Epoch 10/12\n",
            "1600/1600 [==============================] - 67s 42ms/step - loss: 0.3614 - acc: 0.9750 - val_loss: 2.6723e-04 - val_acc: 1.0000\n",
            "Epoch 11/12\n",
            "1600/1600 [==============================] - 67s 42ms/step - loss: 0.3359 - acc: 0.9781 - val_loss: 8.9231e-04 - val_acc: 1.0000\n",
            "Epoch 12/12\n",
            "1600/1600 [==============================] - 67s 42ms/step - loss: 0.6565 - acc: 0.9463 - val_loss: 0.0033 - val_acc: 1.0000\n",
            "Compiling Pretrained resnet50 Model\n",
            "Training Pretrained resnet50 Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/12\n",
            "1600/1600 [==============================] - 79s 50ms/step - loss: 8.0103 - acc: 0.4994 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 2/12\n",
            "1600/1600 [==============================] - 68s 42ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 3/12\n",
            "1600/1600 [==============================] - 68s 42ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 4/12\n",
            "1600/1600 [==============================] - 68s 42ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 5/12\n",
            "1600/1600 [==============================] - 67s 42ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 6/12\n",
            "1600/1600 [==============================] - 68s 42ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 7/12\n",
            "1600/1600 [==============================] - 68s 42ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 8/12\n",
            "1600/1600 [==============================] - 68s 42ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 9/12\n",
            "1600/1600 [==============================] - 67s 42ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 10/12\n",
            "1600/1600 [==============================] - 67s 42ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 11/12\n",
            "1600/1600 [==============================] - 67s 42ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 12/12\n",
            "1600/1600 [==============================] - 67s 42ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Compiling Pretrained resnet50 Model\n",
            "Training Pretrained resnet50 Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/12\n",
            "1600/1600 [==============================] - 78s 48ms/step - loss: 0.6502 - acc: 0.9119 - val_loss: 0.0450 - val_acc: 1.0000\n",
            "Epoch 2/12\n",
            "1600/1600 [==============================] - 67s 42ms/step - loss: 0.5252 - acc: 0.9312 - val_loss: 0.3327 - val_acc: 0.9500\n",
            "Epoch 3/12\n",
            "1600/1600 [==============================] - 67s 42ms/step - loss: 0.3456 - acc: 0.9494 - val_loss: 0.0065 - val_acc: 1.0000\n",
            "Epoch 4/12\n",
            "1600/1600 [==============================] - 67s 42ms/step - loss: 0.3109 - acc: 0.9750 - val_loss: 0.0554 - val_acc: 0.9725\n",
            "Epoch 5/12\n",
            "1600/1600 [==============================] - 66s 41ms/step - loss: 1.5886 - acc: 0.8806 - val_loss: 4.8760 - val_acc: 0.6900\n",
            "Epoch 6/12\n",
            "1600/1600 [==============================] - 66s 42ms/step - loss: 1.7606 - acc: 0.8763 - val_loss: 1.3309 - val_acc: 0.9175\n",
            "Epoch 7/12\n",
            "1600/1600 [==============================] - 66s 41ms/step - loss: 0.5379 - acc: 0.9581 - val_loss: 0.0100 - val_acc: 0.9950\n",
            "Epoch 8/12\n",
            "1600/1600 [==============================] - 66s 41ms/step - loss: 0.6540 - acc: 0.9506 - val_loss: 0.7698 - val_acc: 0.9475\n",
            "Epoch 9/12\n",
            "1600/1600 [==============================] - 66s 42ms/step - loss: 0.4819 - acc: 0.9606 - val_loss: 0.0027 - val_acc: 1.0000\n",
            "Epoch 10/12\n",
            "1600/1600 [==============================] - 67s 42ms/step - loss: 0.3398 - acc: 0.9756 - val_loss: 0.0076 - val_acc: 1.0000\n",
            "Epoch 11/12\n",
            "1600/1600 [==============================] - 66s 41ms/step - loss: 0.4692 - acc: 0.9669 - val_loss: 0.0036 - val_acc: 1.0000\n",
            "Epoch 12/12\n",
            "1600/1600 [==============================] - 66s 42ms/step - loss: 0.2933 - acc: 0.9812 - val_loss: 3.4825e-04 - val_acc: 1.0000\n",
            "Compiling Pretrained resnet50 Model\n",
            "Training Pretrained resnet50 Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/12\n",
            "1600/1600 [==============================] - 77s 48ms/step - loss: 0.8620 - acc: 0.8737 - val_loss: 0.1958 - val_acc: 0.9925\n",
            "Epoch 2/12\n",
            "1600/1600 [==============================] - 66s 41ms/step - loss: 0.7673 - acc: 0.8631 - val_loss: 0.2526 - val_acc: 0.9475\n",
            "Epoch 3/12\n",
            "1600/1600 [==============================] - 66s 42ms/step - loss: 0.4156 - acc: 0.9619 - val_loss: 0.0264 - val_acc: 1.0000\n",
            "Epoch 4/12\n",
            "1600/1600 [==============================] - 66s 41ms/step - loss: 0.4823 - acc: 0.9488 - val_loss: 0.0293 - val_acc: 1.0000\n",
            "Epoch 5/12\n",
            "1600/1600 [==============================] - 66s 41ms/step - loss: 0.5265 - acc: 0.9581 - val_loss: 0.0134 - val_acc: 1.0000\n",
            "Epoch 6/12\n",
            "1600/1600 [==============================] - 66s 41ms/step - loss: 0.4198 - acc: 0.9706 - val_loss: 0.0033 - val_acc: 1.0000\n",
            "Epoch 7/12\n",
            "1600/1600 [==============================] - 66s 41ms/step - loss: 0.5916 - acc: 0.9537 - val_loss: 0.0169 - val_acc: 1.0000\n",
            "Epoch 8/12\n",
            "1600/1600 [==============================] - 66s 41ms/step - loss: 0.4980 - acc: 0.9537 - val_loss: 0.2040 - val_acc: 0.9775\n",
            "Epoch 9/12\n",
            "1600/1600 [==============================] - 66s 41ms/step - loss: 0.4505 - acc: 0.9537 - val_loss: 0.0290 - val_acc: 0.9975\n",
            "Epoch 10/12\n",
            "1600/1600 [==============================] - 66s 41ms/step - loss: 0.9592 - acc: 0.9187 - val_loss: 0.1818 - val_acc: 0.9275\n",
            "Epoch 11/12\n",
            "1600/1600 [==============================] - 66s 41ms/step - loss: 0.3255 - acc: 0.9700 - val_loss: 0.0349 - val_acc: 0.9875\n",
            "Epoch 12/12\n",
            "1600/1600 [==============================] - 66s 42ms/step - loss: 0.3092 - acc: 0.9756 - val_loss: 0.0041 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jKgFIa4gkgkk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "# print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "# model.fit(X_train, Y_train,\n",
        "#           batch_size=sizeBatch, epochs=1, verbose=1,\n",
        "#           validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "agqqH8sf3CiV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# K.clear_session()\n",
        "\n",
        "# input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "# # Building sequential model with name 'model'\n",
        "# model = Sequential()\n",
        "\n",
        "# modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "# model.add(modelWoTop)\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "# # Model compiling\n",
        "\n",
        "# print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "# model.compile(loss='binary_crossentropy',\n",
        "#               optimizer='adam',\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "# numEpochs = 1\n",
        "\n",
        "# print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "# print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "# model.fit(X_train, Y_train,\n",
        "#           batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "#           validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qexmaPZVz04q",
        "colab_type": "code",
        "outputId": "bd692c27-5016-49b1-e7ca-4e580f76f67c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.plot(Y_test[:, 1], 'r')\n",
        "\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.plot(Y_pred[:, 1], 'b')\n",
        "\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.plot(Y_test[:, 1] - Y_pred[:, 1], 'g')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "IPTFOJh3DTgq",
        "colab_type": "code",
        "outputId": "9fd508d7-0b39-4277-9c98-07f45e0921d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "cell_type": "code",
      "source": [
        "now = datetime.datetime.now()\n",
        "\n",
        "# modelSaved = '{}-{}_{}_{}.h5'.format(folderNormal, folderFault, pretrainedModel, now.strftime('%m-%d-%H:%M:%S'))\n",
        "\n",
        "modelSaved = '{}-{}_{}_{}.h5'.format(folderNormal, folderFault, pretrainedModel, now.strftime('%m-%d-%H-%M-%S'))\n",
        "meanSaved = 'mean_{}.npy'.format(now.strftime('%m-%d-%H-%M-%S'))\n",
        "stdSaved = 'std_{}.npy'.format(now.strftime('%m-%d-%H-%M-%S'))\n",
        "\n",
        "inputStr = input('''Save Model as '{}'? (y/n)\\n'''.format(modelSaved))\n",
        "\n",
        "if (inputStr == 'y' or inputStr == 'Y'):  \n",
        "    model.save(modelPath + '/{}'.format(modelSaved))\n",
        "    np.save(modelPath + '/{}'.format(meanSaved), trainMean)\n",
        "    np.save(modelPath + '/{}'.format(stdSaved), trainStd)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Save Model as '['P1N1', 'P1N2', 'P1N3', 'P1N4', 'P1N5']-['P5N1', 'P5N2', 'P5N3', 'P5N4', 'P5N5']_ResNet50_11-18-22-40-41.h5'? (y/n)\n",
            "n\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}