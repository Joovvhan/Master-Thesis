{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning Clean Up.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joovvhan/Master-Thesis/blob/master/log/(PN)N-F_Inception.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "c3821KWLNey6",
        "colab_type": "code",
        "outputId": "70912d82-e642-426e-90c5-59b83022075f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Import necessary modules\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy.io.wavfile as wf\n",
        "import time\n",
        "import glob\n",
        "import datetime\n",
        "\n",
        "from tqdm import trange\n",
        "\n",
        "# Import Keras modules\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.layers import Input, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
        "from keras.models import Sequential\n",
        "from keras import backend as K\n",
        "from keras.models import load_model\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "nxSASpgF7unA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Mount google drive\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "# os.listdir('gdrive/My Drive/Colab')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rw9NU8Xjwcz2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set data directories\n",
        "\n",
        "dataPath = '''D:\\\\0_Joowhan's Paper\\\\Synthesized\\\\Total\\\\Impulse'''\n",
        "modelPath = '''D:\\\\0_Joowhan's Paper\\\\Synthesized\\\\Total\\\\Model'''\n",
        "\n",
        "\n",
        "# Changed variable names to normal and fault\n",
        "# Changed variable names from folder to path\n",
        "# Need to consider multiple folders\n",
        "# Need to add files to be tested\n",
        "\n",
        "# folderNormal = ['P1N1', 'P2N1', 'P3N1', 'P4N1', 'P5N1']\n",
        "folderNormal = list()\n",
        "\n",
        "for x in range(1, 6):\n",
        "    for y in range(1, 6):\n",
        "        if (x <= 2 and y <= 2):\n",
        "            folderNormal.append('P{}N{}'.format(x, y))\n",
        "\n",
        "folderFault = list()\n",
        "\n",
        "# folderFault = ['P1N5', 'P2N5', 'P3N5', 'P4N5', 'P5N5']\n",
        "\n",
        "for x in range(1, 6):\n",
        "    for y in range(1, 6):\n",
        "        if (x == 5 or y == 5):\n",
        "            folderFault.append('P{}N{}'.format(x, y))\n",
        "\n",
        "\n",
        "pathNormal = list()\n",
        "pathFault = list()\n",
        "\n",
        "for i in range(len(folderNormal)):\n",
        "    pathNormal.append(dataPath + '/' + folderNormal[i])\n",
        "    \n",
        "for i in range(len(folderFault)):\n",
        "    pathFault.append(dataPath + '/' + folderFault[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xgGP7PZO-rTA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Specgram settings\n",
        "\n",
        "nsc = 1470\n",
        "nov = nsc/2\n",
        "nff = nsc \n",
        "imgSize = 224\n",
        "\n",
        "# pretrainedModel = 'VGG19'\n",
        "# pretrainedModel = 'Xception'\n",
        "# pretrainedModel = 'ResNet50'\n",
        "\n",
        "# pretrainedModel = 'DenseNet169'\n",
        "pretrainedModel = 'InceptionV3'\n",
        "\n",
        "\n",
        "lastActivation = 'softmax'\n",
        "sizeBatch = 4\n",
        "numEpochs = 12\n",
        "verb = 1\n",
        "\n",
        "\n",
        "# Learning parameters\n",
        "\n",
        "trainingRatio = 0.8\n",
        "\n",
        "totalDataNum = 1000\n",
        "repeat = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5AskF2qFT2xr",
        "colab_type": "code",
        "outputId": "14bffba0-41c7-4f49-b3e7-cf72fa3e0342",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "cell_type": "code",
      "source": [
        "startNum = 0\n",
        "\n",
        "pickNum = int(np.ceil(totalDataNum / len(pathNormal)))\n",
        "\n",
        "for i in range(startNum, len(pathNormal)):\n",
        "\n",
        "    npyTestPath = glob.glob(pathNormal[i] + '/' + '*Image_With_Label.npy')\n",
        "    data = np.load(npyTestPath[0])\n",
        "    \n",
        "    pickIdx = np.random.choice(1000, pickNum, replace=False)\n",
        "    pickIdx.sort()\n",
        "    \n",
        "#     imgs = np.moveaxis(np.dstack(data[:, 0]), 2, 0)\n",
        "#     label = data[:, 1:5]\n",
        "\n",
        "    imgs = np.moveaxis(np.dstack(data[pickIdx, 0]), 2, 0)\n",
        "    label = data[pickIdx, 1:5]\n",
        "    \n",
        "    if i == startNum:\n",
        "        labelListNormal = label\n",
        "        imgsNormal = imgs\n",
        "    else:\n",
        "        labelListNormal = np.vstack([labelListNormal, label])\n",
        "        imgsNormal = np.vstack([imgsNormal, imgs])\n",
        "\n",
        "    print('Normal Image Shape From {}: {}:'.format(pathNormal[i], totalDataNum))    \n",
        "    print('Selected {}/{}:'.format(pickNum * (i + 1), len(data)))    \n",
        "    \n",
        "    \n",
        "print('Normal Image Shape: {}'.format(imgsNormal.shape))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P1N1: 1000:\n",
            "Selected 250/1000:\n",
            "Normal Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P1N2: 1000:\n",
            "Selected 500/1000:\n",
            "Normal Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P2N1: 1000:\n",
            "Selected 750/1000:\n",
            "Normal Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P2N2: 1000:\n",
            "Selected 1000/1000:\n",
            "Normal Image Shape: (1000, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P_MZtpk3Br_i",
        "colab_type": "code",
        "outputId": "1e58bd16-f06c-485c-b6d6-906df5251ef0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "cell_type": "code",
      "source": [
        "startNum = 0\n",
        "\n",
        "pickNum = int(np.ceil(totalDataNum / len(pathFault)))\n",
        "\n",
        "for i in range(startNum, len(pathFault)):\n",
        "\n",
        "    npyTestPath = glob.glob(pathFault[i] + '/' + '*Image_With_Label.npy')\n",
        "    data = np.load(npyTestPath[0])\n",
        "    \n",
        "    pickIdx = np.random.choice(1000, pickNum, replace=False)\n",
        "    pickIdx.sort()\n",
        "    \n",
        "#     imgs = np.moveaxis(np.dstack(data[:, 0]), 2, 0)\n",
        "#     label = data[:, 1:5]\n",
        "    \n",
        "    imgs = np.moveaxis(np.dstack(data[pickIdx, 0]), 2, 0)\n",
        "    label = data[pickIdx, 1:5]\n",
        "    \n",
        "    if i == startNum:\n",
        "        labelListFault = label\n",
        "        imgsFault = imgs\n",
        "    else:\n",
        "        labelListFault = np.vstack([labelListFault, label])\n",
        "        imgsFault = np.vstack([imgsFault, imgs])\n",
        "\n",
        "    print('Fault Image Shape From {}: {}:'.format(pathFault[i], totalDataNum))    \n",
        "    print('Selected {}/{}:'.format(pickNum * (i + 1), len(data)))     \n",
        "    \n",
        "print('Fault Image Shape: {}'.format(imgsFault.shape))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P1N5: 1000:\n",
            "Selected 112/1000:\n",
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P2N5: 1000:\n",
            "Selected 224/1000:\n",
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P3N5: 1000:\n",
            "Selected 336/1000:\n",
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P4N5: 1000:\n",
            "Selected 448/1000:\n",
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P5N1: 1000:\n",
            "Selected 560/1000:\n",
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P5N2: 1000:\n",
            "Selected 672/1000:\n",
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P5N3: 1000:\n",
            "Selected 784/1000:\n",
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P5N4: 1000:\n",
            "Selected 896/1000:\n",
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P5N5: 1000:\n",
            "Selected 1008/1000:\n",
            "Fault Image Shape: (1008, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e91QsAurSkIP",
        "colab_type": "code",
        "outputId": "aa7820c9-b461-45c7-844b-59f4934b6e63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "cell_type": "code",
      "source": [
        "# Change name from imgsF1 or imgsF5 to imgsNormal and imgsFault\n",
        "\n",
        "dataNumNormal = len(imgsNormal)\n",
        "dataNumFault = len(imgsFault)\n",
        "dataNumNormalTrain = int(dataNumNormal * trainingRatio)\n",
        "dataNumFaultTrain = int(dataNumFault * trainingRatio)\n",
        "dataNumNormalTest = dataNumNormal - dataNumNormalTrain\n",
        "dataNumFaultTest = dataNumFault - dataNumFaultTrain\n",
        "\n",
        "print('Normal Train:Test = {:d}:{:d}'.format(dataNumNormalTrain, dataNumNormalTest))\n",
        "print('Fault  Train:Test = {:d}:{:d}\\n'.format(dataNumFaultTrain, dataNumFaultTest))\n",
        "\n",
        "trainIdxNormal = np.random.choice(dataNumNormal - 1, dataNumNormalTrain, replace=False)\n",
        "testIdxNormal = list(set(range(0, dataNumNormal)) - set(trainIdxNormal))\n",
        "\n",
        "trainImgsNormal = imgsNormal[trainIdxNormal, :, :]\n",
        "testImgsNormal = imgsNormal[testIdxNormal, :, :]\n",
        "\n",
        "print('Normal Training Image Shape {}'.format(trainImgsNormal.shape))\n",
        "print('Normal Test Image Shape {}\\n'.format(testImgsNormal.shape))\n",
        "\n",
        "trainIdxFault  = np.random.choice(dataNumFault - 1, dataNumFaultTrain, replace=False)\n",
        "testIdxFault = list(set(range(0, dataNumFault)) - set(trainIdxFault))\n",
        "\n",
        "trainImgsFault = imgsFault[trainIdxFault, :, :]\n",
        "testImgsFault = imgsFault[testIdxFault, :, :]\n",
        "\n",
        "print('Fault Training Image Shape {}'.format(trainImgsFault.shape))\n",
        "print('Fault Test Image Shape {}\\n'.format(testImgsFault.shape))\n",
        "\n",
        "trainImgs = np.vstack([trainImgsNormal, trainImgsFault])\n",
        "testImgs = np.vstack([testImgsNormal, testImgsFault])\n",
        "\n",
        "print('Training Image Shape {}'.format(trainImgs.shape))\n",
        "print('Test Image Shape {}'.format(testImgs.shape))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal Train:Test = 800:200\n",
            "Fault  Train:Test = 806:202\n",
            "\n",
            "Normal Training Image Shape (800, 224, 224)\n",
            "Normal Test Image Shape (200, 224, 224)\n",
            "\n",
            "Fault Training Image Shape (806, 224, 224)\n",
            "Fault Test Image Shape (202, 224, 224)\n",
            "\n",
            "Training Image Shape (1606, 224, 224)\n",
            "Test Image Shape (402, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MoE7f_hzs0av",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "feQ_AHAcUgHD",
        "colab_type": "code",
        "outputId": "2d840c73-09de-4707-ebea-d72e7c1b9a70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "trainMean = np.mean(trainImgs)\n",
        "trainStd = np.std(trainImgs)\n",
        "\n",
        "print('Mean of Training Image: {}'.format(trainMean))\n",
        "print('Standard Deviation of Training Image: {}'.format(trainStd))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean of Training Image: -79.20158041963678\n",
            "Standard Deviation of Training Image: 8.123772694967995\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wUi9IuXNUpir",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Should Change Norm to Normalized\n",
        "\n",
        "trainImgsNorm = (trainImgs - trainMean) / trainStd\n",
        "testImgsNorm = (testImgs - trainMean) / trainStd\n",
        "\n",
        "trainImgsNorm = trainImgsNorm.reshape(list(trainImgsNorm.shape) + [1])\n",
        "testImgsNorm = testImgsNorm.reshape(list(testImgsNorm.shape) + [1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aklxiPz1Ve4n",
        "colab_type": "code",
        "outputId": "a7f275a6-db90-4fda-cce9-358557656fbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = np.stack([trainImgsNorm[:, :, :, 0], trainImgsNorm[:, :, :, 0], trainImgsNorm[:, :, :, 0]], axis = -1)\n",
        "X_test = np.stack([testImgsNorm[:, :, :, 0], testImgsNorm[:, :, :, 0], testImgsNorm[:, :, :, 0]], axis = -1)\n",
        "\n",
        "print('X_train Shape: {}'.format(X_train.shape))\n",
        "print('X_test  Shape: {}'.format(X_test.shape))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train Shape: (1606, 224, 224, 3)\n",
            "X_test  Shape: (402, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sRgIPzT7K_YP",
        "colab_type": "code",
        "outputId": "9f020a15-2cbf-4860-f4dd-a0bcba67b84e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "trainLabelNormal = np.stack((np.ones(dataNumNormalTrain), np.zeros(dataNumNormalTrain)), axis = -1)\n",
        "testLabelNormal = np.stack((np.ones(dataNumNormalTest), np.zeros(dataNumNormalTest)), axis = -1)\n",
        "\n",
        "trainLabelFault = np.stack((np.zeros(dataNumFaultTrain), np.ones(dataNumFaultTrain)), axis = -1)\n",
        "testLabelFault = np.stack((np.zeros(dataNumFaultTest), np.ones(dataNumFaultTest)), axis = -1)\n",
        "\n",
        "Y_train = np.vstack((trainLabelNormal, trainLabelFault))\n",
        "Y_test = np.vstack((testLabelNormal, testLabelFault))\n",
        "\n",
        "print('Y_train Normal:Fault = {:d}:{:d}'.format(len(trainLabelNormal), len(trainLabelFault)))\n",
        "print('Y_test  Normal:Fault = {:d}:{:d}'.format(len(testLabelNormal), len(testLabelFault)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Y_train Normal:Fault = 800:806\n",
            "Y_test  Normal:Fault = 200:202\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kczwZk7Tbp5C",
        "colab_type": "code",
        "outputId": "006edf68-358a-44c9-a575-45e594838d53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2647
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG19\n",
        "from keras.applications import VGG16\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications.densenet import DenseNet169\n",
        "from keras.applications.densenet import DenseNet201\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# pretrainedModel = 'ResNet50'\n",
        "# lastActivation = 'softmax'\n",
        "# lossFunction = 'binary_crossentropy'\n",
        "# sizeBatch = 2\n",
        "# numEpochs = 2\n",
        "# verb = 1\n",
        "\n",
        "for rp in range(repeat):\n",
        "\n",
        "    # Refresh all background variables\n",
        "    K.clear_session()\n",
        "\n",
        "    input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "    # Building sequential model with name 'model'\n",
        "    model = Sequential()\n",
        "\n",
        "    # Model selection\n",
        "\n",
        "    if (pretrainedModel == 'VGG16'):\n",
        "\n",
        "        modelWoTop = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'VGG19'):\n",
        "\n",
        "        modelWoTop = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif pretrainedModel == 'ResNet50':\n",
        "\n",
        "        modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'InceptionV3'):\n",
        "        modelWoTop = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'Xception'):\n",
        "        modelWoTop = Xception(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet169'):\n",
        "\n",
        "        modelWoTop = DenseNet169(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet201'):\n",
        "        modelWoTop = DenseNet201(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    else:\n",
        "        print('Invalid Pretrained Model Selection')\n",
        "\n",
        "\n",
        "\n",
        "    # Model compiling\n",
        "\n",
        "    print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "    print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "    model.fit(X_train, Y_train,\n",
        "              batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "              validation_data=(X_test, Y_test))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compiling Pretrained inception_v3 Model\n",
            "Training Pretrained inception_v3 Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1606 samples, validate on 402 samples\n",
            "Epoch 1/12\n",
            "1606/1606 [==============================] - 72s 45ms/step - loss: 0.4208 - acc: 0.8443 - val_loss: 0.2094 - val_acc: 0.9179\n",
            "Epoch 2/12\n",
            "1606/1606 [==============================] - 55s 35ms/step - loss: 0.3323 - acc: 0.8823 - val_loss: 1.2356 - val_acc: 0.8010\n",
            "Epoch 3/12\n",
            "1606/1606 [==============================] - 55s 34ms/step - loss: 0.2544 - acc: 0.9166 - val_loss: 0.4954 - val_acc: 0.6816\n",
            "Epoch 4/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.1992 - acc: 0.9284 - val_loss: 0.0818 - val_acc: 0.9751\n",
            "Epoch 5/12\n",
            "1606/1606 [==============================] - 57s 35ms/step - loss: 0.1971 - acc: 0.9284 - val_loss: 0.0997 - val_acc: 0.9751\n",
            "Epoch 6/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.1691 - acc: 0.9396 - val_loss: 0.1079 - val_acc: 0.9652\n",
            "Epoch 7/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.1334 - acc: 0.9626 - val_loss: 0.8242 - val_acc: 0.8532\n",
            "Epoch 8/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.1076 - acc: 0.9714 - val_loss: 0.0570 - val_acc: 0.9826\n",
            "Epoch 9/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.0821 - acc: 0.9745 - val_loss: 0.0650 - val_acc: 0.9801\n",
            "Epoch 10/12\n",
            "1606/1606 [==============================] - 57s 35ms/step - loss: 0.0645 - acc: 0.9813 - val_loss: 0.0583 - val_acc: 0.9826\n",
            "Epoch 11/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.0810 - acc: 0.9695 - val_loss: 0.0635 - val_acc: 0.9876\n",
            "Epoch 12/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.1942 - acc: 0.9328 - val_loss: 0.7764 - val_acc: 0.7836\n",
            "Compiling Pretrained inception_v3 Model\n",
            "Training Pretrained inception_v3 Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1606 samples, validate on 402 samples\n",
            "Epoch 1/12\n",
            "1606/1606 [==============================] - 70s 44ms/step - loss: 0.5645 - acc: 0.7422 - val_loss: 4.9357 - val_acc: 0.5224\n",
            "Epoch 2/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.4407 - acc: 0.8288 - val_loss: 6.8445 - val_acc: 0.5348\n",
            "Epoch 3/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.3020 - acc: 0.8991 - val_loss: 0.2277 - val_acc: 0.9627\n",
            "Epoch 4/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.2611 - acc: 0.9060 - val_loss: 0.3990 - val_acc: 0.8806\n",
            "Epoch 5/12\n",
            "1606/1606 [==============================] - 55s 34ms/step - loss: 0.2431 - acc: 0.9166 - val_loss: 6.2798 - val_acc: 0.6070\n",
            "Epoch 6/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.3771 - acc: 0.8499 - val_loss: 1.8319 - val_acc: 0.8284\n",
            "Epoch 7/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.2909 - acc: 0.8917 - val_loss: 0.1853 - val_acc: 0.9677\n",
            "Epoch 8/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.2078 - acc: 0.9240 - val_loss: 0.1450 - val_acc: 0.9502\n",
            "Epoch 9/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.1741 - acc: 0.9408 - val_loss: 0.1051 - val_acc: 0.9701\n",
            "Epoch 10/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.1776 - acc: 0.9390 - val_loss: 0.2361 - val_acc: 0.8856\n",
            "Epoch 11/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.1267 - acc: 0.9608 - val_loss: 0.2126 - val_acc: 0.9179\n",
            "Epoch 12/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.1184 - acc: 0.9608 - val_loss: 2.9041 - val_acc: 0.7289\n",
            "Compiling Pretrained inception_v3 Model\n",
            "Training Pretrained inception_v3 Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1606 samples, validate on 402 samples\n",
            "Epoch 1/12\n",
            "1606/1606 [==============================] - 71s 44ms/step - loss: 0.5422 - acc: 0.7927 - val_loss: 0.9220 - val_acc: 0.6542\n",
            "Epoch 2/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.3980 - acc: 0.8636 - val_loss: 1.0210 - val_acc: 0.8781\n",
            "Epoch 3/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.3395 - acc: 0.8780 - val_loss: 5.1829 - val_acc: 0.5896\n",
            "Epoch 4/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.2693 - acc: 0.9078 - val_loss: 0.3392 - val_acc: 0.9428\n",
            "Epoch 5/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.2265 - acc: 0.9184 - val_loss: 0.7197 - val_acc: 0.5224\n",
            "Epoch 6/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.1399 - acc: 0.9545 - val_loss: 0.0874 - val_acc: 0.9751\n",
            "Epoch 7/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.1736 - acc: 0.9452 - val_loss: 0.2784 - val_acc: 0.8682\n",
            "Epoch 8/12\n",
            "1606/1606 [==============================] - 57s 35ms/step - loss: 0.1471 - acc: 0.9521 - val_loss: 0.2314 - val_acc: 0.9328\n",
            "Epoch 9/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.0994 - acc: 0.9726 - val_loss: 0.0837 - val_acc: 0.9751\n",
            "Epoch 10/12\n",
            "1606/1606 [==============================] - 57s 35ms/step - loss: 0.1629 - acc: 0.9521 - val_loss: 0.3781 - val_acc: 0.8781\n",
            "Epoch 11/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.0747 - acc: 0.9732 - val_loss: 1.8657 - val_acc: 0.7512\n",
            "Epoch 12/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.0896 - acc: 0.9720 - val_loss: 0.0849 - val_acc: 0.9701\n",
            "Compiling Pretrained inception_v3 Model\n",
            "Training Pretrained inception_v3 Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1606 samples, validate on 402 samples\n",
            "Epoch 1/12\n",
            "1606/1606 [==============================] - 71s 44ms/step - loss: 0.4770 - acc: 0.8088 - val_loss: 0.6890 - val_acc: 0.6592\n",
            "Epoch 2/12\n",
            "1606/1606 [==============================] - 57s 36ms/step - loss: 0.3105 - acc: 0.9016 - val_loss: 6.0919 - val_acc: 0.5348\n",
            "Epoch 3/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.3344 - acc: 0.8736 - val_loss: 7.9752 - val_acc: 0.5025\n",
            "Epoch 4/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.2773 - acc: 0.8960 - val_loss: 0.1227 - val_acc: 0.9652\n",
            "Epoch 5/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.1617 - acc: 0.9496 - val_loss: 2.7592 - val_acc: 0.7065\n",
            "Epoch 6/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.1846 - acc: 0.9396 - val_loss: 0.2357 - val_acc: 0.8706\n",
            "Epoch 7/12\n",
            "1606/1606 [==============================] - 57s 35ms/step - loss: 0.1334 - acc: 0.9570 - val_loss: 0.0448 - val_acc: 0.9876\n",
            "Epoch 8/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.0895 - acc: 0.9732 - val_loss: 0.1100 - val_acc: 0.9776\n",
            "Epoch 9/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.0975 - acc: 0.9639 - val_loss: 0.0635 - val_acc: 0.9776\n",
            "Epoch 10/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.1041 - acc: 0.9689 - val_loss: 0.0587 - val_acc: 0.9826\n",
            "Epoch 11/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.1054 - acc: 0.9645 - val_loss: 0.0462 - val_acc: 0.9851\n",
            "Epoch 12/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.0635 - acc: 0.9813 - val_loss: 0.0447 - val_acc: 0.9851\n",
            "Compiling Pretrained inception_v3 Model\n",
            "Training Pretrained inception_v3 Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1606 samples, validate on 402 samples\n",
            "Epoch 1/12\n",
            "1606/1606 [==============================] - 70s 44ms/step - loss: 0.4436 - acc: 0.8406 - val_loss: 0.3370 - val_acc: 0.8806\n",
            "Epoch 2/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.3229 - acc: 0.8910 - val_loss: 0.9688 - val_acc: 0.3632\n",
            "Epoch 3/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.2646 - acc: 0.9016 - val_loss: 0.1526 - val_acc: 0.9627\n",
            "Epoch 4/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.1873 - acc: 0.9390 - val_loss: 1.5519 - val_acc: 0.8781\n",
            "Epoch 5/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.1148 - acc: 0.9695 - val_loss: 0.0614 - val_acc: 0.9851\n",
            "Epoch 6/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.1032 - acc: 0.9664 - val_loss: 0.0604 - val_acc: 0.9776\n",
            "Epoch 7/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.1567 - acc: 0.9521 - val_loss: 0.0873 - val_acc: 0.9701\n",
            "Epoch 8/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.1059 - acc: 0.9701 - val_loss: 4.8093 - val_acc: 0.6841\n",
            "Epoch 9/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.1920 - acc: 0.9346 - val_loss: 0.3459 - val_acc: 0.8458\n",
            "Epoch 10/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.0817 - acc: 0.9751 - val_loss: 0.1527 - val_acc: 0.9577\n",
            "Epoch 11/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.0703 - acc: 0.9788 - val_loss: 0.2237 - val_acc: 0.9428\n",
            "Epoch 12/12\n",
            "1606/1606 [==============================] - 56s 35ms/step - loss: 0.0826 - acc: 0.9757 - val_loss: 0.0447 - val_acc: 0.9925\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jKgFIa4gkgkk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "# print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "# model.fit(X_train, Y_train,\n",
        "#           batch_size=sizeBatch, epochs=1, verbose=1,\n",
        "#           validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "agqqH8sf3CiV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# K.clear_session()\n",
        "\n",
        "# input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "# # Building sequential model with name 'model'\n",
        "# model = Sequential()\n",
        "\n",
        "# modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "# model.add(modelWoTop)\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "# # Model compiling\n",
        "\n",
        "# print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "# model.compile(loss='binary_crossentropy',\n",
        "#               optimizer='adam',\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "# numEpochs = 1\n",
        "\n",
        "# print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "# print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "# model.fit(X_train, Y_train,\n",
        "#           batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "#           validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qexmaPZVz04q",
        "colab_type": "code",
        "outputId": "31158efa-c300-40fa-97ec-bbc4272c30a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.plot(Y_test[:, 1], 'r')\n",
        "\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.plot(Y_pred[:, 1], 'b')\n",
        "\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.plot(Y_test[:, 1] - Y_pred[:, 1], 'g')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3Xl8VPXV+PHPyR6SQAgJi2xhK4IbICJWf9ZqK4sWWrdi+1i3VrvY2qqPQhcf2+dRW9u6vVq1qNSlFQVbLVKtWrXFioIEQUFA2Qn7HshGlvP743tnyWQmmYTJTGY479crr7nLd+49853Jme89c+eOqCrGGGNSS1qiAzDGGBN7ltyNMSYFWXI3xpgUZMndGGNSkCV3Y4xJQZbcjTEmBVlyN8aYFGTJ3RhjUpAld2OMSUEZrTUQkVnAhcAuVT0xzHoBHgAmA1XAVaq6tLXtFhcXa2lpaZsDNsaYY1lZWdkeVS1prV2ryR14Avgd8FSE9ZOAYd7f6cDD3m2LSktLWbJkSRS7N8YY4yMim6Jp12pyV9UFIlLaQpOpwFPqLlLznogUikgfVd0eVaTGdCYrVsCLLyY6CpPqJk2CU0/t0F1EM3JvTV9gS9B8ubesWXIXkeuA6wAGDBgQg10bE2N33QWzZyc6CpPqiouTIrlLmGVhLzWpqjOBmQBjx461y1Gazqe2FkaOhOXLEx2JSWVpHX8uSyySeznQP2i+H7AtBts1Jv4aGiAjw/0Zk8Ri8fYxD/iGOOOBg1ZvN0mrvh7S0xMdhTFHLZpTIWcD5wDFIlIO/A+QCaCqjwAv406DXIs7FfLqjgrWmA7nG7kbk+SiOVvm8lbWK/C9mEVkTCI1NNjI3aQE+4aqMcHq623kblKCJXdjgtnI3aQIS+7GBLPkblKEJXdjgllZxqQIS+7GBLORu0kRltyNCWbJ3aQIS+7GBLOyjEkRltyNCWYjd5MiLLkbE8ySu0kRltyNCWZlGZMiLLkbE8xG7iZFWHI3Jpgld5MiLLkbE8zKMiZFWHI3JpiN3E2KsORuTDBL7iZFWHI3JpiVZUyKsORuTDAbuZsUYcndmGCW3E2KsORuTDAry5gUYcndmGA2cjcpIqrkLiITRWSNiKwVkelh1l8lIrtFZJn3983Yh2pMB1OFxkZL7iYltHr8KSLpwO+BLwLlwPsiMk9VPw5p+pyq3tABMRoTH42N7tbKMiYFRDNyHwesVdX1qnoEeBaY2rFhGZMA9fXu1kbuJgVEk9z7AluC5su9ZaEuFpEPReR5EekfbkMicp2ILBGRJbt3725HuMZ0oIYGd2vJ3aSAaJK7hFmmIfMvAaWqejLwT+DJcBtS1ZmqOlZVx5aUlLQtUmM6mi+5W1nGpIBokns5EDwS7wdsC26gqntVtdabfRQ4NTbhGRNHVpYxKSSa5P4+MExEBolIFjANmBfcQET6BM1OAVbFLkRj4sTKMiaFtHr8qar1InID8CqQDsxS1ZUi8gtgiarOA34gIlOAemAfcFUHxmxMx7CyjEkhUb2KVfVl4OWQZbcHTc8AZsQ2NGPizMoyJoXYN1SN8bGRu0khltyN8bGau0khltyN8bGyjEkhltyN8bGyjEkhltyN8bGyjEkhltyN8bGyjEkhltyN8bGyjEkhltyN8bGyjEkhltyN8bGyjEkhltyN8bGyjEkhltyN8bGyjEkhltyN8bGyjEkhltyN8bGyjEkhltyN8bGyjEkhltyN8bGyjEkhltyN8bGyjEkhltyN8bGyjEkhltyN8bGyjEkhltyN8bGyjEkhltyN8bGyjEkhUSV3EZkoImtEZK2ITA+zPltEnvPWLxKR0lgHakyHs7KMSSGtJncRSQd+D0wCRgKXi8jIkGbXAvtVdShwH/CrWAdqTIezsoxJIdG8iscBa1V1PYCIPAtMBT4OajMVuMObfh74nYiIqmoMY3VWrYLly2O+WWNYtMjd2sjdpIBokntfYEvQfDlweqQ2qlovIgeBHsCe4EYich1wHcCAAQPaF/H8+XDrre27rzGtyc6GgoJER2HMUYsmuUuYZaEj8mjaoKozgZkAY8eObd+o/ppr4EtfatddjWlVURHk5yc6CmOOWjTJvRzoHzTfD9gWoU25iGQA3YB9MYkwVI8e7s8YY0xE0ST394FhIjII2ApMA74W0mYecCXwLnAJ8GZr9faysrI9IrKp7SEDUExIyaeTsLjaxuJqG4urbVI1roHRNGo1uXs19BuAV4F0YJaqrhSRXwBLVHUe8DjwtIisxY3Yp0Wx3ZJoAgxHRJao6tj23r+jWFxtY3G1jcXVNsd6XFGd86WqLwMvhyy7PWi6Brg0tqEZY4xpL/uGqjHGpKBkTe4zEx1ABBZX21hcbWNxtc0xHZd0xPeMjDHGJFayjtyNMca0wJK7McakoKRL7q1doTLOsWwUkY9EZJmILPGWFYnI6yLyqXfbPQ5xzBKRXSKyImhZ2DjEedDrvw9FZEyc47pDRLZ6fbZMRCYHrZvhxbVGRCZ0UEz9ReQtEVklIitF5EZveUL7q4W4Et1fOSKyWESWe3H93Fs+yLsC7KfeFWGzvOVxuUJsC3E9ISIbgvprlLc8bq97b3/pIvKBiMz35uPfX6qaNH+48+zXAYOBLGA5MDKB8WwEikOW3QNM96anA7+KQxxnA2OAFa3FAUwGXsFdMmI8sCjOcd0B3BKm7Ujv+cwGBnnPc3oHxNQHGONNFwCfePtOaH+1EFei+0uAfG86E1jk9cMcYJq3/BHgO970d4FHvOlpwHMd1F+R4noCuCRM+7i97r393QQ8A8z35uPeX8k2cvdfoVJVjwC+K1R2JlOBJ73pJ4Evd/QOVXUBzS/3ECmOqcBT6rwHFIpInzjGFclU4FlVrVXVDcBa3PMd65i2q+pSb/oQsAp34buE9lcLcUUSr/5SVT3szWZ6fwqci7sCLDTvL18/Pg+cJyLhrj3VUXFFErfXvYj0Ay4AHvPmhQT0V7Il93BXqGzpH6CjKfCaiJSJu+IlQC9V3Q7uHxbomaDYIsXRGfrwBu/QeFZQ2SrucXmHwKNxo75O018hcUGC+8srMSwDdgGv444SDqhqfZh9N7lCLOC7QmyHx6Wqvv660+uv+0QkOzSuMDHH2v3ArUCjN9+DBPRXND/W0axuGrI+nrWsqK4+GUdnquoY3A+ZfE9Ezk5gLNFKdB8+DAwBRgHbgd96y+Mal4jkA38BfqiqFS01DbMsnnElvL9UtUFVR+EuGjgOGNHCvhMWl4icCMwAjgdOA4qA2+IZl4hcCOxS1bLgxS3su8PiavU8dy9hHcYd0pwYZv1k4Pu4mtbpwAOqGnq992aKi4u1tLS0PTEbY8wxq6ysbI9GcW2uaC4ctqCVT3D9tSzgPREpFJE+vkPcSEpLS1myZElruzfGGBNEoryabix+LDJSLavF5G5MMrjnHsjNhWXL4Ne/hptvhooKGDwYqqpgzx4YNcr9gNPhw/D229CnD1RXQ69esH8/HDjgtjFhgmuflQXvvuvWAQwcCJWVge2OHQsrV8LBg/D1r8O997r733gjFBfDI4+43/IuL4dzznH7efFFt93iYtixw/0VFcFpp8HixW4fmza5H5ny7ffQIXfbty8UFsK+fbBrF+TkuP1lZoKIi7lrV6irC/zV10OXLlBbG/hd8bbKzISePUEVGhvdn286O9vFsHu32/5nPuMeb0kJrF4Nkya5NgsWuPYHD7pbEdcHXbu6x7dr11G/BCI6/ngX75o1bb/vD3/Y8b85FNXlB7yR+/wIZZm/A3er6n+8+TeAW0NqTr62wT+zd+qmTe29nLsxHe/IEZdAfIYOhbVrm7ZJTw/8rja45LxvH9TUuMTXvbtL9tu3u+U+paXQr59LDkuXukQ3eDCsWNE8Wfbs6Zb57p+V5RJfdnYgeeXkuMRWXe3WnXqqS+Zbtrgflqqrc28Chw655Jee7m5V4cMP3W337i7R19S47dTXu8fWvbt7I8vMDPxlZLg3pJwcN98eNTXujSMtzf2JBKYrK13/lXjFhzVr3Pq6Oujd2/UnwIABLobu3V0cdXWwdSts2+Ye98knty+21uzaBZ984qaHDw/EGa2bb4Yvt/M8OhEp0yguGRyLkXs0v9QExOhn9oyJk2XLms6vXQuXXw4zZriEfPHFLpFWVrqksnGjG8Wnp7tRZFVV4Bf7qqpcwunZ041GBw92yQpg506XqAsL3RvKb38L554LCxe6dT/9qWs7a5ZL/j/6UWDUuG6dOzI44QQXyxtvuKR9yilu/ebNcNxxLSfghoZAcu2sGr3zTiorXV898QScdRaMHBm+fXm5a9fWpButhQvhzDPd9FNPwbiYn4R69GIxcr8AuIHAB6oPqmqrD3Xs2LFqNXfTmd1/v0ukwe66yyV3c2yrrnYlrrQ0dzQUfITX0WI2cheR2cA5QLGIlAP/g/vCAKr6CO5HPCbjvkRRBVzd/rCN6Tw++qj5sqFD4x+H6Xxyc93RUXp6fBN7W0RztszlraxX4Hsxi8iYTqKy0tVT77kHpnrfg7bkbnyefrpzl7JiUXM3JiVVV7sP66ZMCSwbMiRx8ZjOJVK9v7NItssPGBM3NTXu8BsCI/euXRMXjzFtYSN3YyLwjdwB5s51p+YZkyxs5G5MBMEj98zMwGmNxiQDS+7GRBA8cjcm2VhyNyaCmhpL7iZ5WXI3JgLfV/mNSUaW3I2JwEbuJplZcjcmAhu5m2Rmyd2YMFRt5G6SmyV3Y8Koq3NXIrSRu0lWltyNCaOmxt3ayN0kK0vuxoRRXe1ubeRukpUld2PCsJG7SXaW3I0Jw0buJtlZcjcmDBu5m2Rnyd2YMHzJ3UbuJllZcjcmDF9ZxkbuJllZcjcmDBu5m2Rnyd2YMGzkbpJdVMldRCaKyBoRWSsi08Osv0pEdovIMu/vm7EP1Zj4sZG7SXat/syeiKQDvwe+CJQD74vIPFX9OKTpc6p6QwfEaEzc2cjdJLtoRu7jgLWqul5VjwDPAlM7NixjEquqyt3m5SU2DmPaK5rk3hfYEjRf7i0LdbGIfCgiz4tI/5hEZ0yCVFa62y5dEhuHMe0VTXKXMMs0ZP4loFRVTwb+CTwZdkMi14nIEhFZsnv37rZFakwbPfkkXHBB++5bVQUiVpYxySua5F4OBI/E+wHbghuo6l5VrfVmHwVODbchVZ2pqmNVdWxJSUl74jUmaosXw1tvte++lZVu1C7hhjbGJIFokvv7wDARGSQiWcA0YF5wAxHpEzQ7BVgVuxCNaZ/aWvfXHlVVVpIxya3Vs2VUtV5EbgBeBdKBWaq6UkR+ASxR1XnAD0RkClAP7AOu6sCYjYlKba37wY36esho9ZXelCV3k+yiesmr6svAyyHLbg+angHMiG1oxhwd36i9trbtyb2y0s6UMcnNvqFqUlZwcm8rG7mbZGfJ/Rj3ox/Bn/6U6Cg6hi+pHznS9vtacjfJro0HqwZAvRNBk/1MClW4/343ffzxMHZsYuOJtaMZuVdWgp3QZZKZjdzboUsXOOOMREdx9OrqAtPr1iUujo7iG7FbWcYciyy5t0NNDSxalOgojp7v+ikAhw4lLo6OYjV3cyyz5H6MWLmyaTKHwPVTACoq4htPPBxtWcbOljHJzJL7MaCyEk48Ea64ouny4GRvyb0pG7mbZGfJ/Rhw+LC7ffXVpsstuYenGrj8gDHJypJ7GzU0JDqCtvPV00NPCbSae3hFRe7WyjImmVlyb6PQunUy8I3cg8+OgWOn5t7W89wPHHC39itMJpmlbHLfuRM++KDt91uzBvbvj7w+OCF2Zg0N8K1vwYoVgeSuIRdqtrJMc8FHZhs2xDYeY+IpZZP7sGEwZkzb7/f5z8Ndd0VeH5zcO3OJZvt2eOwxeOWVyCUXX3IvKrKyzPr17ktps2cHll17bcfEZUw8pGxy9yWrxsbo27/5JuzY4RJjJAcPBqZ9v9bTGfniPHgwMHIP5UvuvXt33pF7Q0P73kTr6wPPfTTJvazM3T7wgLt97DE46aS279eYziIlk7vvl+sB5s5teVRaUeFqrF/9Kpx3nitd+GquoRYsgFGjAvOduUQTTXL3xd+rV+dN7lddBZdf3vb7BSf0aJJ7Vpa79f1AWLdubd+nMZ1JSib3jz8OTE+b5hJEJL17Q/fu8K9/BZZFSu4rVzadT/TIvaYm8htXcHIPbvPEE4Fp38i9Z8/OW5ZZsaJ5v0ejrcnd91zu3OluLbmbZJeSyf3DD5vOh/tgdeVKV2P1JbjgDxcjJfe9e5vOJzq5n3kmdO0afl2kkfvVVwfOHgkty+zZ0/Sop62WLXN9+p//tH8bofbubd7v0Qg+Q2b7drj++shHMBB4zn2PP1K/GpMskjq5NzTApk3Nl69e3XQ++CyRQ4dcsn/jjcjbjZTc9+xpOh8pub/xBlx4Ycd/4Lp0qbsNPcURWi7L+D5T8CX3Xr1cjbqkxJWn2uuf/3S3c+e2fxuhfMk99Eyf1gSP1n/zG5g5E2bNitw+9Dm3kbtJdkmd3G+6CUpLAyO7pUvdsiefbHo5XtVAcvjf/3Vn0fzqV5G3G+3IPVLN/ZVX4O9/Dxzit+S+++CFF8Kvmz8fdu1yZ+/ccYdLwOGsXdt8ma+GXlHRvOSydau7rapytebhwwPr5s2j3Xx166MZ/QerqXEx1te3POoOJ1wppqXvKFhyN6kmKZO7b0T84IPuduNG90HYpEkuWe7YAZ/9bKD9pk2QmekS/IIFbtm2bZG3X1kZfjQcbVnGlzy3bHG3Bw64mMK56Sa46KLmyysq4Etfch/yzp4NP/+5ewxvvtm8bfBnDD6hI/f+/QPlqvJyd1td7b5if/rpgftlZgamN26M/mwjCCTIWH3RK7i/21qaCZfcWyqjhSZ3K8uYZJd0yf2FF+C00+DuuwPLNm+GZ591o9xp09yy0B9aaGhwSTe0Hh9J8CmPPtGWZXzJs7zc7bd7dxgxonm70C9LTZ8O997r3oR8X6BZsaJp6ekvf3G3wUcN0ST3ggLo29ct8735VFe7b2H6lgMUFrrbd96BQYPg8cfDP8ZwfEcqkd7I2irWyd33vIQT+nzbdWVMsosquYvIRBFZIyJrRWR6mPXZIvKct36RiJTGOlCfvDxXM//xjwPLNm92H5AWFQW+gHTZZc3vO3euS2ijRweW/eQn4fcTrjTT2sh9zx53BBGc3J95JrC90IQTXE45cMCVim6+GXJy4LXXAuuCyyp1dS75P/VUYFm4D4xDz5bJz3dvMjk5bj+bNweSO8DkyYHHWF8fOCp69133ZZ7//d/m+wjlS+7hPgcJtXw5/O1vgflbb4Vf/rJpbb0tyf2DDwJHShA+ufvWb9kCf/6zewObOzdwOmywZP+VLWNQ1Rb/gHRgHTAYyAKWAyND2nwXeMSbngY819p2Tz31VG2v995TnT9fde9e1dxcX0Vd9ayz3PraWtXGxsBy31+PHqoiqvfd5+aLilT372/eDlQfecRta9s21b/+VfX555u3uftu1S98QfXii1Ufe8wty85Wzcx00zffrPr1rwfaf/CB2+ahQ6o//anqL38ZWOeLKTjWcHFNmKD69783bdenj3u8vnh/9jPViRMDbUaPVj33XLfet2zKFNWLLlI98cRAvz7yiFu3Zo1qVpabPvVU1fR0N/3aay0/L2ed5drl5Kg2NERut3VrII7Dh11/BD/G1atdu7lzA8ueeSb8thYuVP3sZ1UzMtxj8nnjjeZ9N3y4W3fOOU2Xl5SolpaqnndeYJkxnRWwRFvJr+q9jFtL7mcArwbNzwBmhLR5FTjDm84A9gDS0naPJrk3faCBv2uvbbruwQdVZ89Wfe451a5dXZvzzlMtK3PTXboE3gTOP795Mpg5s+mbR/DfKaeo9uwZfl3o34knutuxY1V37FC94ILmbUpK3JuCL0FC4E0i9G/YsKaPGVQ3bnSPecqU8Pe5+mq3/rLL3Hzfvi7hn3ZaoL9eesmtGz/e3Q4dGrh/QYHqccep7tnj2tbUqB444KYPHVK94oqm+1uwwCX4qirVigr3Znz11arTp6sWFgba/fWvqnfe2fS+N92k+oc/qP74x4Flt9+u+utfq/7lL+45e/FFl9RDH2f37u4xheuDnBzVtWtV09ICfT5/vmp+vpufNs1t96GHYvLSNKZDxDK5XwI8FjR/BfC7kDYrgH5B8+uA4pa22xHJ/cYbI7f71rfc6GzBAjfi9yV3VdXt212yCpcQCgtVJ09uvvzee6NL7KB6zz3Nl+Xludt+/QLLbrnFxfM//+PmMzJa3/Y//uFuR49W7dUrcrt33nHbbmx0ycu3/NZbA3308cdN7/Pww4Hpf//bvdl07x4YKYMb2Qe/CZx1lntsw4e75enp4d8gv/ENt63gpFxbqzpmTPT92pa/SZOaJvmyMvemo6o6a5Zbfv31MXlJGtOhok3uGVFUbsJVH7UdbRCR64DrAAYMGBDFrls3bx588omrLX/ve5HbzZwZFJjC978f+PC1d293u2WLO/1u9253O3MmfP3r7px1cGfanHCC+5C0Wzf3RZmsLFi4EE491d1n9WrIyHB16ooKV9e9+moYMMDVmV991Z2d8pvfuNMlzz/f3T7zjKs7g/s8obwchg51nw88/rj7QPazn3X18x073DZ27YIJE+DXv4ann4YvftFdD+XMM90Hs6ec4s49P/74wA96i8DXvgavv+4+0P3ZzwL9MmKE+wLS4sXu8V1xhftgt7oazj4bHn0Ufv971/YHP4AePeD55yE93X3QPWsWfPvb7v5z5sDgwa5fcnNh7Fh3xs6+fe4D3mnT3Dn1P/sZfPnL7hIDWVlw223w0ENw6aXucV9wgdvPp5/Cdde553vPHsjOhu9+131Gccoprq9XrYKf/tR9z6CgwH0mUlAAS5a4U0nvvdc9V//3f00vKnfVVa6mf/bZ7X0VGtP5iHsjaKGByBnAHao6wZufAaCqdwe1edVr866IZAA7gBJtYeNjx47VJUuWxOAhGGPMsUNEylR1bGvtojlb5n1gmIgMEpEs3AemoV91mQdc6U1fArzZUmI3xhjTsVoduQOIyGTgftyZM7NU9U4R+QWu9jNPRHKAp4HRwD5gmqqub2Wbu4EoTpoLqxj3oW1nY3G1jcXVNhZX26RqXANVtaS1RlEl985GRJZEc1gSbxZX21hcbWNxtc2xHlfSfUPVGGNM6yy5G2NMCkrW5D6z9SYJYXG1jcXVNhZX2xzTcSVlzd0YY0zLknXkbowxpgVJl9xbu0JlnGPZKCIficgyEVniLSsSkddF5FPvtnsc4pglIrtEZEXQsrBxiPOg138fisiYyFvukLjuEJGtXp8t806z9a2b4cW1RkQmdFBM/UXkLRFZJSIrReRGb3lC+6uFuBLdXzkislhElntx/dxbPsi7Auyn3hVhs7zlcblCbAtxPSEiG4L6a5S3PG6ve29/6SLygYjM9+bj31/RXKOgs/wRxRUq4xzPRkKuoQPcA0z3pqcDv4pDHGcDY4AVrcUBTAZewV0yYjywKM5x3QHcEqbtSO/5zAYGec9zegfE1AcY400XAJ94+05of7UQV6L7S4B8bzoTWOT1wxzc91kAHgG+4023+QqxMY7rCeCSMO3j9rr39ncT8Aww35uPe38l28h9HLBWVder6hHgWWBqgmMKNRV40pt+EvhyR+9QVRfgvjwWTRxTgafUeQ8oFJE+cYwrkqnAs6paq6obgLW45zvWMW1X1aXe9CFgFdCXBPdXC3FFEq/+UlX1/chhpvenwLnA897y0P7y9ePzwHkisb86fgtxRRK3172I9AMuAB7z5oUE9FeyJfe+QNBPMlBOy/8AHU2B10SkTNxF0QB6qep2cP+wQM8ExRYpjs7Qhzd4h8azgspWcY/LOwQejRv1dZr+CokLEtxfXolhGbALeB13lHBAVX2/6hu8b39c3vqDQI94xKWqvv660+uv+0QkOzSuMDHH2v3ArYDvRyp7kID+illyD1df7QBRXX0yjs5U1THAJOB7IpIM1xVMdB8+DAwBRgHbgd96y+Mal4jkA38BfqiqFS01DbMsnnElvL9UtUFVRwH9cEcHYX400r/vhMUlIififm/ieOA0oAi4LZ5xiciFwC5VLQte3MK+OyyuWI7cnwAmxnB74ZQD/YPm+wEt/NR1x1LVbd7tLuAF3At/p+9wz7vdlaDwIsWR0D5U1Z3eP2Uj8CiBUkLc4hKRTFwC/bOq/tVbnPD+ChdXZ+gvH1U9APwLV7MuFHcF2NB9++Py1ncj+tLc0cY10StvqarWAn8k/v11JjBFRDbiysbn4kbyce+vmJ7n7h1OzlfVE1trW1xcrKWlpTHbtzHGHAvKysr2aBQXDovmxzpiRkJ+rMOu526MMW0jIlFdTTeuH6iq6kxVHauqY0tKWn3jMSburn/pekb+fmSiwzDmqMV15G5MZzdzaWe9HIkxbZNsp0IaExeN2th6I2M6sVieCjkbeBcYLiLlInJtrLZtTLztr96f6BCMOSoxK8uo6uWx2pYxibarchc9unTId2+MiQsryxgTxu6q3YkOwZijYsndmCD5WfkA7K605G6SmyV3Y4J0z3GXbvm/t/+PAzUHEhyNMe1nyd2YIN1yugGwbMcyHnr/oQRHY0z7WXI3JogEXccpOz27hZbGdG6W3I0JUtdY558+dORQAiMx5uhYcjcmSH1jPV876WvkZ+VzsOZgosMxpt0suRsTpK6hjoy0DLpld+NgrSV3k7wsuRsTpK6xjsy0TLrlWHI3yc2SuzFB6hq85J7dzcoyJqlZcjcmSH1jvSvL2MjdJDlL7sYEqWusIzPdRu4m+VlyNyaIryxTmFNoI3eT1Cy5GxPEX5axkbtJcpbcjfGoKg3a4MoyOd2obailtr420WEZ0y6W3I3x+L6d6jtbBrDSjElaltyN8dQ31gOQmZ5J1+yuAFTUViQyJGPazZK7MZ66Bjdyz0jLoCC7AIDDRw4nMiRj2s2SuzGe4LKM70c7LLmbZGXJ3RiPb+SemW7J3SQ/S+7GeHw194y0DH9yP1Rrl/01ycmSuzGe4LJMQZbV3E1ys+RujMfKMiaVWHI3xhOuLGPJ3SQrS+7GeILLMlnpWWSkZdhP7ZkhiFP4AAAWH0lEQVSkZcndGE9wWUZEKMgqsJG7SVqW3I3xBJdlAPKz8i25m6Rlyd0YT3BZBiy5m+Rmyd0YT3BZBlxyt5q7SVaW3I3xhI7cC7IDNfe5K+fy7fnfTlhsxrSVJXdjPC3V3C97/jL+UPYHDtQcSFh8xrRFzJK7iEwUkTUislZEpsdqu8bES7iyzJaDWzjhoRP8bZZuX5qQ2Ezn84NXfsCP/vGjRIcRUUySu4ikA78HJgEjgctFZGQstm1MvISWZY7vcTx7q/fy8e6P/W2WbFsSv3ga6jjScKTZMpN4VXVVPLr0UWYunUlNfU2iwwkrI0bbGQesVdX1ACLyLDAV+LjFe8XA3qq9VNVVUd9Yz8DCgaRJdO9XK3atoLSw1P9NxGCqSk19DYu3LmZMnzH+a3s3NDaQnpbub7f54GbSJI3dlbsZUjSEitoKNh3YBMC4vuNIkzTKK8oZWDiQfdX7qGuo440NbzCieASj+4ympr6GnIwc9lbtpWx7GV8c/EVEBIAPd35IflY+RblFrNy1kp55PTmu4Dgy0zOpqK2gW3Y3FCUrPYvNBzfzr43/YlDhIEoLS+md35sFmxYwtGgoH+z4gGFFwzih5wlNHuO/N/6bBm3g3EHnNnvse6v3UtdQR5+CPqzes5rqumpG9xnN9kPbeWvjW+Rl5tE1uysF2QV8uvdTaupruGTkJSzdvpQTep7ArspdLCpfRK/8XvTM60ldQx1DioaQn5VPdV01jdpIcZdiKmoreH3964zvN55+XfsBsOPwDt7f+j6fH/R5Xl37Kif1OoncjFx2Ve5iVO9RbDywkUNHDpGVnsWI4hEs3rqY/t36c7DmIBW1FZzc62S2HtpKQVYB9Y311DfWU15Rzvh+4/lk7ycs27GMycMm0y2nW5PHveXgFv8Pc/jKMheNuIjb/3V7k3aPLn2UJduWsHznckb3Hk3/rv0pP1TOvup9HGk4whcGfYEDNQdQlH3V++iV14tuOd3YXbmbtfvXUphTyIGaA5xQcgJ98vv4X4vZGdn079qfzQc38/LalxneYzir9qziUO0hrhl9DQ2NDfxl1V/YUrGFr57wVfrk9yE3M5c1e9dQXVfNkO5DyEzPZPHWxfQp6MNZ/c9id9VuVu5eyaDCQdQ11FGYU0hVXRXdcrohCF2zu6IoGw9spL6xnp55Pf0/UqKqgdcEGnFZ8PJol0XaZqM2Ut9YT0F2AXUNddTU15CdkY0gbD64mZyMHPbX7GdAtwE8t/I5+hb05Yx+Z5CVnkVWeha5mbkI7v9n+c7lZKdnc3zx8XSEdfvX+ZP6jH/OYHD3wW26/zml53BSr5M6IjQ/Ce7cdm9E5BJgoqp+05u/AjhdVW8IaXcdcB3AgAEDTt20adNR73vco+N4f9v7ADw+5XGuGX1N2Hb3vHMPCzYt4K7z7mJo0VDy7spjyvAp/G3a39iwfwO983tz8ZyLWbhlIbUNtf4nbkTxCCYMmcDbm9+mbHsZp/c9ncq6Sn5+zs+5eM7FEeMa3mM4a/auAWDOJXO46bWbKK8oB1zyOKf0HN5Y/wYXj7yYNze8yb7qfTww8QG+P+77/OnDP/GNF7/B2OPGUl1XzcrdKyPuZ+V3VzLu0XFU1lX6lw3sNpBNBzf5EwnA6u+tZnjxcKrqqpj/yXy++vxXAXjkgke4fuz1AGw/tJ2RD43kQM0B+nftz2NTHmPCnyaQmZZJ2XVlTPrzJLYe2ho2juIuxeyp2sO3xnyL19a9xqaD4Z/b3Ixcquur+cU5v2DOx3NYsWsFAKf2OZXXr3idK1+8kpc+ecnfvktmFzLTMjlYe5AeuT3YW73Xv660sJSNBzY22X7X7K5Nfj3puILj2HZoG98f933+uOyPHD5ymEGFg3hx2ov0zu9Nz7yevPLpK3zlua/QPbc7Ow7vYN0P1jG4+2BUlcEPDqauoY6th7Yya8osbvzHjVTXV9Mnvw8Ha90byqDCQZTklVB5pJKVu1eSlZ7FkYYjFGQVUFVXRYM2kJGWwfAewzlQc4CC7ALW7lvrr/HnZeZR1+hG6TkZOZzc62TW7luLIIzvN56XP32ZjLQMzh9yPl2zuzL/k/k0aANVdVUM6e7eNH39WJhTSGVdJTX1NaRJGgO7DWTDgQ10ze7KodpDpKel+/cb/JxkpWd16p8U7JbdjYO1B/3P76jeo1BVPtr1EY3a2Kx9flY+dQ111DZ03G/g9snvg6LsOLyjzfd9+IKH+fbY9n1ALyJlqjq21XYxSu6XAhNCkvs4Vf1+pPuMHTtWlyw5+kNc+bn4p6edOI3ZF8/2z1829zLysvJo1EaeWv4UAKN7j+ahCx7ijMfPICcjh8ofV5L+i3TO6HcG75a/22TbV426iudWPEd1fXWz/Q7pPoR1+9dFFWO/rv38iX32xbN5YNEDvFf+Xti2RblF7KveF9V2Ab520td45qNneOvKt6iuq+bu/9zN25vfbtbuv07+L57+ytNM+vMk/rH2H2SkZTCk+xC6Zndl8bcWA/DSmpeY8uwU/32Ck2lORg4FWQXMuXSO/x+soraC4wqOo/JIJT958ye8s+Ud/32fuegZjis4jk0HN5GRlsGyHctYuGUhRblFTZL37Wffzke7PuKF1S/4l53c62TG9x3Pyt0r/dsc13ccA7sNpFdeL8b3G8+SbUv425q/seHAhmaPNV3SadCGZstzMnJ4aPJDXDPPDQAKcwq5eMTFPP3h003KH5t/uJn+3foDTUeWIkJNfQ0NjQ3+11V9Yz1Z6Vn+tgdqDpCXlYeqkpGWQYM2UFtfS5qkkZeV599WbX2t/8Pa/Kx8GrSBuoY6/xFFozbSqI3uEgheUu6S2aXJ46muqyY3MxeAmvoafznpSMMRquqq6JLZhdzMXP8RYnVdNdkZ2f6BS3Wde10XZBeQlZ5FTX0NlUcq/UePvlGw77FHWha8PNpl4bYpIqRLuv/ILCcjh9r6Whq0gfysfGrra8lIy+Bg7UG653T3Px9pkkZ9Y73/8fj6tFEbqaqroqMczfWH8rLyyMnIadd+453czwDuUNUJ3vwMAFW9O9J92pvcl+9YztV/u5ryinKOKziO5TuXuxgQhhQNoey6Mq568Spu/9ztjP7D6Cb3PX/I+by27jUuO+Ey5qycQ7qkM2vqLK588cpm+5l76VwuGXkJuyt3s37/eo40HOHsJ85u0uaBiQ9QU19DXmYeJ/U6iec/fp50SefJ5U+yv2Y/d3zuDg4fOcxv3v0NEEgatfW1/PmjP5OVnsUVL1wBwGv/9Rrn/+l8/7bPHXQub254s1lcl468lDvPvZPP/O4z/mWjeo/ig+s/ANz1x19d9yrPrXyO5z9+HoCzBpwFwNtXv+1/M7x/wv0sLF/I8h3LWX3Dah5f+jj//fp/s79mP3v+ew9jZo5h88HNTBo6ibLtZQjCm1e+yciSyB+lTPjTBF5b9xolXUrYecvOJv/UwSpqK7jouYvYcXgHy769DFUl7y43ep04dCJPffkpSvJK+Psnf+fC2RcC8MJXX+DLx3+52bbW71/PI0se4T+b/8M5pedw57l3IiK8teEtzn2qacnptONOY/G3FvOr//yK6W+4z/y7ZHZhwpAJrN+/3v9a2nbTNvoU9In4OI1JpGiTe6xq7u8Dw0RkELAVmAZ8LUbbbuLtzW+z+eBmRpaM9I9Q51wyhy0VW7j5tZs5/bHTWb1ntX80FezBiQ8y+g+jmbNyDgAN2hA2sQN8buDnACjJK6EkrwRwpYOy7WX+NsVdivnaSYGHefZAl/wXbV3Eu+XvMqJkBJ8b+Dl+8+5vKO5S7B8NZmdkc83oa9hdudt/3y8O+SIXfuZCumV349KRl9K3a19Oe/Q0oOkpeUW5RQzrMYyK6RV0/aWrj1447EL/dgqyC7hk5CX8e+O//e175fVi1Z5V/iOCX573S24cfyMfzfuIitoKGrWRb770TcAd/vbo0oP7JtzHxXMu5kuf+RIPTHyAguwCeuf3bvG5GVzo6o4n9TopYmIHVzr55zf+SX1jvb++ve4H68jNzKW4S7G/na8OHzrdZJ/dB3PPF+9pttz3OUkw3xvTbWfdxi2fvYU0SfPHeencS/3J3Vd3NiaZxSS5q2q9iNwAvAqkA7NUNXKh+Ch897Tv8vWTvk733O70vbcv2w5t44SeJ3D+kPN55qNn/Ml30dZFTe53xclXMLx4OOcNPo/5n8xvcR/pkk6PLj2aLe/frX+T5F6YUxj2/iOKR7jkXjyCXvm92HnLziaHjD6+Nw1f0nzp8kC5orbe1QpvOeMW3i1/l00HN1FaWMptZ94GNE1evjeVcNvumdeTotwi1u9fz5dmfwnA/+Fq1+yuHDpyqMkZIL6660UjLmLFd1ZwfPHxTT5EbklpYSkA/bv2j6q9L7ED/je+YH279g1MF/Rttr4loSUMgEGFg/zToY+pV14v/21w+cSYZBWrkTuq+jLwcqy2F0mapNE9tzsA/77q3/zxgz9yfPHxpEkaC69dyKrdq3jo/YeYuXSm/z79u/bnqa+4mvv0M6fTK68XuRm5/O7934XdR0leSdizbvoVNB09dsvu1qwNuDLI/E/n85kernTSM69nxMez4cYNYc/Yyc7IpurHVeRk5PDJ3k9o1EZGlIwIu43x/cY3W+bbZ0mXEopyi6ipr2HhloUA/jMIfFc9/NfGf/nv9/8G/D//dOgZNq3xJcy8zNgkxx65PchOz6ZBG1rsw3DCJfdwb9g+vuQe/IZiTDKLWXJPhKFFQ7nzvDv981npWZzS+xTOG3xek+QeXCI4c8CZnDngTLZWbGXxtsUs3rq42XZ9/+ihQksDkUbuV426iitOuaLJyDQS32g3HN+HZcOLh4dd/8PTf8h7W98LW4Io6dJ05B5un77yw/r968nJyOGD6z+I+Nij8dUTvspD7z/EjeNvbPc2gokIfbv2pa6hLuqjB5/g5D7jrBlU11Vz9airI7bvle8ed6zemIxJtKRO7pEEn7s9vt947j3/3mZt+nbty6JvLmL2R7Opqa/h4SUP+0+p9P2jhxrWY1iT+UjJXUTIkI7v2vsm3hdxnW+k2zOvJ91zuvuXb7xxo/9Nx/emsH7/eoq7FB/1OcH9u/Vn/Y3rj2oboYYWDW32RZ5oBCf34wqO44ZxN7TQGn+tP9yI35hklJLJPfhDuXeueafFLzZdftLlAEweNpl/rP0H1867NuLoderwqTz9laf9Z7iEfhGmM/HV3H1lGZ+BhQP9076R+4YDG+iRG7lkkUizpswKex5za3Izcv3T0STsdHFHBm0t/xjTWaVkcgd4aPJDLCxfGPU3Vnvl9+LKUVfyzpZ3OH/I+WHbpKelc96g8/zznfkQvm9BXwqyChhRMqJZWcanICswcv986efjGV7U2lsDT09LJzs9m9qG2qiS+6Rhk7hp/E1MP8sui2RSQ8om9++c9h2+c9p32ny/mV+a2eL64NPkWjrdL9EKsgvYetNW8rPy+XDnh0DTL5BA4LH4LgeQarpkdok6uWelZ/HbCb+NQ1TGxIdd8reNkqkmW5BdgIj4R+6h34gL/iA2VZM7NC3RGHOssOTeRp15tB6JL7mHfsMz+CgklZN7Mr0hGxMrKVuWMQF5WXms/t7qJh+mQqDmDnTaD1SPhiV3cyyz5N5Obf3GZKKFO1feRu7GpC5L7u1w4LYDUX1BqbPLzsj2T5/e7/QERtIxLLmbY1nyZ6gE6Mznt7fViu+soEeXHq1eFCwZWXI3xzJL7se4tl4/JplYcjfHMjtbxqQsX1Jv748iGJPMLLmblNUlswtdMrsk5emrxhwtK8uYlHXt6Gs5udfJiQ7DmISw5G5S1ug+oxndZ3TrDY1JQVaWMcaYFBSTH8hu145FdgOb2nn3YmBPDMOJFYurbSyutrG42iZV4xqoqiWtNUpYcj8aIrIkml//jjeLq20srraxuNrmWI/LyjLGGJOCLLkbY0wKStbk3vIvaiSOxdU2FlfbWFxtc0zHlZQ1d2OMMS1L1pG7McaYFiRdcheRiSKyRkTWikhCf81YRDaKyEciskxElnjLikTkdRH51LvtHoc4ZonILhFZEbQsbBziPOj134ciMibOcd0hIlu9PlsmIpOD1s3w4lojIhM6KKb+IvKWiKwSkZUicqO3PKH91UJcie6vHBFZLCLLvbh+7i0fJCKLvP56TkSyvOXZ3vxab31pnON6QkQ2BPXXKG953F733v7SReQDEZnvzce/v1Q1af6AdGAdMBjIApYDIxMYz0agOGTZPcB0b3o68Ks4xHE2MAZY0VocwGTgFUCA8cCiOMd1B3BLmLYjveczGxjkPc/pHRBTH2CMN10AfOLtO6H91UJcie4vAfK96UxgkdcPc4Bp3vJHgO94098FHvGmpwHPdVB/RYrrCeCSMO3j9rr39ncT8Aww35uPe38l28h9HLBWVder6hHgWWBqgmMKNRV40pt+EvhyC21jQlUXAPuijGMq8JQ67wGFItInjnFFMhV4VlVrVXUDsBb3fMc6pu2qutSbPgSsAvqS4P5qIa5I4tVfqqqHvdlM70+Bc4HnveWh/eXrx+eB80Rif+W2FuKKJG6vexHpB1wAPObNCwnor2RL7n2BLUHz5bT8D9DRFHhNRMpE5DpvWS9V3Q7uHxbomaDYIsXRGfrwBu/QeFZQ2SrucXmHwKNxo75O018hcUGC+8srMSwDdgGv444SDqhqfZh9++Py1h8EOuQHekPjUlVff93p9dd9IuL7ubF4Po/3A7cCjd58DxLQX8mW3MO9oyXydJ8zVXUMMAn4noicncBYopXoPnwYGAKMArYDv/WWxzUuEckH/gL8UFUrWmoaZlk840p4f6lqg6qOAvrhjg5GtLDvhMUlIicCM4DjgdOAIuC2eMYlIhcCu1S1LHhxC/vusLiSLbmXA/2D5vsB2xIUC6q6zbvdBbyAe+Hv9B3uebe7EhRepDgS2oequtP7p2wEHiVQSohbXCKSiUugf1bVv3qLE95f4eLqDP3lo6oHgH/hataFIuK7qmzwvv1xeeu7EX1p7mjjmuiVt1RVa4E/Ev/+OhOYIiIbcWXjc3Ej+bj3V7Il9/eBYd4nz1m4DyDmJSIQEckTkQLfNHA+sMKL50qv2ZXA3xIRXwtxzAO+4Z09MB446CtHxENInfMruD7zxTXNO3tgEDAMWNwB+xfgcWCVqt4btCqh/RUprk7QXyUiUuhN5wJfwH0e8BZwidcstL98/XgJ8KZ6nxbGIa7VQW/QgqtrB/dXhz+PqjpDVfupaikuP72pql8nEf0Vq09m4/WH+9T7E1zd7ycJjGMw7myF5cBKXyy4etkbwKfebVEcYpmNO2Svw40Ero0UB+4w8Pde/30EjI1zXE97+/3Qe2H3CWr/Ey+uNcCkDorpLNxh74fAMu9vcqL7q4W4Et1fJwMfePtfAdwe9PpfjPsgdy6Q7S3P8ebXeusHxzmuN73+WgH8icAZNXF73QfFeA6Bs2Xi3l/2DVVjjElByVaWMcYYEwVL7sYYk4IsuRtjTAqy5G6MMSnIkrsxxqQgS+7GGJOCLLkbY0wKsuRujDEp6P8D7ytMXkrbRkQAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "IPTFOJh3DTgq",
        "colab_type": "code",
        "outputId": "708e0a90-fc2e-4afb-bf8e-832ce60b0e33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "cell_type": "code",
      "source": [
        "now = datetime.datetime.now()\n",
        "\n",
        "# modelSaved = '{}-{}_{}_{}.h5'.format(folderNormal, folderFault, pretrainedModel, now.strftime('%m-%d-%H:%M:%S'))\n",
        "\n",
        "modelSaved = '{}-{}_{}_{}.h5'.format(folderNormal, folderFault, pretrainedModel, now.strftime('%m-%d-%H-%M-%S'))\n",
        "meanSaved = 'mean_{}.npy'.format(now.strftime('%m-%d-%H-%M-%S'))\n",
        "stdSaved = 'std_{}.npy'.format(now.strftime('%m-%d-%H-%M-%S'))\n",
        "\n",
        "inputStr = input('''Save Model as '{}'? (y/n)\\n'''.format(modelSaved))\n",
        "\n",
        "if (inputStr == 'y' or inputStr == 'Y'):  \n",
        "    model.save(modelPath + '/{}'.format(modelSaved))\n",
        "    np.save(modelPath + '/{}'.format(meanSaved), trainMean)\n",
        "    np.save(modelPath + '/{}'.format(stdSaved), trainStd)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Save Model as '['P1N1', 'P1N2', 'P2N1', 'P2N2']-['P1N5', 'P2N5', 'P3N5', 'P4N5', 'P5N1', 'P5N2', 'P5N3', 'P5N4', 'P5N5']_InceptionV3_11-19-15-27-34.h5'? (y/n)\n",
            "y\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}