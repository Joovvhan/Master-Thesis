{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning Clean Up.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joovvhan/Master-Thesis/blob/master/log/(PN)N1-N5_Inception.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "c3821KWLNey6",
        "colab_type": "code",
        "outputId": "a0f41777-7e56-49e5-9719-28b430b469ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Import necessary modules\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy.io.wavfile as wf\n",
        "import time\n",
        "import glob\n",
        "import datetime\n",
        "\n",
        "from tqdm import trange\n",
        "\n",
        "# Import Keras modules\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.layers import Input, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
        "from keras.models import Sequential\n",
        "from keras import backend as K\n",
        "from keras.models import load_model\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "nxSASpgF7unA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Mount google drive\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "# os.listdir('gdrive/My Drive/Colab')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rw9NU8Xjwcz2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set data directories\n",
        "\n",
        "dataPath = '''D:\\\\0_Joowhan's Paper\\\\Synthesized\\\\Total\\\\Impulse'''\n",
        "modelPath = '''D:\\\\0_Joowhan's Paper\\\\Synthesized\\\\Total\\\\Model'''\n",
        "\n",
        "\n",
        "# Changed variable names to normal and fault\n",
        "# Changed variable names from folder to path\n",
        "# Need to consider multiple folders\n",
        "# Need to add files to be tested\n",
        "\n",
        "folderNormal = ['P1N1', 'P2N1', 'P3N1', 'P4N1', 'P5N1']\n",
        "# folderNormal = list()\n",
        "\n",
        "# for x in range(1, 6):\n",
        "#     for y in range(1, 6):\n",
        "#         for z in range(1, 6):\n",
        "#             if (x <= 2 and y <= 2 and z <= 2):\n",
        "#                 folderNormal.append('A{}F{}P{}'.format(x, y, z))\n",
        "\n",
        "# folderFault = list()\n",
        "\n",
        "folderFault = ['P1N5', 'P2N5', 'P3N5', 'P4N5', 'P5N5']\n",
        "\n",
        "# for x in range(1, 6):\n",
        "#     for y in range(1, 6):\n",
        "#         for z in range(1, 6):\n",
        "#             if (x == 5 or y == 5 or z == 5):\n",
        "#                 folderFault.append('A{}F{}P{}'.format(x, y, z))\n",
        "\n",
        "\n",
        "pathNormal = list()\n",
        "pathFault = list()\n",
        "\n",
        "for i in range(len(folderNormal)):\n",
        "    pathNormal.append(dataPath + '/' + folderNormal[i])\n",
        "    \n",
        "for i in range(len(folderFault)):\n",
        "    pathFault.append(dataPath + '/' + folderFault[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xgGP7PZO-rTA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Specgram settings\n",
        "\n",
        "nsc = 1470\n",
        "nov = nsc/2\n",
        "nff = nsc \n",
        "imgSize = 224\n",
        "\n",
        "# pretrainedModel = 'VGG19'\n",
        "# pretrainedModel = 'Xception'\n",
        "# pretrainedModel = 'ResNet50'\n",
        "\n",
        "# pretrainedModel = 'DenseNet169'\n",
        "pretrainedModel = 'InceptionV3'\n",
        "\n",
        "\n",
        "lastActivation = 'softmax'\n",
        "sizeBatch = 4\n",
        "numEpochs = 12\n",
        "verb = 1\n",
        "\n",
        "\n",
        "# Learning parameters\n",
        "\n",
        "trainingRatio = 0.8\n",
        "\n",
        "totalDataNum = 1000\n",
        "repeat = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5AskF2qFT2xr",
        "colab_type": "code",
        "outputId": "309152ef-3218-4b24-bc34-002ff2b567ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "cell_type": "code",
      "source": [
        "startNum = 0\n",
        "\n",
        "pickNum = int(np.ceil(totalDataNum / len(pathNormal)))\n",
        "\n",
        "for i in range(startNum, len(pathNormal)):\n",
        "\n",
        "    npyTestPath = glob.glob(pathNormal[i] + '/' + '*Image_With_Label.npy')\n",
        "    data = np.load(npyTestPath[0])\n",
        "    \n",
        "    pickIdx = np.random.choice(1000, pickNum, replace=False)\n",
        "    pickIdx.sort()\n",
        "    \n",
        "#     imgs = np.moveaxis(np.dstack(data[:, 0]), 2, 0)\n",
        "#     label = data[:, 1:5]\n",
        "\n",
        "    imgs = np.moveaxis(np.dstack(data[pickIdx, 0]), 2, 0)\n",
        "    label = data[pickIdx, 1:5]\n",
        "    \n",
        "    if i == startNum:\n",
        "        labelListNormal = label\n",
        "        imgsNormal = imgs\n",
        "    else:\n",
        "        labelListNormal = np.vstack([labelListNormal, label])\n",
        "        imgsNormal = np.vstack([imgsNormal, imgs])\n",
        "\n",
        "    print('Normal Image Shape From {}: {}:'.format(pathNormal[i], totalDataNum))    \n",
        "    print('Selected {}/{}:'.format(pickNum * (i + 1), len(data)))    \n",
        "    \n",
        "    \n",
        "print('Normal Image Shape: {}'.format(imgsNormal.shape))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P1N1: 1000:\n",
            "Selected 200/1000:\n",
            "Normal Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P2N1: 1000:\n",
            "Selected 400/1000:\n",
            "Normal Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P3N1: 1000:\n",
            "Selected 600/1000:\n",
            "Normal Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P4N1: 1000:\n",
            "Selected 800/1000:\n",
            "Normal Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P5N1: 1000:\n",
            "Selected 1000/1000:\n",
            "Normal Image Shape: (1000, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P_MZtpk3Br_i",
        "colab_type": "code",
        "outputId": "6496c764-5bf8-44a9-8cfd-ce6d272422f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "cell_type": "code",
      "source": [
        "startNum = 0\n",
        "\n",
        "pickNum = int(np.ceil(totalDataNum / len(pathFault)))\n",
        "\n",
        "for i in range(startNum, len(pathFault)):\n",
        "\n",
        "    npyTestPath = glob.glob(pathFault[i] + '/' + '*Image_With_Label.npy')\n",
        "    data = np.load(npyTestPath[0])\n",
        "    \n",
        "    pickIdx = np.random.choice(1000, pickNum, replace=False)\n",
        "    pickIdx.sort()\n",
        "    \n",
        "#     imgs = np.moveaxis(np.dstack(data[:, 0]), 2, 0)\n",
        "#     label = data[:, 1:5]\n",
        "    \n",
        "    imgs = np.moveaxis(np.dstack(data[pickIdx, 0]), 2, 0)\n",
        "    label = data[pickIdx, 1:5]\n",
        "    \n",
        "    if i == startNum:\n",
        "        labelListFault = label\n",
        "        imgsFault = imgs\n",
        "    else:\n",
        "        labelListFault = np.vstack([labelListFault, label])\n",
        "        imgsFault = np.vstack([imgsFault, imgs])\n",
        "\n",
        "    print('Fault Image Shape From {}: {}:'.format(pathFault[i], totalDataNum))    \n",
        "    print('Selected {}/{}:'.format(pickNum * (i + 1), len(data)))     \n",
        "    \n",
        "print('Fault Image Shape: {}'.format(imgsFault.shape))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P1N5: 1000:\n",
            "Selected 200/1000:\n",
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P2N5: 1000:\n",
            "Selected 400/1000:\n",
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P3N5: 1000:\n",
            "Selected 600/1000:\n",
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P4N5: 1000:\n",
            "Selected 800/1000:\n",
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P5N5: 1000:\n",
            "Selected 1000/1000:\n",
            "Fault Image Shape: (1000, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e91QsAurSkIP",
        "colab_type": "code",
        "outputId": "c40f0dd8-82fe-4668-cb5e-c9bb523d5203",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "cell_type": "code",
      "source": [
        "# Change name from imgsF1 or imgsF5 to imgsNormal and imgsFault\n",
        "\n",
        "dataNumNormal = len(imgsNormal)\n",
        "dataNumFault = len(imgsFault)\n",
        "dataNumNormalTrain = int(dataNumNormal * trainingRatio)\n",
        "dataNumFaultTrain = int(dataNumFault * trainingRatio)\n",
        "dataNumNormalTest = dataNumNormal - dataNumNormalTrain\n",
        "dataNumFaultTest = dataNumFault - dataNumFaultTrain\n",
        "\n",
        "print('Normal Train:Test = {:d}:{:d}'.format(dataNumNormalTrain, dataNumNormalTest))\n",
        "print('Fault  Train:Test = {:d}:{:d}\\n'.format(dataNumFaultTrain, dataNumFaultTest))\n",
        "\n",
        "trainIdxNormal = np.random.choice(dataNumNormal - 1, dataNumNormalTrain, replace=False)\n",
        "testIdxNormal = list(set(range(0, dataNumNormal)) - set(trainIdxNormal))\n",
        "\n",
        "trainImgsNormal = imgsNormal[trainIdxNormal, :, :]\n",
        "testImgsNormal = imgsNormal[testIdxNormal, :, :]\n",
        "\n",
        "print('Normal Training Image Shape {}'.format(trainImgsNormal.shape))\n",
        "print('Normal Test Image Shape {}\\n'.format(testImgsNormal.shape))\n",
        "\n",
        "trainIdxFault  = np.random.choice(dataNumFault - 1, dataNumFaultTrain, replace=False)\n",
        "testIdxFault = list(set(range(0, dataNumFault)) - set(trainIdxFault))\n",
        "\n",
        "trainImgsFault = imgsFault[trainIdxFault, :, :]\n",
        "testImgsFault = imgsFault[testIdxFault, :, :]\n",
        "\n",
        "print('Fault Training Image Shape {}'.format(trainImgsFault.shape))\n",
        "print('Fault Test Image Shape {}\\n'.format(testImgsFault.shape))\n",
        "\n",
        "trainImgs = np.vstack([trainImgsNormal, trainImgsFault])\n",
        "testImgs = np.vstack([testImgsNormal, testImgsFault])\n",
        "\n",
        "print('Training Image Shape {}'.format(trainImgs.shape))\n",
        "print('Test Image Shape {}'.format(testImgs.shape))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal Train:Test = 800:200\n",
            "Fault  Train:Test = 800:200\n",
            "\n",
            "Normal Training Image Shape (800, 224, 224)\n",
            "Normal Test Image Shape (200, 224, 224)\n",
            "\n",
            "Fault Training Image Shape (800, 224, 224)\n",
            "Fault Test Image Shape (200, 224, 224)\n",
            "\n",
            "Training Image Shape (1600, 224, 224)\n",
            "Test Image Shape (400, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MoE7f_hzs0av",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "feQ_AHAcUgHD",
        "colab_type": "code",
        "outputId": "454b0435-5624-43f9-bb3f-b8e16e901624",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "trainMean = np.mean(trainImgs)\n",
        "trainStd = np.std(trainImgs)\n",
        "\n",
        "print('Mean of Training Image: {}'.format(trainMean))\n",
        "print('Standard Deviation of Training Image: {}'.format(trainStd))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean of Training Image: -79.05224856034862\n",
            "Standard Deviation of Training Image: 8.232111137170278\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wUi9IuXNUpir",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Should Change Norm to Normalized\n",
        "\n",
        "trainImgsNorm = (trainImgs - trainMean) / trainStd\n",
        "testImgsNorm = (testImgs - trainMean) / trainStd\n",
        "\n",
        "trainImgsNorm = trainImgsNorm.reshape(list(trainImgsNorm.shape) + [1])\n",
        "testImgsNorm = testImgsNorm.reshape(list(testImgsNorm.shape) + [1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aklxiPz1Ve4n",
        "colab_type": "code",
        "outputId": "b57845fa-f5a9-4873-a41b-7c0fa8c22fd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = np.stack([trainImgsNorm[:, :, :, 0], trainImgsNorm[:, :, :, 0], trainImgsNorm[:, :, :, 0]], axis = -1)\n",
        "X_test = np.stack([testImgsNorm[:, :, :, 0], testImgsNorm[:, :, :, 0], testImgsNorm[:, :, :, 0]], axis = -1)\n",
        "\n",
        "print('X_train Shape: {}'.format(X_train.shape))\n",
        "print('X_test  Shape: {}'.format(X_test.shape))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train Shape: (1600, 224, 224, 3)\n",
            "X_test  Shape: (400, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sRgIPzT7K_YP",
        "colab_type": "code",
        "outputId": "e43a5c7d-4eef-49e3-a8a5-fec68d1164d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "trainLabelNormal = np.stack((np.ones(dataNumNormalTrain), np.zeros(dataNumNormalTrain)), axis = -1)\n",
        "testLabelNormal = np.stack((np.ones(dataNumNormalTest), np.zeros(dataNumNormalTest)), axis = -1)\n",
        "\n",
        "trainLabelFault = np.stack((np.zeros(dataNumFaultTrain), np.ones(dataNumFaultTrain)), axis = -1)\n",
        "testLabelFault = np.stack((np.zeros(dataNumFaultTest), np.ones(dataNumFaultTest)), axis = -1)\n",
        "\n",
        "Y_train = np.vstack((trainLabelNormal, trainLabelFault))\n",
        "Y_test = np.vstack((testLabelNormal, testLabelFault))\n",
        "\n",
        "print('Y_train Normal:Fault = {:d}:{:d}'.format(len(trainLabelNormal), len(trainLabelFault)))\n",
        "print('Y_test  Normal:Fault = {:d}:{:d}'.format(len(testLabelNormal), len(testLabelFault)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Y_train Normal:Fault = 800:800\n",
            "Y_test  Normal:Fault = 200:200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kczwZk7Tbp5C",
        "colab_type": "code",
        "outputId": "8bade455-ef20-44ce-b04b-9e5c1cd459e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2647
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG19\n",
        "from keras.applications import VGG16\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications.densenet import DenseNet169\n",
        "from keras.applications.densenet import DenseNet201\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# pretrainedModel = 'ResNet50'\n",
        "# lastActivation = 'softmax'\n",
        "# lossFunction = 'binary_crossentropy'\n",
        "# sizeBatch = 2\n",
        "# numEpochs = 2\n",
        "# verb = 1\n",
        "\n",
        "for rp in range(repeat):\n",
        "\n",
        "    # Refresh all background variables\n",
        "    K.clear_session()\n",
        "\n",
        "    input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "    # Building sequential model with name 'model'\n",
        "    model = Sequential()\n",
        "\n",
        "    # Model selection\n",
        "\n",
        "    if (pretrainedModel == 'VGG16'):\n",
        "\n",
        "        modelWoTop = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'VGG19'):\n",
        "\n",
        "        modelWoTop = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif pretrainedModel == 'ResNet50':\n",
        "\n",
        "        modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'InceptionV3'):\n",
        "        modelWoTop = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'Xception'):\n",
        "        modelWoTop = Xception(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet169'):\n",
        "\n",
        "        modelWoTop = DenseNet169(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet201'):\n",
        "        modelWoTop = DenseNet201(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    else:\n",
        "        print('Invalid Pretrained Model Selection')\n",
        "\n",
        "\n",
        "\n",
        "    # Model compiling\n",
        "\n",
        "    print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "    print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "    model.fit(X_train, Y_train,\n",
        "              batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "              validation_data=(X_test, Y_test))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compiling Pretrained inception_v3 Model\n",
            "Training Pretrained inception_v3 Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/12\n",
            "1600/1600 [==============================] - 73s 45ms/step - loss: 0.3084 - acc: 0.9150 - val_loss: 0.6644 - val_acc: 0.4950\n",
            "Epoch 2/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.1310 - acc: 0.9581 - val_loss: 0.0927 - val_acc: 0.9825\n",
            "Epoch 3/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.1228 - acc: 0.9600 - val_loss: 0.2571 - val_acc: 0.9075\n",
            "Epoch 4/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0826 - acc: 0.9712 - val_loss: 0.6344 - val_acc: 0.9225\n",
            "Epoch 5/12\n",
            "1600/1600 [==============================] - 55s 35ms/step - loss: 0.0614 - acc: 0.9819 - val_loss: 0.0623 - val_acc: 0.9800\n",
            "Epoch 6/12\n",
            "1600/1600 [==============================] - 55s 35ms/step - loss: 0.0512 - acc: 0.9819 - val_loss: 0.1961 - val_acc: 0.9150\n",
            "Epoch 7/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.1140 - acc: 0.9606 - val_loss: 0.1036 - val_acc: 0.9800\n",
            "Epoch 8/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0686 - acc: 0.9769 - val_loss: 0.0892 - val_acc: 0.9850\n",
            "Epoch 9/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0672 - acc: 0.9812 - val_loss: 0.7131 - val_acc: 0.6250\n",
            "Epoch 10/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0629 - acc: 0.9850 - val_loss: 0.0657 - val_acc: 0.9850\n",
            "Epoch 11/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0442 - acc: 0.9869 - val_loss: 0.0531 - val_acc: 0.9850\n",
            "Epoch 12/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0385 - acc: 0.9881 - val_loss: 0.0392 - val_acc: 0.9850\n",
            "Compiling Pretrained inception_v3 Model\n",
            "Training Pretrained inception_v3 Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.2988 - acc: 0.8981 - val_loss: 0.1485 - val_acc: 0.9550\n",
            "Epoch 2/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.1543 - acc: 0.9488 - val_loss: 0.0798 - val_acc: 0.9750\n",
            "Epoch 3/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.1180 - acc: 0.9619 - val_loss: 0.9772 - val_acc: 0.8625\n",
            "Epoch 4/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0677 - acc: 0.9750 - val_loss: 1.4106 - val_acc: 0.7525\n",
            "Epoch 5/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0823 - acc: 0.9731 - val_loss: 1.2160 - val_acc: 0.5850\n",
            "Epoch 6/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0592 - acc: 0.9794 - val_loss: 0.3681 - val_acc: 0.7875\n",
            "Epoch 7/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0797 - acc: 0.9694 - val_loss: 0.0836 - val_acc: 0.9775\n",
            "Epoch 8/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0560 - acc: 0.9781 - val_loss: 0.0343 - val_acc: 0.9850\n",
            "Epoch 9/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0566 - acc: 0.9831 - val_loss: 0.0397 - val_acc: 0.9775\n",
            "Epoch 10/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0456 - acc: 0.9819 - val_loss: 0.0809 - val_acc: 0.9825\n",
            "Epoch 11/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0550 - acc: 0.9812 - val_loss: 0.0930 - val_acc: 0.9800\n",
            "Epoch 12/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0699 - acc: 0.9781 - val_loss: 2.2890 - val_acc: 0.7750\n",
            "Compiling Pretrained inception_v3 Model\n",
            "Training Pretrained inception_v3 Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/12\n",
            "1600/1600 [==============================] - 70s 43ms/step - loss: 0.3612 - acc: 0.8894 - val_loss: 0.1534 - val_acc: 0.9150\n",
            "Epoch 2/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.1992 - acc: 0.9294 - val_loss: 0.1706 - val_acc: 0.9600\n",
            "Epoch 3/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0849 - acc: 0.9738 - val_loss: 0.0777 - val_acc: 0.9800\n",
            "Epoch 4/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0640 - acc: 0.9806 - val_loss: 0.0478 - val_acc: 0.9850\n",
            "Epoch 5/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0469 - acc: 0.9844 - val_loss: 0.1167 - val_acc: 0.9800\n",
            "Epoch 6/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0893 - acc: 0.9738 - val_loss: 0.6164 - val_acc: 0.7475\n",
            "Epoch 7/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.1391 - acc: 0.9563 - val_loss: 0.9189 - val_acc: 0.7675\n",
            "Epoch 8/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0680 - acc: 0.9788 - val_loss: 0.0491 - val_acc: 0.9825\n",
            "Epoch 9/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0668 - acc: 0.9781 - val_loss: 0.1283 - val_acc: 0.9750\n",
            "Epoch 10/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0790 - acc: 0.9738 - val_loss: 2.3993 - val_acc: 0.6850\n",
            "Epoch 11/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0489 - acc: 0.9806 - val_loss: 0.0426 - val_acc: 0.9800\n",
            "Epoch 12/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0550 - acc: 0.9819 - val_loss: 0.2008 - val_acc: 0.9425\n",
            "Compiling Pretrained inception_v3 Model\n",
            "Training Pretrained inception_v3 Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/12\n",
            "1600/1600 [==============================] - 69s 43ms/step - loss: 0.2885 - acc: 0.9000 - val_loss: 0.7270 - val_acc: 0.6275\n",
            "Epoch 2/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.1248 - acc: 0.9556 - val_loss: 0.1576 - val_acc: 0.9600\n",
            "Epoch 3/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.2022 - acc: 0.9344 - val_loss: 0.2705 - val_acc: 0.9700\n",
            "Epoch 4/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0838 - acc: 0.9762 - val_loss: 0.4602 - val_acc: 0.7875\n",
            "Epoch 5/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0807 - acc: 0.9681 - val_loss: 0.2240 - val_acc: 0.9775\n",
            "Epoch 6/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0773 - acc: 0.9744 - val_loss: 0.9835 - val_acc: 0.5325\n",
            "Epoch 7/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.1021 - acc: 0.9700 - val_loss: 0.0960 - val_acc: 0.9675\n",
            "Epoch 8/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.1062 - acc: 0.9663 - val_loss: 0.1031 - val_acc: 0.9600\n",
            "Epoch 9/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0536 - acc: 0.9769 - val_loss: 0.0424 - val_acc: 0.9850\n",
            "Epoch 10/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0471 - acc: 0.9850 - val_loss: 0.1165 - val_acc: 0.9700\n",
            "Epoch 11/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0546 - acc: 0.9819 - val_loss: 0.0548 - val_acc: 0.9800\n",
            "Epoch 12/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0562 - acc: 0.9781 - val_loss: 6.6042 - val_acc: 0.3350\n",
            "Compiling Pretrained inception_v3 Model\n",
            "Training Pretrained inception_v3 Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.3031 - acc: 0.8962 - val_loss: 0.1859 - val_acc: 0.9200\n",
            "Epoch 2/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.1543 - acc: 0.9431 - val_loss: 4.1987 - val_acc: 0.7200\n",
            "Epoch 3/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0720 - acc: 0.9794 - val_loss: 0.2337 - val_acc: 0.9825\n",
            "Epoch 4/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0864 - acc: 0.9762 - val_loss: 2.9373 - val_acc: 0.7325\n",
            "Epoch 5/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0956 - acc: 0.9656 - val_loss: 0.0498 - val_acc: 0.9825\n",
            "Epoch 6/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0917 - acc: 0.9681 - val_loss: 0.2139 - val_acc: 0.9200\n",
            "Epoch 7/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0725 - acc: 0.9819 - val_loss: 0.1189 - val_acc: 0.9575\n",
            "Epoch 8/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0542 - acc: 0.9844 - val_loss: 0.0506 - val_acc: 0.9850\n",
            "Epoch 9/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0486 - acc: 0.9806 - val_loss: 0.3461 - val_acc: 0.9775\n",
            "Epoch 10/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0673 - acc: 0.9794 - val_loss: 0.0500 - val_acc: 0.9825\n",
            "Epoch 11/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0520 - acc: 0.9819 - val_loss: 0.0749 - val_acc: 0.9575\n",
            "Epoch 12/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0679 - acc: 0.9769 - val_loss: 0.0516 - val_acc: 0.9825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jKgFIa4gkgkk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "# print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "# model.fit(X_train, Y_train,\n",
        "#           batch_size=sizeBatch, epochs=1, verbose=1,\n",
        "#           validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "agqqH8sf3CiV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# K.clear_session()\n",
        "\n",
        "# input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "# # Building sequential model with name 'model'\n",
        "# model = Sequential()\n",
        "\n",
        "# modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "# model.add(modelWoTop)\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "# # Model compiling\n",
        "\n",
        "# print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "# model.compile(loss='binary_crossentropy',\n",
        "#               optimizer='adam',\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "# numEpochs = 1\n",
        "\n",
        "# print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "# print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "# model.fit(X_train, Y_train,\n",
        "#           batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "#           validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qexmaPZVz04q",
        "colab_type": "code",
        "outputId": "ec99ad75-3e7d-4199-c816-5a799a46838e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.plot(Y_test[:, 1], 'r')\n",
        "\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.plot(Y_pred[:, 1], 'b')\n",
        "\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.plot(Y_test[:, 1] - Y_pred[:, 1], 'g')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3XmcVNWZ//HPQy8sijQ0qMjWjSFRNMYAGsmiiPuC4BbJmBijDskomsTJZCDOJI6/ZHyZSaJJNDpmxnFFNBgdYnAIRuMyI2ojiCBRNpEWEBBBkKXp7uf3x73Vfbu6uuo2dq1+369Xve52+t6nTlU/dercW+eauyMiIqWlW74DEBGRrqfkLiJSgpTcRURKkJK7iEgJUnIXESlBSu4iIiVIyV1EpAQpuYuIlCAldxGRElSeqYCZ3QWcDWx09yNTbDfgl8CZwE7gUnd/JdN++/fv7zU1NZ0OWETk42zBggWb3X1ApnIZkztwN3ArcG8H288ARoSPzwG3h9O0ampqqKuri3F4ERFJMLM1ccplTO7u/qyZ1aQpMhG414NBauabWZWZDXT39bEiFSk0TzwBCxbkOwopZWecAaNHZ/UQcVrumQwC1kaW68N17ZK7mU0BpgAMHTq0Cw4tkgVTpkB9fb6jkFLWv39RJHdLsS7lUJPufidwJ8CYMWM0HKUUpj17ggR/2235jkRKVbfsX8vSFcm9HhgSWR4MrOuC/YrkR1MTVFRAeVf8e4jkR1d8fMwGLrHAccA29bdLUWtsVGKXohfnUsgHgXFAfzOrB34EVAC4+x3AHILLIFcQXAr5jWwFK5ITTU1QVpbvKEQ+kjhXy3wlw3YHruqyiETyTcldSoB+oSqSTN0yUgKU3EWSqeUuJUDJXSSquRncldyl6Cm5i0Q1NQVTdctIkVNyF4lKJHe13KXIKbmLRDU2BlMldylySu4iUeqWkRKh5C4SpW4ZKRFK7iJRiW4ZtdylyCm5i0Sp5S4lQsldJErJXUqEkrtIlLplpEQouYtEqeUuJULJXSRK17lLiVByF4nSde5SIpTcRaLULSMlQsldJErdMlIilNxFotQtIyVCyV0kSt0yUiKU3EWidJ27lIhYyd3MTjezN8xshZlNS7H9UjPbZGaLwscVXR+qSA6o5S4lImPzxMzKgNuAU4B64GUzm+3urycVfcjdp2YhRpHcUXKXEhGn5X4ssMLdV7l7AzATmJjdsETyRN0yUiLiJPdBwNrIcn24Ltn5ZrbYzGaZ2ZBUOzKzKWZWZ2Z1mzZt2odwRbJMLXcpEXGSu6VY50nLfwBq3P0o4EngnlQ7cvc73X2Mu48ZMGBA5yIVyQVd5y4lIk5yrweiLfHBwLpoAXd/z933hIu/BUZ3TXgiOabr3KVExEnuLwMjzKzWzCqBycDsaAEzGxhZPAdY1nUhiuSQumWkRGRsnrh7o5lNBeYCZcBd7r7UzG4A6tx9NnCNmZ0DNAJbgEuzGLNI9qhbRkpErO+e7j4HmJO07oeR+enA9K4NTSQP1C0jJUK/UBWJUreMlAgld5EodctIiVByF4lSt4yUCCV3kSh1y0iJUHIXidLwA1IilNxFotRylxKh5C4SpeQuJULJXSRK3TJSIpTcRaLUcpcSoeQuEqXr3KVEKLmLROk6dykRSu4iUYnk3k3/GlLc9A4WiWpsDBK7pbpHjUjxUHIXiWpqUpeMlAQld5GopiadTJWSoOQuEtXYqJa7lAQld5EotdylRCi5i0QpuUuJUHIXiVK3jJQIJXeRKLXcpUTESu5mdrqZvWFmK8xsWort3c3soXD7i2ZW09WBiuREY6OSu5SEjMndzMqA24AzgJHAV8xsZFKxy4H33f0TwM3ATV0dqEhO6Dp3KRFx3sXHAivcfRWAmc0EJgKvR8pMBK4P52cBt5qZubt3YayBZcvg1Ve7fLciAKxapZa7lIQ4yX0QsDayXA98rqMy7t5oZtuAamBztJCZTQGmAAwdOnTfIn78cfj+9/ftb0Xi+Pzn8x2ByEcWJ7mnGmQjuUUepwzufidwJ8CYMWP2rVV/2WUwYcI+/alILIMH5zsCkY8sTnKvB4ZElgcD6zooU29m5UAfYEuXRJisujp4iIhIh+Ik95eBEWZWC7wDTAb+JqnMbODrwAvABcBTmfrbFyxYsNnM1nQ+ZAD6k9TlUyAKNS4o3NgUV+cors4pxbiGxSmUMbmHfehTgblAGXCXuy81sxuAOnefDfwncJ+ZrSBosU+Osd8BcQJMxczq3H3Mvv59thRqXFC4sSmuzlFcnfNxjivWNV/uPgeYk7Tuh5H53cCFXRuaiIjsK/1CVUSkBBVrcr8z3wF0oFDjgsKNTXF1juLqnI9tXJaN3xmJiEh+FWvLXURE0lByFxEpQUWX3DONUJnjWN4ys9fMbJGZ1YXr+pnZPDNbHk775iCOu8xso5ktiaxLGYcFfhXW32IzG5XjuK43s3fCOltkZmdGtk0P43rDzE7LYlxDzOxpM1tmZkvN7Nvh+rzWWZq48lpnZtbDzF4ys1fDuP4lXF8bjgK7PBwVtjJcn7NRYtPEdreZrY7U2dHh+ly+/8vMbKGZPR4u57a+3L1oHgTX2a8EhgOVwKvAyDzG8xbQP2ndT4Fp4fw04KYcxHE8MApYkikO4EzgCYIhI44DXsxxXNcD30tRdmT4enYHasPXuSxLcQ0ERoXzvYE3w+Pntc7SxJXXOguf9/7hfAXwYlgPDwOTw/V3AH8Xzl8J3BHOTwYeyuJ7rKPY7gYuSFE+l+//a4EZwOPhck7rq9ha7i0jVLp7A5AYobKQTATuCefvASZl+4Du/izth3voKI6JwL0emA9UmdnAHMbVkYnATHff4+6rgRUEr3c24lrv7q+E89uBZQSD3+W1ztLE1ZGc1Fn4vHeEixXhw4HxBKPAQvv6StTjLOAkM0s1/lQ2Y+tITl5LMxsMnAX8R7hs5Li+ii25pxqhMt2bP9sc+JOZLbBgxEuAg9x9PQT/rMCBeYqtozgKoQ6nhl+J74p0W+UlrvAr8GcJWnwFU2dJcUGe6yzsYlgEbATmEXxL2OrujSmO3WaUWCAxSmxWJMfm7ok6+0lYZzebWffk2FLE3ZVuAb4PNIfL1eS4vuLcrKNdv2nS9pz1YRFz9Mkc+oK7jyK4kclVZnZ8HmOJK991eDtwKHA0sB74ebg+53GZ2f7AI8B33P2DdEVTrMtabCniynuduXuTux9NMHDgscDhaY6d0/pKjs3MjgSmA4cBxwD9gH/MVWxmdjaw0d0XRFenOW5WYsp4nXuYsHYQfJU5MsX2M4GrCfqyPgf80t2Tx3tvp3///l5TU7MvMYuIfGwtWLBgs8cYmyvOwGHPZjh729KHBcw3syozG5j4etuRmpoa6urqMh1eREQiLOZoul1xs8iO+rDSJneRQnXrrdC3L7zwAtxyS+stVW+9FR57DPr0gfHjg9utPv10sFxVBa+9BmbtH5B6fdwHwM6dwSMhut/oNN22jsq6B8+lsbH9Pjp7rKam4JGhQ+Ajyc6p2Xj7Tt6eqi7iLE+dCmeeSVZ1RXKP3V9kXXGbPZEsu/rq1vnvfAc+8Ylg/u67YeFCaG6G3/++/d8deSQccECQ2BIPaLu8r4/99oNevVqTcWK/0WmqdXHKQvABVlbWdv9x/z46LSsLHt2ydKlGNj80Mu07eXtHdRlnedeuzsW2L7oiuce5UxPQRbfZE8mhpqbW+cbGoEX/3nvty/XrB/PnB0lYpBB0RXKfTXCZ1kyCE6rbMvW3ixSLaFdFYyP07Nm+zBNPQP/+SuxSWDImdzN7EBgH9DezeuBHBD8UwN3vILiJx5kEP6DYCXwjW8GK5Fq05d7UlDq5jx0b9LuLFJI4V8t8JcN2B67qsohECkhyyz25dW4GvXvnNiaROIrtF6oiOZWp5V5Vlb2ThyIfhd6WImlk6nPvm/UxP0X2jZK7SBqZWu5K7lKolNxFIpqb2y4nt9x79Wq7vaoq+zGJ7Asld5GIaDJPXla3jBQTJXeRiGg3TPJyU1P7lruSuxQqJXeRiOTknqnlXp21UcpFPhold5GI5G6Z5JZ7ZWXrpY9f+lLbcWhEComSu0hEppZ7eXmQ4AEmTIBDDsldbCKdoeQuEpGpz72srDW5J6YihUjJXSSio6tlmpuDYVvLy6GiIlin5C6FTMldJKKjbpnEVC13KRZK7iIRHZ1QTUyjfe5K7lLIlNxFIjrTck90z4gUIiV3kYiOTqhGW+7qc5dioOQuEtHRCdXEVN0yUiyU3EUiMrXcdUJVioWSu0hEpj73aMtdfe5SyJTcRSI6ulomekJVfe5SDJTcRSI6arnrUkgpNrGSu5mdbmZvmNkKM5uWYvulZrbJzBaFjyu6PlSR7NOPmKRUlGcqYGZlwG3AKUA98LKZzXb315OKPuTuU7MQo0jO6EdMUiritNyPBVa4+yp3bwBmAhOzG5ZIfuhHTFIq4iT3QcDayHJ9uC7Z+Wa22MxmmdmQLolOJMfitNx1QlWKQZzkbinWedLyH4Aadz8KeBK4J+WOzKaYWZ2Z1W3atKlzkYrkQGcuhVRyl0IWJ7nXA9GW+GBgXbSAu7/n7nvCxd8Co1PtyN3vdPcx7j5mwIAB+xKvSFZ19CMmnVCVYhMnub8MjDCzWjOrBCYDs6MFzGxgZPEcYFnXhSiSOx0NP6ATqlJsMl4t4+6NZjYVmAuUAXe5+1IzuwGoc/fZwDVmdg7QCGwBLs1izCJZE+eEaqLPXSdUpZBlTO4A7j4HmJO07oeR+enA9K4NTST34owK2b17MK/kLoUsVnIX+bjINCpkWRlccgkMGQLd9PtuKWBK7iIRcVruI0YED5FCpraHSEScPneRYqDkLhKRaVTIcn3XlSKh5C4SEWdUSJFioOQuEhHnhKpIMVByF4mIc0JVpBgouYtE6ISqlAold5GIOKNCihQDJXeRCLXcpVQouYtEZBoVUi13KRZK7iIRmUaFVMtdioWSu0hEnJt1iBQDJXeRCJ1QlVKh5C4SoROqUiqU3EUi9CMmKRVK7iIRGn5ASsXHLrn/6U8wZgzs2ZN6+w9+ALfcktuYpHCkuxTSTDfokOLxsXurPvUULFgAb73VfltjI9x4I3z3u+3/yeXjId2okGq1SzEpyuTe2Bg83OGDDzKXjVqzJph++9tw002wa1frtqVLW+effbZrYv0o9u7NdwRdZ906WLQo31FklqpbpqEhmKq/XYpJrORuZqeb2RtmtsLMpqXY3t3MHgq3v2hmNV0daII7HHMMjBsHM2fCIYfApk3BtrffDrpUTjsN5s8Pul6GDAm+TldUwOWXtyb3uXNh2jQ47zw45xw4/3w4+ujW48ydC83NcO218MIL+x7v3XfDm292vL2+Hv7v/4L5p54KvjVcfDF8+cvQs2d+EuIzz8C776be9sornfvQmTEj+Kb0ve/BKacEr9+MGcHzS+W//zuos6jly2HSJJg1K/5xO8Mdzj0XHnigbcu9V6/gPdWrF/z852q5S5Fx97QPoAxYCQwHKoFXgZFJZa4E7gjnJwMPZdrv6NGjfV/MmuUe/Du6T54cTMvL3X/2M/cLL2zd9s1vur/wQutyt27uvXu7H3xw67rjjmudTzyGDXMfM8Z93Dj3Rx8N1l18cfz4HnvMfd68YH7DhuDvL7mk4/IXXeTeq5f7rl3u557bPp59rKZ99v777mVl7n/7t+23vfGGu5n7L38Zb18fftj6PA49NJiuXOl+8snB/Nq17f/myCPd+/Z1b2pqXffDH7buZ/v2fXte6bz1VrDvU05x//rX3YcOdb/3XveFC92vucb9H/7B/fLL3f/pn7r+2CKdBdR5hvzqwVs6Y3IfC8yNLE8HpieVmQuMDefLgc2Apdvvvib3xx9vnwDB/ZBD3A84wH3SpOCfdORI95tvDra98477ffe1/5v//d+2y8cc4753r/vVVwcJ9zOfCdYPHuze3NxxTHfe6f7EE0EyO+AA9yFD3Bsb3R98sO3fL1rkvmlT6981Nrr36xeUefJJ9+rq1M/tnXfcd+7cp+rqtEceaf2QS37Oifo89dR4+/rTn9o/lxkz3PffP5ifObNt+Y0bW8stWtS6fty41vWPPfaRnl5KDzwQ7Lt376DBMHx41x9DpKvETe5xehEHAWsjy/XA5zoq4+6NZrYNqA6TfJc66yxYvx4GDmy7ft26YHrxxUE3yHXXwe23B90yhxwCn/98+30dd1zb5bFjg37V446DX/8aXn01mJ8/H77xDaisbL+PnTuDr/M9e8L48cE5gA8+gMmTYcWKoEx9PXzlK/C73wXxnHxy6/mCLVuCMtdeC++913bfZ54Jc+bAoEHBsb/8ZejePfjb5uZgCq1XcZgFDwi6Tt59NygzaBCsXg1bt8KnP922XHRqFnShQNB9demlbZ/zX/7SOv3qV4PzFbt2BWUGDAj+/rXXgj7qUaOC+WQ33AA7dgTzkyfD/ffDgQcGca5f31pu/HgYPRp69w66xa68Eu67LzhX8sc/wqpVQTfJsGHtj5FOQ0Pwt4ceGtRZc3PQ1QSwfTs8/TQccEDn9ilSiMwTGaKjAmYXAqe5+xXh8teAY9396kiZpWGZ+nB5ZVjmvaR9TQGmAAwdOnT0mkQH+D445xxYsgROOin4p1y+PEgEf/hDkEzPPTdIIpddFiQU96AvfuXKIHGYwZ13wm9+A889B++8E5xgHTs26Ku/+uogwf3mN3DGGa0JKZXRo2HjRli7Fo44IiibeGonngh1dUGMo0YFV+ls3dqakKurYcQIeP75IKkcd1zwAfPqq/Dww/DNbwYfVocdBosXtybh6COR7KMJv6IC+vYNlt97L6ibvn2DD8FEmY6mJ5wQxJzqOZ96auvJ5p49oUePIMG//36wrn//INknEvWJJwZJeNkyqKkJnmdVVXDe5O23g/poaGh9LjU1QaxLlsDBBwcfnrt2BYl99Wr48Y9h27ag3pqagrrsDLPgwy7RGEgcd9y44Dlv3QoTJsC//3vn9iuSK2a2wN3HZCwXI7mPBa5399PC5ekA7n5jpMzcsMwLZlYObAAGeJqdjxkzxuvq6mI9GRERCcRN7nGulnkZGGFmtWZWSXDCdHZSmdnA18P5C4Cn0iV2ERHJrowtdwAzOxO4heDKmbvc/SdmdgNBx/5sM+sB3Ad8FtgCTHb3VRn2uQnY136Z/mShP78LFGpcULixKa7OUVydU4pxDXP3AZkKxUruhcbM6uJ8Lcm1Qo0LCjc2xdU5iqtzPs5xFeUvVEVEJD0ldxGRElSsyf3OfAfQgUKNCwo3NsXVOYqrcz62cRVln7uIiKRXrC13ERFJo+iSe6YRKnMcy1tm9pqZLTKzunBdPzObZ2bLw2nfHMRxl5ltNLMlkXUp47DAr8L6W2xmo3Ic1/Vm9k5YZ4vCy2wT26aHcb1hZqdlMa4hZva0mS0zs6Vm9u1wfV7rLE1cea0zM+thZi+Z2athXP8Srq8NR4FdHo4KWxmuz9kosWliu9vMVkfq7OhwfS7f/2VmttDMHg+Xc1tfcQagKZQHMUaozHE8bwH9k9b9FJgWzk8DbspBHMcDo4AlmeIAzgSeAAw4Dngxx3FdD3wvRdmR4evZHagNX+eyLMU1EBgVzvcG3gyPn9c6SxNXXussfN77h/MVwIthPTxM8JsWgDuAvwvnOz1KbBZiuxu4IEX5XL7/rwVmAI+Hyzmtr4wt91Str6TtOfskBI4FVrj7KndvAGYCE7N4vH0xEbgnnL8HmJTtA7r7swQ/HosTx0TgXg/MB6rMLGkYtqzG1ZGJwEx33+Puq4EVBK93NuJa7+6vhPPbgWUEg9/ltc7SxNWRnNRZ+LwTIw1VhA8HxgOJUfaT6ytRj7OAk8wSQ9TlLLaO5OS1NLPBwFnAf4TLRo7rK063zN3A6Wm2nwGMCB9TgNs/alBppBqhMt2bP9sc+JOZLbBgUDSAg9x9PQT/rMCBeYqtozgKoQ6nhg2Bu6y12yovcYVfgT9L0OIrmDpLigvyXGdhF8MiYCMwj+BbwlZ3T9y7KnrsNqPEAolRYrMiOTZ3T9TZT8I6u9nMuifHliLurnQL8H2gOVyuJsf1lTG5x2h95awlSPBVKlk+L/f5gruPIviAu8rMjs9jLHHluw5vBw4FjgbWAz8P1+c8LjPbH3gE+I67p7thY05jSxFX3uvM3Zvc/WhgMMG3g8PTHDun9ZUcm5kdSXDficOAY4B+wD/mKjYzOxvY6O4LoqvTHDcrMXXFCdVctmrqgSGR5cHAuiwdKyN3XxdONwKPErzp3018uIXTjXkKr6M48lqH7v5u+M/YDPyW1m6EnMZlZhUECfQBd/99uDrvdZYqrkKpszCWrcBfCPqrqywYBTb52C1xhdv7EL97ritiOz3s4nJ33wP8F7mtsy8A55jZWwRdx+MJWvI5ra+4A4fVEJwUODLFtj8CN7r78+Hyn4HvJ31qJcq2jOe+3377jT7ssMM+UvAiIh83CxYs2OwxBg7rivu5x/4kdPc7CX+ZpfHcRUQ6z8xijabbFcl9NsHJnpkEt9/bljgpJVKMGpoauHz25RxzyDHcUXcHlWWVbNm1hWFVw3juG8/lOzyRWDImdzN7EBgH9DezeuBHBJcb4e53AHMIrh1dAewEvpGtYEVy4e1tb3P/4vt5YPEDOM7Jw09mR8MOFq5fmO/QRGLLmNzd/SsZtjtwVZdFJJJnTc1NADhOTVUN8742j+lPTufm+TfnOTKR+Ipu+AGRbGtsbmyZL+8WtH/KupW1WS9S6JTcRZJEk3iZlQFBkm/yJuJcXSZSCJTcRZKkarknpk3elJeYRDpLyV0kSdrk3qzkLsVByV0kSbR13tLnHnbPqN9dioWSu0iSNn3u3Vr73JO3iRQyJXeRJOm6ZZTcpVgouYsk0QlVKQVK7iJJoidNo9e5g1ruUjyU3EWSqFtGSoGSu0iSjn7ElLxNpJApuYsk0XXuUgqU3EWSpBxbRte5S5FRchdJkupHTOqWkWKj5C6SRD9iklKg5C6SRNe5SylQchdJ0tF47snbRAqZkrtIkjY/YrL2fe6PvP4Ix//X8XmJTSQuJXeRJJn63BesX8Bzbz+nyyKloMVK7mZ2upm9YWYrzGxaiu2XmtkmM1sUPq7o+lBFciPTde4NTQ0ALVORQpTxBtlmVgbcBpwC1AMvm9lsd389qehD7j41CzGK5FSm69yjyb1nRc/cBygSQ5yW+7HACndf5e4NwExgYnbDEsmfTNe5q+UuxSBOch8ErI0s14frkp1vZovNbJaZDUm1IzObYmZ1Zla3adOmfQhXJPsyjS2TSOp7mvbkPjiRmOIkd0uxLvkW8H8Aatz9KOBJ4J5UO3L3O919jLuPGTBgQOciFcmRTNe5q+UuxSBOcq8Hoi3xwcC6aAF3f8/dE82Y3wKjuyY8kdzLdJ27krsUgzjJ/WVghJnVmlklMBmYHS1gZgMji+cAy7ouRJHcyjSeu5K7FIOMV8u4e6OZTQXmAmXAXe6+1MxuAOrcfTZwjZmdAzQCW4BLsxizSFZFr19PdZ17oq9dyV0KWcbkDuDuc4A5Set+GJmfDkzv2tBE8kPXuUsp0C9URZJ05jp3kUKl5C6SRH3uUgqU3EWS6EdMUgqU3EWSpPsRU/Q69z2N+hGTFC4ld5Ekus5dSoGSu0gS9blLKVByF0mi5C6lQMldJEn0hGqiO0aXQkqxUXIXSZKq5W5mdLNu+hGTFA0ld5EkqZJ7Yl4tdykWSu4iSdIl973Ne1uS+rQ/T+P+xffnPD6ROJTcRZK0GTgs7GtPzO9u3N2m7Iv1L+YsLpHOUHIXSZKu5b5r7642Zd/f/X7O4hLpDCV3kSTpkvvOxp1tym7ZtSVncYl0hpK7SJJ0yf3Dhg/blFVyl0Kl5C6SpM3YMt3K2szv3Nu25a5uGSlUSu4iSVKNCpmY39XYts9dLXcpVEruIknS9rknt9x3vY+75yw2kbhiJXczO93M3jCzFWY2LcX27mb2ULj9RTOr6epARXKlM8m9yZvY3rA9Z7GJxJUxuZtZGXAbcAYwEviKmY1MKnY58L67fwK4GbipqwMVyZVU47kn5pOTO8DTq5/muTXP5SQ2kbjitNyPBVa4+yp3bwBmAhOTykwE7gnnZwEnmZl1XZgiuRP9EVOm69wBJj00ibMfPJutu7fmJD6ROMozF2EQsDayXA98rqMy7t5oZtuAamBzVwSZyqSZk1iycQknDz+ZD/Z8wPIty9m/cn9mT55N/Qf1nP/w+exo2MFln72M68ddj7tzxgNnsPL9lZwy/BQM47azbuP2l2/n+bXP884H73DjSTcydshY9jTuYeqcqdRvr+fWM27lrBlnsaNhR4exjBo4ik07N7F221qOOPAIdjTsYM3WNQCMrx1P3bo6tjds5+iDj2bN1jW8v/t9jGAgqv69+jOiegTPrXmOPj36cNyg4yjvVs7ijYuZef5MvvXHb7H8veV8svqTLH53MWaGYW2m7k6zN+N4S/9vebdy+vbsi7uzZdcWenfvTVWPKtZtX9dSxgmnScvjasYFMe9p291gZpw6/FSeWfMMAD3Ke9Czoie7G3e3JLbqntVUlFWwYccGAE6sOZFu1o2/bv4rtX1reW7Nc1T1qOKYQcewZusa1mxbQ0NTQ8tzqamq4YDuB/Dau69x0P4H8WHDh+xp2sO9k+5l5fsrufH5G9m2exvVvappam7qdEI1Mw7pfQjrt69vWTas5Tlv3rmZjR9upLKskoamBirKKlr+tqKsgvd2vZdyvx/s+YBDf3UolWWV7frgE+0cw9osp9LQ1EBDUwPuTnm38pYrdCrLKulV0Qto/3pFj9fRa5q8nPx3iWMlYky37472B9DNulFmZWmfY6rjpy1HzHJdvL+ExHuzo2N1VKfptv3s1J9x6dGXdiqOzrJMFWJmFwKnufsV4fLXgGPd/epImaVhmfpweWVY5r2kfU0BpgAMHTp09Jo1a/Yp6PoP6hly85CU22aeP5PlW5bzz0//M5+q/hQf7v2Qtd9dy4otKxjx6xFtyjb+cyPl/6/1823qMVP59Zm/5r5X7+OSxy4BYPTA0SxYv4BLPnMJFd0qSLarcRczXptBr4pejKsZx5xo93bEAAAKw0lEQVTlcwC4YOQFrNiygkUbFgHw5SO+zCOvP8KQPkM4seZEHGdHww5mvT4LgKMOOorF7y5us+/TP3E6/7PifwDoXtadC0ZeECSPMIknpt2sW2uyD/85G72Rd3e8i+MM6j2It7a+xbY92zhiwBEtZaFt4jGMhRsWsnDDQgC+dtTXqCyrbInnmTXPsGLLCnqU9+C8w89j195d7G7cTUVZBdU9qzGM1ze/zt6mvXzmoM+wZNMSXnrnpTbP6bD+h/HXzX9tWT77k2czoNcAHGfDjg0tz7e6ZzWjBo6id/fezFk+h0uOuoQZS2ZQ3bOak4efzOqtqymzMob2GZryfdCRhqYGVm9dTW1VLWXdynB3Fm5Y2FL3F3/6Yqp6VDHpsEks2rCIvx/79y119MjrjzB35Vz6dO/D8cOOp9mbeWbNM/Tp3oeqHlUs2bikzYcupE/EqZR3K6eirKJlBMomb6JXRS8amhrYuXdnytctupxqXUfLiXXuTpM3temOyrTvVPtzgkZG9JtPJnG/4EePm8v9RRtMjqd8/sn7S44h1baLjriILw37UqwYkpnZAncfk7FcjOQ+Frje3U8Ll6cDuPuNkTJzwzIvmFk5sAEY4Gl2PmbMGK+rq4v1ZKJmvDaDi39/cbv1NVU1bN+znWFVw4JWrDtXjLqCq5+4mjXfWcOfV/2Zy2Zf1uZv5n1tHqfcd0rL8ierP8mzlz7Lj/7yIx5c8iAjB4xkfv18aqtqWfXtVR3GdP/i+xnUexBjh4xl8C8G06dHH5ZfvZxHlz3KBb+7gNqqWlZes5Jlm5cxcP+B9O3ZF4Bmb2bgzwey8cONPHPpM1w066KWFm+CYWz43gb6dO9D9/Luna6vznr8zceZ8OAEPtHvEyy/enmbbbe9dBtTn5jKWSPO4vG/eTzjvp5e/TTj7x3fZt3vLvwdV8y+gm17tvHIlx/hvMPPa9m2ZdcW+v+0P46z9MqljBwQnNo59b5TmbdqHgBz/mYOZ4w446M+zTYeXvowF826iKoeVWz+h81trm0XKTRxk3ucPveXgRFmVmtmlcBkYHZSmdnA18P5C4Cn0iX2j+Kg/Q5qmb/8s5cDQVK+/oTrmfCpCbyy/hUWbVjEuJpxfH7I5wEYdsswLpt9GdU9q9u09C783YVt9v3me29S+8tannv7OcYOHsu/jv9XIOhaSeerR32VE2tPpEd5Dx696FFmnj+TbtaN8bXjKbMyTj30VMyMkQNGtiR2CL7CTvjkBKp7VjN28FjG1Yxrt+8Tak7gwP0OzElih6AbZb+K/ZjwyQnttk341AQqyyq5YOQFsfaVqP+qHlUtiXrs4LF8cegXAfjS0LYtl349+zFq4CgO3v9gDu9/eJuYIPj2cmLtiZ1/UhkcP+z4lniU2KVUZOxzD/vQpwJzgTLgLndfamY3AHXuPhv4T+A+M1sBbCH4AMiKk4afxDXHXsOuxl1cdMRFvFD/AvMvn0/v7r2ZdNgkzj/8fJ5c9SRXHnMlw/sOZ1zNOHY37mbX3l1cOPJC5q2ax9vb3gZg6+6tXHXMVexXsR+VZZX8+Lkfs6txF69vep3JR0zmxNoTueOsOzqVUKJftfr27MuTlzzZkthS+cVpv+C6L11HRVkFP/jiDzhh2Als+nAT3cu7M2f5HO479759r6x9sF/lfiz61iIG7j+w3bahfYay9rtrGdBrQKx9dS/vzvPfeJ7BBwzm3/7v32hoamDQAYO4duy1jBo4igH7td/P7WfdzvaG7W2+2l4+6nK27dnGeYefR4/yHvv+5Dpw8P4HM/2L0zmp9qQu37dIvmTslsmWfe2W+agufexS7nn1Hq770nWcMOwETh5+cksiWfX+Kg791aEALP7WYj590KdzHl+p2t24m517d9KvZ798hyJS1OJ2y8S5Wqak1FbVAjBl9JR2J+MS2wAl9i7Wo7xHVlrdIpLaxy65X/KZS6goq2DIAe2vtjEz5n1tHr0re+chMhGRrvOx65YRESlmXXm1jIiIFJm8tdzNbBOwb79igv5k8devH0GhxgWFG5vi6hzF1TmlGNcwd894yVrekvtHYWZ1cb6W5FqhxgWFG5vi6hzF1Tkf57jULSMiUoKU3EVESlCxJvc78x1ABwo1Lijc2BRX5yiuzvnYxlWUfe4iIpJesbbcRUQkjaJL7pnu55rjWN4ys9fMbJGZ1YXr+pnZPDNbHk77ZtpPF8Rxl5ltNLMlkXUp47DAr8L6W2xmo3Ic1/Vm9k5YZ4vM7MzItulhXG+Y2WlZjGuImT1tZsvMbKmZfTtcn9c6SxNXXuvMzHqY2Utm9moY17+E62stuGfycgvuoVwZrs/ZPZXTxHa3ma2O1NnR4fpcvv/LzGyhmT0eLue2vty9aB4Eo1KuBIYDlcCrwMg8xvMW0D9p3U+BaeH8NOCmHMRxPDAKWJIpDuBM4AnAgOOAF3Mc1/XA91KUHRm+nt2B2vB1LstSXAOBUeF8b+DN8Ph5rbM0ceW1zsLnvX84XwG8GNbDw8DkcP0dwN+F81cCd4Tzk4GHsvge6yi2u4ELUpTP5fv/WmAG8Hi4nNP6KraWe5z7ueZb9H6y9wCTsn1Ad3+WYKjlOHFMBO71wHygyszaj++bvbg6MhGY6e573H01sILg9c5GXOvd/ZVwfjuwjOBWkXmtszRxdSQndRY+78R9JivChwPjCe6ZDO3rKyf3VE4TW0dy8lqa2WDgLOA/wmUjx/VVbMk91f1c0735s82BP5nZAgtuIQhwkLuvh+CfFTgwT7F1FEch1OHU8CvxXZFuq7zEFX4F/ixBi69g6iwpLshznYVdDIuAjcA8gm8JW909cW++6LHb3FMZSNxTOSuSY3P3RJ39JKyzm80scbebXNXZLcD3geZwuZoc11exJfdUn2b5vNznC+4+CjgDuMrMjs9jLHHluw5vBw4FjgbWAz8P1+c8LjPbH3gE+I67f5CuaIp1WYstRVx5rzN3b3L3o4HBBN8ODk9VLNdxpYrNzI4EpgOHAccA/YB/zFVsZnY2sNHdF0RXpzluVmIqtuReD0TH6h0MrMtTLLj7unC6EXiU4E3/buJrXjjdmKfwOoojr3Xo7u+G/4zNwG9p7UbIaVxmVkGQQB9w99+Hq/NeZ6niKpQ6C2PZCvyFoL+6yoJ7JicfuyWucHsf4nfPdUVsp4ddXO7ue4D/Ird19gXgHDN7i6DreDxBSz6n9VVsyT3O/Vxzwsz2M7PeiXngVGAJbe8n+3Xgv/MRX5o4ZgOXhFcNHAdsS3RF5EJS/+a5BHWWiGtyeOVALTACeClLMRjBrSGXufsvIpvyWmcdxZXvOjOzAWZWFc73BE4mOB/wNME9k6F9feXknsodxPbXyIe0EfRtR+ssq6+lu09398HuXkOQo55y94vJdX111ZnhXD0Izna/SdDnd10e4xhOcKXCq8DSRCwEfWV/BpaH0345iOVBgq/rewlaAZd3FAfBV8Dbwvp7DRiT47juC4+7OHxTD4yUvy6M6w3gjCzG9UWCr72LgUXh48x811mauPJaZ8BRwMLw+EuAH0b+B14iOJH7O6B7uL5HuLwi3D48i69lR7E9FdbZEuB+Wq+oydn7PzzeOFqvlslpfekXqiIiJajYumVERCQGJXcRkRKk5C4iUoKU3EVESpCSu4hICVJyFxEpQUruIiIlSMldRKQE/X9a4Rd3Gqc/dQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "IPTFOJh3DTgq",
        "colab_type": "code",
        "outputId": "bed253d2-8afc-4db2-e019-a56843a823a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "cell_type": "code",
      "source": [
        "now = datetime.datetime.now()\n",
        "\n",
        "# modelSaved = '{}-{}_{}_{}.h5'.format(folderNormal, folderFault, pretrainedModel, now.strftime('%m-%d-%H:%M:%S'))\n",
        "\n",
        "modelSaved = '{}-{}_{}_{}.h5'.format(folderNormal, folderFault, pretrainedModel, now.strftime('%m-%d-%H-%M-%S'))\n",
        "meanSaved = 'mean_{}.npy'.format(now.strftime('%m-%d-%H-%M-%S'))\n",
        "stdSaved = 'std_{}.npy'.format(now.strftime('%m-%d-%H-%M-%S'))\n",
        "\n",
        "inputStr = input('''Save Model as '{}'? (y/n)\\n'''.format(modelSaved))\n",
        "\n",
        "if (inputStr == 'y' or inputStr == 'Y'):  \n",
        "    model.save(modelPath + '/{}'.format(modelSaved))\n",
        "    np.save(modelPath + '/{}'.format(meanSaved), trainMean)\n",
        "    np.save(modelPath + '/{}'.format(stdSaved), trainStd)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Save Model as '['P1N1', 'P2N1', 'P3N1', 'P4N1', 'P5N1']-['P1N5', 'P2N5', 'P3N5', 'P4N5', 'P5N5']_InceptionV3_11-18-00-39-52.h5'? (y/n)\n",
            "n\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}