{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning Clean Up.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joovvhan/Master-Thesis/blob/master/log/['P1N3']-['P5N3']_VGG16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "c3821KWLNey6",
        "colab_type": "code",
        "outputId": "f5ba18e5-ffe0-4883-9224-fa247c51870c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Import necessary modules\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy.io.wavfile as wf\n",
        "import time\n",
        "import glob\n",
        "import datetime\n",
        "\n",
        "from tqdm import trange\n",
        "\n",
        "# Import Keras modules\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.layers import Input, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
        "from keras.models import Sequential\n",
        "from keras import backend as K\n",
        "from keras.models import load_model\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "nxSASpgF7unA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Mount google drive\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "# os.listdir('gdrive/My Drive/Colab')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rw9NU8Xjwcz2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set data directories\n",
        "\n",
        "dataPath = '''D:\\\\0_Joowhan's Paper\\\\Synthesized\\\\Total\\\\Impulse'''\n",
        "modelPath = '''D:\\\\0_Joowhan's Paper\\\\Synthesized\\\\Total\\\\Model'''\n",
        "\n",
        "\n",
        "# Changed variable names to normal and fault\n",
        "# Changed variable names from folder to path\n",
        "# Need to consider multiple folders\n",
        "# Need to add files to be tested\n",
        "\n",
        "folderNormal = ['P1N3']\n",
        "# folderNormal = list()\n",
        "\n",
        "# for x in range(1, 6):\n",
        "#     for y in range(1, 6):\n",
        "#         for z in range(1, 6):\n",
        "#             if (x <= 2 and y <= 2 and z <= 2):\n",
        "#                 folderNormal.append('A{}F{}P{}'.format(x, y, z))\n",
        "\n",
        "# folderFault = list()\n",
        "\n",
        "folderFault = ['P5N3']\n",
        "\n",
        "# for x in range(1, 6):\n",
        "#     for y in range(1, 6):\n",
        "#         for z in range(1, 6):\n",
        "#             if (x == 5 or y == 5 or z == 5):\n",
        "#                 folderFault.append('A{}F{}P{}'.format(x, y, z))\n",
        "\n",
        "\n",
        "pathNormal = list()\n",
        "pathFault = list()\n",
        "\n",
        "for i in range(len(folderNormal)):\n",
        "    pathNormal.append(dataPath + '/' + folderNormal[i])\n",
        "    \n",
        "for i in range(len(folderFault)):\n",
        "    pathFault.append(dataPath + '/' + folderFault[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xgGP7PZO-rTA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Specgram settings\n",
        "\n",
        "nsc = 1470\n",
        "nov = nsc/2\n",
        "nff = nsc \n",
        "imgSize = 224\n",
        "\n",
        "# pretrainedModel = 'VGG19'\n",
        "# pretrainedModel = 'Xception'\n",
        "# pretrainedModel = 'ResNet50'\n",
        "\n",
        "pretrainedModel = 'VGG16'\n",
        "\n",
        "\n",
        "lastActivation = 'softmax'\n",
        "sizeBatch = 4\n",
        "numEpochs = 4\n",
        "verb = 1\n",
        "\n",
        "\n",
        "# Learning parameters\n",
        "\n",
        "trainingRatio = 0.8\n",
        "\n",
        "totalDataNum = 1000\n",
        "repeat = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5AskF2qFT2xr",
        "colab_type": "code",
        "outputId": "8f774831-a857-4c8c-9fb7-5ec4b6835f41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "startNum = 0\n",
        "\n",
        "pickNum = int(np.ceil(totalDataNum / len(pathNormal)))\n",
        "\n",
        "for i in range(startNum, len(pathNormal)):\n",
        "\n",
        "    npyTestPath = glob.glob(pathNormal[i] + '/' + '*Image_With_Label.npy')\n",
        "    data = np.load(npyTestPath[0])\n",
        "    \n",
        "    pickIdx = np.random.choice(1000, pickNum, replace=False)\n",
        "    pickIdx.sort()\n",
        "    \n",
        "#     imgs = np.moveaxis(np.dstack(data[:, 0]), 2, 0)\n",
        "#     label = data[:, 1:5]\n",
        "\n",
        "    imgs = np.moveaxis(np.dstack(data[pickIdx, 0]), 2, 0)\n",
        "    label = data[pickIdx, 1:5]\n",
        "    \n",
        "    if i == startNum:\n",
        "        labelListNormal = label\n",
        "        imgsNormal = imgs\n",
        "    else:\n",
        "        labelListNormal = np.vstack([labelListNormal, label])\n",
        "        imgsNormal = np.vstack([imgsNormal, imgs])\n",
        "\n",
        "    print('Normal Image Shape From {}: {}:'.format(pathNormal[i], totalDataNum))    \n",
        "    print('Selected {}/{}:'.format(pickNum * (i + 1), len(data)))    \n",
        "    \n",
        "    \n",
        "print('Normal Image Shape: {}'.format(imgsNormal.shape))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P1N3: 1000:\n",
            "Selected 1000/1000:\n",
            "Normal Image Shape: (1000, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P_MZtpk3Br_i",
        "colab_type": "code",
        "outputId": "96bcf6f1-a70f-4826-ac58-5732b58d3ffb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "startNum = 0\n",
        "\n",
        "pickNum = int(np.ceil(totalDataNum / len(pathFault)))\n",
        "\n",
        "for i in range(startNum, len(pathFault)):\n",
        "\n",
        "    npyTestPath = glob.glob(pathFault[i] + '/' + '*Image_With_Label.npy')\n",
        "    data = np.load(npyTestPath[0])\n",
        "    \n",
        "    pickIdx = np.random.choice(1000, pickNum, replace=False)\n",
        "    pickIdx.sort()\n",
        "    \n",
        "#     imgs = np.moveaxis(np.dstack(data[:, 0]), 2, 0)\n",
        "#     label = data[:, 1:5]\n",
        "    \n",
        "    imgs = np.moveaxis(np.dstack(data[pickIdx, 0]), 2, 0)\n",
        "    label = data[pickIdx, 1:5]\n",
        "    \n",
        "    if i == startNum:\n",
        "        labelListFault = label\n",
        "        imgsFault = imgs\n",
        "    else:\n",
        "        labelListFault = np.vstack([labelListFault, label])\n",
        "        imgsFault = np.vstack([imgsFault, imgs])\n",
        "\n",
        "    print('Fault Image Shape From {}: {}:'.format(pathFault[i], totalDataNum))    \n",
        "    print('Selected {}/{}:'.format(pickNum * (i + 1), len(data)))     \n",
        "    \n",
        "print('Fault Image Shape: {}'.format(imgsFault.shape))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P5N3: 1000:\n",
            "Selected 1000/1000:\n",
            "Fault Image Shape: (1000, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e91QsAurSkIP",
        "colab_type": "code",
        "outputId": "88a6e93a-6909-4567-98d5-84d676472887",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "cell_type": "code",
      "source": [
        "# Change name from imgsF1 or imgsF5 to imgsNormal and imgsFault\n",
        "\n",
        "dataNumNormal = len(imgsNormal)\n",
        "dataNumFault = len(imgsFault)\n",
        "dataNumNormalTrain = int(dataNumNormal * trainingRatio)\n",
        "dataNumFaultTrain = int(dataNumFault * trainingRatio)\n",
        "dataNumNormalTest = dataNumNormal - dataNumNormalTrain\n",
        "dataNumFaultTest = dataNumFault - dataNumFaultTrain\n",
        "\n",
        "print('Normal Train:Test = {:d}:{:d}'.format(dataNumNormalTrain, dataNumNormalTest))\n",
        "print('Fault  Train:Test = {:d}:{:d}\\n'.format(dataNumFaultTrain, dataNumFaultTest))\n",
        "\n",
        "trainIdxNormal = np.random.choice(dataNumNormal - 1, dataNumNormalTrain, replace=False)\n",
        "testIdxNormal = list(set(range(0, dataNumNormal)) - set(trainIdxNormal))\n",
        "\n",
        "trainImgsNormal = imgsNormal[trainIdxNormal, :, :]\n",
        "testImgsNormal = imgsNormal[testIdxNormal, :, :]\n",
        "\n",
        "print('Normal Training Image Shape {}'.format(trainImgsNormal.shape))\n",
        "print('Normal Test Image Shape {}\\n'.format(testImgsNormal.shape))\n",
        "\n",
        "trainIdxFault  = np.random.choice(dataNumFault - 1, dataNumFaultTrain, replace=False)\n",
        "testIdxFault = list(set(range(0, dataNumFault)) - set(trainIdxFault))\n",
        "\n",
        "trainImgsFault = imgsFault[trainIdxFault, :, :]\n",
        "testImgsFault = imgsFault[testIdxFault, :, :]\n",
        "\n",
        "print('Fault Training Image Shape {}'.format(trainImgsFault.shape))\n",
        "print('Fault Test Image Shape {}\\n'.format(testImgsFault.shape))\n",
        "\n",
        "trainImgs = np.vstack([trainImgsNormal, trainImgsFault])\n",
        "testImgs = np.vstack([testImgsNormal, testImgsFault])\n",
        "\n",
        "print('Training Image Shape {}'.format(trainImgs.shape))\n",
        "print('Test Image Shape {}'.format(testImgs.shape))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal Train:Test = 800:200\n",
            "Fault  Train:Test = 800:200\n",
            "\n",
            "Normal Training Image Shape (800, 224, 224)\n",
            "Normal Test Image Shape (200, 224, 224)\n",
            "\n",
            "Fault Training Image Shape (800, 224, 224)\n",
            "Fault Test Image Shape (200, 224, 224)\n",
            "\n",
            "Training Image Shape (1600, 224, 224)\n",
            "Test Image Shape (400, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MoE7f_hzs0av",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "feQ_AHAcUgHD",
        "colab_type": "code",
        "outputId": "473d0048-56c6-423e-b348-1191b4063d87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "trainMean = np.mean(trainImgs)\n",
        "trainStd = np.std(trainImgs)\n",
        "\n",
        "print('Mean of Training Image: {}'.format(trainMean))\n",
        "print('Standard Deviation of Training Image: {}'.format(trainStd))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean of Training Image: -79.1727439051439\n",
            "Standard Deviation of Training Image: 8.200949969325903\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wUi9IuXNUpir",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Should Change Norm to Normalized\n",
        "\n",
        "trainImgsNorm = (trainImgs - trainMean) / trainStd\n",
        "testImgsNorm = (testImgs - trainMean) / trainStd\n",
        "\n",
        "trainImgsNorm = trainImgsNorm.reshape(list(trainImgsNorm.shape) + [1])\n",
        "testImgsNorm = testImgsNorm.reshape(list(testImgsNorm.shape) + [1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aklxiPz1Ve4n",
        "colab_type": "code",
        "outputId": "99a637b9-6b83-4da6-e035-6889c85b7ab7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = np.stack([trainImgsNorm[:, :, :, 0], trainImgsNorm[:, :, :, 0], trainImgsNorm[:, :, :, 0]], axis = -1)\n",
        "X_test = np.stack([testImgsNorm[:, :, :, 0], testImgsNorm[:, :, :, 0], testImgsNorm[:, :, :, 0]], axis = -1)\n",
        "\n",
        "print('X_train Shape: {}'.format(X_train.shape))\n",
        "print('X_test  Shape: {}'.format(X_test.shape))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train Shape: (1600, 224, 224, 3)\n",
            "X_test  Shape: (400, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sRgIPzT7K_YP",
        "colab_type": "code",
        "outputId": "5e04b63a-c1b6-470e-96b9-c35cff2952c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "trainLabelNormal = np.stack((np.ones(dataNumNormalTrain), np.zeros(dataNumNormalTrain)), axis = -1)\n",
        "testLabelNormal = np.stack((np.ones(dataNumNormalTest), np.zeros(dataNumNormalTest)), axis = -1)\n",
        "\n",
        "trainLabelFault = np.stack((np.zeros(dataNumFaultTrain), np.ones(dataNumFaultTrain)), axis = -1)\n",
        "testLabelFault = np.stack((np.zeros(dataNumFaultTest), np.ones(dataNumFaultTest)), axis = -1)\n",
        "\n",
        "Y_train = np.vstack((trainLabelNormal, trainLabelFault))\n",
        "Y_test = np.vstack((testLabelNormal, testLabelFault))\n",
        "\n",
        "print('Y_train Normal:Fault = {:d}:{:d}'.format(len(trainLabelNormal), len(trainLabelFault)))\n",
        "print('Y_test  Normal:Fault = {:d}:{:d}'.format(len(testLabelNormal), len(testLabelFault)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Y_train Normal:Fault = 800:800\n",
            "Y_test  Normal:Fault = 200:200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kczwZk7Tbp5C",
        "colab_type": "code",
        "outputId": "4576658a-f84d-4764-bd5d-9d97980c34f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1207
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG19\n",
        "from keras.applications import VGG16\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications.densenet import DenseNet169\n",
        "from keras.applications.densenet import DenseNet201\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# pretrainedModel = 'ResNet50'\n",
        "# lastActivation = 'softmax'\n",
        "# lossFunction = 'binary_crossentropy'\n",
        "# sizeBatch = 2\n",
        "# numEpochs = 2\n",
        "# verb = 1\n",
        "\n",
        "for rp in range(repeat):\n",
        "\n",
        "    # Refresh all background variables\n",
        "    K.clear_session()\n",
        "\n",
        "    input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "    # Building sequential model with name 'model'\n",
        "    model = Sequential()\n",
        "\n",
        "    # Model selection\n",
        "\n",
        "    if (pretrainedModel == 'VGG16'):\n",
        "\n",
        "        modelWoTop = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'VGG19'):\n",
        "\n",
        "        modelWoTop = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif pretrainedModel == 'ResNet50':\n",
        "\n",
        "        modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'InceptionV3'):\n",
        "        modelWoTop = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'Xception'):\n",
        "        modelWoTop = Xception(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet169'):\n",
        "\n",
        "        modelWoTop = DenseNet169(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet201'):\n",
        "        modelWoTop = DenseNet201(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    else:\n",
        "        print('Invalid Pretrained Model Selection')\n",
        "\n",
        "\n",
        "\n",
        "    # Model compiling\n",
        "\n",
        "    print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "    print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "    model.fit(X_train, Y_train,\n",
        "              batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "              validation_data=(X_test, Y_test))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compiling Pretrained vgg16 Model\n",
            "Training Pretrained vgg16 Model\n",
            "Batch Size: 4\t Epochs: 4\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/4\n",
            "1600/1600 [==============================] - 114s 72ms/step - loss: 7.9955 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 2/4\n",
            "1600/1600 [==============================] - 105s 66ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 3/4\n",
            "1600/1600 [==============================] - 105s 66ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 4/4\n",
            "1600/1600 [==============================] - 105s 66ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Compiling Pretrained vgg16 Model\n",
            "Training Pretrained vgg16 Model\n",
            "Batch Size: 4\t Epochs: 4\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/4\n",
            "1600/1600 [==============================] - 113s 71ms/step - loss: 8.0079 - acc: 0.4994 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 2/4\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 3/4\n",
            "1600/1600 [==============================] - 105s 66ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 4/4\n",
            "1600/1600 [==============================] - 105s 66ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Compiling Pretrained vgg16 Model\n",
            "Training Pretrained vgg16 Model\n",
            "Batch Size: 4\t Epochs: 4\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/4\n",
            "1600/1600 [==============================] - 113s 70ms/step - loss: 8.0103 - acc: 0.4988 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 2/4\n",
            "1600/1600 [==============================] - 105s 66ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 3/4\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 4/4\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Compiling Pretrained vgg16 Model\n",
            "Training Pretrained vgg16 Model\n",
            "Batch Size: 4\t Epochs: 4\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/4\n",
            "1600/1600 [==============================] - 113s 71ms/step - loss: 8.0034 - acc: 0.4988 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 2/4\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 3/4\n",
            "1600/1600 [==============================] - 105s 66ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 4/4\n",
            "1600/1600 [==============================] - 105s 66ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Compiling Pretrained vgg16 Model\n",
            "Training Pretrained vgg16 Model\n",
            "Batch Size: 4\t Epochs: 4\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/4\n",
            "1600/1600 [==============================] - 113s 71ms/step - loss: 8.0070 - acc: 0.4988 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 2/4\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 3/4\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 4/4\n",
            "1600/1600 [==============================] - 106s 66ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qexmaPZVz04q",
        "colab_type": "code",
        "outputId": "437b61e2-8f02-4b67-9795-cf5c3089bd1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.plot(Y_test[:, 1], 'r')\n",
        "\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.plot(Y_pred[:, 1], 'b')\n",
        "\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.plot(Y_test[:, 1] - Y_pred[:, 1], 'g')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "IPTFOJh3DTgq",
        "colab_type": "code",
        "outputId": "7d684189-ba4f-48c6-c553-8cf3ba801b10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "now = datetime.datetime.now()\n",
        "\n",
        "# modelSaved = '{}-{}_{}_{}.h5'.format(folderNormal, folderFault, pretrainedModel, now.strftime('%m-%d-%H:%M:%S'))\n",
        "\n",
        "modelSaved = '{}-{}_{}_{}.h5'.format(folderNormal, folderFault, pretrainedModel, now.strftime('%m-%d-%H-%M-%S'))\n",
        "meanSaved = 'mean_{}.npy'.format(now.strftime('%m-%d-%H-%M-%S'))\n",
        "stdSaved = 'std_{}.npy'.format(now.strftime('%m-%d-%H-%M-%S'))\n",
        "\n",
        "inputStr = input('''Save Model as '{}'? (y/n)\\n'''.format(modelSaved))\n",
        "\n",
        "if (inputStr == 'y' or inputStr == 'Y'):  \n",
        "    model.save(modelPath + '/{}'.format(modelSaved))\n",
        "    np.save(modelPath + '/{}'.format(meanSaved), trainMean)\n",
        "    np.save(modelPath + '/{}'.format(stdSaved), trainStd)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Save Model as '['P1N3']-['P5N3']_VGG16_11-16-12-09-08.h5'? (y/n)\n",
            "y\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}