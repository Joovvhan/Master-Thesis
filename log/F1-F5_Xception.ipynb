{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning Clean Up.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joovvhan/Master-Thesis/blob/master/log/F1-F5_Xception.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "c3821KWLNey6",
        "colab_type": "code",
        "outputId": "d676941a-7755-47fc-a6b2-fb104d7d58d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Import necessary modules\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy.io.wavfile as wf\n",
        "import time\n",
        "import glob\n",
        "import datetime\n",
        "\n",
        "from tqdm import trange\n",
        "\n",
        "# Import Keras modules\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.layers import Input, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
        "from keras.models import Sequential\n",
        "from keras import backend as K\n",
        "from keras.models import load_model\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "nxSASpgF7unA",
        "colab_type": "code",
        "outputId": "955a4c50-a34a-4ca9-b746-7d911fbf8a54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "cell_type": "code",
      "source": [
        "# Mount google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "os.listdir('gdrive/My Drive/Colab')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Data', 'Model', 'Data_']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "rw9NU8Xjwcz2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set data directories\n",
        "\n",
        "dataPath = 'gdrive/My Drive/Colab/Data'\n",
        "\n",
        "# Changed variable names to normal and fault\n",
        "# Changed variable names from folder to path\n",
        "# Need to consider multiple folders\n",
        "# Need to add files to be tested\n",
        "\n",
        "#folderNormal = ['A1F3P3']\n",
        "folderNormal = list()\n",
        "\n",
        "for x in range(1, 6):\n",
        "    for y in range(1, 2):\n",
        "        for z in range(1, 6):\n",
        "            #if (x <= 2 and y <= 2 and z <= 2):\n",
        "            folderNormal.append('A{}F{}P{}'.format(x, y, z))\n",
        "\n",
        "folderFault = list()\n",
        "\n",
        "# folderFault = ['A5F3P3']\n",
        "\n",
        "for x in range(1, 6):\n",
        "    for y in range(5, 6):\n",
        "        for z in range(1, 6):\n",
        "            #if (x == 5 or y == 5 or z == 5):\n",
        "            folderFault.append('A{}F{}P{}'.format(x, y, z))\n",
        "\n",
        "\n",
        "pathNormal = list()\n",
        "pathFault = list()\n",
        "\n",
        "for i in range(len(folderNormal)):\n",
        "    pathNormal.append(dataPath + '/' + folderNormal[i])\n",
        "    \n",
        "for i in range(len(folderFault)):\n",
        "    pathFault.append(dataPath + '/' + folderFault[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xgGP7PZO-rTA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Specgram settings\n",
        "\n",
        "nsc = 1470\n",
        "nov = nsc/2\n",
        "nff = nsc \n",
        "imgSize = 224\n",
        "\n",
        "# pretrainedModel = 'VGG19'\n",
        "pretrainedModel = 'Xception'\n",
        "#pretrainedModel = 'ResNet50'\n",
        "\n",
        "# pretrainedModel = 'VGG19'\n",
        "# pretrainedModel = 'InceptionV3'\n",
        "#pretrainedModel = 'DenseNet169'\n",
        "#pretrainedModel = 'DenseNet201'\n",
        "\n",
        "\n",
        "lastActivation = 'softmax'\n",
        "sizeBatch = 4\n",
        "numEpochs = 12\n",
        "verb = 1\n",
        "\n",
        "\n",
        "# Learning parameters\n",
        "\n",
        "trainingRatio = 0.8\n",
        "\n",
        "totalDataNum = 1000\n",
        "repeat = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5AskF2qFT2xr",
        "colab_type": "code",
        "outputId": "c0a66c2f-58a4-4db2-9e3e-cdd7386bae8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "cell_type": "code",
      "source": [
        "startNum = 0\n",
        "\n",
        "pickNum = int(np.ceil(totalDataNum / len(pathNormal)))\n",
        "\n",
        "for i in range(startNum, len(pathNormal)):\n",
        "\n",
        "    npyTestPath = glob.glob(pathNormal[i] + '/' + '*Image_With_Label.npy')\n",
        "    data = np.load(npyTestPath[0])\n",
        "    \n",
        "    pickIdx = np.random.choice(1000, pickNum, replace=False)\n",
        "    pickIdx.sort()\n",
        "    \n",
        "#     imgs = np.moveaxis(np.dstack(data[:, 0]), 2, 0)\n",
        "#     label = data[:, 1:5]\n",
        "\n",
        "    imgs = np.moveaxis(np.dstack(data[pickIdx, 0]), 2, 0)\n",
        "    label = data[pickIdx, 1:5]\n",
        "    \n",
        "    if i == startNum:\n",
        "        labelListNormal = label\n",
        "        imgsNormal = imgs\n",
        "    else:\n",
        "        labelListNormal = np.vstack([labelListNormal, label])\n",
        "        imgsNormal = np.vstack([imgsNormal, imgs])\n",
        "\n",
        "    print('Normal Image Shape From {}: {}:'.format(pathNormal[i], totalDataNum))    \n",
        "    print('Selected {}/{}:'.format(pickNum * (i + 1), len(data)))    \n",
        "    \n",
        "    \n",
        "print('Normal Image Shape: {}'.format(imgsNormal.shape))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A1F1P1: 1000:\n",
            "Selected 40/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A1F1P2: 1000:\n",
            "Selected 80/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A1F1P3: 1000:\n",
            "Selected 120/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A1F1P4: 1000:\n",
            "Selected 160/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A1F1P5: 1000:\n",
            "Selected 200/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A2F1P1: 1000:\n",
            "Selected 240/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A2F1P2: 1000:\n",
            "Selected 280/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A2F1P3: 1000:\n",
            "Selected 320/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A2F1P4: 1000:\n",
            "Selected 360/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A2F1P5: 1000:\n",
            "Selected 400/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A3F1P1: 1000:\n",
            "Selected 440/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A3F1P2: 1000:\n",
            "Selected 480/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A3F1P3: 1000:\n",
            "Selected 520/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A3F1P4: 1000:\n",
            "Selected 560/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A3F1P5: 1000:\n",
            "Selected 600/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A4F1P1: 1000:\n",
            "Selected 640/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A4F1P2: 1000:\n",
            "Selected 680/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A4F1P3: 1000:\n",
            "Selected 720/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A4F1P4: 1000:\n",
            "Selected 760/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A4F1P5: 1000:\n",
            "Selected 800/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A5F1P1: 1000:\n",
            "Selected 840/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A5F1P2: 1000:\n",
            "Selected 880/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A5F1P3: 1000:\n",
            "Selected 920/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A5F1P4: 1000:\n",
            "Selected 960/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A5F1P5: 1000:\n",
            "Selected 1000/1000:\n",
            "Normal Image Shape: (1000, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P_MZtpk3Br_i",
        "colab_type": "code",
        "outputId": "48ee1e15-6636-4ac0-be4e-ac36c8ebb912",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "cell_type": "code",
      "source": [
        "startNum = 0\n",
        "\n",
        "pickNum = int(np.ceil(totalDataNum / len(pathFault)))\n",
        "\n",
        "for i in range(startNum, len(pathFault)):\n",
        "\n",
        "    npyTestPath = glob.glob(pathFault[i] + '/' + '*Image_With_Label.npy')\n",
        "    data = np.load(npyTestPath[0])\n",
        "    \n",
        "    pickIdx = np.random.choice(1000, pickNum, replace=False)\n",
        "    pickIdx.sort()\n",
        "    \n",
        "#     imgs = np.moveaxis(np.dstack(data[:, 0]), 2, 0)\n",
        "#     label = data[:, 1:5]\n",
        "    \n",
        "    imgs = np.moveaxis(np.dstack(data[pickIdx, 0]), 2, 0)\n",
        "    label = data[pickIdx, 1:5]\n",
        "    \n",
        "    if i == startNum:\n",
        "        labelListFault = label\n",
        "        imgsFault = imgs\n",
        "    else:\n",
        "        labelListFault = np.vstack([labelListFault, label])\n",
        "        imgsFault = np.vstack([imgsFault, imgs])\n",
        "\n",
        "    print('Fault Image Shape From {}: {}:'.format(pathFault[i], totalDataNum))    \n",
        "    print('Selected {}/{}:'.format(pickNum * (i + 1), len(data)))     \n",
        "    \n",
        "print('Fault Image Shape: {}'.format(imgsFault.shape))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A1F5P1: 1000:\n",
            "Selected 40/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A1F5P2: 1000:\n",
            "Selected 80/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A1F5P3: 1000:\n",
            "Selected 120/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A1F5P4: 1000:\n",
            "Selected 160/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A1F5P5: 1000:\n",
            "Selected 200/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A2F5P1: 1000:\n",
            "Selected 240/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A2F5P2: 1000:\n",
            "Selected 280/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A2F5P3: 1000:\n",
            "Selected 320/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A2F5P4: 1000:\n",
            "Selected 360/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A2F5P5: 1000:\n",
            "Selected 400/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A3F5P1: 1000:\n",
            "Selected 440/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A3F5P2: 1000:\n",
            "Selected 480/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A3F5P3: 1000:\n",
            "Selected 520/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A3F5P4: 1000:\n",
            "Selected 560/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A3F5P5: 1000:\n",
            "Selected 600/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A4F5P1: 1000:\n",
            "Selected 640/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A4F5P2: 1000:\n",
            "Selected 680/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A4F5P3: 1000:\n",
            "Selected 720/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A4F5P4: 1000:\n",
            "Selected 760/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A4F5P5: 1000:\n",
            "Selected 800/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A5F5P1: 1000:\n",
            "Selected 840/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A5F5P2: 1000:\n",
            "Selected 880/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A5F5P3: 1000:\n",
            "Selected 920/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A5F5P4: 1000:\n",
            "Selected 960/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A5F5P5: 1000:\n",
            "Selected 1000/1000:\n",
            "Fault Image Shape: (1000, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e91QsAurSkIP",
        "colab_type": "code",
        "outputId": "9be8f50e-9e4d-4f0d-cba1-7c027788baaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "cell_type": "code",
      "source": [
        "# Change name from imgsF1 or imgsF5 to imgsNormal and imgsFault\n",
        "\n",
        "dataNumNormal = len(imgsNormal)\n",
        "dataNumFault = len(imgsFault)\n",
        "dataNumNormalTrain = int(dataNumNormal * trainingRatio)\n",
        "dataNumFaultTrain = int(dataNumFault * trainingRatio)\n",
        "dataNumNormalTest = dataNumNormal - dataNumNormalTrain\n",
        "dataNumFaultTest = dataNumFault - dataNumFaultTrain\n",
        "\n",
        "print('Normal Train:Test = {:d}:{:d}'.format(dataNumNormalTrain, dataNumNormalTest))\n",
        "print('Fault  Train:Test = {:d}:{:d}\\n'.format(dataNumFaultTrain, dataNumFaultTest))\n",
        "\n",
        "trainIdxNormal = np.random.choice(dataNumNormal - 1, dataNumNormalTrain, replace=False)\n",
        "testIdxNormal = list(set(range(0, dataNumNormal)) - set(trainIdxNormal))\n",
        "\n",
        "trainImgsNormal = imgsNormal[trainIdxNormal, :, :]\n",
        "testImgsNormal = imgsNormal[testIdxNormal, :, :]\n",
        "\n",
        "print('Normal Training Image Shape {}'.format(trainImgsNormal.shape))\n",
        "print('Normal Test Image Shape {}\\n'.format(testImgsNormal.shape))\n",
        "\n",
        "trainIdxFault  = np.random.choice(dataNumFault - 1, dataNumFaultTrain, replace=False)\n",
        "testIdxFault = list(set(range(0, dataNumFault)) - set(trainIdxFault))\n",
        "\n",
        "trainImgsFault = imgsFault[trainIdxFault, :, :]\n",
        "testImgsFault = imgsFault[testIdxFault, :, :]\n",
        "\n",
        "print('Fault Training Image Shape {}'.format(trainImgsFault.shape))\n",
        "print('Fault Test Image Shape {}\\n'.format(testImgsFault.shape))\n",
        "\n",
        "trainImgs = np.vstack([trainImgsNormal, trainImgsFault])\n",
        "testImgs = np.vstack([testImgsNormal, testImgsFault])\n",
        "\n",
        "print('Training Image Shape {}'.format(trainImgs.shape))\n",
        "print('Test Image Shape {}'.format(testImgs.shape))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal Train:Test = 800:200\n",
            "Fault  Train:Test = 800:200\n",
            "\n",
            "Normal Training Image Shape (800, 224, 224)\n",
            "Normal Test Image Shape (200, 224, 224)\n",
            "\n",
            "Fault Training Image Shape (800, 224, 224)\n",
            "Fault Test Image Shape (200, 224, 224)\n",
            "\n",
            "Training Image Shape (1600, 224, 224)\n",
            "Test Image Shape (400, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MoE7f_hzs0av",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "feQ_AHAcUgHD",
        "colab_type": "code",
        "outputId": "75a29bc3-4a33-467c-8231-02a177339c04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "trainMean = np.mean(trainImgs)\n",
        "trainStd = np.std(trainImgs)\n",
        "\n",
        "print('Mean of Training Image: {}'.format(trainMean))\n",
        "print('Standard Deviation of Training Image: {}'.format(trainStd))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean of Training Image: -78.28082072478696\n",
            "Standard Deviation of Training Image: 9.325384578338126\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wUi9IuXNUpir",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Should Change Norm to Normalized\n",
        "\n",
        "trainImgsNorm = (trainImgs - trainMean) / trainStd\n",
        "testImgsNorm = (testImgs - trainMean) / trainStd\n",
        "\n",
        "trainImgsNorm = trainImgsNorm.reshape(list(trainImgsNorm.shape) + [1])\n",
        "testImgsNorm = testImgsNorm.reshape(list(testImgsNorm.shape) + [1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aklxiPz1Ve4n",
        "colab_type": "code",
        "outputId": "1b657867-6c22-45d3-ca95-f6178920f004",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = np.stack([trainImgsNorm[:, :, :, 0], trainImgsNorm[:, :, :, 0], trainImgsNorm[:, :, :, 0]], axis = -1)\n",
        "X_test = np.stack([testImgsNorm[:, :, :, 0], testImgsNorm[:, :, :, 0], testImgsNorm[:, :, :, 0]], axis = -1)\n",
        "\n",
        "print('X_train Shape: {}'.format(X_train.shape))\n",
        "print('X_test  Shape: {}'.format(X_test.shape))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train Shape: (1600, 224, 224, 3)\n",
            "X_test  Shape: (400, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sRgIPzT7K_YP",
        "colab_type": "code",
        "outputId": "9cefdadb-d48f-4a9f-9775-f33c105f7622",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "trainLabelNormal = np.stack((np.ones(dataNumNormalTrain), np.zeros(dataNumNormalTrain)), axis = -1)\n",
        "testLabelNormal = np.stack((np.ones(dataNumNormalTest), np.zeros(dataNumNormalTest)), axis = -1)\n",
        "\n",
        "trainLabelFault = np.stack((np.zeros(dataNumFaultTrain), np.ones(dataNumFaultTrain)), axis = -1)\n",
        "testLabelFault = np.stack((np.zeros(dataNumFaultTest), np.ones(dataNumFaultTest)), axis = -1)\n",
        "\n",
        "Y_train = np.vstack((trainLabelNormal, trainLabelFault))\n",
        "Y_test = np.vstack((testLabelNormal, testLabelFault))\n",
        "\n",
        "print('Y_train Normal:Fault = {:d}:{:d}'.format(len(trainLabelNormal), len(trainLabelFault)))\n",
        "print('Y_test  Normal:Fault = {:d}:{:d}'.format(len(testLabelNormal), len(testLabelFault)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Y_train Normal:Fault = 800:800\n",
            "Y_test  Normal:Fault = 200:200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kczwZk7Tbp5C",
        "colab_type": "code",
        "outputId": "eec6f751-8d55-4ede-cdcb-2be1cec5b20b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1495
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG19\n",
        "from keras.applications import VGG16\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications.densenet import DenseNet169\n",
        "from keras.applications.densenet import DenseNet201\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# pretrainedModel = 'ResNet50'\n",
        "# lastActivation = 'softmax'\n",
        "# lossFunction = 'binary_crossentropy'\n",
        "# sizeBatch = 2\n",
        "# numEpochs = 2\n",
        "# verb = 1\n",
        "\n",
        "for rp in range(repeat):\n",
        "\n",
        "    # Refresh all background variables\n",
        "    K.clear_session()\n",
        "\n",
        "    input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "    # Building sequential model with name 'model'\n",
        "    model = Sequential()\n",
        "\n",
        "    # Model selection\n",
        "\n",
        "    if (pretrainedModel == 'VGG16'):\n",
        "\n",
        "        modelWoTop = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'VGG19'):\n",
        "\n",
        "        modelWoTop = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif pretrainedModel == 'ResNet50':\n",
        "\n",
        "        modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'InceptionV3'):\n",
        "        modelWoTop = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'Xception'):\n",
        "        modelWoTop = Xception(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet169'):\n",
        "\n",
        "        modelWoTop = DenseNet169(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet201'):\n",
        "        modelWoTop = DenseNet201(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    else:\n",
        "        print('Invalid Pretrained Model Selection')\n",
        "\n",
        "\n",
        "\n",
        "    # Model compiling\n",
        "\n",
        "    print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "    print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "    model.fit(X_train, Y_train,\n",
        "              batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "              validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 1s 0us/step\n",
            "Compiling Pretrained xception Model\n",
            "Training Pretrained xception Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/12\n",
            "1600/1600 [==============================] - 127s 79ms/step - loss: 0.3024 - acc: 0.8988 - val_loss: 0.0731 - val_acc: 0.9825\n",
            "Epoch 2/12\n",
            "1600/1600 [==============================] - 111s 69ms/step - loss: 0.1453 - acc: 0.9600 - val_loss: 0.0503 - val_acc: 0.9925\n",
            "Epoch 3/12\n",
            "1600/1600 [==============================] - 111s 69ms/step - loss: 0.1437 - acc: 0.9531 - val_loss: 0.0423 - val_acc: 0.9950\n",
            "Epoch 4/12\n",
            "1600/1600 [==============================] - 111s 69ms/step - loss: 0.0526 - acc: 0.9875 - val_loss: 0.0420 - val_acc: 0.9925\n",
            "Epoch 5/12\n",
            "1600/1600 [==============================] - 111s 69ms/step - loss: 0.0463 - acc: 0.9869 - val_loss: 0.0172 - val_acc: 0.9950\n",
            "Epoch 6/12\n",
            "1600/1600 [==============================] - 111s 69ms/step - loss: 0.1101 - acc: 0.9719 - val_loss: 0.0864 - val_acc: 0.9650\n",
            "Epoch 7/12\n",
            "1600/1600 [==============================] - 111s 69ms/step - loss: 0.0917 - acc: 0.9781 - val_loss: 0.1829 - val_acc: 0.9950\n",
            "Epoch 8/12\n",
            "1600/1600 [==============================] - 112s 70ms/step - loss: 0.0320 - acc: 0.9919 - val_loss: 0.0302 - val_acc: 0.9975\n",
            "Epoch 9/12\n",
            "1600/1600 [==============================] - 111s 69ms/step - loss: 0.0121 - acc: 0.9975 - val_loss: 0.0269 - val_acc: 0.9950\n",
            "Epoch 10/12\n",
            "1600/1600 [==============================] - 111s 69ms/step - loss: 0.0255 - acc: 0.9925 - val_loss: 0.0063 - val_acc: 1.0000\n",
            "Epoch 11/12\n",
            "1600/1600 [==============================] - 111s 69ms/step - loss: 0.0184 - acc: 0.9950 - val_loss: 0.0815 - val_acc: 0.9875\n",
            "Epoch 12/12\n",
            "1600/1600 [==============================] - 112s 70ms/step - loss: 0.0331 - acc: 0.9919 - val_loss: 0.0141 - val_acc: 0.9975\n",
            "Compiling Pretrained xception Model\n",
            "Training Pretrained xception Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/12\n",
            "1600/1600 [==============================] - 126s 79ms/step - loss: 0.4074 - acc: 0.8656 - val_loss: 3.6270 - val_acc: 0.5025\n",
            "Epoch 2/12\n",
            "1600/1600 [==============================] - 110s 69ms/step - loss: 0.2726 - acc: 0.8844 - val_loss: 0.0384 - val_acc: 0.9975\n",
            "Epoch 3/12\n",
            "1600/1600 [==============================] - 109s 68ms/step - loss: 0.1447 - acc: 0.9556 - val_loss: 1.3939 - val_acc: 0.9025\n",
            "Epoch 4/12\n",
            "1600/1600 [==============================] - 109s 68ms/step - loss: 0.0694 - acc: 0.9806 - val_loss: 0.4739 - val_acc: 0.9400\n",
            "Epoch 5/12\n",
            "1600/1600 [==============================] - 109s 68ms/step - loss: 0.0614 - acc: 0.9806 - val_loss: 0.0196 - val_acc: 0.9950\n",
            "Epoch 6/12\n",
            "1600/1600 [==============================] - 109s 68ms/step - loss: 0.0317 - acc: 0.9931 - val_loss: 0.0109 - val_acc: 0.9975\n",
            "Epoch 7/12\n",
            "1600/1600 [==============================] - 109s 68ms/step - loss: 0.0261 - acc: 0.9937 - val_loss: 0.0045 - val_acc: 0.9975\n",
            "Epoch 8/12\n",
            "1600/1600 [==============================] - 109s 68ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
            "Epoch 9/12\n",
            "1600/1600 [==============================] - 109s 68ms/step - loss: 0.0431 - acc: 0.9900 - val_loss: 0.0117 - val_acc: 0.9950\n",
            "Epoch 10/12\n",
            "1600/1600 [==============================] - 109s 68ms/step - loss: 0.0342 - acc: 0.9906 - val_loss: 0.0165 - val_acc: 0.9975\n",
            "Epoch 11/12\n",
            "1600/1600 [==============================] - 110s 69ms/step - loss: 0.0249 - acc: 0.9950 - val_loss: 0.0037 - val_acc: 0.9975\n",
            "Epoch 12/12\n",
            "1600/1600 [==============================] - 110s 68ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0062 - val_acc: 0.9975\n",
            "Compiling Pretrained xception Model\n",
            "Training Pretrained xception Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/12\n",
            "1600/1600 [==============================] - 123s 77ms/step - loss: 0.3176 - acc: 0.8975 - val_loss: 1.0454 - val_acc: 0.6425\n",
            "Epoch 2/12\n",
            "1600/1600 [==============================] - 112s 70ms/step - loss: 0.1849 - acc: 0.9463 - val_loss: 3.8816 - val_acc: 0.7350\n",
            "Epoch 3/12\n",
            "1600/1600 [==============================] - 112s 70ms/step - loss: 0.1304 - acc: 0.9587 - val_loss: 0.0139 - val_acc: 0.9975\n",
            "Epoch 4/12\n",
            "1600/1600 [==============================] - 112s 70ms/step - loss: 0.0433 - acc: 0.9919 - val_loss: 0.0162 - val_acc: 0.9975\n",
            "Epoch 5/12\n",
            "1600/1600 [==============================] - 112s 70ms/step - loss: 0.0514 - acc: 0.9838 - val_loss: 0.1380 - val_acc: 0.9550\n",
            "Epoch 6/12\n",
            "1600/1600 [==============================] - 112s 70ms/step - loss: 0.0589 - acc: 0.9806 - val_loss: 0.0165 - val_acc: 0.9975\n",
            "Epoch 7/12\n",
            "1600/1600 [==============================] - 112s 70ms/step - loss: 0.0213 - acc: 0.9925 - val_loss: 0.0154 - val_acc: 0.9950\n",
            "Epoch 8/12\n",
            " 928/1600 [================>.............] - ETA: 44s - loss: 0.0894 - acc: 0.9838"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eA9GZhLGe5X9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "# print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "# model.fit(X_train, Y_train,\n",
        "#           batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "#           validation_data=(X_test, Y_test))\n",
        "\n",
        "# Y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qexmaPZVz04q",
        "colab_type": "code",
        "collapsed": true,
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.plot(Y_test[:, 1], 'r')\n",
        "\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.plot(Y_pred[:, 1], 'b')\n",
        "\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.plot(Y_test[:, 1] - Y_pred[:, 1], 'g')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IPTFOJh3DTgq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "now = datetime.datetime.now()\n",
        "\n",
        "# modelSaved = '{}-{}_{}_{}.h5'.format(folderNormal, folderFault, pretrainedModel, now.strftime('%m-%d-%H:%M:%S'))\n",
        "\n",
        "modelSaved = '{}-{}_{}_{}.h5'.format('A1', 'A5', pretrainedModel, now.strftime('%m-%d-%H:%M:%S'))\n",
        "meanSaved = 'mean_{}.npy'.format(now.strftime('%m-%d-%H:%M:%S'))\n",
        "stdSaved = 'std_{}.npy'.format(now.strftime('%m-%d-%H:%M:%S'))\n",
        "\n",
        "inputStr = input('''Save Model as '{}'? (y/n)\\n'''.format(modelSaved))\n",
        "\n",
        "if (inputStr == 'y' or inputStr == 'Y'):  \n",
        "    model.save('gdrive/My Drive/Colab/Model/{}'.format(modelSaved))\n",
        "    np.save('gdrive/My Drive/Colab/Model/{}'.format(meanSaved), trainMean)\n",
        "    np.save('gdrive/My Drive/Colab/Model/{}'.format(stdSaved), trainStd)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}