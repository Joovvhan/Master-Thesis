{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning Clean Up.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joovvhan/Master-Thesis/blob/master/log/F1-F5_Xception.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "c3821KWLNey6",
        "colab_type": "code",
        "outputId": "0c3cacbf-3613-4ed1-8091-0b43092b3a27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Import necessary modules\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy.io.wavfile as wf\n",
        "import time\n",
        "import glob\n",
        "import datetime\n",
        "\n",
        "from tqdm import trange\n",
        "\n",
        "# Import Keras modules\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.layers import Input, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
        "from keras.models import Sequential\n",
        "from keras import backend as K\n",
        "from keras.models import load_model\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "nxSASpgF7unA",
        "colab_type": "code",
        "outputId": "9d258065-54be-475f-d605-f28ec7717503",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "cell_type": "code",
      "source": [
        "# Mount google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "os.listdir('gdrive/My Drive/Colab')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Data', 'Model', 'Data_']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "rw9NU8Xjwcz2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set data directories\n",
        "\n",
        "dataPath = 'gdrive/My Drive/Colab/Data'\n",
        "\n",
        "# Changed variable names to normal and fault\n",
        "# Changed variable names from folder to path\n",
        "# Need to consider multiple folders\n",
        "# Need to add files to be tested\n",
        "\n",
        "#folderNormal = ['A1F3P3']\n",
        "folderNormal = list()\n",
        "\n",
        "for x in range(1, 6):\n",
        "    for y in range(1, 2):\n",
        "        for z in range(1, 6):\n",
        "            #if (x <= 2 and y <= 2 and z <= 2):\n",
        "            folderNormal.append('A{}F{}P{}'.format(x, y, z))\n",
        "\n",
        "folderFault = list()\n",
        "\n",
        "# folderFault = ['A5F3P3']\n",
        "\n",
        "for x in range(1, 6):\n",
        "    for y in range(5, 6):\n",
        "        for z in range(1, 6):\n",
        "            #if (x == 5 or y == 5 or z == 5):\n",
        "            folderFault.append('A{}F{}P{}'.format(x, y, z))\n",
        "\n",
        "\n",
        "pathNormal = list()\n",
        "pathFault = list()\n",
        "\n",
        "for i in range(len(folderNormal)):\n",
        "    pathNormal.append(dataPath + '/' + folderNormal[i])\n",
        "    \n",
        "for i in range(len(folderFault)):\n",
        "    pathFault.append(dataPath + '/' + folderFault[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xgGP7PZO-rTA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Specgram settings\n",
        "\n",
        "nsc = 1470\n",
        "nov = nsc/2\n",
        "nff = nsc \n",
        "imgSize = 224\n",
        "\n",
        "# pretrainedModel = 'VGG19'\n",
        "pretrainedModel = 'Xception'\n",
        "# pretrainedModel = 'ResNet50'\n",
        "\n",
        "# pretrainedModel = 'VGG19'\n",
        "# pretrainedModel = 'InceptionV3'\n",
        "# pretrainedModel = 'DenseNet169'\n",
        "# pretrainedModel = 'DenseNet201'\n",
        "\n",
        "\n",
        "lastActivation = 'softmax'\n",
        "sizeBatch = 4\n",
        "numEpochs = 8\n",
        "verb = 1\n",
        "\n",
        "\n",
        "# Learning parameters\n",
        "\n",
        "trainingRatio = 0.8\n",
        "\n",
        "totalDataNum = 1000\n",
        "repeat = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5AskF2qFT2xr",
        "colab_type": "code",
        "outputId": "52ed69ad-8db2-450a-8177-30fb7ca51954",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "cell_type": "code",
      "source": [
        "startNum = 0\n",
        "\n",
        "pickNum = int(np.ceil(totalDataNum / len(pathNormal)))\n",
        "\n",
        "for i in range(startNum, len(pathNormal)):\n",
        "\n",
        "    npyTestPath = glob.glob(pathNormal[i] + '/' + '*Image_With_Label.npy')\n",
        "    data = np.load(npyTestPath[0])\n",
        "    \n",
        "    pickIdx = np.random.choice(1000, pickNum, replace=False)\n",
        "    pickIdx.sort()\n",
        "    \n",
        "#     imgs = np.moveaxis(np.dstack(data[:, 0]), 2, 0)\n",
        "#     label = data[:, 1:5]\n",
        "\n",
        "    imgs = np.moveaxis(np.dstack(data[pickIdx, 0]), 2, 0)\n",
        "    label = data[pickIdx, 1:5]\n",
        "    \n",
        "    if i == startNum:\n",
        "        labelListNormal = label\n",
        "        imgsNormal = imgs\n",
        "    else:\n",
        "        labelListNormal = np.vstack([labelListNormal, label])\n",
        "        imgsNormal = np.vstack([imgsNormal, imgs])\n",
        "\n",
        "    print('Normal Image Shape From {}: {}:'.format(pathNormal[i], totalDataNum))    \n",
        "    print('Selected {}/{}:'.format(pickNum * (i + 1), len(data)))    \n",
        "    \n",
        "    \n",
        "print('Normal Image Shape: {}'.format(imgsNormal.shape))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A1F1P1: 1000:\n",
            "Selected 40/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A1F1P2: 1000:\n",
            "Selected 80/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A1F1P3: 1000:\n",
            "Selected 120/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A1F1P4: 1000:\n",
            "Selected 160/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A1F1P5: 1000:\n",
            "Selected 200/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A2F1P1: 1000:\n",
            "Selected 240/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A2F1P2: 1000:\n",
            "Selected 280/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A2F1P3: 1000:\n",
            "Selected 320/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A2F1P4: 1000:\n",
            "Selected 360/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A2F1P5: 1000:\n",
            "Selected 400/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A3F1P1: 1000:\n",
            "Selected 440/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A3F1P2: 1000:\n",
            "Selected 480/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A3F1P3: 1000:\n",
            "Selected 520/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A3F1P4: 1000:\n",
            "Selected 560/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A3F1P5: 1000:\n",
            "Selected 600/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A4F1P1: 1000:\n",
            "Selected 640/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A4F1P2: 1000:\n",
            "Selected 680/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A4F1P3: 1000:\n",
            "Selected 720/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A4F1P4: 1000:\n",
            "Selected 760/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A4F1P5: 1000:\n",
            "Selected 800/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A5F1P1: 1000:\n",
            "Selected 840/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A5F1P2: 1000:\n",
            "Selected 880/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A5F1P3: 1000:\n",
            "Selected 920/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A5F1P4: 1000:\n",
            "Selected 960/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A5F1P5: 1000:\n",
            "Selected 1000/1000:\n",
            "Normal Image Shape: (1000, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P_MZtpk3Br_i",
        "colab_type": "code",
        "outputId": "5e85e080-c866-4256-af8d-6384628b03d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "cell_type": "code",
      "source": [
        "startNum = 0\n",
        "\n",
        "pickNum = int(np.ceil(totalDataNum / len(pathFault)))\n",
        "\n",
        "for i in range(startNum, len(pathFault)):\n",
        "\n",
        "    npyTestPath = glob.glob(pathFault[i] + '/' + '*Image_With_Label.npy')\n",
        "    data = np.load(npyTestPath[0])\n",
        "    \n",
        "    pickIdx = np.random.choice(1000, pickNum, replace=False)\n",
        "    pickIdx.sort()\n",
        "    \n",
        "#     imgs = np.moveaxis(np.dstack(data[:, 0]), 2, 0)\n",
        "#     label = data[:, 1:5]\n",
        "    \n",
        "    imgs = np.moveaxis(np.dstack(data[pickIdx, 0]), 2, 0)\n",
        "    label = data[pickIdx, 1:5]\n",
        "    \n",
        "    if i == startNum:\n",
        "        labelListFault = label\n",
        "        imgsFault = imgs\n",
        "    else:\n",
        "        labelListFault = np.vstack([labelListFault, label])\n",
        "        imgsFault = np.vstack([imgsFault, imgs])\n",
        "\n",
        "    print('Fault Image Shape From {}: {}:'.format(pathFault[i], totalDataNum))    \n",
        "    print('Selected {}/{}:'.format(pickNum * (i + 1), len(data)))     \n",
        "    \n",
        "print('Fault Image Shape: {}'.format(imgsFault.shape))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A1F5P1: 1000:\n",
            "Selected 40/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A1F5P2: 1000:\n",
            "Selected 80/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A1F5P3: 1000:\n",
            "Selected 120/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A1F5P4: 1000:\n",
            "Selected 160/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A1F5P5: 1000:\n",
            "Selected 200/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A2F5P1: 1000:\n",
            "Selected 240/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A2F5P2: 1000:\n",
            "Selected 280/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A2F5P3: 1000:\n",
            "Selected 320/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A2F5P4: 1000:\n",
            "Selected 360/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A2F5P5: 1000:\n",
            "Selected 400/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A3F5P1: 1000:\n",
            "Selected 440/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A3F5P2: 1000:\n",
            "Selected 480/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A3F5P3: 1000:\n",
            "Selected 520/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A3F5P4: 1000:\n",
            "Selected 560/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A3F5P5: 1000:\n",
            "Selected 600/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A4F5P1: 1000:\n",
            "Selected 640/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A4F5P2: 1000:\n",
            "Selected 680/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A4F5P3: 1000:\n",
            "Selected 720/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A4F5P4: 1000:\n",
            "Selected 760/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A4F5P5: 1000:\n",
            "Selected 800/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A5F5P1: 1000:\n",
            "Selected 840/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A5F5P2: 1000:\n",
            "Selected 880/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A5F5P3: 1000:\n",
            "Selected 920/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A5F5P4: 1000:\n",
            "Selected 960/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A5F5P5: 1000:\n",
            "Selected 1000/1000:\n",
            "Fault Image Shape: (1000, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e91QsAurSkIP",
        "colab_type": "code",
        "outputId": "6b54c9ad-27a0-445a-d07f-73be1521da5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "cell_type": "code",
      "source": [
        "# Change name from imgsF1 or imgsF5 to imgsNormal and imgsFault\n",
        "\n",
        "dataNumNormal = len(imgsNormal)\n",
        "dataNumFault = len(imgsFault)\n",
        "dataNumNormalTrain = int(dataNumNormal * trainingRatio)\n",
        "dataNumFaultTrain = int(dataNumFault * trainingRatio)\n",
        "dataNumNormalTest = dataNumNormal - dataNumNormalTrain\n",
        "dataNumFaultTest = dataNumFault - dataNumFaultTrain\n",
        "\n",
        "print('Normal Train:Test = {:d}:{:d}'.format(dataNumNormalTrain, dataNumNormalTest))\n",
        "print('Fault  Train:Test = {:d}:{:d}\\n'.format(dataNumFaultTrain, dataNumFaultTest))\n",
        "\n",
        "trainIdxNormal = np.random.choice(dataNumNormal - 1, dataNumNormalTrain, replace=False)\n",
        "testIdxNormal = list(set(range(0, dataNumNormal)) - set(trainIdxNormal))\n",
        "\n",
        "trainImgsNormal = imgsNormal[trainIdxNormal, :, :]\n",
        "testImgsNormal = imgsNormal[testIdxNormal, :, :]\n",
        "\n",
        "print('Normal Training Image Shape {}'.format(trainImgsNormal.shape))\n",
        "print('Normal Test Image Shape {}\\n'.format(testImgsNormal.shape))\n",
        "\n",
        "trainIdxFault  = np.random.choice(dataNumFault - 1, dataNumFaultTrain, replace=False)\n",
        "testIdxFault = list(set(range(0, dataNumFault)) - set(trainIdxFault))\n",
        "\n",
        "trainImgsFault = imgsFault[trainIdxFault, :, :]\n",
        "testImgsFault = imgsFault[testIdxFault, :, :]\n",
        "\n",
        "print('Fault Training Image Shape {}'.format(trainImgsFault.shape))\n",
        "print('Fault Test Image Shape {}\\n'.format(testImgsFault.shape))\n",
        "\n",
        "trainImgs = np.vstack([trainImgsNormal, trainImgsFault])\n",
        "testImgs = np.vstack([testImgsNormal, testImgsFault])\n",
        "\n",
        "print('Training Image Shape {}'.format(trainImgs.shape))\n",
        "print('Test Image Shape {}'.format(testImgs.shape))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal Train:Test = 800:200\n",
            "Fault  Train:Test = 800:200\n",
            "\n",
            "Normal Training Image Shape (800, 224, 224)\n",
            "Normal Test Image Shape (200, 224, 224)\n",
            "\n",
            "Fault Training Image Shape (800, 224, 224)\n",
            "Fault Test Image Shape (200, 224, 224)\n",
            "\n",
            "Training Image Shape (1600, 224, 224)\n",
            "Test Image Shape (400, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MoE7f_hzs0av",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "feQ_AHAcUgHD",
        "colab_type": "code",
        "outputId": "579301b7-8bcc-4925-984f-f9023072cb6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "trainMean = np.mean(trainImgs)\n",
        "trainStd = np.std(trainImgs)\n",
        "\n",
        "print('Mean of Training Image: {}'.format(trainMean))\n",
        "print('Standard Deviation of Training Image: {}'.format(trainStd))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean of Training Image: -78.28638841210112\n",
            "Standard Deviation of Training Image: 9.32760295541255\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wUi9IuXNUpir",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Should Change Norm to Normalized\n",
        "\n",
        "trainImgsNorm = (trainImgs - trainMean) / trainStd\n",
        "testImgsNorm = (testImgs - trainMean) / trainStd\n",
        "\n",
        "trainImgsNorm = trainImgsNorm.reshape(list(trainImgsNorm.shape) + [1])\n",
        "testImgsNorm = testImgsNorm.reshape(list(testImgsNorm.shape) + [1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aklxiPz1Ve4n",
        "colab_type": "code",
        "outputId": "fde52e4d-7af3-4991-8a4e-b947bc320dfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = np.stack([trainImgsNorm[:, :, :, 0], trainImgsNorm[:, :, :, 0], trainImgsNorm[:, :, :, 0]], axis = -1)\n",
        "X_test = np.stack([testImgsNorm[:, :, :, 0], testImgsNorm[:, :, :, 0], testImgsNorm[:, :, :, 0]], axis = -1)\n",
        "\n",
        "print('X_train Shape: {}'.format(X_train.shape))\n",
        "print('X_test  Shape: {}'.format(X_test.shape))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train Shape: (1600, 224, 224, 3)\n",
            "X_test  Shape: (400, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sRgIPzT7K_YP",
        "colab_type": "code",
        "outputId": "fa3a4bb6-1f9d-4723-ac00-133bdf6e18d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "trainLabelNormal = np.stack((np.ones(dataNumNormalTrain), np.zeros(dataNumNormalTrain)), axis = -1)\n",
        "testLabelNormal = np.stack((np.ones(dataNumNormalTest), np.zeros(dataNumNormalTest)), axis = -1)\n",
        "\n",
        "trainLabelFault = np.stack((np.zeros(dataNumFaultTrain), np.ones(dataNumFaultTrain)), axis = -1)\n",
        "testLabelFault = np.stack((np.zeros(dataNumFaultTest), np.ones(dataNumFaultTest)), axis = -1)\n",
        "\n",
        "Y_train = np.vstack((trainLabelNormal, trainLabelFault))\n",
        "Y_test = np.vstack((testLabelNormal, testLabelFault))\n",
        "\n",
        "print('Y_train Normal:Fault = {:d}:{:d}'.format(len(trainLabelNormal), len(trainLabelFault)))\n",
        "print('Y_test  Normal:Fault = {:d}:{:d}'.format(len(testLabelNormal), len(testLabelFault)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Y_train Normal:Fault = 800:800\n",
            "Y_test  Normal:Fault = 200:200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kczwZk7Tbp5C",
        "colab_type": "code",
        "outputId": "3d47eb32-28a4-4499-dd8f-f669c9655101",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG19\n",
        "from keras.applications import VGG16\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications.densenet import DenseNet169\n",
        "from keras.applications.densenet import DenseNet201\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# pretrainedModel = 'ResNet50'\n",
        "# lastActivation = 'softmax'\n",
        "# lossFunction = 'binary_crossentropy'\n",
        "# sizeBatch = 2\n",
        "# numEpochs = 2\n",
        "# verb = 1\n",
        "\n",
        "for rp in range(repeat):\n",
        "\n",
        "    # Refresh all background variables\n",
        "    K.clear_session()\n",
        "\n",
        "    input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "    # Building sequential model with name 'model'\n",
        "    model = Sequential()\n",
        "\n",
        "    # Model selection\n",
        "\n",
        "    if (pretrainedModel == 'VGG16'):\n",
        "\n",
        "        modelWoTop = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'VGG19'):\n",
        "\n",
        "        modelWoTop = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif pretrainedModel == 'ResNet50':\n",
        "\n",
        "        modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'InceptionV3'):\n",
        "        modelWoTop = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'Xception'):\n",
        "        modelWoTop = Xception(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet169'):\n",
        "\n",
        "        modelWoTop = DenseNet169(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet201'):\n",
        "        modelWoTop = DenseNet201(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    else:\n",
        "        print('Invalid Pretrained Model Selection')\n",
        "\n",
        "\n",
        "\n",
        "    # Model compiling\n",
        "\n",
        "    print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "    print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "    model.fit(X_train, Y_train,\n",
        "              batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "              validation_data=(X_test, Y_test))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 3s 0us/step\n",
            "Compiling Pretrained xception Model\n",
            "Training Pretrained xception Model\n",
            "Batch Size: 4\t Epochs: 8\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/8\n",
            "1600/1600 [==============================] - 117s 73ms/step - loss: 0.4936 - acc: 0.7688 - val_loss: 0.1988 - val_acc: 0.8525\n",
            "Epoch 2/8\n",
            "1600/1600 [==============================] - 105s 65ms/step - loss: 0.2115 - acc: 0.9281 - val_loss: 0.0956 - val_acc: 0.9650\n",
            "Epoch 3/8\n",
            "1600/1600 [==============================] - 105s 65ms/step - loss: 0.0785 - acc: 0.9781 - val_loss: 4.8562 - val_acc: 0.6100\n",
            "Epoch 4/8\n",
            "1600/1600 [==============================] - 105s 65ms/step - loss: 0.0908 - acc: 0.9775 - val_loss: 0.0583 - val_acc: 0.9900\n",
            "Epoch 5/8\n",
            "1600/1600 [==============================] - 104s 65ms/step - loss: 0.0451 - acc: 0.9881 - val_loss: 0.0731 - val_acc: 0.9800\n",
            "Epoch 6/8\n",
            "1600/1600 [==============================] - 104s 65ms/step - loss: 0.0565 - acc: 0.9894 - val_loss: 1.5071 - val_acc: 0.8650\n",
            "Epoch 7/8\n",
            "1600/1600 [==============================] - 104s 65ms/step - loss: 0.0600 - acc: 0.9869 - val_loss: 0.0368 - val_acc: 0.9875\n",
            "Epoch 8/8\n",
            "1600/1600 [==============================] - 105s 65ms/step - loss: 0.0382 - acc: 0.9894 - val_loss: 0.0535 - val_acc: 0.9875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-aE0MIEjuC_k",
        "colab_type": "code",
        "outputId": "e4349760-6247-4e35-a642-38d96ea56291",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "for rp in range(repeat):\n",
        "\n",
        "    # Refresh all background variables\n",
        "    K.clear_session()\n",
        "\n",
        "    input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "    # Building sequential model with name 'model'\n",
        "    model = Sequential()\n",
        "\n",
        "    # Model selection\n",
        "\n",
        "    if (pretrainedModel == 'VGG16'):\n",
        "\n",
        "        modelWoTop = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'VGG19'):\n",
        "\n",
        "        modelWoTop = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif pretrainedModel == 'ResNet50':\n",
        "\n",
        "        modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'InceptionV3'):\n",
        "        modelWoTop = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'Xception'):\n",
        "        modelWoTop = Xception(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet169'):\n",
        "\n",
        "        modelWoTop = DenseNet169(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet201'):\n",
        "        modelWoTop = DenseNet201(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    else:\n",
        "        print('Invalid Pretrained Model Selection')\n",
        "\n",
        "\n",
        "\n",
        "    # Model compiling\n",
        "\n",
        "    print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "    print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "    model.fit(X_train, Y_train,\n",
        "              batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "              validation_data=(X_test, Y_test))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compiling Pretrained xception Model\n",
            "Training Pretrained xception Model\n",
            "Batch Size: 4\t Epochs: 8\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/8\n",
            "1600/1600 [==============================] - 114s 71ms/step - loss: 0.3493 - acc: 0.8800 - val_loss: 0.5579 - val_acc: 0.8875\n",
            "Epoch 2/8\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.2145 - acc: 0.9356 - val_loss: 0.1353 - val_acc: 0.9625\n",
            "Epoch 3/8\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.1587 - acc: 0.9569 - val_loss: 0.0731 - val_acc: 0.9825\n",
            "Epoch 4/8\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.1201 - acc: 0.9700 - val_loss: 6.0783 - val_acc: 0.5975\n",
            "Epoch 5/8\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.1007 - acc: 0.9806 - val_loss: 0.0348 - val_acc: 0.9925\n",
            "Epoch 6/8\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.0523 - acc: 0.9887 - val_loss: 0.0570 - val_acc: 0.9850\n",
            "Epoch 7/8\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.0505 - acc: 0.9887 - val_loss: 0.1759 - val_acc: 0.9650\n",
            "Epoch 8/8\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.0455 - acc: 0.9869 - val_loss: 0.0452 - val_acc: 0.9900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "15t3_glRqbHT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "e2c86b0f-a0a8-4548-87c5-20d87d90a0f4"
      },
      "cell_type": "code",
      "source": [
        "# Refresh all background variables\n",
        "K.clear_session()\n",
        "\n",
        "input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "# Building sequential model with name 'model'\n",
        "model = Sequential()\n",
        "\n",
        "# Model selection\n",
        "\n",
        "if (pretrainedModel == 'VGG16'):\n",
        "\n",
        "    modelWoTop = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'VGG19'):\n",
        "\n",
        "    modelWoTop = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif pretrainedModel == 'ResNet50':\n",
        "\n",
        "    modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'InceptionV3'):\n",
        "    modelWoTop = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'Xception'):\n",
        "    modelWoTop = Xception(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'DenseNet169'):\n",
        "\n",
        "    modelWoTop = DenseNet169(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'DenseNet201'):\n",
        "    modelWoTop = DenseNet201(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "else:\n",
        "    print('Invalid Pretrained Model Selection')\n",
        "\n",
        "\n",
        "\n",
        "# Model compiling\n",
        "\n",
        "print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compiling Pretrained xception Model\n",
            "Training Pretrained xception Model\n",
            "Batch Size: 4\t Epochs: 8\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/8\n",
            "1600/1600 [==============================] - 115s 72ms/step - loss: 0.4018 - acc: 0.8706 - val_loss: 1.6985 - val_acc: 0.7925\n",
            "Epoch 2/8\n",
            "1600/1600 [==============================] - 103s 65ms/step - loss: 0.1739 - acc: 0.9438 - val_loss: 0.1099 - val_acc: 0.9850\n",
            "Epoch 3/8\n",
            "1600/1600 [==============================] - 104s 65ms/step - loss: 0.1016 - acc: 0.9688 - val_loss: 0.5147 - val_acc: 0.8475\n",
            "Epoch 4/8\n",
            "1600/1600 [==============================] - 104s 65ms/step - loss: 0.1296 - acc: 0.9663 - val_loss: 0.0488 - val_acc: 0.9875\n",
            "Epoch 5/8\n",
            "1600/1600 [==============================] - 104s 65ms/step - loss: 0.1145 - acc: 0.9656 - val_loss: 0.0617 - val_acc: 0.9825\n",
            "Epoch 6/8\n",
            "1600/1600 [==============================] - 104s 65ms/step - loss: 0.0801 - acc: 0.9794 - val_loss: 0.0469 - val_acc: 0.9850\n",
            "Epoch 7/8\n",
            "1600/1600 [==============================] - 104s 65ms/step - loss: 0.0688 - acc: 0.9825 - val_loss: 0.0732 - val_acc: 0.9750\n",
            "Epoch 8/8\n",
            "1600/1600 [==============================] - 104s 65ms/step - loss: 0.0352 - acc: 0.9912 - val_loss: 0.0516 - val_acc: 0.9800\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0c9735e470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "JJoK167dqbdS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "89c05ebf-4038-4392-950b-8e6e5c5bad6d"
      },
      "cell_type": "code",
      "source": [
        "K.clear_session()\n",
        "\n",
        "input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "# Building sequential model with name 'model'\n",
        "model = Sequential()\n",
        "\n",
        "# Model selection\n",
        "\n",
        "if (pretrainedModel == 'VGG16'):\n",
        "\n",
        "    modelWoTop = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'VGG19'):\n",
        "\n",
        "    modelWoTop = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif pretrainedModel == 'ResNet50':\n",
        "\n",
        "    modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'InceptionV3'):\n",
        "    modelWoTop = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'Xception'):\n",
        "    modelWoTop = Xception(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'DenseNet169'):\n",
        "\n",
        "    modelWoTop = DenseNet169(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'DenseNet201'):\n",
        "    modelWoTop = DenseNet201(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "else:\n",
        "    print('Invalid Pretrained Model Selection')\n",
        "\n",
        "\n",
        "\n",
        "# Model compiling\n",
        "\n",
        "print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compiling Pretrained xception Model\n",
            "Training Pretrained xception Model\n",
            "Batch Size: 4\t Epochs: 8\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/8\n",
            "1600/1600 [==============================] - 115s 72ms/step - loss: 0.3617 - acc: 0.8856 - val_loss: 0.8175 - val_acc: 0.5600\n",
            "Epoch 2/8\n",
            "1600/1600 [==============================] - 104s 65ms/step - loss: 0.1378 - acc: 0.9631 - val_loss: 0.0381 - val_acc: 0.9925\n",
            "Epoch 3/8\n",
            "1600/1600 [==============================] - 104s 65ms/step - loss: 0.1097 - acc: 0.9669 - val_loss: 0.0686 - val_acc: 0.9875\n",
            "Epoch 4/8\n",
            "1600/1600 [==============================] - 104s 65ms/step - loss: 0.0728 - acc: 0.9819 - val_loss: 0.0611 - val_acc: 0.9875\n",
            "Epoch 5/8\n",
            "1600/1600 [==============================] - 104s 65ms/step - loss: 0.0510 - acc: 0.9875 - val_loss: 0.0455 - val_acc: 0.9875\n",
            "Epoch 6/8\n",
            "1600/1600 [==============================] - 104s 65ms/step - loss: 0.0434 - acc: 0.9919 - val_loss: 0.0553 - val_acc: 0.9825\n",
            "Epoch 7/8\n",
            "1600/1600 [==============================] - 104s 65ms/step - loss: 0.0321 - acc: 0.9950 - val_loss: 0.0256 - val_acc: 0.9925\n",
            "Epoch 8/8\n",
            "1600/1600 [==============================] - 104s 65ms/step - loss: 0.0245 - acc: 0.9925 - val_loss: 0.0972 - val_acc: 0.9775\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0c8d615780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "eA9GZhLGe5X9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "# print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "# model.fit(X_train, Y_train,\n",
        "#           batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "#           validation_data=(X_test, Y_test))\n",
        "\n",
        "# Y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qexmaPZVz04q",
        "colab_type": "code",
        "outputId": "c59acfff-1cd1-4e13-deb2-a39427e436f3",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "cell_type": "code",
      "source": [
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.plot(Y_test[:, 1], 'r')\n",
        "\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.plot(Y_pred[:, 1], 'b')\n",
        "\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.plot(Y_test[:, 1] - Y_pred[:, 1], 'g')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFKCAYAAAAqkecjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIBAIBHHifwER4s1jamye0QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f0cb3095160>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "IPTFOJh3DTgq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "2eb15863-4eb6-4ca0-c0af-dadc0864a265"
      },
      "cell_type": "code",
      "source": [
        "now = datetime.datetime.now()\n",
        "\n",
        "modelSaved = '{}-{}_{}_{}.h5'.format(folderNormal, folderFault, pretrainedModel, now.strftime('%m-%d-%H:%M:%S'))\n",
        "\n",
        "modelSaved = '{}-{}_{}_{}.h5'.format('F1', 'F5', pretrainedModel, now.strftime('%m-%d-%H:%M:%S'))\n",
        "meanSaved = 'mean_{}.npy'.format(now.strftime('%m-%d-%H:%M:%S'))\n",
        "stdSaved = 'std_{}.npy'.format(now.strftime('%m-%d-%H:%M:%S'))\n",
        "\n",
        "inputStr = input('''Save Model as '{}'? (y/n)\\n'''.format(modelSaved))\n",
        "\n",
        "if (inputStr == 'y' or inputStr == 'Y'):  \n",
        "    model.save('gdrive/My Drive/Colab/Model/{}'.format(modelSaved))\n",
        "    np.save('gdrive/My Drive/Colab/Model/{}'.format(meanSaved), trainMean)\n",
        "    np.save('gdrive/My Drive/Colab/Model/{}'.format(stdSaved), trainStd)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Save Model as 'F1-F5_Xception_11-20-12:22:50.h5'? (y/n)\n",
            "y\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}