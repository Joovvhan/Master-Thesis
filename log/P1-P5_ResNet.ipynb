{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning Clean Up.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joovvhan/Master-Thesis/blob/master/log/P1-P5_ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "c3821KWLNey6",
        "colab_type": "code",
        "outputId": "7c3b3413-d6f8-4960-cf9c-8fffd5c09137",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Import necessary modules\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy.io.wavfile as wf\n",
        "import time\n",
        "import glob\n",
        "import datetime\n",
        "\n",
        "from tqdm import trange\n",
        "\n",
        "# Import Keras modules\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.layers import Input, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
        "from keras.models import Sequential\n",
        "from keras import backend as K\n",
        "from keras.models import load_model\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "nxSASpgF7unA",
        "colab_type": "code",
        "outputId": "4d456863-563c-49ec-e30d-8f1a0ebfae54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "cell_type": "code",
      "source": [
        "# Mount google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "os.listdir('gdrive/My Drive/Colab')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Data', 'Model', 'Data_']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "rw9NU8Xjwcz2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set data directories\n",
        "\n",
        "dataPath = 'gdrive/My Drive/Colab/Data'\n",
        "\n",
        "# Changed variable names to normal and fault\n",
        "# Changed variable names from folder to path\n",
        "# Need to consider multiple folders\n",
        "# Need to add files to be tested\n",
        "\n",
        "#folderNormal = ['A1F3P3']\n",
        "folderNormal = list()\n",
        "\n",
        "for x in range(1, 6):\n",
        "    for y in range(1, 6):\n",
        "        for z in range(1, 2):\n",
        "            #if (x <= 2 and y <= 2 and z <= 2):\n",
        "            folderNormal.append('A{}F{}P{}'.format(x, y, z))\n",
        "\n",
        "folderFault = list()\n",
        "\n",
        "# folderFault = ['A5F3P3']\n",
        "\n",
        "for x in range(1, 6):\n",
        "    for y in range(1, 6):\n",
        "        for z in range(5, 6):\n",
        "            #if (x == 5 or y == 5 or z == 5):\n",
        "            folderFault.append('A{}F{}P{}'.format(x, y, z))\n",
        "\n",
        "\n",
        "pathNormal = list()\n",
        "pathFault = list()\n",
        "\n",
        "for i in range(len(folderNormal)):\n",
        "    pathNormal.append(dataPath + '/' + folderNormal[i])\n",
        "    \n",
        "for i in range(len(folderFault)):\n",
        "    pathFault.append(dataPath + '/' + folderFault[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xgGP7PZO-rTA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Specgram settings\n",
        "\n",
        "nsc = 1470\n",
        "nov = nsc/2\n",
        "nff = nsc \n",
        "imgSize = 224\n",
        "\n",
        "# pretrainedModel = 'VGG19'\n",
        "# pretrainedModel = 'Xception'\n",
        "pretrainedModel = 'ResNet50'\n",
        "\n",
        "# pretrainedModel = 'VGG19'\n",
        "# pretrainedModel = 'InceptionV3'\n",
        "#pretrainedModel = 'DenseNet169'\n",
        "#pretrainedModel = 'DenseNet201'\n",
        "\n",
        "\n",
        "lastActivation = 'softmax'\n",
        "sizeBatch = 4\n",
        "numEpochs = 16\n",
        "verb = 1\n",
        "\n",
        "\n",
        "# Learning parameters\n",
        "\n",
        "trainingRatio = 0.8\n",
        "\n",
        "totalDataNum = 1000\n",
        "repeat = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5AskF2qFT2xr",
        "colab_type": "code",
        "outputId": "4d3c39f2-0549-4aaf-9c15-d09565a89d40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "cell_type": "code",
      "source": [
        "startNum = 0\n",
        "\n",
        "pickNum = int(np.ceil(totalDataNum / len(pathNormal)))\n",
        "\n",
        "for i in range(startNum, len(pathNormal)):\n",
        "\n",
        "    npyTestPath = glob.glob(pathNormal[i] + '/' + '*Image_With_Label.npy')\n",
        "    data = np.load(npyTestPath[0])\n",
        "    \n",
        "    pickIdx = np.random.choice(1000, pickNum, replace=False)\n",
        "    pickIdx.sort()\n",
        "    \n",
        "#     imgs = np.moveaxis(np.dstack(data[:, 0]), 2, 0)\n",
        "#     label = data[:, 1:5]\n",
        "\n",
        "    imgs = np.moveaxis(np.dstack(data[pickIdx, 0]), 2, 0)\n",
        "    label = data[pickIdx, 1:5]\n",
        "    \n",
        "    if i == startNum:\n",
        "        labelListNormal = label\n",
        "        imgsNormal = imgs\n",
        "    else:\n",
        "        labelListNormal = np.vstack([labelListNormal, label])\n",
        "        imgsNormal = np.vstack([imgsNormal, imgs])\n",
        "\n",
        "    print('Normal Image Shape From {}: {}:'.format(pathNormal[i], totalDataNum))    \n",
        "    print('Selected {}/{}:'.format(pickNum * (i + 1), len(data)))    \n",
        "    \n",
        "    \n",
        "print('Normal Image Shape: {}'.format(imgsNormal.shape))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A1F1P1: 1000:\n",
            "Selected 40/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A1F2P1: 1000:\n",
            "Selected 80/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A1F3P1: 1000:\n",
            "Selected 120/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A1F4P1: 1000:\n",
            "Selected 160/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A1F5P1: 1000:\n",
            "Selected 200/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A2F1P1: 1000:\n",
            "Selected 240/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A2F2P1: 1000:\n",
            "Selected 280/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A2F3P1: 1000:\n",
            "Selected 320/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A2F4P1: 1000:\n",
            "Selected 360/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A2F5P1: 1000:\n",
            "Selected 400/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A3F1P1: 1000:\n",
            "Selected 440/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A3F2P1: 1000:\n",
            "Selected 480/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A3F3P1: 1000:\n",
            "Selected 520/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A3F4P1: 1000:\n",
            "Selected 560/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A3F5P1: 1000:\n",
            "Selected 600/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A4F1P1: 1000:\n",
            "Selected 640/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A4F2P1: 1000:\n",
            "Selected 680/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A4F3P1: 1000:\n",
            "Selected 720/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A4F4P1: 1000:\n",
            "Selected 760/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A4F5P1: 1000:\n",
            "Selected 800/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A5F1P1: 1000:\n",
            "Selected 840/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A5F2P1: 1000:\n",
            "Selected 880/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A5F3P1: 1000:\n",
            "Selected 920/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A5F4P1: 1000:\n",
            "Selected 960/1000:\n",
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A5F5P1: 1000:\n",
            "Selected 1000/1000:\n",
            "Normal Image Shape: (1000, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P_MZtpk3Br_i",
        "colab_type": "code",
        "outputId": "17762b6f-8c0a-40bb-a1c9-178615e5c24e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "cell_type": "code",
      "source": [
        "startNum = 0\n",
        "\n",
        "pickNum = int(np.ceil(totalDataNum / len(pathFault)))\n",
        "\n",
        "for i in range(startNum, len(pathFault)):\n",
        "\n",
        "    npyTestPath = glob.glob(pathFault[i] + '/' + '*Image_With_Label.npy')\n",
        "    data = np.load(npyTestPath[0])\n",
        "    \n",
        "    pickIdx = np.random.choice(1000, pickNum, replace=False)\n",
        "    pickIdx.sort()\n",
        "    \n",
        "#     imgs = np.moveaxis(np.dstack(data[:, 0]), 2, 0)\n",
        "#     label = data[:, 1:5]\n",
        "    \n",
        "    imgs = np.moveaxis(np.dstack(data[pickIdx, 0]), 2, 0)\n",
        "    label = data[pickIdx, 1:5]\n",
        "    \n",
        "    if i == startNum:\n",
        "        labelListFault = label\n",
        "        imgsFault = imgs\n",
        "    else:\n",
        "        labelListFault = np.vstack([labelListFault, label])\n",
        "        imgsFault = np.vstack([imgsFault, imgs])\n",
        "\n",
        "    print('Fault Image Shape From {}: {}:'.format(pathFault[i], totalDataNum))    \n",
        "    print('Selected {}/{}:'.format(pickNum * (i + 1), len(data)))     \n",
        "    \n",
        "print('Fault Image Shape: {}'.format(imgsFault.shape))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A1F1P5: 1000:\n",
            "Selected 40/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A1F2P5: 1000:\n",
            "Selected 80/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A1F3P5: 1000:\n",
            "Selected 120/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A1F4P5: 1000:\n",
            "Selected 160/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A1F5P5: 1000:\n",
            "Selected 200/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A2F1P5: 1000:\n",
            "Selected 240/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A2F2P5: 1000:\n",
            "Selected 280/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A2F3P5: 1000:\n",
            "Selected 320/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A2F4P5: 1000:\n",
            "Selected 360/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A2F5P5: 1000:\n",
            "Selected 400/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A3F1P5: 1000:\n",
            "Selected 440/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A3F2P5: 1000:\n",
            "Selected 480/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A3F3P5: 1000:\n",
            "Selected 520/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A3F4P5: 1000:\n",
            "Selected 560/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A3F5P5: 1000:\n",
            "Selected 600/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A4F1P5: 1000:\n",
            "Selected 640/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A4F2P5: 1000:\n",
            "Selected 680/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A4F3P5: 1000:\n",
            "Selected 720/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A4F4P5: 1000:\n",
            "Selected 760/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A4F5P5: 1000:\n",
            "Selected 800/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A5F1P5: 1000:\n",
            "Selected 840/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A5F2P5: 1000:\n",
            "Selected 880/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A5F3P5: 1000:\n",
            "Selected 920/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A5F4P5: 1000:\n",
            "Selected 960/1000:\n",
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A5F5P5: 1000:\n",
            "Selected 1000/1000:\n",
            "Fault Image Shape: (1000, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e91QsAurSkIP",
        "colab_type": "code",
        "outputId": "61e83187-306c-417f-ff7e-2c92b94f1cfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "cell_type": "code",
      "source": [
        "# Change name from imgsF1 or imgsF5 to imgsNormal and imgsFault\n",
        "\n",
        "dataNumNormal = len(imgsNormal)\n",
        "dataNumFault = len(imgsFault)\n",
        "dataNumNormalTrain = int(dataNumNormal * trainingRatio)\n",
        "dataNumFaultTrain = int(dataNumFault * trainingRatio)\n",
        "dataNumNormalTest = dataNumNormal - dataNumNormalTrain\n",
        "dataNumFaultTest = dataNumFault - dataNumFaultTrain\n",
        "\n",
        "print('Normal Train:Test = {:d}:{:d}'.format(dataNumNormalTrain, dataNumNormalTest))\n",
        "print('Fault  Train:Test = {:d}:{:d}\\n'.format(dataNumFaultTrain, dataNumFaultTest))\n",
        "\n",
        "trainIdxNormal = np.random.choice(dataNumNormal - 1, dataNumNormalTrain, replace=False)\n",
        "testIdxNormal = list(set(range(0, dataNumNormal)) - set(trainIdxNormal))\n",
        "\n",
        "trainImgsNormal = imgsNormal[trainIdxNormal, :, :]\n",
        "testImgsNormal = imgsNormal[testIdxNormal, :, :]\n",
        "\n",
        "print('Normal Training Image Shape {}'.format(trainImgsNormal.shape))\n",
        "print('Normal Test Image Shape {}\\n'.format(testImgsNormal.shape))\n",
        "\n",
        "trainIdxFault  = np.random.choice(dataNumFault - 1, dataNumFaultTrain, replace=False)\n",
        "testIdxFault = list(set(range(0, dataNumFault)) - set(trainIdxFault))\n",
        "\n",
        "trainImgsFault = imgsFault[trainIdxFault, :, :]\n",
        "testImgsFault = imgsFault[testIdxFault, :, :]\n",
        "\n",
        "print('Fault Training Image Shape {}'.format(trainImgsFault.shape))\n",
        "print('Fault Test Image Shape {}\\n'.format(testImgsFault.shape))\n",
        "\n",
        "trainImgs = np.vstack([trainImgsNormal, trainImgsFault])\n",
        "testImgs = np.vstack([testImgsNormal, testImgsFault])\n",
        "\n",
        "print('Training Image Shape {}'.format(trainImgs.shape))\n",
        "print('Test Image Shape {}'.format(testImgs.shape))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal Train:Test = 800:200\n",
            "Fault  Train:Test = 800:200\n",
            "\n",
            "Normal Training Image Shape (800, 224, 224)\n",
            "Normal Test Image Shape (200, 224, 224)\n",
            "\n",
            "Fault Training Image Shape (800, 224, 224)\n",
            "Fault Test Image Shape (200, 224, 224)\n",
            "\n",
            "Training Image Shape (1600, 224, 224)\n",
            "Test Image Shape (400, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MoE7f_hzs0av",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "feQ_AHAcUgHD",
        "colab_type": "code",
        "outputId": "9875dafd-18d4-4dd8-9bcd-eda62514267e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "trainMean = np.mean(trainImgs)\n",
        "trainStd = np.std(trainImgs)\n",
        "\n",
        "print('Mean of Training Image: {}'.format(trainMean))\n",
        "print('Standard Deviation of Training Image: {}'.format(trainStd))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean of Training Image: -78.3161566226221\n",
            "Standard Deviation of Training Image: 9.335931464786146\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wUi9IuXNUpir",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Should Change Norm to Normalized\n",
        "\n",
        "trainImgsNorm = (trainImgs - trainMean) / trainStd\n",
        "testImgsNorm = (testImgs - trainMean) / trainStd\n",
        "\n",
        "trainImgsNorm = trainImgsNorm.reshape(list(trainImgsNorm.shape) + [1])\n",
        "testImgsNorm = testImgsNorm.reshape(list(testImgsNorm.shape) + [1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aklxiPz1Ve4n",
        "colab_type": "code",
        "outputId": "ecb0b738-3ebf-4232-a396-384a54f7a067",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = np.stack([trainImgsNorm[:, :, :, 0], trainImgsNorm[:, :, :, 0], trainImgsNorm[:, :, :, 0]], axis = -1)\n",
        "X_test = np.stack([testImgsNorm[:, :, :, 0], testImgsNorm[:, :, :, 0], testImgsNorm[:, :, :, 0]], axis = -1)\n",
        "\n",
        "print('X_train Shape: {}'.format(X_train.shape))\n",
        "print('X_test  Shape: {}'.format(X_test.shape))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train Shape: (1600, 224, 224, 3)\n",
            "X_test  Shape: (400, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sRgIPzT7K_YP",
        "colab_type": "code",
        "outputId": "64ed8bb2-d503-4014-a5c9-f6aa2c69c29c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "trainLabelNormal = np.stack((np.ones(dataNumNormalTrain), np.zeros(dataNumNormalTrain)), axis = -1)\n",
        "testLabelNormal = np.stack((np.ones(dataNumNormalTest), np.zeros(dataNumNormalTest)), axis = -1)\n",
        "\n",
        "trainLabelFault = np.stack((np.zeros(dataNumFaultTrain), np.ones(dataNumFaultTrain)), axis = -1)\n",
        "testLabelFault = np.stack((np.zeros(dataNumFaultTest), np.ones(dataNumFaultTest)), axis = -1)\n",
        "\n",
        "Y_train = np.vstack((trainLabelNormal, trainLabelFault))\n",
        "Y_test = np.vstack((testLabelNormal, testLabelFault))\n",
        "\n",
        "print('Y_train Normal:Fault = {:d}:{:d}'.format(len(trainLabelNormal), len(trainLabelFault)))\n",
        "print('Y_test  Normal:Fault = {:d}:{:d}'.format(len(testLabelNormal), len(testLabelFault)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Y_train Normal:Fault = 800:800\n",
            "Y_test  Normal:Fault = 200:200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kczwZk7Tbp5C",
        "colab_type": "code",
        "outputId": "09f5c46b-4677-4c33-f610-18b14c9cacb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG19\n",
        "from keras.applications import VGG16\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications.densenet import DenseNet169\n",
        "from keras.applications.densenet import DenseNet201\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# pretrainedModel = 'ResNet50'\n",
        "# lastActivation = 'softmax'\n",
        "# lossFunction = 'binary_crossentropy'\n",
        "# sizeBatch = 2\n",
        "# numEpochs = 2\n",
        "# verb = 1\n",
        "\n",
        "for rp in range(repeat):\n",
        "\n",
        "    # Refresh all background variables\n",
        "    K.clear_session()\n",
        "\n",
        "    input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "    # Building sequential model with name 'model'\n",
        "    model = Sequential()\n",
        "\n",
        "    # Model selection\n",
        "\n",
        "    if (pretrainedModel == 'VGG16'):\n",
        "\n",
        "        modelWoTop = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'VGG19'):\n",
        "\n",
        "        modelWoTop = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif pretrainedModel == 'ResNet50':\n",
        "\n",
        "        modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'InceptionV3'):\n",
        "        modelWoTop = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'Xception'):\n",
        "        modelWoTop = Xception(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet169'):\n",
        "\n",
        "        modelWoTop = DenseNet169(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet201'):\n",
        "        modelWoTop = DenseNet201(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    else:\n",
        "        print('Invalid Pretrained Model Selection')\n",
        "\n",
        "\n",
        "\n",
        "    # Model compiling\n",
        "\n",
        "    print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "    print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "    model.fit(X_train, Y_train,\n",
        "              batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "              validation_data=(X_test, Y_test))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94658560/94653016 [==============================] - 26s 0us/step\n",
            "Compiling Pretrained resnet50 Model\n",
            "Training Pretrained resnet50 Model\n",
            "Batch Size: 4\t Epochs: 16\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/16\n",
            "1600/1600 [==============================] - 138s 86ms/step - loss: 2.1915 - acc: 0.6750 - val_loss: 0.5641 - val_acc: 0.7775\n",
            "Epoch 2/16\n",
            "1600/1600 [==============================] - 121s 76ms/step - loss: 1.3476 - acc: 0.6825 - val_loss: 0.5829 - val_acc: 0.6975\n",
            "Epoch 3/16\n",
            "1600/1600 [==============================] - 121s 76ms/step - loss: 1.6278 - acc: 0.6481 - val_loss: 6.2513 - val_acc: 0.5925\n",
            "Epoch 4/16\n",
            "1600/1600 [==============================] - 122s 76ms/step - loss: 2.1749 - acc: 0.5681 - val_loss: 1.3201 - val_acc: 0.5650\n",
            "Epoch 5/16\n",
            "1600/1600 [==============================] - 121s 76ms/step - loss: 2.3203 - acc: 0.5619 - val_loss: 3.6929 - val_acc: 0.6275\n",
            "Epoch 6/16\n",
            "1600/1600 [==============================] - 121s 76ms/step - loss: 1.9359 - acc: 0.6150 - val_loss: 2.0289 - val_acc: 0.6125\n",
            "Epoch 7/16\n",
            "1600/1600 [==============================] - 121s 76ms/step - loss: 2.2707 - acc: 0.6225 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 8/16\n",
            "1600/1600 [==============================] - 121s 76ms/step - loss: 1.9848 - acc: 0.5831 - val_loss: 1.0664 - val_acc: 0.5550\n",
            "Epoch 9/16\n",
            "1600/1600 [==============================] - 122s 76ms/step - loss: 2.3325 - acc: 0.5663 - val_loss: 5.6746 - val_acc: 0.5300\n",
            "Epoch 10/16\n",
            "1600/1600 [==============================] - 121s 76ms/step - loss: 2.3777 - acc: 0.5750 - val_loss: 1.3077 - val_acc: 0.5700\n",
            "Epoch 11/16\n",
            "1600/1600 [==============================] - 122s 76ms/step - loss: 2.0611 - acc: 0.5894 - val_loss: 3.0003 - val_acc: 0.5700\n",
            "Epoch 12/16\n",
            "1600/1600 [==============================] - 121s 76ms/step - loss: 2.1873 - acc: 0.5844 - val_loss: 2.1019 - val_acc: 0.5875\n",
            "Epoch 13/16\n",
            "1600/1600 [==============================] - 122s 76ms/step - loss: 2.0127 - acc: 0.6106 - val_loss: 1.3196 - val_acc: 0.5675\n",
            "Epoch 14/16\n",
            "1600/1600 [==============================] - 121s 76ms/step - loss: 1.9271 - acc: 0.6100 - val_loss: 1.4615 - val_acc: 0.5850\n",
            "Epoch 15/16\n",
            "1600/1600 [==============================] - 122s 76ms/step - loss: 1.7987 - acc: 0.6306 - val_loss: 1.5086 - val_acc: 0.5950\n",
            "Epoch 16/16\n",
            "1600/1600 [==============================] - 122s 76ms/step - loss: 1.7456 - acc: 0.6338 - val_loss: 1.1286 - val_acc: 0.6225\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-aE0MIEjuC_k",
        "colab_type": "code",
        "outputId": "e2d378ed-eb31-4e70-e240-c0d02c14dc8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "for rp in range(repeat):\n",
        "\n",
        "    # Refresh all background variables\n",
        "    K.clear_session()\n",
        "\n",
        "    input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "    # Building sequential model with name 'model'\n",
        "    model = Sequential()\n",
        "\n",
        "    # Model selection\n",
        "\n",
        "    if (pretrainedModel == 'VGG16'):\n",
        "\n",
        "        modelWoTop = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'VGG19'):\n",
        "\n",
        "        modelWoTop = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif pretrainedModel == 'ResNet50':\n",
        "\n",
        "        modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'InceptionV3'):\n",
        "        modelWoTop = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'Xception'):\n",
        "        modelWoTop = Xception(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet169'):\n",
        "\n",
        "        modelWoTop = DenseNet169(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet201'):\n",
        "        modelWoTop = DenseNet201(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    else:\n",
        "        print('Invalid Pretrained Model Selection')\n",
        "\n",
        "\n",
        "\n",
        "    # Model compiling\n",
        "\n",
        "    print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "    print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "    model.fit(X_train, Y_train,\n",
        "              batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "              validation_data=(X_test, Y_test))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Compiling Pretrained resnet50 Model\n",
            "Training Pretrained resnet50 Model\n",
            "Batch Size: 4\t Epochs: 16\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/16\n",
            "1600/1600 [==============================] - 135s 84ms/step - loss: 7.8313 - acc: 0.5100 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 2/16\n",
            "1600/1600 [==============================] - 121s 76ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 3/16\n",
            "1600/1600 [==============================] - 121s 76ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 4/16\n",
            "1600/1600 [==============================] - 121s 76ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 5/16\n",
            "1600/1600 [==============================] - 121s 76ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 6/16\n",
            "1600/1600 [==============================] - 121s 76ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 7/16\n",
            "1600/1600 [==============================] - 121s 76ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 8/16\n",
            "1600/1600 [==============================] - 120s 75ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 9/16\n",
            "1600/1600 [==============================] - 120s 75ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 10/16\n",
            "1600/1600 [==============================] - 121s 76ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 11/16\n",
            "1600/1600 [==============================] - 121s 76ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 12/16\n",
            "1600/1600 [==============================] - 121s 76ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 13/16\n",
            "1600/1600 [==============================] - 121s 76ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 14/16\n",
            "1600/1600 [==============================] - 121s 76ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 15/16\n",
            "1600/1600 [==============================] - 121s 76ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 16/16\n",
            "1600/1600 [==============================] - 121s 76ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "15t3_glRqbHT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 757
        },
        "outputId": "ab25b230-3a7b-4398-cbba-da8ce7e6d881"
      },
      "cell_type": "code",
      "source": [
        "# Refresh all background variables\n",
        "K.clear_session()\n",
        "\n",
        "input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "# Building sequential model with name 'model'\n",
        "model = Sequential()\n",
        "\n",
        "# Model selection\n",
        "\n",
        "if (pretrainedModel == 'VGG16'):\n",
        "\n",
        "    modelWoTop = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'VGG19'):\n",
        "\n",
        "    modelWoTop = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif pretrainedModel == 'ResNet50':\n",
        "\n",
        "    modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'InceptionV3'):\n",
        "    modelWoTop = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'Xception'):\n",
        "    modelWoTop = Xception(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'DenseNet169'):\n",
        "\n",
        "    modelWoTop = DenseNet169(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'DenseNet201'):\n",
        "    modelWoTop = DenseNet201(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "else:\n",
        "    print('Invalid Pretrained Model Selection')\n",
        "\n",
        "\n",
        "\n",
        "# Model compiling\n",
        "\n",
        "print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Compiling Pretrained resnet50 Model\n",
            "Training Pretrained resnet50 Model\n",
            "Batch Size: 4\t Epochs: 16\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/16\n",
            "1600/1600 [==============================] - 135s 84ms/step - loss: 8.0099 - acc: 0.4994 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 2/16\n",
            "1600/1600 [==============================] - 122s 76ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 3/16\n",
            "1600/1600 [==============================] - 121s 76ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 4/16\n",
            "1600/1600 [==============================] - 121s 76ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 5/16\n",
            "1600/1600 [==============================] - 121s 76ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 6/16\n",
            "1600/1600 [==============================] - 121s 76ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 7/16\n",
            "1600/1600 [==============================] - 121s 76ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 8/16\n",
            "1600/1600 [==============================] - 121s 76ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 9/16\n",
            "1600/1600 [==============================] - 121s 76ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 10/16\n",
            "1600/1600 [==============================] - 121s 75ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 11/16\n",
            "1600/1600 [==============================] - 120s 75ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 12/16\n",
            "1600/1600 [==============================] - 120s 75ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 13/16\n",
            "1600/1600 [==============================] - 120s 75ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 14/16\n",
            "1600/1600 [==============================] - 120s 75ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 15/16\n",
            "1600/1600 [==============================] - 120s 75ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 16/16\n",
            "1600/1600 [==============================] - 120s 75ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f999b3b4550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "JJoK167dqbdS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 757
        },
        "outputId": "580392e8-aa3f-42b6-e706-7301d343d156"
      },
      "cell_type": "code",
      "source": [
        "K.clear_session()\n",
        "\n",
        "input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "# Building sequential model with name 'model'\n",
        "model = Sequential()\n",
        "\n",
        "# Model selection\n",
        "\n",
        "if (pretrainedModel == 'VGG16'):\n",
        "\n",
        "    modelWoTop = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'VGG19'):\n",
        "\n",
        "    modelWoTop = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif pretrainedModel == 'ResNet50':\n",
        "\n",
        "    modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'InceptionV3'):\n",
        "    modelWoTop = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'Xception'):\n",
        "    modelWoTop = Xception(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'DenseNet169'):\n",
        "\n",
        "    modelWoTop = DenseNet169(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'DenseNet201'):\n",
        "    modelWoTop = DenseNet201(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "else:\n",
        "    print('Invalid Pretrained Model Selection')\n",
        "\n",
        "\n",
        "\n",
        "# Model compiling\n",
        "\n",
        "print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Compiling Pretrained resnet50 Model\n",
            "Training Pretrained resnet50 Model\n",
            "Batch Size: 4\t Epochs: 16\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/16\n",
            "1600/1600 [==============================] - 134s 83ms/step - loss: 8.0173 - acc: 0.4988 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 2/16\n",
            "1600/1600 [==============================] - 121s 75ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 3/16\n",
            "1600/1600 [==============================] - 120s 75ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 4/16\n",
            "1600/1600 [==============================] - 121s 75ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 5/16\n",
            "1600/1600 [==============================] - 121s 75ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 6/16\n",
            "1600/1600 [==============================] - 121s 76ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 7/16\n",
            "1600/1600 [==============================] - 121s 75ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 8/16\n",
            "1600/1600 [==============================] - 120s 75ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 9/16\n",
            "1600/1600 [==============================] - 121s 75ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 10/16\n",
            "1600/1600 [==============================] - 121s 75ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 11/16\n",
            "1600/1600 [==============================] - 121s 76ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 12/16\n",
            "1600/1600 [==============================] - 121s 76ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 13/16\n",
            "1600/1600 [==============================] - 121s 76ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 14/16\n",
            "1600/1600 [==============================] - 121s 76ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 15/16\n",
            "1600/1600 [==============================] - 121s 75ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 16/16\n",
            "1600/1600 [==============================] - 121s 76ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f99997c6550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "z-sV54Vuqbl1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 757
        },
        "outputId": "9144e8bf-d394-491c-c46e-fb2667ac495c"
      },
      "cell_type": "code",
      "source": [
        "K.clear_session()\n",
        "\n",
        "input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "# Building sequential model with name 'model'\n",
        "model = Sequential()\n",
        "\n",
        "# Model selection\n",
        "\n",
        "if (pretrainedModel == 'VGG16'):\n",
        "\n",
        "    modelWoTop = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'VGG19'):\n",
        "\n",
        "    modelWoTop = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif pretrainedModel == 'ResNet50':\n",
        "\n",
        "    modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'InceptionV3'):\n",
        "    modelWoTop = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'Xception'):\n",
        "    modelWoTop = Xception(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'DenseNet169'):\n",
        "\n",
        "    modelWoTop = DenseNet169(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'DenseNet201'):\n",
        "    modelWoTop = DenseNet201(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "else:\n",
        "    print('Invalid Pretrained Model Selection')\n",
        "\n",
        "\n",
        "\n",
        "# Model compiling\n",
        "\n",
        "print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Compiling Pretrained resnet50 Model\n",
            "Training Pretrained resnet50 Model\n",
            "Batch Size: 4\t Epochs: 16\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/16\n",
            "1600/1600 [==============================] - 134s 84ms/step - loss: 7.9780 - acc: 0.5012 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 2/16\n",
            "1600/1600 [==============================] - 121s 75ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 3/16\n",
            "1600/1600 [==============================] - 121s 76ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 4/16\n",
            "1600/1600 [==============================] - 121s 75ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 5/16\n",
            "1600/1600 [==============================] - 121s 76ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 6/16\n",
            "1600/1600 [==============================] - 121s 76ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 7/16\n",
            "1600/1600 [==============================] - 121s 75ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 8/16\n",
            "1600/1600 [==============================] - 121s 76ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 9/16\n",
            "1600/1600 [==============================] - 120s 75ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 10/16\n",
            "1600/1600 [==============================] - 121s 75ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 11/16\n",
            "1600/1600 [==============================] - 121s 76ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 12/16\n",
            "1600/1600 [==============================] - 121s 75ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 13/16\n",
            "1600/1600 [==============================] - 121s 76ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 14/16\n",
            "1600/1600 [==============================] - 121s 75ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 15/16\n",
            "1600/1600 [==============================] - 121s 75ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 16/16\n",
            "1600/1600 [==============================] - 121s 75ms/step - loss: 8.0151 - acc: 0.5000 - val_loss: 8.0151 - val_acc: 0.5000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f998b3109b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "c-TT_erUqbso",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 757
        },
        "outputId": "d1fefc86-9c0b-4fc4-e524-3730cb61c693"
      },
      "cell_type": "code",
      "source": [
        "K.clear_session()\n",
        "\n",
        "input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "# Building sequential model with name 'model'\n",
        "model = Sequential()\n",
        "\n",
        "# Model selection\n",
        "\n",
        "if (pretrainedModel == 'VGG16'):\n",
        "\n",
        "    modelWoTop = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'VGG19'):\n",
        "\n",
        "    modelWoTop = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif pretrainedModel == 'ResNet50':\n",
        "\n",
        "    modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'InceptionV3'):\n",
        "    modelWoTop = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'Xception'):\n",
        "    modelWoTop = Xception(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'DenseNet169'):\n",
        "\n",
        "    modelWoTop = DenseNet169(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'DenseNet201'):\n",
        "    modelWoTop = DenseNet201(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "else:\n",
        "    print('Invalid Pretrained Model Selection')\n",
        "\n",
        "\n",
        "\n",
        "# Model compiling\n",
        "\n",
        "print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Compiling Pretrained resnet50 Model\n",
            "Training Pretrained resnet50 Model\n",
            "Batch Size: 4\t Epochs: 16\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/16\n",
            "1600/1600 [==============================] - 133s 83ms/step - loss: 2.2639 - acc: 0.6794 - val_loss: 0.7009 - val_acc: 0.5000\n",
            "Epoch 2/16\n",
            "1600/1600 [==============================] - 121s 75ms/step - loss: 2.7920 - acc: 0.5006 - val_loss: 0.6940 - val_acc: 0.5000\n",
            "Epoch 3/16\n",
            "1600/1600 [==============================] - 120s 75ms/step - loss: 2.3203 - acc: 0.5212 - val_loss: 2.3277 - val_acc: 0.5950\n",
            "Epoch 4/16\n",
            "1600/1600 [==============================] - 120s 75ms/step - loss: 2.5627 - acc: 0.5319 - val_loss: 2.3063 - val_acc: 0.5050\n",
            "Epoch 5/16\n",
            "1600/1600 [==============================] - 121s 75ms/step - loss: 3.0118 - acc: 0.5075 - val_loss: 6.6204 - val_acc: 0.5175\n",
            "Epoch 6/16\n",
            "1600/1600 [==============================] - 120s 75ms/step - loss: 3.0577 - acc: 0.5231 - val_loss: 5.4604 - val_acc: 0.4925\n",
            "Epoch 7/16\n",
            "1600/1600 [==============================] - 121s 75ms/step - loss: 2.8479 - acc: 0.4869 - val_loss: 0.7304 - val_acc: 0.5200\n",
            "Epoch 8/16\n",
            "1600/1600 [==============================] - 120s 75ms/step - loss: 2.4801 - acc: 0.5256 - val_loss: 3.4988 - val_acc: 0.5625\n",
            "Epoch 9/16\n",
            "1600/1600 [==============================] - 121s 75ms/step - loss: 2.1288 - acc: 0.5575 - val_loss: 6.4039 - val_acc: 0.4450\n",
            "Epoch 10/16\n",
            "1600/1600 [==============================] - 121s 75ms/step - loss: 2.1423 - acc: 0.5650 - val_loss: 2.3810 - val_acc: 0.5850\n",
            "Epoch 11/16\n",
            "1600/1600 [==============================] - 120s 75ms/step - loss: 3.0320 - acc: 0.4944 - val_loss: 2.5607 - val_acc: 0.4575\n",
            "Epoch 12/16\n",
            "1600/1600 [==============================] - 121s 75ms/step - loss: 3.5309 - acc: 0.4756 - val_loss: 2.0589 - val_acc: 0.5275\n",
            "Epoch 13/16\n",
            "1600/1600 [==============================] - 121s 75ms/step - loss: 3.3297 - acc: 0.4963 - val_loss: 2.6802 - val_acc: 0.4825\n",
            "Epoch 14/16\n",
            "1600/1600 [==============================] - 120s 75ms/step - loss: 3.0532 - acc: 0.5006 - val_loss: 1.4982 - val_acc: 0.5125\n",
            "Epoch 15/16\n",
            "1600/1600 [==============================] - 120s 75ms/step - loss: 2.9436 - acc: 0.5100 - val_loss: 1.4989 - val_acc: 0.5175\n",
            "Epoch 16/16\n",
            "1600/1600 [==============================] - 120s 75ms/step - loss: 2.5603 - acc: 0.4800 - val_loss: 1.5779 - val_acc: 0.5100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f997ce37630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "eA9GZhLGe5X9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "# print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "# model.fit(X_train, Y_train,\n",
        "#           batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "#           validation_data=(X_test, Y_test))\n",
        "\n",
        "# Y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qexmaPZVz04q",
        "colab_type": "code",
        "outputId": "af5f0440-5870-467c-d127-ef08b774c2b2",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "cell_type": "code",
      "source": [
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.plot(Y_test[:, 1], 'r')\n",
        "\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.plot(Y_pred[:, 1], 'b')\n",
        "\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.plot(Y_test[:, 1] - Y_pred[:, 1], 'g')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFKCAYAAAAnj5dkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA0hjcxMLWjyZAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f999efa1940>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "IPTFOJh3DTgq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "034a37a6-8ca4-4e69-adf8-2302377f3f13"
      },
      "cell_type": "code",
      "source": [
        "now = datetime.datetime.now()\n",
        "\n",
        "# modelSaved = '{}-{}_{}_{}.h5'.format(folderNormal, folderFault, pretrainedModel, now.strftime('%m-%d-%H:%M:%S'))\n",
        "\n",
        "modelSaved = '{}-{}_{}_{}.h5'.format('A1', 'A5', pretrainedModel, now.strftime('%m-%d-%H:%M:%S'))\n",
        "meanSaved = 'mean_{}.npy'.format(now.strftime('%m-%d-%H:%M:%S'))\n",
        "stdSaved = 'std_{}.npy'.format(now.strftime('%m-%d-%H:%M:%S'))\n",
        "\n",
        "inputStr = input('''Save Model as '{}'? (y/n)\\n'''.format(modelSaved))\n",
        "\n",
        "if (inputStr == 'y' or inputStr == 'Y'):  \n",
        "    model.save('gdrive/My Drive/Colab/Model/{}'.format(modelSaved))\n",
        "    np.save('gdrive/My Drive/Colab/Model/{}'.format(meanSaved), trainMean)\n",
        "    np.save('gdrive/My Drive/Colab/Model/{}'.format(stdSaved), trainStd)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Save Model as 'A1-A5_ResNet50_11-19-08:42:03.h5'? (y/n)\n",
            "n\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}