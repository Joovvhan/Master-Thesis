{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning Clean Up.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joovvhan/Master-Thesis/blob/master/log/(PN)P1-P5_Xception.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "c3821KWLNey6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import necessary modules\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy.io.wavfile as wf\n",
        "import time\n",
        "import glob\n",
        "import datetime\n",
        "\n",
        "from tqdm import trange\n",
        "\n",
        "# Import Keras modules\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.layers import Input, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
        "from keras.models import Sequential\n",
        "from keras import backend as K\n",
        "from keras.models import load_model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nxSASpgF7unA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Mount google drive\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "# os.listdir('gdrive/My Drive/Colab')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rw9NU8Xjwcz2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set data directories\n",
        "\n",
        "dataPath = '''D:\\\\0_Joowhan's Paper\\\\Synthesized\\\\Total\\\\Impulse'''\n",
        "modelPath = '''D:\\\\0_Joowhan's Paper\\\\Synthesized\\\\Total\\\\Model'''\n",
        "\n",
        "\n",
        "# Changed variable names to normal and fault\n",
        "# Changed variable names from folder to path\n",
        "# Need to consider multiple folders\n",
        "# Need to add files to be tested\n",
        "\n",
        "folderNormal = ['P1N1', 'P2N1', 'P3N1', 'P4N1', 'P5N1']\n",
        "# folderNormal = list()\n",
        "\n",
        "# for x in range(1, 6):\n",
        "#     for y in range(1, 6):\n",
        "#         for z in range(1, 6):\n",
        "#             if (x <= 2 and y <= 2 and z <= 2):\n",
        "#                 folderNormal.append('A{}F{}P{}'.format(x, y, z))\n",
        "\n",
        "# folderFault = list()\n",
        "\n",
        "folderFault = ['P1N5', 'P2N5', 'P3N5', 'P4N5', 'P5N5']\n",
        "\n",
        "# for x in range(1, 6):\n",
        "#     for y in range(1, 6):\n",
        "#         for z in range(1, 6):\n",
        "#             if (x == 5 or y == 5 or z == 5):\n",
        "#                 folderFault.append('A{}F{}P{}'.format(x, y, z))\n",
        "\n",
        "\n",
        "pathNormal = list()\n",
        "pathFault = list()\n",
        "\n",
        "for i in range(len(folderNormal)):\n",
        "    pathNormal.append(dataPath + '/' + folderNormal[i])\n",
        "    \n",
        "for i in range(len(folderFault)):\n",
        "    pathFault.append(dataPath + '/' + folderFault[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xgGP7PZO-rTA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Specgram settings\n",
        "\n",
        "nsc = 1470\n",
        "nov = nsc/2\n",
        "nff = nsc \n",
        "imgSize = 224\n",
        "\n",
        "# pretrainedModel = 'VGG19'\n",
        "pretrainedModel = 'Xception'\n",
        "# pretrainedModel = 'ResNet50'\n",
        "\n",
        "# pretrainedModel = 'DenseNet169'\n",
        "# pretrainedModel = 'InceptionV3'\n",
        "\n",
        "\n",
        "lastActivation = 'softmax'\n",
        "sizeBatch = 4\n",
        "numEpochs = 12\n",
        "verb = 1\n",
        "\n",
        "\n",
        "# Learning parameters\n",
        "\n",
        "trainingRatio = 0.8\n",
        "\n",
        "totalDataNum = 1000\n",
        "repeat = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5AskF2qFT2xr",
        "colab_type": "code",
        "outputId": "e9c140ef-d48c-4859-a832-d268ed608aac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "cell_type": "code",
      "source": [
        "startNum = 0\n",
        "\n",
        "pickNum = int(np.ceil(totalDataNum / len(pathNormal)))\n",
        "\n",
        "for i in range(startNum, len(pathNormal)):\n",
        "\n",
        "    npyTestPath = glob.glob(pathNormal[i] + '/' + '*Image_With_Label.npy')\n",
        "    data = np.load(npyTestPath[0])\n",
        "    \n",
        "    pickIdx = np.random.choice(1000, pickNum, replace=False)\n",
        "    pickIdx.sort()\n",
        "    \n",
        "#     imgs = np.moveaxis(np.dstack(data[:, 0]), 2, 0)\n",
        "#     label = data[:, 1:5]\n",
        "\n",
        "    imgs = np.moveaxis(np.dstack(data[pickIdx, 0]), 2, 0)\n",
        "    label = data[pickIdx, 1:5]\n",
        "    \n",
        "    if i == startNum:\n",
        "        labelListNormal = label\n",
        "        imgsNormal = imgs\n",
        "    else:\n",
        "        labelListNormal = np.vstack([labelListNormal, label])\n",
        "        imgsNormal = np.vstack([imgsNormal, imgs])\n",
        "\n",
        "    print('Normal Image Shape From {}: {}:'.format(pathNormal[i], totalDataNum))    \n",
        "    print('Selected {}/{}:'.format(pickNum * (i + 1), len(data)))    \n",
        "    \n",
        "    \n",
        "print('Normal Image Shape: {}'.format(imgsNormal.shape))\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P1N1: 1000:\n",
            "Selected 200/1000:\n",
            "Normal Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P2N1: 1000:\n",
            "Selected 400/1000:\n",
            "Normal Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P3N1: 1000:\n",
            "Selected 600/1000:\n",
            "Normal Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P4N1: 1000:\n",
            "Selected 800/1000:\n",
            "Normal Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P5N1: 1000:\n",
            "Selected 1000/1000:\n",
            "Normal Image Shape: (1000, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P_MZtpk3Br_i",
        "colab_type": "code",
        "outputId": "fe175622-f3ec-4a00-8ea7-1ee0d06b05eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "cell_type": "code",
      "source": [
        "startNum = 0\n",
        "\n",
        "pickNum = int(np.ceil(totalDataNum / len(pathFault)))\n",
        "\n",
        "for i in range(startNum, len(pathFault)):\n",
        "\n",
        "    npyTestPath = glob.glob(pathFault[i] + '/' + '*Image_With_Label.npy')\n",
        "    data = np.load(npyTestPath[0])\n",
        "    \n",
        "    pickIdx = np.random.choice(1000, pickNum, replace=False)\n",
        "    pickIdx.sort()\n",
        "    \n",
        "#     imgs = np.moveaxis(np.dstack(data[:, 0]), 2, 0)\n",
        "#     label = data[:, 1:5]\n",
        "    \n",
        "    imgs = np.moveaxis(np.dstack(data[pickIdx, 0]), 2, 0)\n",
        "    label = data[pickIdx, 1:5]\n",
        "    \n",
        "    if i == startNum:\n",
        "        labelListFault = label\n",
        "        imgsFault = imgs\n",
        "    else:\n",
        "        labelListFault = np.vstack([labelListFault, label])\n",
        "        imgsFault = np.vstack([imgsFault, imgs])\n",
        "\n",
        "    print('Fault Image Shape From {}: {}:'.format(pathFault[i], totalDataNum))    \n",
        "    print('Selected {}/{}:'.format(pickNum * (i + 1), len(data)))     \n",
        "    \n",
        "print('Fault Image Shape: {}'.format(imgsFault.shape))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P1N5: 1000:\n",
            "Selected 200/1000:\n",
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P2N5: 1000:\n",
            "Selected 400/1000:\n",
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P3N5: 1000:\n",
            "Selected 600/1000:\n",
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P4N5: 1000:\n",
            "Selected 800/1000:\n",
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P5N5: 1000:\n",
            "Selected 1000/1000:\n",
            "Fault Image Shape: (1000, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e91QsAurSkIP",
        "colab_type": "code",
        "outputId": "a7fd8d7f-bbd1-4a5d-bc23-09e2e3f6bed8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "cell_type": "code",
      "source": [
        "# Change name from imgsF1 or imgsF5 to imgsNormal and imgsFault\n",
        "\n",
        "dataNumNormal = len(imgsNormal)\n",
        "dataNumFault = len(imgsFault)\n",
        "dataNumNormalTrain = int(dataNumNormal * trainingRatio)\n",
        "dataNumFaultTrain = int(dataNumFault * trainingRatio)\n",
        "dataNumNormalTest = dataNumNormal - dataNumNormalTrain\n",
        "dataNumFaultTest = dataNumFault - dataNumFaultTrain\n",
        "\n",
        "print('Normal Train:Test = {:d}:{:d}'.format(dataNumNormalTrain, dataNumNormalTest))\n",
        "print('Fault  Train:Test = {:d}:{:d}\\n'.format(dataNumFaultTrain, dataNumFaultTest))\n",
        "\n",
        "trainIdxNormal = np.random.choice(dataNumNormal - 1, dataNumNormalTrain, replace=False)\n",
        "testIdxNormal = list(set(range(0, dataNumNormal)) - set(trainIdxNormal))\n",
        "\n",
        "trainImgsNormal = imgsNormal[trainIdxNormal, :, :]\n",
        "testImgsNormal = imgsNormal[testIdxNormal, :, :]\n",
        "\n",
        "print('Normal Training Image Shape {}'.format(trainImgsNormal.shape))\n",
        "print('Normal Test Image Shape {}\\n'.format(testImgsNormal.shape))\n",
        "\n",
        "trainIdxFault  = np.random.choice(dataNumFault - 1, dataNumFaultTrain, replace=False)\n",
        "testIdxFault = list(set(range(0, dataNumFault)) - set(trainIdxFault))\n",
        "\n",
        "trainImgsFault = imgsFault[trainIdxFault, :, :]\n",
        "testImgsFault = imgsFault[testIdxFault, :, :]\n",
        "\n",
        "print('Fault Training Image Shape {}'.format(trainImgsFault.shape))\n",
        "print('Fault Test Image Shape {}\\n'.format(testImgsFault.shape))\n",
        "\n",
        "trainImgs = np.vstack([trainImgsNormal, trainImgsFault])\n",
        "testImgs = np.vstack([testImgsNormal, testImgsFault])\n",
        "\n",
        "print('Training Image Shape {}'.format(trainImgs.shape))\n",
        "print('Test Image Shape {}'.format(testImgs.shape))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal Train:Test = 800:200\n",
            "Fault  Train:Test = 800:200\n",
            "\n",
            "Normal Training Image Shape (800, 224, 224)\n",
            "Normal Test Image Shape (200, 224, 224)\n",
            "\n",
            "Fault Training Image Shape (800, 224, 224)\n",
            "Fault Test Image Shape (200, 224, 224)\n",
            "\n",
            "Training Image Shape (1600, 224, 224)\n",
            "Test Image Shape (400, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MoE7f_hzs0av",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "feQ_AHAcUgHD",
        "colab_type": "code",
        "outputId": "ba4aca64-5bcb-4664-f333-4865c667d417",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "trainMean = np.mean(trainImgs)\n",
        "trainStd = np.std(trainImgs)\n",
        "\n",
        "print('Mean of Training Image: {}'.format(trainMean))\n",
        "print('Standard Deviation of Training Image: {}'.format(trainStd))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean of Training Image: -79.04975255882005\n",
            "Standard Deviation of Training Image: 8.23149503658227\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wUi9IuXNUpir",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Should Change Norm to Normalized\n",
        "\n",
        "trainImgsNorm = (trainImgs - trainMean) / trainStd\n",
        "testImgsNorm = (testImgs - trainMean) / trainStd\n",
        "\n",
        "trainImgsNorm = trainImgsNorm.reshape(list(trainImgsNorm.shape) + [1])\n",
        "testImgsNorm = testImgsNorm.reshape(list(testImgsNorm.shape) + [1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aklxiPz1Ve4n",
        "colab_type": "code",
        "outputId": "5aff93ec-9091-4044-98bf-7f37a93a9398",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = np.stack([trainImgsNorm[:, :, :, 0], trainImgsNorm[:, :, :, 0], trainImgsNorm[:, :, :, 0]], axis = -1)\n",
        "X_test = np.stack([testImgsNorm[:, :, :, 0], testImgsNorm[:, :, :, 0], testImgsNorm[:, :, :, 0]], axis = -1)\n",
        "\n",
        "print('X_train Shape: {}'.format(X_train.shape))\n",
        "print('X_test  Shape: {}'.format(X_test.shape))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train Shape: (1600, 224, 224, 3)\n",
            "X_test  Shape: (400, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sRgIPzT7K_YP",
        "colab_type": "code",
        "outputId": "32acb527-3214-4b65-b236-57212c4a8102",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "trainLabelNormal = np.stack((np.ones(dataNumNormalTrain), np.zeros(dataNumNormalTrain)), axis = -1)\n",
        "testLabelNormal = np.stack((np.ones(dataNumNormalTest), np.zeros(dataNumNormalTest)), axis = -1)\n",
        "\n",
        "trainLabelFault = np.stack((np.zeros(dataNumFaultTrain), np.ones(dataNumFaultTrain)), axis = -1)\n",
        "testLabelFault = np.stack((np.zeros(dataNumFaultTest), np.ones(dataNumFaultTest)), axis = -1)\n",
        "\n",
        "Y_train = np.vstack((trainLabelNormal, trainLabelFault))\n",
        "Y_test = np.vstack((testLabelNormal, testLabelFault))\n",
        "\n",
        "print('Y_train Normal:Fault = {:d}:{:d}'.format(len(trainLabelNormal), len(trainLabelFault)))\n",
        "print('Y_test  Normal:Fault = {:d}:{:d}'.format(len(testLabelNormal), len(testLabelFault)))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Y_train Normal:Fault = 800:800\n",
            "Y_test  Normal:Fault = 200:200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kczwZk7Tbp5C",
        "colab_type": "code",
        "outputId": "afb621c0-a5de-44a2-fcee-142a9b934343",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2647
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG19\n",
        "from keras.applications import VGG16\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications.densenet import DenseNet169\n",
        "from keras.applications.densenet import DenseNet201\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# pretrainedModel = 'ResNet50'\n",
        "# lastActivation = 'softmax'\n",
        "# lossFunction = 'binary_crossentropy'\n",
        "# sizeBatch = 2\n",
        "# numEpochs = 2\n",
        "# verb = 1\n",
        "\n",
        "for rp in range(repeat):\n",
        "\n",
        "    # Refresh all background variables\n",
        "    K.clear_session()\n",
        "\n",
        "    input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "    # Building sequential model with name 'model'\n",
        "    model = Sequential()\n",
        "\n",
        "    # Model selection\n",
        "\n",
        "    if (pretrainedModel == 'VGG16'):\n",
        "\n",
        "        modelWoTop = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'VGG19'):\n",
        "\n",
        "        modelWoTop = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif pretrainedModel == 'ResNet50':\n",
        "\n",
        "        modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'InceptionV3'):\n",
        "        modelWoTop = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'Xception'):\n",
        "        modelWoTop = Xception(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet169'):\n",
        "\n",
        "        modelWoTop = DenseNet169(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet201'):\n",
        "        modelWoTop = DenseNet201(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    else:\n",
        "        print('Invalid Pretrained Model Selection')\n",
        "\n",
        "\n",
        "\n",
        "    # Model compiling\n",
        "\n",
        "    print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "    print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "    model.fit(X_train, Y_train,\n",
        "              batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "              validation_data=(X_test, Y_test))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compiling Pretrained xception Model\n",
            "Training Pretrained xception Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/12\n",
            "1600/1600 [==============================] - 81s 51ms/step - loss: 0.2825 - acc: 0.9019 - val_loss: 0.1637 - val_acc: 0.9625\n",
            "Epoch 2/12\n",
            "1600/1600 [==============================] - 71s 44ms/step - loss: 0.1119 - acc: 0.9675 - val_loss: 0.0390 - val_acc: 0.9800\n",
            "Epoch 3/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0612 - acc: 0.9775 - val_loss: 0.9647 - val_acc: 0.7275\n",
            "Epoch 4/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0461 - acc: 0.9800 - val_loss: 0.0681 - val_acc: 0.9675\n",
            "Epoch 5/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.2516 - acc: 0.9575 - val_loss: 0.1104 - val_acc: 0.9750\n",
            "Epoch 6/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0859 - acc: 0.9712 - val_loss: 0.3945 - val_acc: 0.8050\n",
            "Epoch 7/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0708 - acc: 0.9725 - val_loss: 0.0487 - val_acc: 0.9825\n",
            "Epoch 8/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0428 - acc: 0.9838 - val_loss: 0.0309 - val_acc: 0.9825\n",
            "Epoch 9/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0282 - acc: 0.9875 - val_loss: 0.1091 - val_acc: 0.9825\n",
            "Epoch 10/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0346 - acc: 0.9844 - val_loss: 0.0536 - val_acc: 0.9775\n",
            "Epoch 11/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0255 - acc: 0.9881 - val_loss: 0.0533 - val_acc: 0.9825\n",
            "Epoch 12/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0352 - acc: 0.9862 - val_loss: 2.9271 - val_acc: 0.5775\n",
            "Compiling Pretrained xception Model\n",
            "Training Pretrained xception Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/12\n",
            "1600/1600 [==============================] - 78s 49ms/step - loss: 0.2757 - acc: 0.9062 - val_loss: 0.1321 - val_acc: 0.9325\n",
            "Epoch 2/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.1744 - acc: 0.9425 - val_loss: 0.3456 - val_acc: 0.8475\n",
            "Epoch 3/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0553 - acc: 0.9762 - val_loss: 0.4275 - val_acc: 0.7675\n",
            "Epoch 4/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0802 - acc: 0.9700 - val_loss: 0.0720 - val_acc: 0.9825\n",
            "Epoch 5/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0645 - acc: 0.9794 - val_loss: 0.0473 - val_acc: 0.9775\n",
            "Epoch 6/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0335 - acc: 0.9856 - val_loss: 0.1357 - val_acc: 0.9675\n",
            "Epoch 7/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0244 - acc: 0.9894 - val_loss: 0.0642 - val_acc: 0.9825\n",
            "Epoch 8/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0268 - acc: 0.9887 - val_loss: 0.0553 - val_acc: 0.9825\n",
            "Epoch 9/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0307 - acc: 0.9869 - val_loss: 0.0738 - val_acc: 0.9825\n",
            "Epoch 10/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0660 - acc: 0.9762 - val_loss: 0.1010 - val_acc: 0.9825\n",
            "Epoch 11/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0317 - acc: 0.9869 - val_loss: 0.1248 - val_acc: 0.9700\n",
            "Epoch 12/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0245 - acc: 0.9906 - val_loss: 0.0420 - val_acc: 0.9850\n",
            "Compiling Pretrained xception Model\n",
            "Training Pretrained xception Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/12\n",
            "1600/1600 [==============================] - 81s 50ms/step - loss: 0.2313 - acc: 0.9275 - val_loss: 0.1574 - val_acc: 0.9650\n",
            "Epoch 2/12\n",
            "1600/1600 [==============================] - 72s 45ms/step - loss: 0.0784 - acc: 0.9731 - val_loss: 0.7500 - val_acc: 0.7775\n",
            "Epoch 3/12\n",
            "1600/1600 [==============================] - 72s 45ms/step - loss: 0.1130 - acc: 0.9456 - val_loss: 0.0546 - val_acc: 0.9825\n",
            "Epoch 4/12\n",
            "1600/1600 [==============================] - 72s 45ms/step - loss: 0.1123 - acc: 0.9631 - val_loss: 0.1137 - val_acc: 0.9825\n",
            "Epoch 5/12\n",
            "1600/1600 [==============================] - 72s 45ms/step - loss: 0.0568 - acc: 0.9850 - val_loss: 0.0463 - val_acc: 0.9825\n",
            "Epoch 6/12\n",
            "1600/1600 [==============================] - 72s 45ms/step - loss: 0.0451 - acc: 0.9844 - val_loss: 0.0523 - val_acc: 0.9825\n",
            "Epoch 7/12\n",
            "1600/1600 [==============================] - 72s 45ms/step - loss: 0.0339 - acc: 0.9875 - val_loss: 0.0566 - val_acc: 0.9825\n",
            "Epoch 8/12\n",
            "1600/1600 [==============================] - 72s 45ms/step - loss: 0.0481 - acc: 0.9819 - val_loss: 0.0321 - val_acc: 0.9825\n",
            "Epoch 9/12\n",
            "1600/1600 [==============================] - 72s 45ms/step - loss: 0.0354 - acc: 0.9875 - val_loss: 0.0640 - val_acc: 0.9825\n",
            "Epoch 10/12\n",
            "1600/1600 [==============================] - 72s 45ms/step - loss: 0.0394 - acc: 0.9856 - val_loss: 0.0469 - val_acc: 0.9825\n",
            "Epoch 11/12\n",
            "1600/1600 [==============================] - 72s 45ms/step - loss: 0.0298 - acc: 0.9869 - val_loss: 0.0540 - val_acc: 0.9825\n",
            "Epoch 12/12\n",
            "1600/1600 [==============================] - 72s 45ms/step - loss: 0.0291 - acc: 0.9869 - val_loss: 0.0398 - val_acc: 0.9825\n",
            "Compiling Pretrained xception Model\n",
            "Training Pretrained xception Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/12\n",
            "1600/1600 [==============================] - 78s 49ms/step - loss: 0.2923 - acc: 0.9106 - val_loss: 0.1716 - val_acc: 0.9675\n",
            "Epoch 2/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0818 - acc: 0.9762 - val_loss: 0.0389 - val_acc: 0.9825\n",
            "Epoch 3/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0942 - acc: 0.9688 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 4/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.3042 - acc: 0.9044 - val_loss: 0.3836 - val_acc: 0.8975\n",
            "Epoch 5/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.1026 - acc: 0.9613 - val_loss: 0.0646 - val_acc: 0.9750\n",
            "Epoch 6/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0700 - acc: 0.9819 - val_loss: 0.0639 - val_acc: 0.9800\n",
            "Epoch 7/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0367 - acc: 0.9856 - val_loss: 0.0683 - val_acc: 0.9800\n",
            "Epoch 8/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0446 - acc: 0.9856 - val_loss: 0.1207 - val_acc: 0.9825\n",
            "Epoch 9/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0253 - acc: 0.9912 - val_loss: 0.0413 - val_acc: 0.9775\n",
            "Epoch 10/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0310 - acc: 0.9900 - val_loss: 1.2907 - val_acc: 0.9100\n",
            "Epoch 11/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0373 - acc: 0.9862 - val_loss: 6.6775 - val_acc: 0.5625\n",
            "Epoch 12/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0328 - acc: 0.9881 - val_loss: 0.0388 - val_acc: 0.9825\n",
            "Compiling Pretrained xception Model\n",
            "Training Pretrained xception Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/12\n",
            "1600/1600 [==============================] - 78s 49ms/step - loss: 0.3103 - acc: 0.8906 - val_loss: 0.1722 - val_acc: 0.9650\n",
            "Epoch 2/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.1679 - acc: 0.9481 - val_loss: 0.1723 - val_acc: 0.9675\n",
            "Epoch 3/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0813 - acc: 0.9725 - val_loss: 0.0375 - val_acc: 0.9775\n",
            "Epoch 4/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0653 - acc: 0.9750 - val_loss: 0.1460 - val_acc: 0.9450\n",
            "Epoch 5/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0911 - acc: 0.9675 - val_loss: 0.0465 - val_acc: 0.9750\n",
            "Epoch 6/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0878 - acc: 0.9719 - val_loss: 1.6818 - val_acc: 0.6975\n",
            "Epoch 7/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0404 - acc: 0.9838 - val_loss: 0.0317 - val_acc: 0.9800\n",
            "Epoch 8/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0635 - acc: 0.9731 - val_loss: 0.0429 - val_acc: 0.9750\n",
            "Epoch 9/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0346 - acc: 0.9869 - val_loss: 0.0958 - val_acc: 0.9525\n",
            "Epoch 10/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0219 - acc: 0.9906 - val_loss: 0.0307 - val_acc: 0.9825\n",
            "Epoch 11/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0277 - acc: 0.9900 - val_loss: 0.2917 - val_acc: 0.9000\n",
            "Epoch 12/12\n",
            "1600/1600 [==============================] - 70s 44ms/step - loss: 0.0383 - acc: 0.9838 - val_loss: 0.0302 - val_acc: 0.9825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jKgFIa4gkgkk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "# print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "# model.fit(X_train, Y_train,\n",
        "#           batch_size=sizeBatch, epochs=1, verbose=1,\n",
        "#           validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "agqqH8sf3CiV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# K.clear_session()\n",
        "\n",
        "# input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "# # Building sequential model with name 'model'\n",
        "# model = Sequential()\n",
        "\n",
        "# modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "# model.add(modelWoTop)\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "# # Model compiling\n",
        "\n",
        "# print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "# model.compile(loss='binary_crossentropy',\n",
        "#               optimizer='adam',\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "# numEpochs = 1\n",
        "\n",
        "# print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "# print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "# model.fit(X_train, Y_train,\n",
        "#           batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "#           validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qexmaPZVz04q",
        "colab_type": "code",
        "outputId": "8ccf081e-f0c0-41bd-a298-da22a2d7ad13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.plot(Y_test[:, 1], 'r')\n",
        "\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.plot(Y_pred[:, 1], 'b')\n",
        "\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.plot(Y_test[:, 1] - Y_pred[:, 1], 'g')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "IPTFOJh3DTgq",
        "colab_type": "code",
        "outputId": "51fe696b-8a22-496f-c519-a423351950ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "cell_type": "code",
      "source": [
        "now = datetime.datetime.now()\n",
        "\n",
        "# modelSaved = '{}-{}_{}_{}.h5'.format(folderNormal, folderFault, pretrainedModel, now.strftime('%m-%d-%H:%M:%S'))\n",
        "\n",
        "modelSaved = '{}-{}_{}_{}.h5'.format(folderNormal, folderFault, pretrainedModel, now.strftime('%m-%d-%H-%M-%S'))\n",
        "meanSaved = 'mean_{}.npy'.format(now.strftime('%m-%d-%H-%M-%S'))\n",
        "stdSaved = 'std_{}.npy'.format(now.strftime('%m-%d-%H-%M-%S'))\n",
        "\n",
        "inputStr = input('''Save Model as '{}'? (y/n)\\n'''.format(modelSaved))\n",
        "\n",
        "if (inputStr == 'y' or inputStr == 'Y'):  \n",
        "    model.save(modelPath + '/{}'.format(modelSaved))\n",
        "    np.save(modelPath + '/{}'.format(meanSaved), trainMean)\n",
        "    np.save(modelPath + '/{}'.format(stdSaved), trainStd)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Save Model as '['P1N1', 'P2N1', 'P3N1', 'P4N1', 'P5N1']-['P1N5', 'P2N5', 'P3N5', 'P4N5', 'P5N5']_Xception_11-17-04-09-25.h5'? (y/n)\n",
            "n\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}