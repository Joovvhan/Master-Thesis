{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning Clean Up.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joovvhan/Master-Thesis/blob/master/log/['A3F3P1']-['A3F3P5']_InceptionV3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "c3821KWLNey6",
        "colab_type": "code",
        "outputId": "34fc4be3-8aba-463f-ac19-55551cac19e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Import necessary modules\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy.io.wavfile as wf\n",
        "import time\n",
        "import glob\n",
        "import datetime\n",
        "\n",
        "from tqdm import trange\n",
        "\n",
        "# Import Keras modules\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.layers import Input, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
        "from keras.models import Sequential\n",
        "from keras import backend as K\n",
        "from keras.models import load_model\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "nxSASpgF7unA",
        "colab_type": "code",
        "outputId": "677d0ad1-89ea-4310-f2fd-66d77517f5a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "cell_type": "code",
      "source": [
        "# Mount google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "os.listdir('gdrive/My Drive/Colab')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Data', 'Model', 'Data_']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "rw9NU8Xjwcz2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set data directories\n",
        "\n",
        "dataPath = 'gdrive/My Drive/Colab/Data'\n",
        "\n",
        "# Changed variable names to normal and fault\n",
        "# Changed variable names from folder to path\n",
        "# Need to consider multiple folders\n",
        "# Need to add files to be tested\n",
        "\n",
        "#folderNormal = ['A1F3P3']\n",
        "folderNormal = list()\n",
        "\n",
        "for x in range(3, 4):\n",
        "    for y in range(3, 4):\n",
        "        for z in range(1, 2):\n",
        "            #if (x <= 2 and y <= 2 and z <= 2):\n",
        "            folderNormal.append('A{}F{}P{}'.format(x, y, z))\n",
        "\n",
        "folderFault = list()\n",
        "\n",
        "# folderFault = ['A5F3P3']\n",
        "\n",
        "for x in range(3, 4):\n",
        "    for y in range(3, 4):\n",
        "        for z in range(5, 6):\n",
        "            #if (x == 5 or y == 5 or z == 5):\n",
        "            folderFault.append('A{}F{}P{}'.format(x, y, z))\n",
        "\n",
        "\n",
        "pathNormal = list()\n",
        "pathFault = list()\n",
        "\n",
        "for i in range(len(folderNormal)):\n",
        "    pathNormal.append(dataPath + '/' + folderNormal[i])\n",
        "    \n",
        "for i in range(len(folderFault)):\n",
        "    pathFault.append(dataPath + '/' + folderFault[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xgGP7PZO-rTA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Specgram settings\n",
        "\n",
        "nsc = 1470\n",
        "nov = nsc/2\n",
        "nff = nsc \n",
        "imgSize = 224\n",
        "\n",
        "# pretrainedModel = 'VGG19'\n",
        "# pretrainedModel = 'Xception'\n",
        "# pretrainedModel = 'ResNet50'\n",
        "\n",
        "# pretrainedModel = 'VGG19'\n",
        "pretrainedModel = 'InceptionV3'\n",
        "#pretrainedModel = 'DenseNet169'\n",
        "#pretrainedModel = 'DenseNet201'\n",
        "\n",
        "\n",
        "lastActivation = 'softmax'\n",
        "sizeBatch = 4\n",
        "numEpochs = 12\n",
        "verb = 1\n",
        "\n",
        "\n",
        "# Learning parameters\n",
        "\n",
        "trainingRatio = 0.8\n",
        "\n",
        "totalDataNum = 1000\n",
        "repeat = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5AskF2qFT2xr",
        "colab_type": "code",
        "outputId": "c0917085-489e-4deb-ad55-566468e80ecd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "startNum = 0\n",
        "\n",
        "pickNum = int(np.ceil(totalDataNum / len(pathNormal)))\n",
        "\n",
        "for i in range(startNum, len(pathNormal)):\n",
        "\n",
        "    npyTestPath = glob.glob(pathNormal[i] + '/' + '*Image_With_Label.npy')\n",
        "    data = np.load(npyTestPath[0])\n",
        "    \n",
        "    pickIdx = np.random.choice(1000, pickNum, replace=False)\n",
        "    pickIdx.sort()\n",
        "    \n",
        "#     imgs = np.moveaxis(np.dstack(data[:, 0]), 2, 0)\n",
        "#     label = data[:, 1:5]\n",
        "\n",
        "    imgs = np.moveaxis(np.dstack(data[pickIdx, 0]), 2, 0)\n",
        "    label = data[pickIdx, 1:5]\n",
        "    \n",
        "    if i == startNum:\n",
        "        labelListNormal = label\n",
        "        imgsNormal = imgs\n",
        "    else:\n",
        "        labelListNormal = np.vstack([labelListNormal, label])\n",
        "        imgsNormal = np.vstack([imgsNormal, imgs])\n",
        "\n",
        "    print('Normal Image Shape From {}: {}:'.format(pathNormal[i], totalDataNum))    \n",
        "    print('Selected {}/{}:'.format(pickNum * (i + 1), len(data)))    \n",
        "    \n",
        "    \n",
        "print('Normal Image Shape: {}'.format(imgsNormal.shape))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal Image Shape From gdrive/My Drive/Colab/Data/A3F3P1: 1000:\n",
            "Selected 1000/1000:\n",
            "Normal Image Shape: (1000, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P_MZtpk3Br_i",
        "colab_type": "code",
        "outputId": "3bdf3e74-4627-495c-da17-07ffda40a6e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "startNum = 0\n",
        "\n",
        "pickNum = int(np.ceil(totalDataNum / len(pathFault)))\n",
        "\n",
        "for i in range(startNum, len(pathFault)):\n",
        "\n",
        "    npyTestPath = glob.glob(pathFault[i] + '/' + '*Image_With_Label.npy')\n",
        "    data = np.load(npyTestPath[0])\n",
        "    \n",
        "    pickIdx = np.random.choice(1000, pickNum, replace=False)\n",
        "    pickIdx.sort()\n",
        "    \n",
        "#     imgs = np.moveaxis(np.dstack(data[:, 0]), 2, 0)\n",
        "#     label = data[:, 1:5]\n",
        "    \n",
        "    imgs = np.moveaxis(np.dstack(data[pickIdx, 0]), 2, 0)\n",
        "    label = data[pickIdx, 1:5]\n",
        "    \n",
        "    if i == startNum:\n",
        "        labelListFault = label\n",
        "        imgsFault = imgs\n",
        "    else:\n",
        "        labelListFault = np.vstack([labelListFault, label])\n",
        "        imgsFault = np.vstack([imgsFault, imgs])\n",
        "\n",
        "    print('Fault Image Shape From {}: {}:'.format(pathFault[i], totalDataNum))    \n",
        "    print('Selected {}/{}:'.format(pickNum * (i + 1), len(data)))     \n",
        "    \n",
        "print('Fault Image Shape: {}'.format(imgsFault.shape))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fault Image Shape From gdrive/My Drive/Colab/Data/A3F3P5: 1000:\n",
            "Selected 1000/1000:\n",
            "Fault Image Shape: (1000, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e91QsAurSkIP",
        "colab_type": "code",
        "outputId": "271dd76e-ba6d-43af-a6c0-1d337a375df4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "cell_type": "code",
      "source": [
        "# Change name from imgsF1 or imgsF5 to imgsNormal and imgsFault\n",
        "\n",
        "dataNumNormal = len(imgsNormal)\n",
        "dataNumFault = len(imgsFault)\n",
        "dataNumNormalTrain = int(dataNumNormal * trainingRatio)\n",
        "dataNumFaultTrain = int(dataNumFault * trainingRatio)\n",
        "dataNumNormalTest = dataNumNormal - dataNumNormalTrain\n",
        "dataNumFaultTest = dataNumFault - dataNumFaultTrain\n",
        "\n",
        "print('Normal Train:Test = {:d}:{:d}'.format(dataNumNormalTrain, dataNumNormalTest))\n",
        "print('Fault  Train:Test = {:d}:{:d}\\n'.format(dataNumFaultTrain, dataNumFaultTest))\n",
        "\n",
        "trainIdxNormal = np.random.choice(dataNumNormal - 1, dataNumNormalTrain, replace=False)\n",
        "testIdxNormal = list(set(range(0, dataNumNormal)) - set(trainIdxNormal))\n",
        "\n",
        "trainImgsNormal = imgsNormal[trainIdxNormal, :, :]\n",
        "testImgsNormal = imgsNormal[testIdxNormal, :, :]\n",
        "\n",
        "print('Normal Training Image Shape {}'.format(trainImgsNormal.shape))\n",
        "print('Normal Test Image Shape {}\\n'.format(testImgsNormal.shape))\n",
        "\n",
        "trainIdxFault  = np.random.choice(dataNumFault - 1, dataNumFaultTrain, replace=False)\n",
        "testIdxFault = list(set(range(0, dataNumFault)) - set(trainIdxFault))\n",
        "\n",
        "trainImgsFault = imgsFault[trainIdxFault, :, :]\n",
        "testImgsFault = imgsFault[testIdxFault, :, :]\n",
        "\n",
        "print('Fault Training Image Shape {}'.format(trainImgsFault.shape))\n",
        "print('Fault Test Image Shape {}\\n'.format(testImgsFault.shape))\n",
        "\n",
        "trainImgs = np.vstack([trainImgsNormal, trainImgsFault])\n",
        "testImgs = np.vstack([testImgsNormal, testImgsFault])\n",
        "\n",
        "print('Training Image Shape {}'.format(trainImgs.shape))\n",
        "print('Test Image Shape {}'.format(testImgs.shape))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal Train:Test = 800:200\n",
            "Fault  Train:Test = 800:200\n",
            "\n",
            "Normal Training Image Shape (800, 224, 224)\n",
            "Normal Test Image Shape (200, 224, 224)\n",
            "\n",
            "Fault Training Image Shape (800, 224, 224)\n",
            "Fault Test Image Shape (200, 224, 224)\n",
            "\n",
            "Training Image Shape (1600, 224, 224)\n",
            "Test Image Shape (400, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MoE7f_hzs0av",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "feQ_AHAcUgHD",
        "colab_type": "code",
        "outputId": "d9928796-52bc-4958-9dd7-858e4a2de3bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "trainMean = np.mean(trainImgs)\n",
        "trainStd = np.std(trainImgs)\n",
        "\n",
        "print('Mean of Training Image: {}'.format(trainMean))\n",
        "print('Standard Deviation of Training Image: {}'.format(trainStd))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean of Training Image: -78.17975868343537\n",
            "Standard Deviation of Training Image: 9.4017672152482\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wUi9IuXNUpir",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Should Change Norm to Normalized\n",
        "\n",
        "trainImgsNorm = (trainImgs - trainMean) / trainStd\n",
        "testImgsNorm = (testImgs - trainMean) / trainStd\n",
        "\n",
        "trainImgsNorm = trainImgsNorm.reshape(list(trainImgsNorm.shape) + [1])\n",
        "testImgsNorm = testImgsNorm.reshape(list(testImgsNorm.shape) + [1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aklxiPz1Ve4n",
        "colab_type": "code",
        "outputId": "ff33a1f0-52db-44bd-f0a8-7608fda8e80f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = np.stack([trainImgsNorm[:, :, :, 0], trainImgsNorm[:, :, :, 0], trainImgsNorm[:, :, :, 0]], axis = -1)\n",
        "X_test = np.stack([testImgsNorm[:, :, :, 0], testImgsNorm[:, :, :, 0], testImgsNorm[:, :, :, 0]], axis = -1)\n",
        "\n",
        "print('X_train Shape: {}'.format(X_train.shape))\n",
        "print('X_test  Shape: {}'.format(X_test.shape))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train Shape: (1600, 224, 224, 3)\n",
            "X_test  Shape: (400, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sRgIPzT7K_YP",
        "colab_type": "code",
        "outputId": "8e520f72-7a43-410f-d7b6-f6548130825a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "trainLabelNormal = np.stack((np.ones(dataNumNormalTrain), np.zeros(dataNumNormalTrain)), axis = -1)\n",
        "testLabelNormal = np.stack((np.ones(dataNumNormalTest), np.zeros(dataNumNormalTest)), axis = -1)\n",
        "\n",
        "trainLabelFault = np.stack((np.zeros(dataNumFaultTrain), np.ones(dataNumFaultTrain)), axis = -1)\n",
        "testLabelFault = np.stack((np.zeros(dataNumFaultTest), np.ones(dataNumFaultTest)), axis = -1)\n",
        "\n",
        "Y_train = np.vstack((trainLabelNormal, trainLabelFault))\n",
        "Y_test = np.vstack((testLabelNormal, testLabelFault))\n",
        "\n",
        "print('Y_train Normal:Fault = {:d}:{:d}'.format(len(trainLabelNormal), len(trainLabelFault)))\n",
        "print('Y_test  Normal:Fault = {:d}:{:d}'.format(len(testLabelNormal), len(testLabelFault)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Y_train Normal:Fault = 800:800\n",
            "Y_test  Normal:Fault = 200:200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kczwZk7Tbp5C",
        "colab_type": "code",
        "outputId": "a6ec0f32-810f-4b82-fc59-6f1adffe14d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG19\n",
        "from keras.applications import VGG16\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications.densenet import DenseNet169\n",
        "from keras.applications.densenet import DenseNet201\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# pretrainedModel = 'ResNet50'\n",
        "# lastActivation = 'softmax'\n",
        "# lossFunction = 'binary_crossentropy'\n",
        "# sizeBatch = 2\n",
        "# numEpochs = 2\n",
        "# verb = 1\n",
        "\n",
        "for rp in range(repeat):\n",
        "\n",
        "    # Refresh all background variables\n",
        "    K.clear_session()\n",
        "\n",
        "    input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "    # Building sequential model with name 'model'\n",
        "    model = Sequential()\n",
        "\n",
        "    # Model selection\n",
        "\n",
        "    if (pretrainedModel == 'VGG16'):\n",
        "\n",
        "        modelWoTop = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'VGG19'):\n",
        "\n",
        "        modelWoTop = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif pretrainedModel == 'ResNet50':\n",
        "\n",
        "        modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'InceptionV3'):\n",
        "        modelWoTop = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'Xception'):\n",
        "        modelWoTop = Xception(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet169'):\n",
        "\n",
        "        modelWoTop = DenseNet169(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet201'):\n",
        "        modelWoTop = DenseNet201(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    else:\n",
        "        print('Invalid Pretrained Model Selection')\n",
        "\n",
        "\n",
        "\n",
        "    # Model compiling\n",
        "\n",
        "    print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "    print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "    model.fit(X_train, Y_train,\n",
        "              batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "              validation_data=(X_test, Y_test))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 3s 0us/step\n",
            "Compiling Pretrained inception_v3 Model\n",
            "Training Pretrained inception_v3 Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/12\n",
            "1600/1600 [==============================] - 123s 77ms/step - loss: 0.2140 - acc: 0.9500 - val_loss: 0.0338 - val_acc: 0.9975\n",
            "Epoch 2/12\n",
            "1600/1600 [==============================] - 101s 63ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 2.3511e-04 - val_acc: 1.0000\n",
            "Epoch 3/12\n",
            "1600/1600 [==============================] - 101s 63ms/step - loss: 3.3947e-04 - acc: 1.0000 - val_loss: 5.3528e-05 - val_acc: 1.0000\n",
            "Epoch 4/12\n",
            "1600/1600 [==============================] - 101s 63ms/step - loss: 1.8884e-04 - acc: 1.0000 - val_loss: 1.0405e-05 - val_acc: 1.0000\n",
            "Epoch 5/12\n",
            "1600/1600 [==============================] - 101s 63ms/step - loss: 1.0449e-04 - acc: 1.0000 - val_loss: 1.1504e-05 - val_acc: 1.0000\n",
            "Epoch 6/12\n",
            "1600/1600 [==============================] - 101s 63ms/step - loss: 7.9238e-05 - acc: 1.0000 - val_loss: 8.1310e-06 - val_acc: 1.0000\n",
            "Epoch 7/12\n",
            "1600/1600 [==============================] - 101s 63ms/step - loss: 4.3295e-05 - acc: 1.0000 - val_loss: 7.1459e-06 - val_acc: 1.0000\n",
            "Epoch 8/12\n",
            "1600/1600 [==============================] - 101s 63ms/step - loss: 0.2318 - acc: 0.9156 - val_loss: 0.0031 - val_acc: 1.0000\n",
            "Epoch 9/12\n",
            "1600/1600 [==============================] - 101s 63ms/step - loss: 0.0796 - acc: 0.9762 - val_loss: 0.0986 - val_acc: 0.9875\n",
            "Epoch 10/12\n",
            "1600/1600 [==============================] - 101s 63ms/step - loss: 0.0078 - acc: 0.9987 - val_loss: 7.7049e-04 - val_acc: 1.0000\n",
            "Epoch 11/12\n",
            "1600/1600 [==============================] - 101s 63ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
            "Epoch 12/12\n",
            "1600/1600 [==============================] - 101s 63ms/step - loss: 0.0686 - acc: 0.9775 - val_loss: 0.0220 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-aE0MIEjuC_k",
        "colab_type": "code",
        "outputId": "e6cce4c2-b814-46bf-923c-ee3a31f8e158",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "for rp in range(repeat):\n",
        "\n",
        "    # Refresh all background variables\n",
        "    K.clear_session()\n",
        "\n",
        "    input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "    # Building sequential model with name 'model'\n",
        "    model = Sequential()\n",
        "\n",
        "    # Model selection\n",
        "\n",
        "    if (pretrainedModel == 'VGG16'):\n",
        "\n",
        "        modelWoTop = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'VGG19'):\n",
        "\n",
        "        modelWoTop = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif pretrainedModel == 'ResNet50':\n",
        "\n",
        "        modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'InceptionV3'):\n",
        "        modelWoTop = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'Xception'):\n",
        "        modelWoTop = Xception(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet169'):\n",
        "\n",
        "        modelWoTop = DenseNet169(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet201'):\n",
        "        modelWoTop = DenseNet201(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    else:\n",
        "        print('Invalid Pretrained Model Selection')\n",
        "\n",
        "\n",
        "\n",
        "    # Model compiling\n",
        "\n",
        "    print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "    print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "    model.fit(X_train, Y_train,\n",
        "              batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "              validation_data=(X_test, Y_test))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compiling Pretrained inception_v3 Model\n",
            "Training Pretrained inception_v3 Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/12\n",
            "1600/1600 [==============================] - 121s 76ms/step - loss: 0.2159 - acc: 0.9337 - val_loss: 6.2329 - val_acc: 0.1400\n",
            "Epoch 2/12\n",
            "1600/1600 [==============================] - 102s 63ms/step - loss: 0.0939 - acc: 0.9706 - val_loss: 0.0325 - val_acc: 1.0000\n",
            "Epoch 3/12\n",
            "1600/1600 [==============================] - 101s 63ms/step - loss: 0.0450 - acc: 0.9838 - val_loss: 4.4734e-04 - val_acc: 1.0000\n",
            "Epoch 4/12\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 1.0000\n",
            "Epoch 5/12\n",
            "1600/1600 [==============================] - 101s 63ms/step - loss: 1.8718e-04 - acc: 1.0000 - val_loss: 4.9256e-04 - val_acc: 1.0000\n",
            "Epoch 6/12\n",
            "1600/1600 [==============================] - 101s 63ms/step - loss: 1.2292e-04 - acc: 1.0000 - val_loss: 1.9906e-04 - val_acc: 1.0000\n",
            "Epoch 7/12\n",
            "1600/1600 [==============================] - 101s 63ms/step - loss: 5.0737e-05 - acc: 1.0000 - val_loss: 1.3250e-04 - val_acc: 1.0000\n",
            "Epoch 8/12\n",
            "1600/1600 [==============================] - 102s 63ms/step - loss: 4.6717e-05 - acc: 1.0000 - val_loss: 1.2407e-04 - val_acc: 1.0000\n",
            "Epoch 9/12\n",
            "1600/1600 [==============================] - 102s 63ms/step - loss: 4.2321e-05 - acc: 1.0000 - val_loss: 2.1235e-04 - val_acc: 1.0000\n",
            "Epoch 10/12\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 2.9501e-05 - acc: 1.0000 - val_loss: 1.1616e-04 - val_acc: 1.0000\n",
            "Epoch 11/12\n",
            "1600/1600 [==============================] - 102s 63ms/step - loss: 2.9448e-05 - acc: 1.0000 - val_loss: 1.1343e-04 - val_acc: 1.0000\n",
            "Epoch 12/12\n",
            "1600/1600 [==============================] - 101s 63ms/step - loss: 0.1907 - acc: 0.9513 - val_loss: 8.2169 - val_acc: 0.3375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "15t3_glRqbHT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "outputId": "bc6d0849-e619-4c81-96ad-4c17307e23ba"
      },
      "cell_type": "code",
      "source": [
        "# Refresh all background variables\n",
        "K.clear_session()\n",
        "\n",
        "input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "# Building sequential model with name 'model'\n",
        "model = Sequential()\n",
        "\n",
        "# Model selection\n",
        "\n",
        "if (pretrainedModel == 'VGG16'):\n",
        "\n",
        "    modelWoTop = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'VGG19'):\n",
        "\n",
        "    modelWoTop = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif pretrainedModel == 'ResNet50':\n",
        "\n",
        "    modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'InceptionV3'):\n",
        "    modelWoTop = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'Xception'):\n",
        "    modelWoTop = Xception(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'DenseNet169'):\n",
        "\n",
        "    modelWoTop = DenseNet169(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'DenseNet201'):\n",
        "    modelWoTop = DenseNet201(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "else:\n",
        "    print('Invalid Pretrained Model Selection')\n",
        "\n",
        "\n",
        "\n",
        "# Model compiling\n",
        "\n",
        "print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compiling Pretrained inception_v3 Model\n",
            "Training Pretrained inception_v3 Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/12\n",
            "1600/1600 [==============================] - 122s 76ms/step - loss: 0.1703 - acc: 0.9456 - val_loss: 7.8809 - val_acc: 0.5000\n",
            "Epoch 2/12\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.0616 - acc: 0.9800 - val_loss: 0.1173 - val_acc: 0.9975\n",
            "Epoch 3/12\n",
            "1600/1600 [==============================] - 102s 63ms/step - loss: 0.0325 - acc: 0.9931 - val_loss: 0.0093 - val_acc: 1.0000\n",
            "Epoch 4/12\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 8.2539e-04 - acc: 1.0000 - val_loss: 6.6234e-04 - val_acc: 1.0000\n",
            "Epoch 5/12\n",
            "1600/1600 [==============================] - 102s 63ms/step - loss: 2.3399e-04 - acc: 1.0000 - val_loss: 0.0248 - val_acc: 0.9975\n",
            "Epoch 6/12\n",
            "1600/1600 [==============================] - 101s 63ms/step - loss: 0.1156 - acc: 0.9681 - val_loss: 2.6176 - val_acc: 0.5000\n",
            "Epoch 7/12\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.1237 - acc: 0.9581 - val_loss: 1.0638e-04 - val_acc: 1.0000\n",
            "Epoch 8/12\n",
            "1600/1600 [==============================] - 101s 63ms/step - loss: 0.0719 - acc: 0.9788 - val_loss: 0.0277 - val_acc: 0.9950\n",
            "Epoch 9/12\n",
            "1600/1600 [==============================] - 102s 63ms/step - loss: 0.0052 - acc: 0.9994 - val_loss: 2.2547e-04 - val_acc: 1.0000\n",
            "Epoch 10/12\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.0077 - acc: 0.9987 - val_loss: 1.0691e-04 - val_acc: 1.0000\n",
            "Epoch 11/12\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 9.6828e-05 - val_acc: 1.0000\n",
            "Epoch 12/12\n",
            "1600/1600 [==============================] - 101s 63ms/step - loss: 2.3580e-04 - acc: 1.0000 - val_loss: 2.3780e-05 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3840c15e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "JJoK167dqbdS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "outputId": "fe7ca5fd-88fa-4642-f518-24bae217aaf0"
      },
      "cell_type": "code",
      "source": [
        "K.clear_session()\n",
        "\n",
        "input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "# Building sequential model with name 'model'\n",
        "model = Sequential()\n",
        "\n",
        "# Model selection\n",
        "\n",
        "if (pretrainedModel == 'VGG16'):\n",
        "\n",
        "    modelWoTop = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'VGG19'):\n",
        "\n",
        "    modelWoTop = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif pretrainedModel == 'ResNet50':\n",
        "\n",
        "    modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'InceptionV3'):\n",
        "    modelWoTop = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'Xception'):\n",
        "    modelWoTop = Xception(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'DenseNet169'):\n",
        "\n",
        "    modelWoTop = DenseNet169(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'DenseNet201'):\n",
        "    modelWoTop = DenseNet201(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "else:\n",
        "    print('Invalid Pretrained Model Selection')\n",
        "\n",
        "\n",
        "\n",
        "# Model compiling\n",
        "\n",
        "print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compiling Pretrained inception_v3 Model\n",
            "Training Pretrained inception_v3 Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/12\n",
            "1600/1600 [==============================] - 121s 76ms/step - loss: 0.2390 - acc: 0.9237 - val_loss: 0.8285 - val_acc: 0.6375\n",
            "Epoch 2/12\n",
            "1600/1600 [==============================] - 102s 63ms/step - loss: 0.0908 - acc: 0.9712 - val_loss: 0.0017 - val_acc: 1.0000\n",
            "Epoch 3/12\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.0126 - acc: 0.9956 - val_loss: 4.8019e-04 - val_acc: 1.0000\n",
            "Epoch 4/12\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 4.4435e-04 - acc: 1.0000 - val_loss: 2.3652e-04 - val_acc: 1.0000\n",
            "Epoch 5/12\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.0652 - acc: 0.9819 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 6/12\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.0668 - acc: 0.9869 - val_loss: 0.0043 - val_acc: 1.0000\n",
            "Epoch 7/12\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.0059 - acc: 0.9981 - val_loss: 5.1212e-04 - val_acc: 1.0000\n",
            "Epoch 8/12\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 3.8327e-04 - acc: 1.0000 - val_loss: 2.7838e-04 - val_acc: 1.0000\n",
            "Epoch 9/12\n",
            "1600/1600 [==============================] - 101s 63ms/step - loss: 1.6800e-04 - acc: 1.0000 - val_loss: 1.4930e-04 - val_acc: 1.0000\n",
            "Epoch 10/12\n",
            "1600/1600 [==============================] - 101s 63ms/step - loss: 2.0611e-04 - acc: 1.0000 - val_loss: 2.6231e-05 - val_acc: 1.0000\n",
            "Epoch 11/12\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 1.2840e-04 - acc: 1.0000 - val_loss: 4.0523e-05 - val_acc: 1.0000\n",
            "Epoch 12/12\n",
            "1600/1600 [==============================] - 101s 63ms/step - loss: 4.6909e-05 - acc: 1.0000 - val_loss: 4.9897e-05 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f381b5f5a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "z-sV54Vuqbl1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "outputId": "e1eeaaeb-5e00-4833-c018-b5e977f3c87a"
      },
      "cell_type": "code",
      "source": [
        "K.clear_session()\n",
        "\n",
        "input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "# Building sequential model with name 'model'\n",
        "model = Sequential()\n",
        "\n",
        "# Model selection\n",
        "\n",
        "if (pretrainedModel == 'VGG16'):\n",
        "\n",
        "    modelWoTop = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'VGG19'):\n",
        "\n",
        "    modelWoTop = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif pretrainedModel == 'ResNet50':\n",
        "\n",
        "    modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'InceptionV3'):\n",
        "    modelWoTop = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'Xception'):\n",
        "    modelWoTop = Xception(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'DenseNet169'):\n",
        "\n",
        "    modelWoTop = DenseNet169(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'DenseNet201'):\n",
        "    modelWoTop = DenseNet201(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "else:\n",
        "    print('Invalid Pretrained Model Selection')\n",
        "\n",
        "\n",
        "\n",
        "# Model compiling\n",
        "\n",
        "print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compiling Pretrained inception_v3 Model\n",
            "Training Pretrained inception_v3 Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/12\n",
            "1600/1600 [==============================] - 120s 75ms/step - loss: 0.2298 - acc: 0.9262 - val_loss: 6.7244 - val_acc: 0.4925\n",
            "Epoch 2/12\n",
            "1600/1600 [==============================] - 101s 63ms/step - loss: 0.0182 - acc: 0.9950 - val_loss: 0.0175 - val_acc: 1.0000\n",
            "Epoch 3/12\n",
            "1600/1600 [==============================] - 101s 63ms/step - loss: 5.6833e-04 - acc: 1.0000 - val_loss: 0.0154 - val_acc: 1.0000\n",
            "Epoch 4/12\n",
            "1600/1600 [==============================] - 101s 63ms/step - loss: 5.2745e-04 - acc: 1.0000 - val_loss: 0.0060 - val_acc: 1.0000\n",
            "Epoch 5/12\n",
            "1600/1600 [==============================] - 100s 62ms/step - loss: 1.2606e-04 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000\n",
            "Epoch 6/12\n",
            "1600/1600 [==============================] - 100s 62ms/step - loss: 0.3064 - acc: 0.9344 - val_loss: 1.0285 - val_acc: 0.5150\n",
            "Epoch 7/12\n",
            "1600/1600 [==============================] - 102s 63ms/step - loss: 0.1203 - acc: 0.9663 - val_loss: 0.0152 - val_acc: 1.0000\n",
            "Epoch 8/12\n",
            "1600/1600 [==============================] - 103s 64ms/step - loss: 0.1288 - acc: 0.9550 - val_loss: 2.4569 - val_acc: 0.5225\n",
            "Epoch 9/12\n",
            "1600/1600 [==============================] - 104s 65ms/step - loss: 0.0885 - acc: 0.9719 - val_loss: 7.6258 - val_acc: 0.5175\n",
            "Epoch 10/12\n",
            "1600/1600 [==============================] - 103s 65ms/step - loss: 0.0085 - acc: 0.9987 - val_loss: 0.0276 - val_acc: 0.9900\n",
            "Epoch 11/12\n",
            "1600/1600 [==============================] - 103s 64ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.8328 - val_acc: 0.8425\n",
            "Epoch 12/12\n",
            "1600/1600 [==============================] - 103s 65ms/step - loss: 4.8723e-04 - acc: 1.0000 - val_loss: 1.0645 - val_acc: 0.9025\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f38086799b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "c-TT_erUqbso",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "outputId": "7e13020d-24b7-440f-a5e4-34535d38af9b"
      },
      "cell_type": "code",
      "source": [
        "K.clear_session()\n",
        "\n",
        "input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "# Building sequential model with name 'model'\n",
        "model = Sequential()\n",
        "\n",
        "# Model selection\n",
        "\n",
        "if (pretrainedModel == 'VGG16'):\n",
        "\n",
        "    modelWoTop = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'VGG19'):\n",
        "\n",
        "    modelWoTop = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif pretrainedModel == 'ResNet50':\n",
        "\n",
        "    modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'InceptionV3'):\n",
        "    modelWoTop = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'Xception'):\n",
        "    modelWoTop = Xception(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'DenseNet169'):\n",
        "\n",
        "    modelWoTop = DenseNet169(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'DenseNet201'):\n",
        "    modelWoTop = DenseNet201(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "else:\n",
        "    print('Invalid Pretrained Model Selection')\n",
        "\n",
        "\n",
        "\n",
        "# Model compiling\n",
        "\n",
        "print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compiling Pretrained inception_v3 Model\n",
            "Training Pretrained inception_v3 Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/12\n",
            "1600/1600 [==============================] - 127s 80ms/step - loss: 0.2679 - acc: 0.9044 - val_loss: 0.0262 - val_acc: 1.0000\n",
            "Epoch 2/12\n",
            "1600/1600 [==============================] - 101s 63ms/step - loss: 0.1238 - acc: 0.9563 - val_loss: 0.0016 - val_acc: 1.0000\n",
            "Epoch 3/12\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.0861 - acc: 0.9744 - val_loss: 8.0151 - val_acc: 0.5000\n",
            "Epoch 4/12\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.2844 - acc: 0.9006 - val_loss: 5.8015 - val_acc: 0.1925\n",
            "Epoch 5/12\n",
            "1600/1600 [==============================] - 101s 63ms/step - loss: 0.0826 - acc: 0.9750 - val_loss: 0.0059 - val_acc: 1.0000\n",
            "Epoch 6/12\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 6.2703e-04 - val_acc: 1.0000\n",
            "Epoch 7/12\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 6.6865e-04 - acc: 1.0000 - val_loss: 2.2047e-04 - val_acc: 1.0000\n",
            "Epoch 8/12\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 3.2720e-04 - acc: 1.0000 - val_loss: 1.4251e-04 - val_acc: 1.0000\n",
            "Epoch 9/12\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 1.1144e-04 - acc: 1.0000 - val_loss: 1.0636e-04 - val_acc: 1.0000\n",
            "Epoch 10/12\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 1.2126e-04 - acc: 1.0000 - val_loss: 2.3145e-04 - val_acc: 1.0000\n",
            "Epoch 11/12\n",
            "1600/1600 [==============================] - 102s 64ms/step - loss: 6.7799e-05 - acc: 1.0000 - val_loss: 1.1938e-04 - val_acc: 1.0000\n",
            "Epoch 12/12\n",
            "1600/1600 [==============================] - 103s 64ms/step - loss: 2.9110e-05 - acc: 1.0000 - val_loss: 2.8203e-05 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f37f57c5d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "eA9GZhLGe5X9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "# print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "# model.fit(X_train, Y_train,\n",
        "#           batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "#           validation_data=(X_test, Y_test))\n",
        "\n",
        "# Y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qexmaPZVz04q",
        "colab_type": "code",
        "outputId": "44bb3c65-a86d-4dd2-e24e-2ff6b19255c3",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "cell_type": "code",
      "source": [
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.plot(Y_test[:, 1], 'r')\n",
        "\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.plot(Y_pred[:, 1], 'b')\n",
        "\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.plot(Y_test[:, 1] - Y_pred[:, 1], 'g')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf4AAAFKCAYAAAD8ND1GAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnxBCCHEgNPgJIYQQB0KDnxBCCHEg/wGTXNtNJNFPmQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f3828b699b0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "IPTFOJh3DTgq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "5958241b-dfdd-47b9-97b1-86ac0192e8c3"
      },
      "cell_type": "code",
      "source": [
        "now = datetime.datetime.now()\n",
        "\n",
        "modelSaved = '{}-{}_{}_{}.h5'.format(folderNormal, folderFault, pretrainedModel, now.strftime('%m-%d-%H:%M:%S'))\n",
        "\n",
        "# modelSaved = '{}-{}_{}_{}.h5'.format('P1', 'P5', pretrainedModel, now.strftime('%m-%d-%H:%M:%S'))\n",
        "meanSaved = 'mean_{}.npy'.format(now.strftime('%m-%d-%H:%M:%S'))\n",
        "stdSaved = 'std_{}.npy'.format(now.strftime('%m-%d-%H:%M:%S'))\n",
        "\n",
        "inputStr = input('''Save Model as '{}'? (y/n)\\n'''.format(modelSaved))\n",
        "\n",
        "if (inputStr == 'y' or inputStr == 'Y'):  \n",
        "    model.save('gdrive/My Drive/Colab/Model/{}'.format(modelSaved))\n",
        "    np.save('gdrive/My Drive/Colab/Model/{}'.format(meanSaved), trainMean)\n",
        "    np.save('gdrive/My Drive/Colab/Model/{}'.format(stdSaved), trainStd)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Save Model as '['A3F3P1']-['A3F3P5']_InceptionV3_11-20-04:57:15.h5'? (y/n)\n",
            "y\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}