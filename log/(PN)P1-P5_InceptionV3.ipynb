{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning Clean Up.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joovvhan/Master-Thesis/blob/master/log/(PN)P1-P5_InceptionV3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "c3821KWLNey6",
        "colab_type": "code",
        "outputId": "ea233957-3cc0-4eb7-b013-7c387530a63f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Import necessary modules\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy.io.wavfile as wf\n",
        "import time\n",
        "import glob\n",
        "import datetime\n",
        "\n",
        "from tqdm import trange\n",
        "\n",
        "# Import Keras modules\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.layers import Input, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
        "from keras.models import Sequential\n",
        "from keras import backend as K\n",
        "from keras.models import load_model\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "nxSASpgF7unA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Mount google drive\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "# os.listdir('gdrive/My Drive/Colab')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rw9NU8Xjwcz2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set data directories\n",
        "\n",
        "dataPath = '''D:\\\\0_Joowhan's Paper\\\\Synthesized\\\\Total\\\\Impulse'''\n",
        "modelPath = '''D:\\\\0_Joowhan's Paper\\\\Synthesized\\\\Total\\\\Model'''\n",
        "\n",
        "\n",
        "# Changed variable names to normal and fault\n",
        "# Changed variable names from folder to path\n",
        "# Need to consider multiple folders\n",
        "# Need to add files to be tested\n",
        "\n",
        "# folderNormal = ['P1N1', 'P2N1', 'P3N1', 'P4N1', 'P5N1']\n",
        "folderNormal = ['P1N1', 'P1N2', 'P1N3', 'P1N4', 'P1N5']\n",
        "\n",
        "# folderNormal = list()\n",
        "\n",
        "# for x in range(1, 6):\n",
        "#     for y in range(1, 6):\n",
        "#         for z in range(1, 6):\n",
        "#             if (x <= 2 and y <= 2 and z <= 2):\n",
        "#                 folderNormal.append('A{}F{}P{}'.format(x, y, z))\n",
        "\n",
        "# folderFault = list()\n",
        "\n",
        "folderFault = ['P5N1', 'P5N2', 'P5N3', 'P5N4', 'P5N5']\n",
        "\n",
        "# for x in range(1, 6):\n",
        "#     for y in range(1, 6):\n",
        "#         for z in range(1, 6):\n",
        "#             if (x == 5 or y == 5 or z == 5):\n",
        "#                 folderFault.append('A{}F{}P{}'.format(x, y, z))\n",
        "\n",
        "\n",
        "pathNormal = list()\n",
        "pathFault = list()\n",
        "\n",
        "for i in range(len(folderNormal)):\n",
        "    pathNormal.append(dataPath + '/' + folderNormal[i])\n",
        "    \n",
        "for i in range(len(folderFault)):\n",
        "    pathFault.append(dataPath + '/' + folderFault[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xgGP7PZO-rTA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Specgram settings\n",
        "\n",
        "nsc = 1470\n",
        "nov = nsc/2\n",
        "nff = nsc \n",
        "imgSize = 224\n",
        "\n",
        "# pretrainedModel = 'VGG19'\n",
        "# pretrainedModel = 'Xception'\n",
        "# pretrainedModel = 'ResNet50'\n",
        "\n",
        "# pretrainedModel = 'DenseNet169'\n",
        "pretrainedModel = 'InceptionV3'\n",
        "\n",
        "\n",
        "lastActivation = 'softmax'\n",
        "sizeBatch = 4\n",
        "numEpochs = 12\n",
        "verb = 1\n",
        "\n",
        "\n",
        "# Learning parameters\n",
        "\n",
        "trainingRatio = 0.8\n",
        "\n",
        "totalDataNum = 1000\n",
        "repeat = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5AskF2qFT2xr",
        "colab_type": "code",
        "outputId": "c022d8fa-e2fe-44d5-bcc8-7f7c9d3236e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "cell_type": "code",
      "source": [
        "startNum = 0\n",
        "\n",
        "pickNum = int(np.ceil(totalDataNum / len(pathNormal)))\n",
        "\n",
        "for i in range(startNum, len(pathNormal)):\n",
        "\n",
        "    npyTestPath = glob.glob(pathNormal[i] + '/' + '*Image_With_Label.npy')\n",
        "    data = np.load(npyTestPath[0])\n",
        "    \n",
        "    pickIdx = np.random.choice(1000, pickNum, replace=False)\n",
        "    pickIdx.sort()\n",
        "    \n",
        "#     imgs = np.moveaxis(np.dstack(data[:, 0]), 2, 0)\n",
        "#     label = data[:, 1:5]\n",
        "\n",
        "    imgs = np.moveaxis(np.dstack(data[pickIdx, 0]), 2, 0)\n",
        "    label = data[pickIdx, 1:5]\n",
        "    \n",
        "    if i == startNum:\n",
        "        labelListNormal = label\n",
        "        imgsNormal = imgs\n",
        "    else:\n",
        "        labelListNormal = np.vstack([labelListNormal, label])\n",
        "        imgsNormal = np.vstack([imgsNormal, imgs])\n",
        "\n",
        "    print('Normal Image Shape From {}: {}:'.format(pathNormal[i], totalDataNum))    \n",
        "    print('Selected {}/{}:'.format(pickNum * (i + 1), len(data)))    \n",
        "    \n",
        "    \n",
        "print('Normal Image Shape: {}'.format(imgsNormal.shape))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P1N1: 1000:\n",
            "Selected 200/1000:\n",
            "Normal Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P1N2: 1000:\n",
            "Selected 400/1000:\n",
            "Normal Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P1N3: 1000:\n",
            "Selected 600/1000:\n",
            "Normal Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P1N4: 1000:\n",
            "Selected 800/1000:\n",
            "Normal Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P1N5: 1000:\n",
            "Selected 1000/1000:\n",
            "Normal Image Shape: (1000, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P_MZtpk3Br_i",
        "colab_type": "code",
        "outputId": "0d31f8cf-68b2-4c91-a1d0-066e3df19a51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "cell_type": "code",
      "source": [
        "startNum = 0\n",
        "\n",
        "pickNum = int(np.ceil(totalDataNum / len(pathFault)))\n",
        "\n",
        "for i in range(startNum, len(pathFault)):\n",
        "\n",
        "    npyTestPath = glob.glob(pathFault[i] + '/' + '*Image_With_Label.npy')\n",
        "    data = np.load(npyTestPath[0])\n",
        "    \n",
        "    pickIdx = np.random.choice(1000, pickNum, replace=False)\n",
        "    pickIdx.sort()\n",
        "    \n",
        "#     imgs = np.moveaxis(np.dstack(data[:, 0]), 2, 0)\n",
        "#     label = data[:, 1:5]\n",
        "    \n",
        "    imgs = np.moveaxis(np.dstack(data[pickIdx, 0]), 2, 0)\n",
        "    label = data[pickIdx, 1:5]\n",
        "    \n",
        "    if i == startNum:\n",
        "        labelListFault = label\n",
        "        imgsFault = imgs\n",
        "    else:\n",
        "        labelListFault = np.vstack([labelListFault, label])\n",
        "        imgsFault = np.vstack([imgsFault, imgs])\n",
        "\n",
        "    print('Fault Image Shape From {}: {}:'.format(pathFault[i], totalDataNum))    \n",
        "    print('Selected {}/{}:'.format(pickNum * (i + 1), len(data)))     \n",
        "    \n",
        "print('Fault Image Shape: {}'.format(imgsFault.shape))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P5N1: 1000:\n",
            "Selected 200/1000:\n",
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P5N2: 1000:\n",
            "Selected 400/1000:\n",
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P5N3: 1000:\n",
            "Selected 600/1000:\n",
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P5N4: 1000:\n",
            "Selected 800/1000:\n",
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P5N5: 1000:\n",
            "Selected 1000/1000:\n",
            "Fault Image Shape: (1000, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e91QsAurSkIP",
        "colab_type": "code",
        "outputId": "c66dc9f0-06ad-47ce-ee6e-e8a09e55f934",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "cell_type": "code",
      "source": [
        "# Change name from imgsF1 or imgsF5 to imgsNormal and imgsFault\n",
        "\n",
        "dataNumNormal = len(imgsNormal)\n",
        "dataNumFault = len(imgsFault)\n",
        "dataNumNormalTrain = int(dataNumNormal * trainingRatio)\n",
        "dataNumFaultTrain = int(dataNumFault * trainingRatio)\n",
        "dataNumNormalTest = dataNumNormal - dataNumNormalTrain\n",
        "dataNumFaultTest = dataNumFault - dataNumFaultTrain\n",
        "\n",
        "print('Normal Train:Test = {:d}:{:d}'.format(dataNumNormalTrain, dataNumNormalTest))\n",
        "print('Fault  Train:Test = {:d}:{:d}\\n'.format(dataNumFaultTrain, dataNumFaultTest))\n",
        "\n",
        "trainIdxNormal = np.random.choice(dataNumNormal - 1, dataNumNormalTrain, replace=False)\n",
        "testIdxNormal = list(set(range(0, dataNumNormal)) - set(trainIdxNormal))\n",
        "\n",
        "trainImgsNormal = imgsNormal[trainIdxNormal, :, :]\n",
        "testImgsNormal = imgsNormal[testIdxNormal, :, :]\n",
        "\n",
        "print('Normal Training Image Shape {}'.format(trainImgsNormal.shape))\n",
        "print('Normal Test Image Shape {}\\n'.format(testImgsNormal.shape))\n",
        "\n",
        "trainIdxFault  = np.random.choice(dataNumFault - 1, dataNumFaultTrain, replace=False)\n",
        "testIdxFault = list(set(range(0, dataNumFault)) - set(trainIdxFault))\n",
        "\n",
        "trainImgsFault = imgsFault[trainIdxFault, :, :]\n",
        "testImgsFault = imgsFault[testIdxFault, :, :]\n",
        "\n",
        "print('Fault Training Image Shape {}'.format(trainImgsFault.shape))\n",
        "print('Fault Test Image Shape {}\\n'.format(testImgsFault.shape))\n",
        "\n",
        "trainImgs = np.vstack([trainImgsNormal, trainImgsFault])\n",
        "testImgs = np.vstack([testImgsNormal, testImgsFault])\n",
        "\n",
        "print('Training Image Shape {}'.format(trainImgs.shape))\n",
        "print('Test Image Shape {}'.format(testImgs.shape))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal Train:Test = 800:200\n",
            "Fault  Train:Test = 800:200\n",
            "\n",
            "Normal Training Image Shape (800, 224, 224)\n",
            "Normal Test Image Shape (200, 224, 224)\n",
            "\n",
            "Fault Training Image Shape (800, 224, 224)\n",
            "Fault Test Image Shape (200, 224, 224)\n",
            "\n",
            "Training Image Shape (1600, 224, 224)\n",
            "Test Image Shape (400, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MoE7f_hzs0av",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "feQ_AHAcUgHD",
        "colab_type": "code",
        "outputId": "40c90f02-60c0-4355-e273-c59a2c762e7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "trainMean = np.mean(trainImgs)\n",
        "trainStd = np.std(trainImgs)\n",
        "\n",
        "print('Mean of Training Image: {}'.format(trainMean))\n",
        "print('Standard Deviation of Training Image: {}'.format(trainStd))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean of Training Image: -79.18427615056027\n",
            "Standard Deviation of Training Image: 8.195042715179895\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wUi9IuXNUpir",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Should Change Norm to Normalized\n",
        "\n",
        "trainImgsNorm = (trainImgs - trainMean) / trainStd\n",
        "testImgsNorm = (testImgs - trainMean) / trainStd\n",
        "\n",
        "trainImgsNorm = trainImgsNorm.reshape(list(trainImgsNorm.shape) + [1])\n",
        "testImgsNorm = testImgsNorm.reshape(list(testImgsNorm.shape) + [1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aklxiPz1Ve4n",
        "colab_type": "code",
        "outputId": "382535a0-72ee-488d-9a2f-d5a488744b95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = np.stack([trainImgsNorm[:, :, :, 0], trainImgsNorm[:, :, :, 0], trainImgsNorm[:, :, :, 0]], axis = -1)\n",
        "X_test = np.stack([testImgsNorm[:, :, :, 0], testImgsNorm[:, :, :, 0], testImgsNorm[:, :, :, 0]], axis = -1)\n",
        "\n",
        "print('X_train Shape: {}'.format(X_train.shape))\n",
        "print('X_test  Shape: {}'.format(X_test.shape))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train Shape: (1600, 224, 224, 3)\n",
            "X_test  Shape: (400, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sRgIPzT7K_YP",
        "colab_type": "code",
        "outputId": "b188689c-dc4c-42bc-810f-c62c8fe725d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "trainLabelNormal = np.stack((np.ones(dataNumNormalTrain), np.zeros(dataNumNormalTrain)), axis = -1)\n",
        "testLabelNormal = np.stack((np.ones(dataNumNormalTest), np.zeros(dataNumNormalTest)), axis = -1)\n",
        "\n",
        "trainLabelFault = np.stack((np.zeros(dataNumFaultTrain), np.ones(dataNumFaultTrain)), axis = -1)\n",
        "testLabelFault = np.stack((np.zeros(dataNumFaultTest), np.ones(dataNumFaultTest)), axis = -1)\n",
        "\n",
        "Y_train = np.vstack((trainLabelNormal, trainLabelFault))\n",
        "Y_test = np.vstack((testLabelNormal, testLabelFault))\n",
        "\n",
        "print('Y_train Normal:Fault = {:d}:{:d}'.format(len(trainLabelNormal), len(trainLabelFault)))\n",
        "print('Y_test  Normal:Fault = {:d}:{:d}'.format(len(testLabelNormal), len(testLabelFault)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Y_train Normal:Fault = 800:800\n",
            "Y_test  Normal:Fault = 200:200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kczwZk7Tbp5C",
        "colab_type": "code",
        "outputId": "6b2ef95b-6956-4938-da98-cc0d465283dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2647
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG19\n",
        "from keras.applications import VGG16\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications.densenet import DenseNet169\n",
        "from keras.applications.densenet import DenseNet201\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# pretrainedModel = 'ResNet50'\n",
        "# lastActivation = 'softmax'\n",
        "# lossFunction = 'binary_crossentropy'\n",
        "# sizeBatch = 2\n",
        "# numEpochs = 2\n",
        "# verb = 1\n",
        "\n",
        "for rp in range(repeat):\n",
        "\n",
        "    # Refresh all background variables\n",
        "    K.clear_session()\n",
        "\n",
        "    input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "    # Building sequential model with name 'model'\n",
        "    model = Sequential()\n",
        "\n",
        "    # Model selection\n",
        "\n",
        "    if (pretrainedModel == 'VGG16'):\n",
        "\n",
        "        modelWoTop = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'VGG19'):\n",
        "\n",
        "        modelWoTop = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif pretrainedModel == 'ResNet50':\n",
        "\n",
        "        modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'InceptionV3'):\n",
        "        modelWoTop = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'Xception'):\n",
        "        modelWoTop = Xception(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet169'):\n",
        "\n",
        "        modelWoTop = DenseNet169(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet201'):\n",
        "        modelWoTop = DenseNet201(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    else:\n",
        "        print('Invalid Pretrained Model Selection')\n",
        "\n",
        "\n",
        "\n",
        "    # Model compiling\n",
        "\n",
        "    print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "    print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "    model.fit(X_train, Y_train,\n",
        "              batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "              validation_data=(X_test, Y_test))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compiling Pretrained inception_v3 Model\n",
            "Training Pretrained inception_v3 Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/12\n",
            "1600/1600 [==============================] - 71s 44ms/step - loss: 0.4445 - acc: 0.8794 - val_loss: 0.0101 - val_acc: 0.9975\n",
            "Epoch 2/12\n",
            "1600/1600 [==============================] - 55s 34ms/step - loss: 0.2202 - acc: 0.9425 - val_loss: 0.0062 - val_acc: 1.0000\n",
            "Epoch 3/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.1444 - acc: 0.9656 - val_loss: 2.5977 - val_acc: 0.8350\n",
            "Epoch 4/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0535 - acc: 0.9900 - val_loss: 8.0616 - val_acc: 0.4275\n",
            "Epoch 5/12\n",
            "1600/1600 [==============================] - 55s 35ms/step - loss: 0.0338 - acc: 0.9912 - val_loss: 0.0037 - val_acc: 1.0000\n",
            "Epoch 6/12\n",
            "1600/1600 [==============================] - 55s 35ms/step - loss: 0.0156 - acc: 0.9975 - val_loss: 0.4778 - val_acc: 0.5000\n",
            "Epoch 7/12\n",
            "1600/1600 [==============================] - 55s 35ms/step - loss: 0.0055 - acc: 0.9994 - val_loss: 0.2630 - val_acc: 0.9625\n",
            "Epoch 8/12\n",
            "1600/1600 [==============================] - 55s 35ms/step - loss: 0.1245 - acc: 0.9613 - val_loss: 7.9755 - val_acc: 0.5025\n",
            "Epoch 9/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0594 - acc: 0.9869 - val_loss: 0.0537 - val_acc: 0.9950\n",
            "Epoch 10/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0191 - acc: 0.9950 - val_loss: 0.8775 - val_acc: 0.9050\n",
            "Epoch 11/12\n",
            "1600/1600 [==============================] - 55s 35ms/step - loss: 0.0488 - acc: 0.9900 - val_loss: 1.3483 - val_acc: 0.9100\n",
            "Epoch 12/12\n",
            "1600/1600 [==============================] - 55s 35ms/step - loss: 0.0046 - acc: 0.9994 - val_loss: 0.0015 - val_acc: 1.0000\n",
            "Compiling Pretrained inception_v3 Model\n",
            "Training Pretrained inception_v3 Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/12\n",
            "1600/1600 [==============================] - 69s 43ms/step - loss: 0.3480 - acc: 0.8938 - val_loss: 6.8856 - val_acc: 0.5050\n",
            "Epoch 2/12\n",
            "1600/1600 [==============================] - 55s 35ms/step - loss: 0.2693 - acc: 0.9231 - val_loss: 0.4818 - val_acc: 0.8250\n",
            "Epoch 3/12\n",
            "1600/1600 [==============================] - 55s 35ms/step - loss: 0.1173 - acc: 0.9619 - val_loss: 0.2129 - val_acc: 0.8350\n",
            "Epoch 4/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0264 - acc: 0.9956 - val_loss: 0.0195 - val_acc: 1.0000\n",
            "Epoch 5/12\n",
            "1600/1600 [==============================] - 55s 35ms/step - loss: 0.0581 - acc: 0.9838 - val_loss: 0.4762 - val_acc: 0.9100\n",
            "Epoch 6/12\n",
            "1600/1600 [==============================] - 55s 34ms/step - loss: 0.0084 - acc: 0.9981 - val_loss: 1.3976 - val_acc: 0.3900\n",
            "Epoch 7/12\n",
            "1600/1600 [==============================] - 55s 34ms/step - loss: 0.0389 - acc: 0.9900 - val_loss: 0.0588 - val_acc: 1.0000\n",
            "Epoch 8/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0760 - acc: 0.9781 - val_loss: 0.0142 - val_acc: 1.0000\n",
            "Epoch 9/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0400 - acc: 0.9894 - val_loss: 0.0133 - val_acc: 0.9975\n",
            "Epoch 10/12\n",
            "1600/1600 [==============================] - 55s 35ms/step - loss: 0.0268 - acc: 0.9937 - val_loss: 0.9213 - val_acc: 0.5000\n",
            "Epoch 11/12\n",
            "1600/1600 [==============================] - 55s 35ms/step - loss: 0.0102 - acc: 0.9994 - val_loss: 0.7441 - val_acc: 0.5000\n",
            "Epoch 12/12\n",
            "1600/1600 [==============================] - 55s 35ms/step - loss: 0.0791 - acc: 0.9812 - val_loss: 0.0352 - val_acc: 0.9925\n",
            "Compiling Pretrained inception_v3 Model\n",
            "Training Pretrained inception_v3 Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/12\n",
            "1600/1600 [==============================] - 68s 43ms/step - loss: 0.3823 - acc: 0.8706 - val_loss: 0.2978 - val_acc: 0.9600\n",
            "Epoch 2/12\n",
            "1600/1600 [==============================] - 55s 34ms/step - loss: 0.2120 - acc: 0.9463 - val_loss: 0.0348 - val_acc: 0.9975\n",
            "Epoch 3/12\n",
            "1600/1600 [==============================] - 55s 35ms/step - loss: 0.0570 - acc: 0.9862 - val_loss: 0.1003 - val_acc: 0.9925\n",
            "Epoch 4/12\n",
            "1600/1600 [==============================] - 55s 35ms/step - loss: 0.1002 - acc: 0.9762 - val_loss: 0.0351 - val_acc: 0.9975\n",
            "Epoch 5/12\n",
            "1600/1600 [==============================] - 55s 35ms/step - loss: 0.0430 - acc: 0.9887 - val_loss: 0.0707 - val_acc: 0.9850\n",
            "Epoch 6/12\n",
            "1600/1600 [==============================] - 55s 35ms/step - loss: 0.0929 - acc: 0.9762 - val_loss: 0.0815 - val_acc: 0.9900\n",
            "Epoch 7/12\n",
            "1600/1600 [==============================] - 55s 35ms/step - loss: 0.0166 - acc: 0.9962 - val_loss: 0.0098 - val_acc: 1.0000\n",
            "Epoch 8/12\n",
            "1600/1600 [==============================] - 55s 34ms/step - loss: 0.0521 - acc: 0.9856 - val_loss: 6.9375 - val_acc: 0.5050\n",
            "Epoch 9/12\n",
            "1600/1600 [==============================] - 55s 34ms/step - loss: 0.0373 - acc: 0.9887 - val_loss: 0.0455 - val_acc: 1.0000\n",
            "Epoch 10/12\n",
            "1600/1600 [==============================] - 55s 34ms/step - loss: 0.0071 - acc: 0.9987 - val_loss: 0.0057 - val_acc: 1.0000\n",
            "Epoch 11/12\n",
            "1600/1600 [==============================] - 55s 34ms/step - loss: 0.0104 - acc: 0.9956 - val_loss: 0.0032 - val_acc: 1.0000\n",
            "Epoch 12/12\n",
            "1600/1600 [==============================] - 55s 34ms/step - loss: 0.0199 - acc: 0.9931 - val_loss: 0.0228 - val_acc: 1.0000\n",
            "Compiling Pretrained inception_v3 Model\n",
            "Training Pretrained inception_v3 Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/12\n",
            "1600/1600 [==============================] - 68s 43ms/step - loss: 0.3710 - acc: 0.8950 - val_loss: 0.5231 - val_acc: 0.9400\n",
            "Epoch 2/12\n",
            "1600/1600 [==============================] - 55s 34ms/step - loss: 0.2455 - acc: 0.9287 - val_loss: 0.4904 - val_acc: 0.6700\n",
            "Epoch 3/12\n",
            "1600/1600 [==============================] - 55s 34ms/step - loss: 0.1769 - acc: 0.9469 - val_loss: 0.3099 - val_acc: 0.8925\n",
            "Epoch 4/12\n",
            "1600/1600 [==============================] - 55s 35ms/step - loss: 0.1210 - acc: 0.9631 - val_loss: 0.1382 - val_acc: 0.9925\n",
            "Epoch 5/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.1134 - acc: 0.9669 - val_loss: 0.0238 - val_acc: 1.0000\n",
            "Epoch 6/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0189 - acc: 0.9950 - val_loss: 1.0935 - val_acc: 0.5000\n",
            "Epoch 7/12\n",
            "1600/1600 [==============================] - 55s 35ms/step - loss: 0.0494 - acc: 0.9875 - val_loss: 0.0254 - val_acc: 1.0000\n",
            "Epoch 8/12\n",
            "1600/1600 [==============================] - 55s 35ms/step - loss: 0.0247 - acc: 0.9925 - val_loss: 0.0701 - val_acc: 1.0000\n",
            "Epoch 9/12\n",
            "1600/1600 [==============================] - 55s 34ms/step - loss: 0.0272 - acc: 0.9937 - val_loss: 0.0176 - val_acc: 0.9900\n",
            "Epoch 10/12\n",
            "1600/1600 [==============================] - 55s 34ms/step - loss: 0.0286 - acc: 0.9906 - val_loss: 0.0053 - val_acc: 1.0000\n",
            "Epoch 11/12\n",
            "1600/1600 [==============================] - 55s 34ms/step - loss: 0.0312 - acc: 0.9931 - val_loss: 7.3130 - val_acc: 0.5350\n",
            "Epoch 12/12\n",
            "1600/1600 [==============================] - 55s 35ms/step - loss: 0.0338 - acc: 0.9887 - val_loss: 0.0025 - val_acc: 1.0000\n",
            "Compiling Pretrained inception_v3 Model\n",
            "Training Pretrained inception_v3 Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1600 samples, validate on 400 samples\n",
            "Epoch 1/12\n",
            "1600/1600 [==============================] - 70s 43ms/step - loss: 0.3456 - acc: 0.8888 - val_loss: 5.2416 - val_acc: 0.5000\n",
            "Epoch 2/12\n",
            "1600/1600 [==============================] - 55s 34ms/step - loss: 0.1848 - acc: 0.9488 - val_loss: 3.2102 - val_acc: 0.7450\n",
            "Epoch 3/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.1147 - acc: 0.9637 - val_loss: 0.7671 - val_acc: 0.5850\n",
            "Epoch 4/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0599 - acc: 0.9825 - val_loss: 0.0123 - val_acc: 1.0000\n",
            "Epoch 5/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0627 - acc: 0.9850 - val_loss: 0.0831 - val_acc: 0.9800\n",
            "Epoch 6/12\n",
            "1600/1600 [==============================] - 55s 35ms/step - loss: 0.0569 - acc: 0.9862 - val_loss: 0.0849 - val_acc: 0.9800\n",
            "Epoch 7/12\n",
            "1600/1600 [==============================] - 55s 35ms/step - loss: 0.0425 - acc: 0.9900 - val_loss: 6.1943 - val_acc: 0.5975\n",
            "Epoch 8/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.1254 - acc: 0.9550 - val_loss: 0.3063 - val_acc: 0.9225\n",
            "Epoch 9/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0270 - acc: 0.9950 - val_loss: 0.0015 - val_acc: 1.0000\n",
            "Epoch 10/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0197 - acc: 0.9944 - val_loss: 0.0250 - val_acc: 0.9925\n",
            "Epoch 11/12\n",
            "1600/1600 [==============================] - 55s 35ms/step - loss: 0.0653 - acc: 0.9856 - val_loss: 0.0121 - val_acc: 0.9950\n",
            "Epoch 12/12\n",
            "1600/1600 [==============================] - 56s 35ms/step - loss: 0.0293 - acc: 0.9937 - val_loss: 0.0011 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jKgFIa4gkgkk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "# print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "# model.fit(X_train, Y_train,\n",
        "#           batch_size=sizeBatch, epochs=1, verbose=1,\n",
        "#           validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "agqqH8sf3CiV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# K.clear_session()\n",
        "\n",
        "# input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "# # Building sequential model with name 'model'\n",
        "# model = Sequential()\n",
        "\n",
        "# modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "# model.add(modelWoTop)\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "# # Model compiling\n",
        "\n",
        "# print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "# model.compile(loss='binary_crossentropy',\n",
        "#               optimizer='adam',\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "# numEpochs = 1\n",
        "\n",
        "# print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "# print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "# model.fit(X_train, Y_train,\n",
        "#           batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "#           validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qexmaPZVz04q",
        "colab_type": "code",
        "outputId": "aa4b3152-6b55-479d-f8ef-9e965c0c867d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.plot(Y_test[:, 1], 'r')\n",
        "\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.plot(Y_pred[:, 1], 'b')\n",
        "\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.plot(Y_test[:, 1] - Y_pred[:, 1], 'g')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "IPTFOJh3DTgq",
        "colab_type": "code",
        "outputId": "5a2267eb-da99-4bda-ceef-328c6ce1c538",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "cell_type": "code",
      "source": [
        "now = datetime.datetime.now()\n",
        "\n",
        "# modelSaved = '{}-{}_{}_{}.h5'.format(folderNormal, folderFault, pretrainedModel, now.strftime('%m-%d-%H:%M:%S'))\n",
        "\n",
        "modelSaved = '{}-{}_{}_{}.h5'.format(folderNormal, folderFault, pretrainedModel, now.strftime('%m-%d-%H-%M-%S'))\n",
        "meanSaved = 'mean_{}.npy'.format(now.strftime('%m-%d-%H-%M-%S'))\n",
        "stdSaved = 'std_{}.npy'.format(now.strftime('%m-%d-%H-%M-%S'))\n",
        "\n",
        "inputStr = input('''Save Model as '{}'? (y/n)\\n'''.format(modelSaved))\n",
        "\n",
        "if (inputStr == 'y' or inputStr == 'Y'):  \n",
        "    model.save(modelPath + '/{}'.format(modelSaved))\n",
        "    np.save(modelPath + '/{}'.format(meanSaved), trainMean)\n",
        "    np.save(modelPath + '/{}'.format(stdSaved), trainStd)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Save Model as '['P1N1', 'P1N2', 'P1N3', 'P1N4', 'P1N5']-['P5N1', 'P5N2', 'P5N3', 'P5N4', 'P5N5']_InceptionV3_11-19-09-11-15.h5'? (y/n)\n",
            "ㅜ\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}