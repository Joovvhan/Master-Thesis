{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning Clean Up.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joovvhan/Master-Thesis/blob/master/log/(PN)N-F_ResNet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "c3821KWLNey6",
        "colab_type": "code",
        "outputId": "d89e6cf2-7ba1-46bb-aa88-fa6e7b619a99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Import necessary modules\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy.io.wavfile as wf\n",
        "import time\n",
        "import glob\n",
        "import datetime\n",
        "\n",
        "from tqdm import trange\n",
        "\n",
        "# Import Keras modules\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.layers import Input, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
        "from keras.models import Sequential\n",
        "from keras import backend as K\n",
        "from keras.models import load_model\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "nxSASpgF7unA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Mount google drive\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "# os.listdir('gdrive/My Drive/Colab')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rw9NU8Xjwcz2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set data directories\n",
        "\n",
        "dataPath = '''D:\\\\0_Joowhan's Paper\\\\Synthesized\\\\Total\\\\Impulse'''\n",
        "modelPath = '''D:\\\\0_Joowhan's Paper\\\\Synthesized\\\\Total\\\\Model'''\n",
        "\n",
        "\n",
        "# Changed variable names to normal and fault\n",
        "# Changed variable names from folder to path\n",
        "# Need to consider multiple folders\n",
        "# Need to add files to be tested\n",
        "\n",
        "# folderNormal = ['P1N1', 'P2N1', 'P3N1', 'P4N1', 'P5N1']\n",
        "folderNormal = list()\n",
        "\n",
        "for x in range(1, 6):\n",
        "    for y in range(1, 6):\n",
        "        if (x <= 2 and y <= 2):\n",
        "            folderNormal.append('P{}N{}'.format(x, y))\n",
        "\n",
        "folderFault = list()\n",
        "\n",
        "# folderFault = ['P1N5', 'P2N5', 'P3N5', 'P4N5', 'P5N5']\n",
        "\n",
        "for x in range(1, 6):\n",
        "    for y in range(1, 6):\n",
        "        if (x == 5 or y == 5):\n",
        "            folderFault.append('P{}N{}'.format(x, y))\n",
        "\n",
        "\n",
        "pathNormal = list()\n",
        "pathFault = list()\n",
        "\n",
        "for i in range(len(folderNormal)):\n",
        "    pathNormal.append(dataPath + '/' + folderNormal[i])\n",
        "    \n",
        "for i in range(len(folderFault)):\n",
        "    pathFault.append(dataPath + '/' + folderFault[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xgGP7PZO-rTA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Specgram settings\n",
        "\n",
        "nsc = 1470\n",
        "nov = nsc/2\n",
        "nff = nsc \n",
        "imgSize = 224\n",
        "\n",
        "# pretrainedModel = 'VGG19'\n",
        "# pretrainedModel = 'Xception'\n",
        "pretrainedModel = 'ResNet50'\n",
        "\n",
        "# pretrainedModel = 'DenseNet169'\n",
        "# pretrainedModel = 'InceptionV3'\n",
        "\n",
        "\n",
        "lastActivation = 'softmax'\n",
        "sizeBatch = 4\n",
        "numEpochs = 12\n",
        "verb = 1\n",
        "\n",
        "\n",
        "# Learning parameters\n",
        "\n",
        "trainingRatio = 0.8\n",
        "\n",
        "totalDataNum = 1000\n",
        "repeat = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5AskF2qFT2xr",
        "colab_type": "code",
        "outputId": "0e163063-81ce-4d2a-c0a5-92437ab6e63b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "cell_type": "code",
      "source": [
        "startNum = 0\n",
        "\n",
        "pickNum = int(np.ceil(totalDataNum / len(pathNormal)))\n",
        "\n",
        "for i in range(startNum, len(pathNormal)):\n",
        "\n",
        "    npyTestPath = glob.glob(pathNormal[i] + '/' + '*Image_With_Label.npy')\n",
        "    data = np.load(npyTestPath[0])\n",
        "    \n",
        "    pickIdx = np.random.choice(1000, pickNum, replace=False)\n",
        "    pickIdx.sort()\n",
        "    \n",
        "#     imgs = np.moveaxis(np.dstack(data[:, 0]), 2, 0)\n",
        "#     label = data[:, 1:5]\n",
        "\n",
        "    imgs = np.moveaxis(np.dstack(data[pickIdx, 0]), 2, 0)\n",
        "    label = data[pickIdx, 1:5]\n",
        "    \n",
        "    if i == startNum:\n",
        "        labelListNormal = label\n",
        "        imgsNormal = imgs\n",
        "    else:\n",
        "        labelListNormal = np.vstack([labelListNormal, label])\n",
        "        imgsNormal = np.vstack([imgsNormal, imgs])\n",
        "\n",
        "    print('Normal Image Shape From {}: {}:'.format(pathNormal[i], totalDataNum))    \n",
        "    print('Selected {}/{}:'.format(pickNum * (i + 1), len(data)))    \n",
        "    \n",
        "    \n",
        "print('Normal Image Shape: {}'.format(imgsNormal.shape))\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P1N1: 1000:\n",
            "Selected 250/1000:\n",
            "Normal Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P1N2: 1000:\n",
            "Selected 500/1000:\n",
            "Normal Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P2N1: 1000:\n",
            "Selected 750/1000:\n",
            "Normal Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P2N2: 1000:\n",
            "Selected 1000/1000:\n",
            "Normal Image Shape: (1000, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P_MZtpk3Br_i",
        "colab_type": "code",
        "outputId": "256174ae-3005-406e-a7fc-924488002329",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "cell_type": "code",
      "source": [
        "startNum = 0\n",
        "\n",
        "pickNum = int(np.ceil(totalDataNum / len(pathFault)))\n",
        "\n",
        "for i in range(startNum, len(pathFault)):\n",
        "\n",
        "    npyTestPath = glob.glob(pathFault[i] + '/' + '*Image_With_Label.npy')\n",
        "    data = np.load(npyTestPath[0])\n",
        "    \n",
        "    pickIdx = np.random.choice(1000, pickNum, replace=False)\n",
        "    pickIdx.sort()\n",
        "    \n",
        "#     imgs = np.moveaxis(np.dstack(data[:, 0]), 2, 0)\n",
        "#     label = data[:, 1:5]\n",
        "    \n",
        "    imgs = np.moveaxis(np.dstack(data[pickIdx, 0]), 2, 0)\n",
        "    label = data[pickIdx, 1:5]\n",
        "    \n",
        "    if i == startNum:\n",
        "        labelListFault = label\n",
        "        imgsFault = imgs\n",
        "    else:\n",
        "        labelListFault = np.vstack([labelListFault, label])\n",
        "        imgsFault = np.vstack([imgsFault, imgs])\n",
        "\n",
        "    print('Fault Image Shape From {}: {}:'.format(pathFault[i], totalDataNum))    \n",
        "    print('Selected {}/{}:'.format(pickNum * (i + 1), len(data)))     \n",
        "    \n",
        "print('Fault Image Shape: {}'.format(imgsFault.shape))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P1N5: 1000:\n",
            "Selected 112/1000:\n",
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P2N5: 1000:\n",
            "Selected 224/1000:\n",
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P3N5: 1000:\n",
            "Selected 336/1000:\n",
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P4N5: 1000:\n",
            "Selected 448/1000:\n",
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P5N1: 1000:\n",
            "Selected 560/1000:\n",
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P5N2: 1000:\n",
            "Selected 672/1000:\n",
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P5N3: 1000:\n",
            "Selected 784/1000:\n",
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P5N4: 1000:\n",
            "Selected 896/1000:\n",
            "Fault Image Shape From D:\\0_Joowhan's Paper\\Synthesized\\Total\\Impulse/P5N5: 1000:\n",
            "Selected 1008/1000:\n",
            "Fault Image Shape: (1008, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e91QsAurSkIP",
        "colab_type": "code",
        "outputId": "ae474a86-65e9-4c2f-ce42-2089c29b0657",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "cell_type": "code",
      "source": [
        "# Change name from imgsF1 or imgsF5 to imgsNormal and imgsFault\n",
        "\n",
        "dataNumNormal = len(imgsNormal)\n",
        "dataNumFault = len(imgsFault)\n",
        "dataNumNormalTrain = int(dataNumNormal * trainingRatio)\n",
        "dataNumFaultTrain = int(dataNumFault * trainingRatio)\n",
        "dataNumNormalTest = dataNumNormal - dataNumNormalTrain\n",
        "dataNumFaultTest = dataNumFault - dataNumFaultTrain\n",
        "\n",
        "print('Normal Train:Test = {:d}:{:d}'.format(dataNumNormalTrain, dataNumNormalTest))\n",
        "print('Fault  Train:Test = {:d}:{:d}\\n'.format(dataNumFaultTrain, dataNumFaultTest))\n",
        "\n",
        "trainIdxNormal = np.random.choice(dataNumNormal - 1, dataNumNormalTrain, replace=False)\n",
        "testIdxNormal = list(set(range(0, dataNumNormal)) - set(trainIdxNormal))\n",
        "\n",
        "trainImgsNormal = imgsNormal[trainIdxNormal, :, :]\n",
        "testImgsNormal = imgsNormal[testIdxNormal, :, :]\n",
        "\n",
        "print('Normal Training Image Shape {}'.format(trainImgsNormal.shape))\n",
        "print('Normal Test Image Shape {}\\n'.format(testImgsNormal.shape))\n",
        "\n",
        "trainIdxFault  = np.random.choice(dataNumFault - 1, dataNumFaultTrain, replace=False)\n",
        "testIdxFault = list(set(range(0, dataNumFault)) - set(trainIdxFault))\n",
        "\n",
        "trainImgsFault = imgsFault[trainIdxFault, :, :]\n",
        "testImgsFault = imgsFault[testIdxFault, :, :]\n",
        "\n",
        "print('Fault Training Image Shape {}'.format(trainImgsFault.shape))\n",
        "print('Fault Test Image Shape {}\\n'.format(testImgsFault.shape))\n",
        "\n",
        "trainImgs = np.vstack([trainImgsNormal, trainImgsFault])\n",
        "testImgs = np.vstack([testImgsNormal, testImgsFault])\n",
        "\n",
        "print('Training Image Shape {}'.format(trainImgs.shape))\n",
        "print('Test Image Shape {}'.format(testImgs.shape))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal Train:Test = 800:200\n",
            "Fault  Train:Test = 806:202\n",
            "\n",
            "Normal Training Image Shape (800, 224, 224)\n",
            "Normal Test Image Shape (200, 224, 224)\n",
            "\n",
            "Fault Training Image Shape (806, 224, 224)\n",
            "Fault Test Image Shape (202, 224, 224)\n",
            "\n",
            "Training Image Shape (1606, 224, 224)\n",
            "Test Image Shape (402, 224, 224)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MoE7f_hzs0av",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "feQ_AHAcUgHD",
        "colab_type": "code",
        "outputId": "a29c8457-8d3d-434f-fc72-93c860d63c21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "trainMean = np.mean(trainImgs)\n",
        "trainStd = np.std(trainImgs)\n",
        "\n",
        "print('Mean of Training Image: {}'.format(trainMean))\n",
        "print('Standard Deviation of Training Image: {}'.format(trainStd))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean of Training Image: -79.2125888777502\n",
            "Standard Deviation of Training Image: 8.118581527896263\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wUi9IuXNUpir",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Should Change Norm to Normalized\n",
        "\n",
        "trainImgsNorm = (trainImgs - trainMean) / trainStd\n",
        "testImgsNorm = (testImgs - trainMean) / trainStd\n",
        "\n",
        "trainImgsNorm = trainImgsNorm.reshape(list(trainImgsNorm.shape) + [1])\n",
        "testImgsNorm = testImgsNorm.reshape(list(testImgsNorm.shape) + [1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aklxiPz1Ve4n",
        "colab_type": "code",
        "outputId": "807db963-e048-485f-afa5-262dc67d500c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = np.stack([trainImgsNorm[:, :, :, 0], trainImgsNorm[:, :, :, 0], trainImgsNorm[:, :, :, 0]], axis = -1)\n",
        "X_test = np.stack([testImgsNorm[:, :, :, 0], testImgsNorm[:, :, :, 0], testImgsNorm[:, :, :, 0]], axis = -1)\n",
        "\n",
        "print('X_train Shape: {}'.format(X_train.shape))\n",
        "print('X_test  Shape: {}'.format(X_test.shape))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train Shape: (1606, 224, 224, 3)\n",
            "X_test  Shape: (402, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sRgIPzT7K_YP",
        "colab_type": "code",
        "outputId": "7e1c23f7-5c36-46d6-83c6-05ab1f61ceb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "trainLabelNormal = np.stack((np.ones(dataNumNormalTrain), np.zeros(dataNumNormalTrain)), axis = -1)\n",
        "testLabelNormal = np.stack((np.ones(dataNumNormalTest), np.zeros(dataNumNormalTest)), axis = -1)\n",
        "\n",
        "trainLabelFault = np.stack((np.zeros(dataNumFaultTrain), np.ones(dataNumFaultTrain)), axis = -1)\n",
        "testLabelFault = np.stack((np.zeros(dataNumFaultTest), np.ones(dataNumFaultTest)), axis = -1)\n",
        "\n",
        "Y_train = np.vstack((trainLabelNormal, trainLabelFault))\n",
        "Y_test = np.vstack((testLabelNormal, testLabelFault))\n",
        "\n",
        "print('Y_train Normal:Fault = {:d}:{:d}'.format(len(trainLabelNormal), len(trainLabelFault)))\n",
        "print('Y_test  Normal:Fault = {:d}:{:d}'.format(len(testLabelNormal), len(testLabelFault)))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Y_train Normal:Fault = 800:806\n",
            "Y_test  Normal:Fault = 200:202\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kczwZk7Tbp5C",
        "colab_type": "code",
        "outputId": "29d32414-33de-42f2-a43e-1465c86fc2c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2683
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG19\n",
        "from keras.applications import VGG16\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications.densenet import DenseNet169\n",
        "from keras.applications.densenet import DenseNet201\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# pretrainedModel = 'ResNet50'\n",
        "# lastActivation = 'softmax'\n",
        "# lossFunction = 'binary_crossentropy'\n",
        "# sizeBatch = 2\n",
        "# numEpochs = 2\n",
        "# verb = 1\n",
        "\n",
        "for rp in range(repeat):\n",
        "\n",
        "    # Refresh all background variables\n",
        "    K.clear_session()\n",
        "\n",
        "    input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "    # Building sequential model with name 'model'\n",
        "    model = Sequential()\n",
        "\n",
        "    # Model selection\n",
        "\n",
        "    if (pretrainedModel == 'VGG16'):\n",
        "\n",
        "        modelWoTop = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'VGG19'):\n",
        "\n",
        "        modelWoTop = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(4096, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif pretrainedModel == 'ResNet50':\n",
        "\n",
        "        modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'InceptionV3'):\n",
        "        modelWoTop = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'Xception'):\n",
        "        modelWoTop = Xception(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet169'):\n",
        "\n",
        "        modelWoTop = DenseNet169(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    elif (pretrainedModel == 'DenseNet201'):\n",
        "        modelWoTop = DenseNet201(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "        model.add(modelWoTop)\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "    else:\n",
        "        print('Invalid Pretrained Model Selection')\n",
        "\n",
        "\n",
        "\n",
        "    # Model compiling\n",
        "\n",
        "    print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "    print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "    model.fit(X_train, Y_train,\n",
        "              batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "              validation_data=(X_test, Y_test))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "c:\\users\\주환\\appdata\\local\\conda\\conda\\envs\\paper\\lib\\site-packages\\keras_applications\\resnet50.py:263: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Compiling Pretrained resnet50 Model\n",
            "Training Pretrained resnet50 Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1606 samples, validate on 402 samples\n",
            "Epoch 1/12\n",
            "1606/1606 [==============================] - 81s 50ms/step - loss: 7.8610 - acc: 0.5056 - val_loss: 7.9752 - val_acc: 0.5025\n",
            "Epoch 2/12\n",
            "1606/1606 [==============================] - 67s 42ms/step - loss: 7.9852 - acc: 0.5019 - val_loss: 7.9752 - val_acc: 0.5025\n",
            "Epoch 3/12\n",
            "1606/1606 [==============================] - 67s 42ms/step - loss: 7.9852 - acc: 0.5019 - val_loss: 7.9752 - val_acc: 0.5025\n",
            "Epoch 4/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 7.9852 - acc: 0.5019 - val_loss: 7.9752 - val_acc: 0.5025\n",
            "Epoch 5/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 7.9852 - acc: 0.5019 - val_loss: 7.9752 - val_acc: 0.5025\n",
            "Epoch 6/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 7.9852 - acc: 0.5019 - val_loss: 7.9752 - val_acc: 0.5025\n",
            "Epoch 7/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 7.9852 - acc: 0.5019 - val_loss: 7.9752 - val_acc: 0.5025\n",
            "Epoch 8/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 7.9852 - acc: 0.5019 - val_loss: 7.9752 - val_acc: 0.5025\n",
            "Epoch 9/12\n",
            "1606/1606 [==============================] - 68s 43ms/step - loss: 7.9852 - acc: 0.5019 - val_loss: 7.9752 - val_acc: 0.5025\n",
            "Epoch 10/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 7.9852 - acc: 0.5019 - val_loss: 7.9752 - val_acc: 0.5025\n",
            "Epoch 11/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 7.9852 - acc: 0.5019 - val_loss: 7.9752 - val_acc: 0.5025\n",
            "Epoch 12/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 7.9852 - acc: 0.5019 - val_loss: 7.9752 - val_acc: 0.5025\n",
            "Compiling Pretrained resnet50 Model\n",
            "Training Pretrained resnet50 Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1606 samples, validate on 402 samples\n",
            "Epoch 1/12\n",
            "1606/1606 [==============================] - 79s 49ms/step - loss: 1.8269 - acc: 0.7578 - val_loss: 1.5898 - val_acc: 0.7811\n",
            "Epoch 2/12\n",
            "1606/1606 [==============================] - 67s 42ms/step - loss: 1.7078 - acc: 0.7615 - val_loss: 1.6073 - val_acc: 0.8284\n",
            "Epoch 3/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 1.1025 - acc: 0.8257 - val_loss: 2.1063 - val_acc: 0.8060\n",
            "Epoch 4/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 1.2639 - acc: 0.8200 - val_loss: 0.3761 - val_acc: 0.8781\n",
            "Epoch 5/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.8894 - acc: 0.8568 - val_loss: 0.3017 - val_acc: 0.8930\n",
            "Epoch 6/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.8226 - acc: 0.8705 - val_loss: 0.2271 - val_acc: 0.9104\n",
            "Epoch 7/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.6371 - acc: 0.8910 - val_loss: 0.1734 - val_acc: 0.9453\n",
            "Epoch 8/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.7516 - acc: 0.9004 - val_loss: 0.1770 - val_acc: 0.9353\n",
            "Epoch 9/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.7619 - acc: 0.8854 - val_loss: 0.1620 - val_acc: 0.9453\n",
            "Epoch 10/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.6946 - acc: 0.9016 - val_loss: 0.1242 - val_acc: 0.9602\n",
            "Epoch 11/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.8103 - acc: 0.9016 - val_loss: 0.2472 - val_acc: 0.9552\n",
            "Epoch 12/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.7567 - acc: 0.8736 - val_loss: 0.2698 - val_acc: 0.9254\n",
            "Compiling Pretrained resnet50 Model\n",
            "Training Pretrained resnet50 Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1606 samples, validate on 402 samples\n",
            "Epoch 1/12\n",
            "1606/1606 [==============================] - 79s 49ms/step - loss: 7.9709 - acc: 0.5019 - val_loss: 7.9752 - val_acc: 0.5025\n",
            "Epoch 2/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 7.9852 - acc: 0.5019 - val_loss: 7.9752 - val_acc: 0.5025\n",
            "Epoch 3/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 7.9852 - acc: 0.5019 - val_loss: 7.9752 - val_acc: 0.5025\n",
            "Epoch 4/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 7.9852 - acc: 0.5019 - val_loss: 7.9752 - val_acc: 0.5025\n",
            "Epoch 5/12\n",
            "1606/1606 [==============================] - 68s 43ms/step - loss: 7.9852 - acc: 0.5019 - val_loss: 7.9752 - val_acc: 0.5025\n",
            "Epoch 6/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 7.9852 - acc: 0.5019 - val_loss: 7.9752 - val_acc: 0.5025\n",
            "Epoch 7/12\n",
            "1606/1606 [==============================] - 69s 43ms/step - loss: 7.9852 - acc: 0.5019 - val_loss: 7.9752 - val_acc: 0.5025\n",
            "Epoch 8/12\n",
            "1606/1606 [==============================] - 68s 43ms/step - loss: 7.9852 - acc: 0.5019 - val_loss: 7.9752 - val_acc: 0.5025\n",
            "Epoch 9/12\n",
            "1606/1606 [==============================] - 68s 43ms/step - loss: 7.9852 - acc: 0.5019 - val_loss: 7.9752 - val_acc: 0.5025\n",
            "Epoch 10/12\n",
            "1606/1606 [==============================] - 68s 43ms/step - loss: 7.9852 - acc: 0.5019 - val_loss: 7.9752 - val_acc: 0.5025\n",
            "Epoch 11/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 7.9852 - acc: 0.5019 - val_loss: 7.9752 - val_acc: 0.5025\n",
            "Epoch 12/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 7.9852 - acc: 0.5019 - val_loss: 7.9752 - val_acc: 0.5025\n",
            "Compiling Pretrained resnet50 Model\n",
            "Training Pretrained resnet50 Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1606 samples, validate on 402 samples\n",
            "Epoch 1/12\n",
            "1606/1606 [==============================] - 79s 49ms/step - loss: 8.0369 - acc: 0.4981 - val_loss: 8.0550 - val_acc: 0.4975\n",
            "Epoch 2/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 8.0451 - acc: 0.4981 - val_loss: 8.0550 - val_acc: 0.4975\n",
            "Epoch 3/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 8.0451 - acc: 0.4981 - val_loss: 8.0550 - val_acc: 0.4975\n",
            "Epoch 4/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 8.0451 - acc: 0.4981 - val_loss: 8.0550 - val_acc: 0.4975\n",
            "Epoch 5/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 8.0451 - acc: 0.4981 - val_loss: 8.0550 - val_acc: 0.4975\n",
            "Epoch 6/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 8.0451 - acc: 0.4981 - val_loss: 8.0550 - val_acc: 0.4975\n",
            "Epoch 7/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 8.0451 - acc: 0.4981 - val_loss: 8.0550 - val_acc: 0.4975\n",
            "Epoch 8/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 8.0451 - acc: 0.4981 - val_loss: 8.0550 - val_acc: 0.4975\n",
            "Epoch 9/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 8.0451 - acc: 0.4981 - val_loss: 8.0550 - val_acc: 0.4975\n",
            "Epoch 10/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 8.0451 - acc: 0.4981 - val_loss: 8.0550 - val_acc: 0.4975\n",
            "Epoch 11/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 8.0451 - acc: 0.4981 - val_loss: 8.0550 - val_acc: 0.4975\n",
            "Epoch 12/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 8.0451 - acc: 0.4981 - val_loss: 8.0550 - val_acc: 0.4975\n",
            "Compiling Pretrained resnet50 Model\n",
            "Training Pretrained resnet50 Model\n",
            "Batch Size: 4\t Epochs: 12\t\n",
            "\n",
            "Train on 1606 samples, validate on 402 samples\n",
            "Epoch 1/12\n",
            "1606/1606 [==============================] - 79s 49ms/step - loss: 2.1718 - acc: 0.7397 - val_loss: 1.5842 - val_acc: 0.8159\n",
            "Epoch 2/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 2.0616 - acc: 0.7036 - val_loss: 8.0949 - val_acc: 0.4950\n",
            "Epoch 3/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 2.1946 - acc: 0.6451 - val_loss: 0.5566 - val_acc: 0.8234\n",
            "Epoch 4/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 1.6202 - acc: 0.7366 - val_loss: 0.5381 - val_acc: 0.8408\n",
            "Epoch 5/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 1.1444 - acc: 0.7839 - val_loss: 0.5158 - val_acc: 0.8433\n",
            "Epoch 6/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 1.0523 - acc: 0.8319 - val_loss: 0.5561 - val_acc: 0.8458\n",
            "Epoch 7/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 1.8439 - acc: 0.7540 - val_loss: 0.5654 - val_acc: 0.8184\n",
            "Epoch 8/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 2.6645 - acc: 0.7179 - val_loss: 5.4390 - val_acc: 0.6294\n",
            "Epoch 9/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.8815 - acc: 0.8487 - val_loss: 1.1137 - val_acc: 0.8408\n",
            "Epoch 10/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.8601 - acc: 0.8817 - val_loss: 0.3872 - val_acc: 0.9129\n",
            "Epoch 11/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.7411 - acc: 0.8954 - val_loss: 0.2584 - val_acc: 0.9129\n",
            "Epoch 12/12\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.7402 - acc: 0.8823 - val_loss: 0.2940 - val_acc: 0.9303\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LMf390ePDy2_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 865
        },
        "outputId": "743747df-e065-4395-ae5b-05c628e06240"
      },
      "cell_type": "code",
      "source": [
        "# Refresh all background variables\n",
        "K.clear_session()\n",
        "\n",
        "input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "# Building sequential model with name 'model'\n",
        "model = Sequential()\n",
        "\n",
        "# Model selection\n",
        "\n",
        "if (pretrainedModel == 'VGG16'):\n",
        "\n",
        "    modelWoTop = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'VGG19'):\n",
        "\n",
        "    modelWoTop = VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif pretrainedModel == 'ResNet50':\n",
        "\n",
        "    modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'InceptionV3'):\n",
        "    modelWoTop = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'Xception'):\n",
        "    modelWoTop = Xception(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'DenseNet169'):\n",
        "\n",
        "    modelWoTop = DenseNet169(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "elif (pretrainedModel == 'DenseNet201'):\n",
        "    modelWoTop = DenseNet201(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "    model.add(modelWoTop)\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "else:\n",
        "    print('Invalid Pretrained Model Selection')\n",
        "\n",
        "\n",
        "\n",
        "# Model compiling\n",
        "\n",
        "print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "numEpochs = 20\n",
        "\n",
        "print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compiling Pretrained resnet50 Model\n",
            "Training Pretrained resnet50 Model\n",
            "Batch Size: 4\t Epochs: 20\t\n",
            "\n",
            "Train on 1606 samples, validate on 402 samples\n",
            "Epoch 1/20\n",
            "1606/1606 [==============================] - 79s 49ms/step - loss: 1.2926 - acc: 0.7503 - val_loss: 1.0799 - val_acc: 0.8184\n",
            "Epoch 2/20\n",
            "1606/1606 [==============================] - 67s 42ms/step - loss: 0.8915 - acc: 0.8194 - val_loss: 2.7507 - val_acc: 0.7662\n",
            "Epoch 3/20\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.8334 - acc: 0.8568 - val_loss: 0.9595 - val_acc: 0.8507\n",
            "Epoch 4/20\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.8654 - acc: 0.8493 - val_loss: 0.4714 - val_acc: 0.8458\n",
            "Epoch 5/20\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.8217 - acc: 0.8630 - val_loss: 0.8609 - val_acc: 0.8632\n",
            "Epoch 6/20\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.9291 - acc: 0.8506 - val_loss: 1.4491 - val_acc: 0.8259\n",
            "Epoch 7/20\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.9524 - acc: 0.8574 - val_loss: 0.5950 - val_acc: 0.8955\n",
            "Epoch 8/20\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.8872 - acc: 0.8848 - val_loss: 0.1715 - val_acc: 0.9403\n",
            "Epoch 9/20\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.7733 - acc: 0.8836 - val_loss: 0.2079 - val_acc: 0.9328\n",
            "Epoch 10/20\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.8705 - acc: 0.8730 - val_loss: 0.4922 - val_acc: 0.8980\n",
            "Epoch 11/20\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.9222 - acc: 0.8593 - val_loss: 0.2841 - val_acc: 0.8955\n",
            "Epoch 12/20\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.8841 - acc: 0.8829 - val_loss: 0.3150 - val_acc: 0.9204\n",
            "Epoch 13/20\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.8165 - acc: 0.8804 - val_loss: 0.3345 - val_acc: 0.9303\n",
            "Epoch 14/20\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.6387 - acc: 0.9153 - val_loss: 0.1537 - val_acc: 0.9453\n",
            "Epoch 15/20\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.7163 - acc: 0.9147 - val_loss: 0.1377 - val_acc: 0.9652\n",
            "Epoch 16/20\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.6734 - acc: 0.9054 - val_loss: 0.1838 - val_acc: 0.9428\n",
            "Epoch 17/20\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.5256 - acc: 0.9191 - val_loss: 0.1535 - val_acc: 0.9453\n",
            "Epoch 18/20\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.5406 - acc: 0.9228 - val_loss: 0.1528 - val_acc: 0.9453\n",
            "Epoch 19/20\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.7089 - acc: 0.9184 - val_loss: 0.2236 - val_acc: 0.9080\n",
            "Epoch 20/20\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.7130 - acc: 0.9203 - val_loss: 0.2379 - val_acc: 0.9602\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x200c156bd30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "jKgFIa4gkgkk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "5b97507b-963b-4694-8f65-6add567abc5c"
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train,\n",
        "          batch_size=sizeBatch, epochs=4, verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1606 samples, validate on 402 samples\n",
            "Epoch 1/4\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.8564 - acc: 0.9209 - val_loss: 3.8823 - val_acc: 0.7463\n",
            "Epoch 2/4\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.8584 - acc: 0.9147 - val_loss: 0.4860 - val_acc: 0.9552\n",
            "Epoch 3/4\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.8656 - acc: 0.9041 - val_loss: 0.2843 - val_acc: 0.9055\n",
            "Epoch 4/4\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.7965 - acc: 0.9153 - val_loss: 0.1596 - val_acc: 0.9527\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1feab3c6e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "wIlomC_jUUhL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "fb3d15e7-70ec-4357-8ef0-460acbf652de"
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train,\n",
        "          batch_size=sizeBatch, epochs=4, verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1606 samples, validate on 402 samples\n",
            "Epoch 1/4\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.6647 - acc: 0.9253 - val_loss: 0.1327 - val_acc: 0.9527\n",
            "Epoch 2/4\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.6067 - acc: 0.9309 - val_loss: 0.1215 - val_acc: 0.9627\n",
            "Epoch 3/4\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 1.2746 - acc: 0.8923 - val_loss: 5.3098 - val_acc: 0.6642\n",
            "Epoch 4/4\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 1.5101 - acc: 0.8773 - val_loss: 0.1380 - val_acc: 0.9751\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1feab3c60b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "ARcwG8qbueCc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "a942b6ff-396b-4300-aebe-da6f000ab40d"
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train,\n",
        "          batch_size=sizeBatch, epochs=8, verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1606 samples, validate on 402 samples\n",
            "Epoch 1/8\n",
            "1606/1606 [==============================] - 67s 42ms/step - loss: 0.5885 - acc: 0.9408 - val_loss: 0.0946 - val_acc: 0.9751\n",
            "Epoch 2/8\n",
            "1606/1606 [==============================] - 67s 42ms/step - loss: 0.7264 - acc: 0.9265 - val_loss: 0.1860 - val_acc: 0.9478\n",
            "Epoch 3/8\n",
            "1606/1606 [==============================] - 67s 42ms/step - loss: 0.7519 - acc: 0.9184 - val_loss: 0.2092 - val_acc: 0.9527\n",
            "Epoch 4/8\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.6394 - acc: 0.9340 - val_loss: 0.2020 - val_acc: 0.9577\n",
            "Epoch 5/8\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.5387 - acc: 0.9290 - val_loss: 0.0899 - val_acc: 0.9776\n",
            "Epoch 6/8\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.5214 - acc: 0.9433 - val_loss: 0.0975 - val_acc: 0.9751\n",
            "Epoch 7/8\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.4381 - acc: 0.9514 - val_loss: 0.1269 - val_acc: 0.9677\n",
            "Epoch 8/8\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.5753 - acc: 0.9433 - val_loss: 0.1765 - val_acc: 0.9726\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1fdffe6acc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "1Rm8ALcuwmJ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "d36b829e-1b3d-44d3-c46c-3b76f31dce51"
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train,\n",
        "          batch_size=sizeBatch, epochs=8, verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1606 samples, validate on 402 samples\n",
            "Epoch 1/8\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.5947 - acc: 0.9433 - val_loss: 0.1455 - val_acc: 0.9677\n",
            "Epoch 2/8\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.5413 - acc: 0.9483 - val_loss: 0.2388 - val_acc: 0.9403\n",
            "Epoch 3/8\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.6446 - acc: 0.9402 - val_loss: 0.1001 - val_acc: 0.9801\n",
            "Epoch 4/8\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.4397 - acc: 0.9620 - val_loss: 0.0953 - val_acc: 0.9801\n",
            "Epoch 5/8\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.4540 - acc: 0.9633 - val_loss: 0.1259 - val_acc: 0.9751\n",
            "Epoch 6/8\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.4329 - acc: 0.9633 - val_loss: 0.1113 - val_acc: 0.9776\n",
            "Epoch 7/8\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.5036 - acc: 0.9595 - val_loss: 0.1323 - val_acc: 0.9751\n",
            "Epoch 8/8\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.6328 - acc: 0.9340 - val_loss: 0.1152 - val_acc: 0.9677\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x200b95af710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "KCrYHgV4oXj7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "77664ac4-a856-408e-a8a4-4b3e4cd101f0"
      },
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train,\n",
        "          batch_size=sizeBatch, epochs=8, verbose=1,\n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1606 samples, validate on 402 samples\n",
            "Epoch 1/8\n",
            "1606/1606 [==============================] - 67s 42ms/step - loss: 0.4677 - acc: 0.9614 - val_loss: 0.1436 - val_acc: 0.9677\n",
            "Epoch 2/8\n",
            "1606/1606 [==============================] - 67s 42ms/step - loss: 0.5773 - acc: 0.9558 - val_loss: 0.1962 - val_acc: 0.9502\n",
            "Epoch 3/8\n",
            "1606/1606 [==============================] - 67s 42ms/step - loss: 0.5281 - acc: 0.9583 - val_loss: 0.1457 - val_acc: 0.9776\n",
            "Epoch 4/8\n",
            "1606/1606 [==============================] - 67s 42ms/step - loss: 0.3370 - acc: 0.9726 - val_loss: 0.1225 - val_acc: 0.9751\n",
            "Epoch 5/8\n",
            "1606/1606 [==============================] - 67s 42ms/step - loss: 0.5053 - acc: 0.9639 - val_loss: 0.1026 - val_acc: 0.9801\n",
            "Epoch 6/8\n",
            "1606/1606 [==============================] - 67s 42ms/step - loss: 0.5060 - acc: 0.9658 - val_loss: 0.1262 - val_acc: 0.9701\n",
            "Epoch 7/8\n",
            "1606/1606 [==============================] - 68s 42ms/step - loss: 0.4516 - acc: 0.9670 - val_loss: 0.1104 - val_acc: 0.9751\n",
            "Epoch 8/8\n",
            "1606/1606 [==============================] - 67s 42ms/step - loss: 0.5171 - acc: 0.9595 - val_loss: 0.1380 - val_acc: 0.9677\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x200b95af550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "agqqH8sf3CiV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# K.clear_session()\n",
        "\n",
        "# input_tensor = Input(shape=(imgSize, imgSize, 3))\n",
        "\n",
        "# # Building sequential model with name 'model'\n",
        "# model = Sequential()\n",
        "\n",
        "# modelWoTop = ResNet50(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
        "# model.add(modelWoTop)\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(2, activation=lastActivation))\n",
        "\n",
        "# # Model compiling\n",
        "\n",
        "# print('Compiling Pretrained {} Model'.format(model.layers[0].name))\n",
        "\n",
        "# model.compile(loss='binary_crossentropy',\n",
        "#               optimizer='adam',\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "# numEpochs = 1\n",
        "\n",
        "# print('Training Pretrained {} Model'.format(model.layers[0].name))\n",
        "# print('Batch Size: {}\\t Epochs: {}\\t\\n'.format(sizeBatch, numEpochs))\n",
        "\n",
        "# model.fit(X_train, Y_train,\n",
        "#           batch_size=sizeBatch, epochs=numEpochs, verbose=1,\n",
        "#           validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qexmaPZVz04q",
        "colab_type": "code",
        "outputId": "f6693cf9-f7be-45d9-c325-de89c2d636a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.plot(Y_test[:, 1], 'r')\n",
        "\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.plot(Y_pred[:, 1], 'b')\n",
        "\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.plot(Y_test[:, 1] - Y_pred[:, 1], 'g')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "IPTFOJh3DTgq",
        "colab_type": "code",
        "outputId": "1a984e39-d747-42d9-cf4d-e5dec2836c61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "now = datetime.datetime.now()\n",
        "\n",
        "# modelSaved = '{}-{}_{}_{}.h5'.format(folderNormal, folderFault, pretrainedModel, now.strftime('%m-%d-%H:%M:%S'))\n",
        "\n",
        "modelSaved = '(PN){}-{}_{}_{}.h5'.format('N', 'F', pretrainedModel, now.strftime('%m-%d-%H-%M-%S'))\n",
        "meanSaved = 'mean_{}.npy'.format(now.strftime('%m-%d-%H-%M-%S'))\n",
        "stdSaved = 'std_{}.npy'.format(now.strftime('%m-%d-%H-%M-%S'))\n",
        "\n",
        "inputStr = input('''Save Model as '{}'? (y/n)\\n'''.format(modelSaved))\n",
        "\n",
        "if (inputStr == 'y' or inputStr == 'Y'):  \n",
        "    model.save(modelPath + '/{}'.format(modelSaved))\n",
        "    np.save(modelPath + '/{}'.format(meanSaved), trainMean)\n",
        "    np.save(modelPath + '/{}'.format(stdSaved), trainStd)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Save Model as '(PN)N-F_ResNet50_11-20-10-12-41.h5'? (y/n)\n",
            "n\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}